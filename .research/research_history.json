{
  "research_topic": "Test-Time Adaptation (TTA) method combining update gating and drift suppression for improved robustness on ImageNet-C / CIFAR-C.",
  "queries": [
    "test-time adaptation",
    "update gating TTA",
    "drift suppression adaptation",
    "ImageNet-C robustness",
    "CIFAR-C corruption resilience"
  ],
  "research_study_list": [
    {
      "title": "Test-Time Training with Self-Supervision for Generalization under Distribution Shifts",
      "abstract": "In this paper, we propose Test-Time Training, a general approach for\nimproving the performance of predictive models when training and test data come\nfrom different distributions. We turn a single unlabeled test sample into a\nself-supervised learning problem, on which we update the model parameters\nbefore making a prediction. This also extends naturally to data in an online\nstream. Our simple approach leads to improvements on diverse image\nclassification benchmarks aimed at evaluating robustness to distribution\nshifts.",
      "full_text": "Test-Time Training with Self-Supervision for Generalization under Distribution Shifts Yu Sun1 Xiaolong Wang1 2 Zhuang Liu1 John Miller1 Alexei A. Efros1 Moritz Hardt1 Abstract In this paper, we propose Test-Time Training, a general approach for improving the performance of predictive models when training and test data come from different distributions. We turn a sin- gle unlabeled test sample into a self-supervised learning problem, on which we update the model parameters before making a prediction. This also extends naturally to data in an online stream. Our simple approach leads to improvements on di- verse image classiﬁcation benchmarks aimed at evaluating robustness to distribution shifts. 1. Introduction Supervised learning remains notoriously weak at generaliza- tion under distribution shifts. Unless training and test data are drawn from the same distribution, even seemingly minor differences turn out to defeat state-of-the-art models (Recht et al., 2018). Adversarial robustness and domain adapta- tion are but a few existing paradigms that try to anticipate differences between the training and test distribution with either topological structure or data from the test distribution available during training. We explore a new take on gener- alization that does not anticipate the distribution shifts, but instead learns from them at test time. We start from a simple observation. The unlabeled test sample xpresented at test time gives us a hint about the distribution from which it was drawn. We propose to take advantage of this hint on the test distribution by allowing the model parameters θto depend on the test sample x, but not its unknown label y. The concept of a variable decision boundary θ(x) is powerful in theory since it breaks away from the limitation of ﬁxed model capacity (see additional discussion in Section A1), but the design of a feedback mechanism from xto θ(x) raises new challenges in practice that we only begin to address here. 1University of California, Berkeley 2University of California, San Diego. Correspondence to: Yu Sun <yusun@berkeley.edu>. Proceedings of the 37 th International Conference on Machine Learning, Vienna, Austria, PMLR 119, 2020. Copyright 2020 by the author(s). Our proposed test-time training method creates a self- supervised learning problem based on this single test sample x, updating θat test time before making a prediction. Self- supervised learning uses an auxiliary task that automatically creates labels from unlabeled inputs. In our experiments, we use the task of rotating each input image by a multiple of 90 degrees and predicting its angle (Gidaris et al., 2018). This approach can also be easily modiﬁed to work outside the standard supervised learning setting. If several test samples arrive in a batch, we can use the entire batch for test-time training. If samples arrive in an online stream, we obtain further improvements by keeping the state of the parameters. After all, prediction is rarely a single event. The online version can be the natural mode of deployment under the additional assumption that test samples are produced by the same or smoothly changing distribution shifts. We experimentally validate our method in the context of object recognition on several standard benchmarks. These include images with diverse types of corruption at various levels (Hendrycks & Dietterich, 2019), video frames of moving objects (Shankar et al., 2019), and a new test set of unknown shifts collected by (Recht et al., 2018). Our algorithm makes substantial improvements under distribu- tion shifts, while maintaining the same performance on the original distribution. In our experiments, we compare with a strong baseline (labeled joint training) that uses both supervised and self- supervised learning at training-time, but keeps the model ﬁxed at test time. Recent work shows that training-time self- supervision improves robustness (Hendrycks et al., 2019a); our joint training baseline corresponds to an improved imple- mentation of this work. A comprehensive review of related work follows in Section 5. We complement the empirical results with theoretical inves- tigations in Section 4, and establish an intuitive sufﬁcient condition on a convex model of when Test-Time Training helps; this condition, roughly speaking, is to have correlated gradients between the loss functions of the two tasks. Project website: https://test-time-training.github.io/. arXiv:1909.13231v3  [cs.LG]  1 Jul 2020Test-Time Training with Self-Supervision for Generalization under Distribution Shifts 2. Method This section describes the algorithmic details of our method. To set up notation, consider a standard K-layer neural net- work with parameters θk for layer k. The stacked parameter vector θ = ( θ1,...,θ K) speciﬁes the entire model for a classiﬁcation task with loss function lm(x,y; θ) on the test sample (x,y). We call this the main task, as indicated by the subscript of the loss function. We assume to have training data (x1,y1),..., (xn,yn) drawn i.i.d. from a distribution P. Standard empirical risk minimization solves the optimization problem: min θ 1 n n∑ i=1 lm(xi,yi; θ). (1) Our method requires a self-supervised auxiliary task with loss function ls(x). In this paper, we choose the rotation prediction task (Gidaris et al., 2018), which has been demon- strated to be simple and effective at feature learning for convolutional neural networks. The task simply rotates x in the image plane by one of 0, 90, 180 and 270 degrees and have the model predict the angle of rotation as a four- way classiﬁcation problem. Other self-supervised tasks in Section 5 might also be used for our method. The auxiliary task shares some of the model parameters θe = ( θ1,...,θ κ) up to a certain κ ∈ {1,...,K }. We designate those κlayers as a shared feature extractor. The auxiliary task uses its own task-speciﬁc parameters θs = (θ′ κ+1,...,θ ′ K). We call the unshared parameters θs the self-supervised task branch, and θm = (θκ+1,...,θ K) the main task branch . Pictorially, the joint architecture is a Y-structure with a shared bottom and two branches. For our experiments, the self-supervised task branch has the same architecture as the main branch, except for the output dimensionality of the last layer due to the different number of classes in the two tasks. Training is done in the fashion of multi-task learning (Caru- ana, 1997); the model is trained on both tasks on the same data drawn fromP. Losses for both tasks are added together, and gradients are taken for the collection of all parameters. The joint training problem is therefore min θe,θm,θs 1 n n∑ i=1 lm(xi,yi; θm,θe) + ls(xi; θs,θe). (2) Now we describe the standard version of Test-Time Training on a single test sample x. Simply put, Test-Time Training ﬁne-tunes the shared feature extractor θe by minimizing the auxiliary task loss on x. This can be formulated as min θe ls(x; θs,θe). (3) Denote θ∗ e the (approximate) minimizer of Equation 3. The model then makes a prediction using the updated parameters θ(x) = (θ∗ e,θm). Empirically, the difference is negligible between minimizing Equation 3 over θe versus over both θe and θs. Theoretically, the difference exists only when optimization is done with more than one gradient step. Test-Time Training naturally beneﬁts from standard data augmentation techniques. On each test sample x, we per- form the exact same set of random transformations as for data augmentation during training, to form a batch only con- taining these augmented copies of xfor Test-Time Training. Online Test-Time Training. In the standard version of our method, the optimization problem in Equation 3 is al- ways initialized with parameters θ= (θe,θs) obtained by minimizing Equation 2. After making a prediction on x, θ∗ e is discarded. Outside of the standard supervised learning setting, when the test samples arrive online sequentially, the online version solves the same optimization problem as in Equation 3 to update the shared feature extractor θe. How- ever, on test sample xt, θis instead initialized with θ(xt−1) updated on the previous sample xt−1. This allows θ(xt) to take advantage of the distributional information available in x1,...,x t−1 as well as xt. 3. Empirical Results We experiment with both versions of our method (standard and online) on three kinds of benchmarks for distribution shifts, presented here in the order of visually low to high- level. Our code is available at the project website. Network details. Our architecture and hyper-parameters are consistent across all experiments. We use ResNets (He et al., 2016b), which are constructed differently for CIFAR-10 (Krizhevsky & Hinton, 2009) (26-layer) and Ima- geNet (Russakovsky et al., 2015) (18-layer). The CIFAR-10 dataset contains 50K images for training, and 10K images for testing. The ImageNet contains 1.2M images for train- ing and the 50K validation images are used as the test set. ResNets on CIFAR-10 have three groups, each containing convolutional layers with the same number of channels and size of feature maps; our splitting point is the end of the second group. ResNets on ImageNet have four groups; our splitting point is the end of the third group. We use Group Normalization (GN) instead of Batch Nor- malization (BN) in our architecture, since BN has been shown to be ineffective when training with small batches, for which the estimated batch statistics are not accurate (Ioffe & Szegedy, 2015). This technicality hurts Test-Time Training since each batch only contains (augmented) copies of a single image. Different from BN, GN is not dependent on batch size and achieves similar results on our baselines.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts originalgauss shot impulsedefocus glass motion zoom snow frost fog bright contrastelasticpixelate jpeg 0 10 20 30 40 50Error (%) Object recognition task only Joint training (Hendrycks et al. 2019) TTT TTT-Online Figure 1.Test error (%) on CIFAR-10-C with level 5 corruptions.We compare our approaches, Test-Time Training (TTT) and its online version (TTT-Online), with two baselines: object recognition without self-supervision, and joint training with self-supervision but keeping the model ﬁxed at test time. TTT improves over the baselines and TTT-Online improves even further. We report results with BN in Section A4 of the appendix for completeness. We directly compare our architecture to that of Hendrycks et al. (2018) in subsection A4.5. Optimization details. For joint training (Equation 2), we use stochastic gradient descent with standard hyper- parameters as (Huang et al., 2016; He et al., 2016a). For Test-Time Training (Equation 3), we use stochastic gradient descent with the learning rate set to that of the last epoch during training, which is 0.001 in all our experiments. We set weight decay and momentum to zero during Test-Time Training, inspired by practice in (He et al., 2018; Liu et al., 2018). For the standard version of Test-Time Training, we take ten gradient steps, using batches independently gener- ated by the same image. For online version of Test-Time Training, we take only one gradient step given each new im- age. We use random crop and random horizontal ﬂip for data augmentation. See Section A2 of the appendix for computa- tional aspects of our method. In all the tables and ﬁgures, object recognition task onlyrefers to the plain ResNet model (using GN, unless otherwise speciﬁed); joint training refers to the model jointly trained on both the main task and the self-supervised task, ﬁxed at test time; this has been pro- posed as the method in Hendrycks et al. (2019a); Test-Time Training (TTT) refers to the standard version described sec- tion 2; and online Test-Time Training (TTT-Online)refers to the online version that does not discardθ(xt) for xt arriving sequentially from the same distribution. Performance for TTT-Online is calculated as the average over the entire test set; we always shufﬂe the test set before TTT-Online to avoid ordering artifacts. 3.1. Object Recognition on Corrupted Images Hendrycks & Dietterich (2019) propose to benchmark ro- bustness of object recognition with 15 types of corruptions from four broad categories: noise, blur, weather and digital. Each corruption type comes in ﬁve levels of severity, with level 5 the most severe (details and sample images in the ap- pendix). The corruptions are simulated to mimic real-world corruptions as much as possible on copies of the test set for both CIFAR-10 and ImageNet. The new test sets are named as CIFAR-10-C and ImageNet-C, respectively. In the pro- posed benchmark, training should be done on the original training set, and the diversity of corruption types should make it difﬁcult for any methods to work well across the board if it relies too much on corruption speciﬁc knowledge. For online Test-Time Training, we take the entire test set as a stream of incoming images, and update and test on each image in an online manner as it arrives. CIFAR-10-C. Our results on the level 5 corruptions (most severe) are shown in Figure 1. The results on levels 1-4 are shown in Section A4 in appendix. Across all ﬁve levels and 15 corruption types, both standard and online versions of Test-Time Training improve over the object recognition task only baseline by a large margin. The standard version always improves over joint training, and the online version often improves signiﬁcantly (>10%) over joint training and never hurts by more than 0.2%. Speciﬁcally, TTT-Online contributes >24% on the three noise types and 38% on pix- elation. For a learning problem with the seemingly unstable setup that abuses a single image, this kind of consistency is rather surprising. The baseline ResNet-26 with object recognition task only has error 8.9% on the original test set of CIFAR-10. The joint training baseline actually improves performance on the original to 8.1%. More surprisingly, unlike many other methods that trade off original performance for robustness, Test-Time Training further improves on the original test set by 0.2% consistently over multiple independent trials. This suggests that our method does not choose between speciﬁcity and generality.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts originalgauss shot impulsedefocus glass motion zoom snow frost fog bright contrastelasticpixelate jpeg 0 20 40 60Accuracy (%) Object recognition task only Joint training (Hendrycks et al. 2019) TTT TTT-Online 0 20000 40000 Number of samples 60 62 64 66 68 70 72 74 76Accuracy (%) Original Sliding window average 0 20000 40000 Number of samples 12 15 18 21 24 27 30 33Accuracy (%) Gaussian Noise Sliding window average 0 20000 40000 Number of samples 16 18 20 22 24 26 28 30 32Accuracy (%) Defocus Blur Sliding window average 0 20000 40000 Number of samples 28 30 32 34 36 38Accuracy (%) Zoom Blur Sliding window average 0 20000 40000 Number of samples 33 36 39 42 45 48 51 54Accuracy (%) Fog Sliding window average 0 20000 40000 Number of samples 30 33 36 39 42 45 48 51Accuracy (%) Elastic Transform Sliding window average Figure 2.Test accuracy (%) on ImageNet-C with level 5 corruptions.Upper panel: Our approaches, TTT and TTT-Online, show signiﬁcant improvements in all corruption types over the two baselines. Lower panel: We show the accuracy of TTT-Online as the average over a sliding window of 100 samples; TTT-Online generalizes better as more samples are evaluated (x-axis), without hurting on the original distribution. We use accuracy instead of error here because the baseline performance is very low for most corruptions. Separate from our method, it is interesting to note that joint training consistently improves over the single-task baseline, as discovered by Hendrycks et al. (2019a). Hendrycks & Dietterich (2019) have also experimented with various other training methods on this benchmark, and point to Adversar- ial Logit Pairing (ALP) (Kannan et al., 2018) as the most effective approach. Results of this additional baseline on all levels of CIFAR-10-C are shown in the appendix, along with its implementation details. While surprisingly robust under some of the most severe corruptions (especially the three noise types), ALP incurs a much larger error (by a factor of two) on the original distribution and some corruptions (e.g. all levels of contrast and fog), and hurts performance signiﬁcantly when the corruptions are not as severe (espe- cially on levels 1-3); this kind of tradeoff is to be expected for methods based on adversarial training. ImageNet-C. Our results on the level 5 corruptions (most severe) are shown in Figure 2. We use accuracy instead of error for this dataset because the baseline performance is very low for most corruptions. The general trend is roughly the same as on CIFAR-10-C. The standard version of TTT always improves over the baseline and joint training, while the online version only hurts on the original by 0.1% over the baseline, but signiﬁcantly improves (by a factor of more than three) on many of the corruption types. In the lower panel of Figure 2, we visualize how the accu- racy (averaged over a sliding window) of the online version changes as more images are tested. Due to space constraints, we show this plot on the original test set, as well as every third corruption type, following the same order as in the original paper. On the original test set, there is no visible trend in performance change after updating on the 50,000 samples. With corruptions, accuracy has already risen sig- niﬁcantly after 10,000 samples, but is still rising towards the end of the 50,000 samples, indicating room for additional improvements if more samples were available. Without seeing a single label, TTT-Online behaves as if we were training on the test set from the appearance of the plots.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts orig gauss shot impul defoc glass motn zoom snow frost fog brit contr elast pixel jpeg TTT-Online 8.2 25.8 22.6 30.6 14.6 34.4 18.3 17.1 20.0 18.0 16.9 11.2 15.6 21.6 18.1 21.2 UDA-SS 9.0 28.2 26.5 20.8 15.6 43.7 24.5 23.8 25.0 24.9 17.2 12.7 11.6 22.1 20.3 22.6 Table 1.Test error (%) on CIFAR-10-C with level 5 corruption.Comparison between online Test-Time Training (TTT-Online) and unsupervised domain adaptation by self-supervision (UDA-SS) (Sun et al., 2019) with access to the entire (unlabeled) test set during training. We highlight the lower error in bold. We have abbreviated the names of the corruptions, in order: original test set, Gaussian noise, shot noise, impulse noise, defocus blur, glass blue, motion blur, zoom blur, snow, frost, fog, brightness, contrast, elastic transformation, pixelation, and JPEG compression. The reported numbers for TTT-Online are the same as in Figure 1. See complete table in Table A2. 0 2000 4000 6000 8000 Number of samples 12 16 20 24 28 32 36 40 44 48Error (%) Gaussian Noise Joint training TTT TTT-Online UDA-SS 0 2000 4000 6000 8000 Number of samples 9 12 15 18 21 24 27 30 33 36Error (%) Shot Noise Joint training TTT TTT-Online UDA-SS 0 2000 4000 6000 8000 Number of samples 15 20 25 30 35 40 45 50Error (%) Impulse Noise Joint training TTT TTT-Online UDA-SS Figure 3.Test error (%) on CIFAR-10-C, for the three noise types, with gradually changing distribution.The distribution shifts are created by increasing the standard deviation of each noise type from small to large, the further we go on the x-axis. As the samples get noisier, all methods suffer greater errors the more we evaluate into the test set, but online Test-Time Training (TTT-Online) achieves gentler slopes than joint training. For the ﬁrst two noise types, TTT-Online also achieves better results over unsupervised domain adaptation by self-supervision (UDA-SS) (Sun et al., 2019). Comparison with unsupervised domain adaptation. Table 1 empirically compares online Test-Time Training (TTT-Online) with unsupervised domain adaptation through self-supervision (UDA-SS) (Sun et al., 2019), which is sim- ilar to our method in spirit but is designed for the setting of unsupervised domain adaptation (Section 5 provides a sur- vey of other related work in this setting). Given labeled data from the training distribution and unlabeled data from the test distribution, UDA-SS hopes to ﬁnd an invariant repre- sentation that extracts useful features for both distributions by learning to perform a self-supervised task, speciﬁcally rotation prediction, simultaneously on data from both. It then learns a labeling function on top of the invariant rep- resentation using the labeled data. In our experiments, the unlabeled data given to UDA-SS is the entire test set itself without the labels. Because TTT-Online can only learn from the unlabeled test samples that have already been evaluated on, it is given less information than UDA-SS at all times. In this sense, UDA- SS should be regarded as an oracle rather than a baseline. Surprisingly, TTT-Online outperforms UDA-SS on 13 out of the 15 corruptions as well as the original distribution. Our explanation is that UDA-SS has to ﬁnd an invariant representation for both distributions, while TTT-Online only adapts the representation to be good for the current test distribution. That is, TTT-Online has the ﬂexibility to forget the training distribution representation, which is no longer relevant. This suggests that in our setting, forgetting is not harmful and perhaps should even be taken advantage of. Gradually changing distribution shifts.In our previous experiments, we have been evaluating the online version under the assumption that the test inputs xt for t= 1...nare all sampled from the same test distribution Q, which can be different from the training distribution P. This assumption is indeed satisﬁed for i.i.d. samples from a shufﬂed test set. But here we show that this assumption can in fact be relaxed to allow xt ∼Qt, where Qt is close to Qt+1 (in the sense of distributional distance). We call this the assumption of gradually changing distribution shifts. We perform experiments by simulating such distribution shifts on the three noise types of CIFAR-10-C. For each noise type, xt is corrupted with standard deviation σt, and σ1,...,σ n interpolate between the standard deviation of level 1 and level 5. So xt is more severely corrupted as we evaluate further into the test set and t grows larger. As shown in Figure 3, TTT-Online still improves upon joint training (and our standard version) with this relaxed assumption, and even upon UDA-SS for the ﬁrst two noise types.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts Accuracy (%) Airplane Bird Car Dog Cat Horse Ship Average Object recognition task only 67.9 35.8 42.6 14.7 52.0 42.0 66.7 41.4 Joint training (Hendrycks et al., 2019a) 70.2 36.7 42.6 15.5 52.0 44.0 66.7 42.4 TTT (standard version) 70.2 39.2 42.6 21.6 54.7 46.0 77.8 45.2 TTT-Online 70.2 39.2 42.6 22.4 54.7 46.0 77.8 45.4 Table 2.Class-wise and average classiﬁcation accuracy (%) on CIFAR classes in VID-Robust, adapted from (Shankar et al., 2019). Test-Time Training (TTT) and online Test-Time Training (TTT-Online) improve over the two baselines on average, and by a large margin on “ship” and “dog” classes where the rotation task is more meaningful than in classes like “airplane” (sample images in Figure A7). 3.2. Object Recognition on Video Frames The Robust ImageNet Video Classiﬁcation (VID-Robust) dataset was developed by Shankar et al. (2019) from the Ima- geNet Video detection dataset (Russakovsky et al., 2015), to demonstrate how deep models for object recognition trained on ImageNet (still images) fail to adapt well to video frames. The VID-Robust dataset contains 1109 sets of video frames in 30 classes; each set is a short video clip of frames that are similar to an anchor frame. Our results are reported on the anchor frames. To map the 1000 ImageNet classes to the 30 VID-Robust classes, we use the max-conversion function in Shankar et al. (2019). Without any modiﬁcations for videos, we apply our method to VID-Robust on top of the same ImageNet model as in the previous subsection. Our classiﬁcation accuracy is reported in Table 3. In addition, we take the seven classes in VID-Robust that overlap with CIFAR-10, and re-scale those video frames to the size of CIFAR-10 images, as a new test set for the model trained on CIFAR-10 in the previous subsection. Again, we apply our method to this dataset without any modiﬁcations. Our results are shown in Table 2, with a breakdown for each class. Noticing that Test-Time Training does not improve on the airplane class, we inspect some airplane samples (Figure A7), and observe black margins on two sides of most images, which provide a trivial hint for rotation prediction. In addition, given an image of airplanes in the sky, it is often impossible even for humans to tell if it is rotated. This shows that our method requires the self-supervised task to be both well deﬁned and non-trivial. 3.3. CIFAR-10.1: Unknown Distribution Shifts CIFAR-10.1 (Recht et al., 2018) is a new test set of size 2000 modeled after CIFAR-10, with the exact same classes and image dimensionality, following the dataset creation process documented by the original CIFAR-10 paper as closely as possible. The purpose is to investigate the distribution shifts present between the two test sets, and the effect on object recognition. All models tested by the authors suffer a large performance drop on CIFAR-10.1 comparing to CIFAR-10, even though there is no human noticeable difference, and Method Accuracy (%) Object recognition task only 62.7 Joint training (Hendrycks et al., 2019a) 63.5 TTT (standard version) 63.8 TTT-Online 64.3 Table 3.Test accuracy (%) on VID-Robust dataset (Shankar et al., 2019). TTT and TTT-Online improve over the baselines. Method Error (%) Object recognition task only 17.4 Joint training (Hendrycks et al., 2019a) 16.7 TTT (standard version) 15.9 Table 4.Test error (%) on CIFAR-10.1 (Recht et al., 2018). TTT is the ﬁrst method to improve the performance of an existing model on this new test set. both have the same human accuracy. This demonstrates how insidious and ubiquitous distribution shifts are, even when researchers strive to minimize them. The distribution shifts from CIFAR-10 to CIFAR-10.1 pose an extremely difﬁcult problem, and no prior work has been able to improve the performance of an existing model on this new test set, probably because: 1) researchers cannot even identify the distribution shifts, let alone describe them mathematically; 2) the samples in CIFAR-10.1 are only revealed at test time; and even if they were revealed during training, the distribution shifts are too subtle, and the sample size is too small, for domain adaptation (Recht et al., 2018). On the original CIFAR-10 test set, the baseline with only object recognition has error 8.9%, and with joint training has 8.1%; comparing to the ﬁrst two rows of Table 4, both suffer the typical performance drop (by a factor of two). TTT yields an improvement of 0.8% (relative improvement of 4.8%) over joint training. We recognize that this improve- ment is small relative to the performance drop, but see it as an encouraging ﬁrst step for this very difﬁcult problem.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts 0 10 20 30 40 50 60 Gradient inner product 0 1 2 3 4 5Improvement (%) Level 5 Level 4 Level 3 Level 2 Level 1 0 10 20 30 40 50 60 Gradient inner product 0 5 10 15 20 25 30 35Improvement (%) Level 5 Level 4 Level 3 Level 2 Level 1 Figure 4.Scatter plot of the inner product between the gradients (on the shared feature extractor θe) of the main task lm and the self- supervised task le, and the improvement in test error (%) from Test-Time Training, for the standard (left) and online (right) version. Each point is the average over a test set, and each scatter plot has 75 test sets, from all 15 types of corruptions over ﬁve levels as described in subsection 3.1. The blue lines and bands are the best linear ﬁts and the 99% conﬁdence intervals. The linear correlation coefﬁcients are 0.93 and 0.89 respectively, indicating strong positive correlation between the two quantities, as suggested by Theorem 1. 4. Theoretical Results This section contains our preliminary study of when and why Test-Time Training is expected to work. For convex models, we prove that positive gradient correlation between the loss functions leads to better performance on the main task after Test-Time Training. Equipped with this insight, we then empirically demonstrate that gradient correlation governs the success of Test-Time Training on the deep learning model discussed in Section 3. Before stating our main theoretical result, we ﬁrst illustrate the general intuition with a toy model. Consider a regression problem where x∈Rd denotes the input, y1 ∈R denotes the label, and the objective is the square loss (ˆy−y1)2/2 for a prediction ˆy. Consider a two layer linear network parametrized by A∈Rh×d and v ∈Rh (where hstands for the hidden dimension). The prediction according to this model is ˆy= v⊤Ax, and the main task loss is lm(x,y1; A,v) = 1 2 ( y1 −v⊤Ax )2 . (4) In addition, consider a self-supervised regression task that also uses the square loss and automatically generates a label ys for x. Let the self-supervised head be parametrized by w∈Rh. Then the self-supervised task loss is ls(x,y2; A,w) = 1 2 ( y2 −w⊤Ax )2 . (5) Now we apply Test-Time Training to update the shared feature extractor Aby one step of gradient descent on ls, which we can compute with y2 known. This gives us A′←A−η ( y2 −w⊤Ax )( −wx⊤) , (6) where A′is the updated matrix and ηis the learning rate. If we set η= η∗where η∗= y1 −v⊤Ax (y2 −w⊤Ax) v⊤wx⊤x, (7) then with some simple algebra, it is easy to see that the main task loss lm(x,y1; A′,v) = 0. Concretely, Test-Time Training drives the main task loss down to zero with a single gradient step for a carefully chosen learning rate. In prac- tice, this learning rate is unknown since it depends on the unknown y1. However, since our model is convex, as long as η∗is positive, it sufﬁces to set η to be a small positive constant (see details in the appendix). If x̸= 0, one sufﬁ- cient condition for η∗to be positive (when neither loss is zero) is to have sign ( y1 −v⊤Ax ) = sign ( y2 −w⊤Ax ) (8) and v⊤w>0 . (9) For our toy model, both parts of the condition above have an intuition interpretation. The ﬁrst part says that the mistakes should be correlated, in the sense that predictions from both tasks are mistaken in the same direction. The second part, v⊤w>0, says that the decision boundaries on the feature space should be correlated. In fact, these two parts hold iff. ⟨∇lm(A),∇ls(A)⟩>0 (see a simple proof of this fact in the appendix). To summarize, if the gradients have positive correlation, Test-Time Training is guaranteed to reduce the main task loss. Our main theoretical result extends this to general smooth and convex loss functions.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts Theorem 1. Let lm(x,y; θ) denote the main task loss on test instance x,y with parameters θ, and ls(x; θ) the self- supervised task loss that only depends onx. Assume that for all x,y, lm(x,y; θ) is differentiable, convex andβ-smooth in θ, and both ∥∇lm(x,y; θ)∥,∥∇ls(x,θ)∥≤ Gfor all θ. With a ﬁxed learning rate η= ϵ βG2 , for every x,y such that ⟨∇lm(x,y; θ),∇ls(x; θ)⟩>ϵ, (10) we have lm(x,y; θ) >lm(x,y; θ(x)), (11) where θ(x) = θ−η∇ls(x; θ) i.e. Test-Time Training with one step of gradient descent. The proof uses standard techniques in optimization, and is left for the appendix. Theorem 1 reveals gradient correlation as a determining factor of the success of Test-Time Training in the smooth and convex case. In Figure 4, we empirically show that our insight also holds for non-convex loss func- tions, on the deep learning model and across the diverse set of corruptions considered in Section 3; stronger gradient cor- relation clearly indicates more performance improvement over the baseline. 5. Related Work Learning on test instances. Shocher et al. (2018) pro- vide a key inspiration for our work by showing that image super-resolution could be learned at test time simply by try- ing to upsample a downsampled version of the input image. More recently, Bau et al. (2019) improve photo manipula- tion by adapting a pre-trained GAN to the statistics of the input image. One of the earlier examples of this idea comes from Jain & Learned-Miller (2011), who improve Viola- Jones face detection (Viola et al., 2001) by bootstrapping the more difﬁcult faces in an image from the more easily detected faces in that same image. The online version of our algorithm is inspired by the work of Mullapudi et al. (2018), which makes video segmentation more efﬁcient by using a student model that learns online from a teacher model. The idea of online updates has also been used in Kalal et al. (2011) for tracking and detection. A recent work in echocardiography (Zhu et al., 2019) improves the deep learning model that tracks myocardial motion and cardiac blood ﬂow with sequential updates. Lastly, we share the philosophy of transductive learning (Vapnik, 2013; Gam- merman et al., 1998), but have little in common with their classical algorithms; recent work by Tripuraneni & Mackey (2019) theoretically explores this for linear prediction, in the context of debiasing the LASSO estimator. Self-supervised learning studies how to create labels from the data, by designing various pretext tasks that can learn semantic information without human annotations, such as context prediction (Doersch et al., 2015), solving jig- saw puzzles (Noroozi & Favaro, 2016), colorization (Lars- son et al., 2017; Zhang et al., 2016), noise prediction (Bo- janowski & Joulin, 2017), feature clustering (Caron et al., 2018). Our paper uses rotation prediction (Gidaris et al., 2018). Asano et al. (2019) show that self-supervised learn- ing on only a single image, surprisingly, can produce low- level features that generalize well. Closely related to our work, Hendrycks et al. (2019a) propose that jointly training a main task and a self-supervised task (our joint training baseline in Section 3) can improve robustness on the main task. The same idea is used in few-shot learning (Su et al., 2019), domain generalization (Carlucci et al., 2019), and unsupervised domain adaptation (Sun et al., 2019). Adversarial robustness studies the robust risk RP,∆(θ) = Ex,y∼P maxδ∈∆ l(x + δ,y; θ), where l is some loss function, and ∆ is the set of perturbations; ∆ is often chosen as the Lp ball, for p ∈{1,2,∞}. Many popular algorithms formulate and solve this as a robust optimization problem (Goodfellow et al., 2014; Madry et al., 2017; Sinha et al., 2017; Raghunathan et al., 2018; Wong & Kolter, 2017; Croce et al., 2018), and the most well known technique is adversarial training. Another line of work is based on randomized smoothing (Cohen et al., 2019; Salman et al., 2019), while some other approaches, such as input transformations (Guo et al., 2017; Song et al., 2017), are shown to be less effective (Athalye et al., 2018). There are two main problems with the approaches above. First, all of them can be seen as smoothing the decision boundary. This establishes a theoretical tradeoff between accuracy and robustness (Tsipras et al., 2018; Zhang et al., 2019), which we also observe empirically with our adversarial training baseline in Section 3. Intuitively, the more diverse ∆ is, the less effective this one-boundary-ﬁts-all approach can be for a particular element of ∆. Second, adversarial methods rely heavily on the mathematical structure of ∆, which might not accurately model perturbations in the real world. Therefore, generalization remains hard outside of the ∆ we know in advance or can mathematically model, especially for non-adversarial distribution shifts. Empirically, Kang et al. (2019) shows that robustness for one ∆ might not transfer to another, and training on the L∞ball actually hurts robustness on the L1 ball. Non-adversarial robustness studies the effect of corrup- tions, perturbations, out-of-distribution examples, and real- world distribution shifts (Hendrycks et al., 2019b;a; 2018; Hendrycks & Gimpel, 2016). Geirhos et al. (2018) show that training on images corrupted by Gaussian noise makes deep learning models robust to this particular noise type, but does not improve performance on images corrupted by another noise type e.g. salt-and-pepper noise.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts Unsupervised domain adaptation (a.k.a. transfer learn- ing) studies the problem of distribution shifts, when an unlabeled dataset from the test distribution (target domain) is available at training time, in addition to a labeled dataset from the training distribution (source domain) (Chen et al., 2011; Gong et al., 2012; Long et al., 2015; Ganin et al., 2016; Long et al., 2016; Tzeng et al., 2017; Hoffman et al., 2017; Csurka, 2017; Chen et al., 2018). The limitation of the problem setting, however, is that generalization might only be improved for this speciﬁc test distribution, which can be difﬁcult to anticipate in advance. Prior work try to anticipate broader distributions by using multiple and evolv- ing domains (Hoffman et al., 2018; 2012; 2014). Test-Time Training does not anticipate any test distribution, by chang- ing the setting of unsupervised domain adaptation, while taking inspiration from its algorithms. Our paper is a follow- up to Sun et al. (2019), which we explain and empirically compare with in Section 3. Our update rule can be viewed as performing one-sample unsupervised domain adaptation on the ﬂy, with the caveat that standard domain adaptation techniques might become ill-deﬁned when there is only one sample from the target domain. Domain generalization studies the setting where a meta distribution generates multiple environment distributions, some of which are available during training (source), while others are used for testing (target) (Li et al., 2018; Shankar et al., 2018; Muandet et al., 2013; Balaji et al., 2018; Ghifary et al., 2015; Motiian et al., 2017; Li et al., 2017a; Gan et al., 2016). With only a few environments, information on the meta distribution is often too scarce to be helpful, and with many environments, we are back to the i.i.d. setting where each environment can be seen as a sample, and a strong baseline is to simply train on all the environments (Li et al., 2019). The setting of domain generalization is limited by the inherent tradeoff between speciﬁcity and generality of a ﬁxed decision boundary, and the fact that generalization is again elusive outside of the meta distribution i.e. the actual P learned by the algorithm. One (few)-shot learning studies how to learn a new task or a new classiﬁcation category using only one (or a few) sample(s), on top of a general representation that has been learned on diverse samples (Snell et al., 2017; Vinyals et al., 2016; Fei-Fei et al., 2006; Ravi & Larochelle, 2016; Li et al., 2017b; Finn et al., 2017; Gidaris & Komodakis, 2018). Our update rule can be viewed as performing one-shot self- supervised learning and can potentially be improved by progress in one-shot learning. Continual learning (a.k.a. learning without forgetting) studies the setting where a model is made to learn a sequence of tasks, and not forget about the earlier ones while training for the later (Li & Hoiem, 2017; Lopez-Paz & Ranzato, 2017; Kirkpatrick et al., 2017; Santoro et al., 2016). In contrast, with Test-Time Training, we are not concerned about forgetting the past test samples since they have already been evaluated on; and if a past sample comes up by any chance, it would go through Test-Time Training again. In addition, the impact of forgetting the training set is minimal, because both tasks have already been jointly trained. Online learning (a.k.a. online optimization) is a well- studied area of learning theory (Shalev-Shwartz et al., 2012; Hazan et al., 2016). The basic setting repeats the following: receive xt, predict ˆyt, receive yt from a worst-case oracle, and learn. Final performance is evaluated using the regret, which colloquially translates to how much worse the online learning algorithm performs in comparison to the best ﬁxed model in hindsight. In contrast, our setting never reveals any yt during testing even for the online version, so we do not need to invoke the concept of the worst-case oracle or the regret. Also, due to the lack of feedback from the envi- ronment after predicting, our algorithm is motivated to learn (with self-supervision) before predicting ˆyt instead of after. Note that some of the previously covered papers (Hoffman et al., 2014; Jain & Learned-Miller, 2011; Mullapudi et al., 2018) use the term “online learning” outside of the learning theory setting, so the term can be overloaded. 6. Discussion The idea of test-time training also makes sense for other tasks, such as segmentation and detection, and in other ﬁelds, such as speech recognition and natural language process- ing. For machine learning practitioners with prior domain knowledge in their respective ﬁelds, their expertise can be leveraged to design better special-purpose self-supervised tasks for test-time training. Researchers for general-purpose self-supervised tasks can also use test-time training as an evaluation benchmark, in addition to the currently prevalent benchmark of pre-training and ﬁne-tuning. More generally, we hope this paper can encourage re- searchers to abandon the self-imposed constraint of a ﬁxed decision boundary for testing, or even the artiﬁcial division between training and testing altogether. Our work is but a small step toward a new paradigm where much of the learning happens after a model is deployed. Acknowledgements. This work is supported by NSF grant 1764033, DARPA and Berkeley DeepDrive. This paper took a long time to develop, and beneﬁted from con- versations with many of our colleagues, including Ben Recht and his students Ludwig Schmidt, Vaishaal Shanker and Becca Roelofs; Ravi Teja Mullapudi, Achal Dave and Deva Ramanan; and Armin Askari, Allan Jabri, Ashish Kumar, Angjoo Kanazawa and Jitendra Malik.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts References Asano, Y . M., Rupprecht, C., and Vedaldi, A. Surprising effectiveness of few-image unsupervised feature learning. arXiv preprint arXiv:1904.13132, 2019. Athalye, A., Carlini, N., and Wagner, D. Obfuscated gradients give a false sense of security: Circumvent- ing defenses to adversarial examples. arXiv preprint arXiv:1802.00420, 2018. Balaji, Y ., Sankaranarayanan, S., and Chellappa, R. Metareg: Towards domain generalization using meta-regularization. In Advances in Neural Information Processing Systems, pp. 998–1008, 2018. Bau, D., Strobelt, H., Peebles, W., Wulff, J., Zhou, B., Zhu, J.-Y ., and Torralba, A. Semantic photo manipulation with a generative image prior. ACM Transactions on Graphics (TOG), 38(4):59, 2019. Bojanowski, P. and Joulin, A. Unsupervised learning by predicting noise. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pp. 517– 526. JMLR. org, 2017. Carlucci, F. M., D’Innocente, A., Bucci, S., Caputo, B., and Tommasi, T. Domain generalization by solving jigsaw puzzles. In Proceedings of the IEEE Conference on Com- puter Vision and Pattern Recognition , pp. 2229–2238, 2019. Caron, M., Bojanowski, P., Joulin, A., and Douze, M. Deep clustering for unsupervised learning of visual features. In Proceedings of the European Conference on Computer Vision (ECCV), pp. 132–149, 2018. Caruana, R. Multitask learning. Machine learning, 28(1): 41–75, 1997. Chen, M., Weinberger, K. Q., and Blitzer, J. Co-training for domain adaptation. In Advances in neural information processing systems, pp. 2456–2464, 2011. Chen, X., Sun, Y ., Athiwaratkun, B., Cardie, C., and Wein- berger, K. Adversarial deep averaging networks for cross- lingual sentiment classiﬁcation. Transactions of the Asso- ciation for Computational Linguistics, 6:557–570, 2018. Cohen, J. M., Rosenfeld, E., and Kolter, J. Z. Certiﬁed adversarial robustness via randomized smoothing. arXiv preprint arXiv:1902.02918, 2019. Croce, F., Andriushchenko, M., and Hein, M. Provable robustness of relu networks via maximization of linear regions. arXiv preprint arXiv:1810.07481, 2018. Csurka, G. Domain adaptation for visual applications: A comprehensive survey. arXiv preprint arXiv:1702.05374, 2017. Ding, G. W., Wang, L., and Jin, X. AdverTorch v0.1: An adversarial robustness toolbox based on pytorch. arXiv preprint arXiv:1902.07623, 2019. Doersch, C., Gupta, A., and Efros, A. A. Unsupervised visual representation learning by context prediction. In Proceedings of the IEEE International Conference on Computer Vision, pp. 1422–1430, 2015. Fei-Fei, L., Fergus, R., and Perona, P. One-shot learning of object categories. IEEE transactions on pattern analysis and machine intelligence, 28(4):594–611, 2006. Finn, C., Abbeel, P., and Levine, S. Model-agnostic meta- learning for fast adaptation of deep networks. In Proceed- ings of the 34th International Conference on Machine Learning-Volume 70, pp. 1126–1135. JMLR. org, 2017. Gammerman, A., V ovk, V ., and Vapnik, V . Learning by transduction. In Proceedings of the Fourteenth conference on Uncertainty in artiﬁcial intelligence , pp. 148–155. Morgan Kaufmann Publishers Inc., 1998. Gan, C., Yang, T., and Gong, B. Learning attributes equals multi-source domain generalization. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 87–97, 2016. Ganin, Y ., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., and Lempitsky, V . Domain-adversarial training of neural networks. The Journal of Machine Learning Research, 17(1):2096–2030, 2016. Geirhos, R., Temme, C. R., Rauber, J., Sch¨utt, H. H., Bethge, M., and Wichmann, F. A. Generalisation in humans and deep neural networks. In Advances in Neural Information Processing Systems, pp. 7538–7550, 2018. Ghifary, M., Bastiaan Kleijn, W., Zhang, M., and Balduzzi, D. Domain generalization for object recognition with multi-task autoencoders. In Proceedings of the IEEE international conference on computer vision, pp. 2551– 2559, 2015. Gidaris, S. and Komodakis, N. Dynamic few-shot visual learning without forgetting. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4367–4375, 2018. Gidaris, S., Singh, P., and Komodakis, N. Unsupervised rep- resentation learning by predicting image rotations. arXiv preprint arXiv:1803.07728, 2018. Gong, B., Shi, Y ., Sha, F., and Grauman, K. Geodesic ﬂow kernel for unsupervised domain adaptation. In2012 IEEE Conference on Computer Vision and Pattern Recognition, pp. 2066–2073. IEEE, 2012.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts Goodfellow, I. J., Shlens, J., and Szegedy, C. Explain- ing and harnessing adversarial examples. arXiv preprint arXiv:1412.6572, 2014. Guo, C., Rana, M., Cisse, M., and van der Maaten, L. Coun- tering adversarial images using input transformations. arXiv preprint arXiv:1711.00117, 2017. Hazan, E. et al. Introduction to online convex optimization. Foundations and Trends® in Optimization, 2(3-4):157– 325, 2016. He, K., Zhang, X., Ren, S., and Sun, J. Deep residual learn- ing for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770–778, 2016a. He, K., Zhang, X., Ren, S., and Sun, J. Identity mappings in deep residual networks. In European conference on computer vision, pp. 630–645. Springer, 2016b. He, K., Girshick, R., and Doll ´ar, P. Rethinking imagenet pre-training. arXiv preprint arXiv:1811.08883, 2018. Hendrycks, D. and Dietterich, T. Benchmarking neural network robustness to common corruptions and perturba- tions. arXiv preprint arXiv:1903.12261, 2019. Hendrycks, D. and Gimpel, K. A baseline for detecting misclassiﬁed and out-of-distribution examples in neural networks. arXiv preprint arXiv:1610.02136, 2016. Hendrycks, D., Mazeika, M., Wilson, D., and Gimpel, K. Using trusted data to train deep networks on labels cor- rupted by severe noise. InAdvances in neural information processing systems, pp. 10456–10465, 2018. Hendrycks, D., Lee, K., and Mazeika, M. Using pre-training can improve model robustness and uncertainty. arXiv preprint arXiv:1901.09960, 2019a. Hendrycks, D., Mazeika, M., Kadavath, S., and Song, D. Improving model robustness and uncertainty estimates with self-supervised learning. arXiv preprint, 2019b. Hoffman, J., Kulis, B., Darrell, T., and Saenko, K. Discover- ing latent domains for multisource domain adaptation. In European Conference on Computer Vision, pp. 702–715. Springer, 2012. Hoffman, J., Darrell, T., and Saenko, K. Continuous man- ifold based adaptation for evolving visual domains. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 867–874, 2014. Hoffman, J., Tzeng, E., Park, T., Zhu, J.-Y ., Isola, P., Saenko, K., Efros, A. A., and Darrell, T. Cycada: Cycle- consistent adversarial domain adaptation. arXiv preprint arXiv:1711.03213, 2017. Hoffman, J., Mohri, M., and Zhang, N. Algorithms and theory for multiple-source adaptation. In Advances in Neural Information Processing Systems, pp. 8246–8256, 2018. Huang, G., Sun, Y ., Liu, Z., Sedra, D., and Weinberger, K. Q. Deep networks with stochastic depth. In European conference on computer vision, pp. 646–661. Springer, 2016. Ioffe, S. and Szegedy, C. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167, 2015. Jain, V . and Learned-Miller, E. Online domain adaptation of a pre-trained cascade of classiﬁers. In CVPR 2011, pp. 577–584. IEEE, 2011. Kalal, Z., Mikolajczyk, K., and Matas, J. Tracking-learning- detection. IEEE transactions on pattern analysis and machine intelligence, 34(7):1409–1422, 2011. Kang, D., Sun, Y ., Brown, T., Hendrycks, D., and Steinhardt, J. Transfer of adversarial robustness between perturbation types. arXiv preprint arXiv:1905.01034, 2019. Kannan, H., Kurakin, A., and Goodfellow, I. Adversarial logit pairing. arXiv preprint arXiv:1803.06373, 2018. Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Des- jardins, G., Rusu, A. A., Milan, K., Quan, J., Ramalho, T., Grabska-Barwinska, A., et al. Overcoming catastrophic forgetting in neural networks. Proceedings of the national academy of sciences, 114(13):3521–3526, 2017. Krizhevsky, A. and Hinton, G. Learning multiple layers of features from tiny images. Technical report, Citeseer, 2009. Larsson, G., Maire, M., and Shakhnarovich, G. Colorization as a proxy task for visual understanding. In CVPR, 2017. Li, D., Yang, Y ., Song, Y .-Z., and Hospedales, T. M. Deeper, broader and artier domain generalization. In Proceed- ings of the IEEE International Conference on Computer Vision, pp. 5542–5550, 2017a. Li, D., Zhang, J., Yang, Y ., Liu, C., Song, Y .-Z., and Hospedales, T. M. Episodic training for domain gen- eralization. arXiv preprint arXiv:1902.00113, 2019. Li, Y ., Tian, X., Gong, M., Liu, Y ., Liu, T., Zhang, K., and Tao, D. Deep domain generalization via conditional invariant adversarial networks. In Proceedings of the European Conference on Computer Vision (ECCV), pp. 624–639, 2018.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts Li, Z. and Hoiem, D. Learning without forgetting. IEEE transactions on pattern analysis and machine intelligence, 40(12):2935–2947, 2017. Li, Z., Zhou, F., Chen, F., and Li, H. Meta-sgd: Learning to learn quickly for few-shot learning. arXiv preprint arXiv:1707.09835, 2017b. Liu, Z., Sun, M., Zhou, T., Huang, G., and Darrell, T. Re- thinking the value of network pruning. arXiv preprint arXiv:1810.05270, 2018. Long, M., Cao, Y ., Wang, J., and Jordan, M. I. Learn- ing transferable features with deep adaptation networks. arXiv preprint arXiv:1502.02791, 2015. Long, M., Zhu, H., Wang, J., and Jordan, M. I. Unsupervised domain adaptation with residual transfer networks. In Advances in Neural Information Processing Systems, pp. 136–144, 2016. Lopez-Paz, D. and Ranzato, M. Gradient episodic memory for continual learning. In Advances in Neural Information Processing Systems, pp. 6467–6476, 2017. Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A. Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083 , 2017. Motiian, S., Piccirilli, M., Adjeroh, D. A., and Doretto, G. Uniﬁed deep supervised domain adaptation and gen- eralization. In Proceedings of the IEEE International Conference on Computer Vision, pp. 5715–5725, 2017. Muandet, K., Balduzzi, D., and Sch ¨olkopf, B. Domain generalization via invariant feature representation. In International Conference on Machine Learning, pp. 10– 18, 2013. Mullapudi, R. T., Chen, S., Zhang, K., Ramanan, D., and Fatahalian, K. Online model distillation for efﬁcient video inference. arXiv preprint arXiv:1812.02699, 2018. Noroozi, M. and Favaro, P. Unsupervised learning of visual representations by solving jigsaw puzzles. In European Conference on Computer Vision , pp. 69–84. Springer, 2016. Raghunathan, A., Steinhardt, J., and Liang, P. Certiﬁed defenses against adversarial examples. arXiv preprint arXiv:1801.09344, 2018. Ravi, S. and Larochelle, H. Optimization as a model for few-shot learning. IEEE transactions on pattern analysis and machine intelligence, 2016. Recht, B., Roelofs, R., Schmidt, L., and Shankar, V . Do cifar-10 classiﬁers generalize to cifar-10? arXiv preprint arXiv:1806.00451, 2018. Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A. C., and Fei-Fei, L. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV) , 115(3):211–252, 2015. doi: 10.1007/s11263-015-0816-y. Salman, H., Yang, G., Li, J., Zhang, P., Zhang, H., Razen- shteyn, I., and Bubeck, S. Provably robust deep learn- ing via adversarially trained smoothed classiﬁers. arXiv preprint arXiv:1906.04584, 2019. Santoro, A., Bartunov, S., Botvinick, M., Wierstra, D., and Lillicrap, T. Meta-learning with memory-augmented neu- ral networks. In International conference on machine learning, pp. 1842–1850, 2016. Shalev-Shwartz, S. et al. Online learning and online con- vex optimization. Foundations and Trends® in Machine Learning, 4(2):107–194, 2012. Shankar, S., Piratla, V ., Chakrabarti, S., Chaudhuri, S., Jyothi, P., and Sarawagi, S. Generalizing across domains via cross-gradient training. arXiv preprint arXiv:1804.10745, 2018. Shankar, V ., Dave, A., Roelofs, R., Ramanan, D., Recht, B., and Schmidt, L. Do image classiﬁers generalize across time? arXiv, 2019. Shocher, A., Cohen, N., and Irani, M. zero-shot super- resolution using deep internal learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3118–3126, 2018. Sinha, A., Namkoong, H., and Duchi, J. Certifying some dis- tributional robustness with principled adversarial training. arXiv preprint arXiv:1710.10571, 2017. Snell, J., Swersky, K., and Zemel, R. Prototypical networks for few-shot learning. In Advances in Neural Information Processing Systems, pp. 4077–4087, 2017. Song, Y ., Kim, T., Nowozin, S., Ermon, S., and Kushman, N. Pixeldefend: Leveraging generative models to understand and defend against adversarial examples. arXiv preprint arXiv:1710.10766, 2017. Su, J.-C., Maji, S., and Hariharan, B. Boosting supervi- sion with self-supervision for few-shot learning. arXiv preprint arXiv:1906.07079, 2019. Sun, Y ., Tzeng, E., Darrell, T., and Efros, A. A. Unsuper- vised domain adaptation through self-supervision. arXiv preprint, 2019.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts Tripuraneni, N. and Mackey, L. Debiasing linear prediction. arXiv preprint arXiv:1908.02341, 2019. Tsipras, D., Santurkar, S., Engstrom, L., Turner, A., and Madry, A. Robustness may be at odds with accuracy. arXiv preprint arXiv:1805.12152, 2018. Tzeng, E., Hoffman, J., Saenko, K., and Darrell, T. Adver- sarial discriminative domain adaptation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7167–7176, 2017. Vapnik, V .The nature of statistical learning theory. Springer science & business media, 2013. Vinyals, O., Blundell, C., Lillicrap, T., Wierstra, D., et al. Matching networks for one shot learning. In Advances in neural information processing systems, pp. 3630–3638, 2016. Viola, P., Jones, M., et al. Rapid object detection using a boosted cascade of simple features. CVPR (1), 1(511- 518):3, 2001. Wong, E. and Kolter, J. Z. Provable defenses against adver- sarial examples via the convex outer adversarial polytope. arXiv preprint arXiv:1711.00851, 2017. Zhang, H., Yu, Y ., Jiao, J., Xing, E. P., Ghaoui, L. E., and Jor- dan, M. I. Theoretically principled trade-off between ro- bustness and accuracy. arXiv preprint arXiv:1901.08573, 2019. Zhang, R., Isola, P., and Efros, A. A. Colorful image col- orization. In European conference on computer vision, pp. 649–666. Springer, 2016. Zhu, W., Huang, Y ., Vannan, M. A., Liu, S., Xu, D., Fan, W., Qian, Z., and Xie, X. Neural multi-scale self-supervised registration for echocardiogram dense tracking. arXiv preprint arXiv:1906.07357, 2019.Appendix: Test-Time Training with Self-Supervision for Generalization under Distribution Shifts A1. Informal Discussion on Our Variable Decision Boundary In the introduction, we claim that in traditional supervised learning θgives a ﬁxed decision boundary, while ourθgives a variable decision boundary. Here we informally discuss this claim. Denote the input space Xand output space Y. A decision boundary is simply a mapping f : X →Y. Let Θ be a model class e.g Rd. Now consider a family of parametrized functions gθ : X→Y , where θ∈Θ. In the context of deep learning, gis the neural network architecture and θcontains the parameters. We say that f is a ﬁxed decision boundary w.r.t. g and Θ if there exists θ ∈Θ s.t. f(x) = gθ(x) for every x ∈X , and a variable decision boundary if for every x∈X, there exists θ∈Θ s.t. f(x) = gθ(x). Note how selection of θcan depend on xfor a variable decision boundary, and cannot for a ﬁxed one. It is then trivial to verify that our claim is true under those deﬁnitions. A critical reader might say that with an arbitrarily large model class, can’t every decision boundary be ﬁxed? Yes, but this is not the end of the story. Let d = dim( X) × dim(Y), and consider the enormous model class Θ′= Rd which is capable of representing all possible mappings be- tween Xand Y. Let g′ θ′ simply be the mapping represented by θ′ ∈Θ′. A variable decision boundary w.r.t. g and Θ then indeed must be a ﬁxed decision boundary w.r.t. g′and Θ′, but we would like to note two things. First, without any prior knowledge, generalization in Θ′is impossible with any ﬁnite amount of training data; reasoning about g′and Θ′is most likely not productive from an algorithmic point of view, and the concept of a variable decision boundary is to avoid such reasoning. Second, selecting θbased on xfor a variable decision boundary can be thought of as “training” on all points x ∈Rd; however, “training” only happens when necessary, for the xthat it actually encounters. Altogether, the concept of a variable decision boundary is different from what can be described by traditional learning theory. A formal discussion is beyond the scope of this paper and might be of interest to future work. A2. Computational Aspects of Our Method At test time, our method is 2 × batch size × number of iterations times slower than regular test- ing, which only performs a single forward pass for each sample. As the ﬁrst work on Test-Time Training, this paper is not as concerned about computational efﬁciency as improving robustness, but here we provide two poten- tial solutions that might be useful, but have not been thor- oughly veriﬁed. The ﬁrst is to use the thresholding trick on ls, introduced as a solution for the small batches prob- lem in the method section. For the models considered in our experiments, roughly 80% of the test instances fall below the threshold, so Test-Time Training can only be performed on the other 20% without much effect on per- formance, because those 20% contain most of the sam- ples with wrong predictions. The second is to reduce the number of iterations of test-time updates. For the online version, the number of iterations is al- ready 1, so there is nothing to do. For the standard ver- sion, we have done some preliminary experiments setting number of iterations to 1 (instead of 10) and learn- ing rate to 0.01 (instead of 0.001), and observing results almost as good as the standard hyper-parameter setting. A more in depth discussion on efﬁciency is left for future works, which might, during training, explicitly make the model amenable to fast updates. A3. Proofs Here we prove the theoretical results in the main paper. A3.1. The Toy Problem The following setting applies to the two lemmas; this is simply the setting of our toy problem, reproduced here for ease of reference.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts Consider a two layer linear network parametrized by A∈ Rh×d (shared) and v,w ∈Rh (ﬁxed) for the two heads, respectively. Denote x∈Rd the input and y1,y2 ∈R the labels for the two tasks, respectively. For the main task loss lm(A; v) = 1 2 ( y1 −v⊤Ax )2 , (12) and the self-supervised task loss ls(A; w) = 1 2 ( y2 −w⊤Ax )2 , (13) Test-Time Training yields an updated matrix A′←A−η ( y2 −w⊤Ax )( −wx⊤) , (14) where ηis the learning rate. Lemma 1. Following the exposition of the main paper, let η∗= (y1 −v⊤Ax) (y2 −w⊤Ax)v⊤wx⊤x. (15) Assume η∗∈[ϵ,∞) for some ϵ> 0. Then for any η∈(0,ϵ], we are guaranteed an improvement on the main loss i.e. lm(A′) <lm(A). Proof. From the exposition of the main paper, we know that lm(A−η∗∇lsA)) = 0, which can also be derived from simple algebra. Then by convexity, we have lm(A−η∇ls(A)) (16) = lm (( 1 − η η∗ ) A+ η η∗(A−η∗∇ls(A)) ) (17) ≤ ( 1 − η η∗ ) lm(A) + 0 (18) ≤ ( 1 −η ϵ ) lm(A) (19) <lm(A), (20) where the last inequality uses the assumption that lm(A) > 0, which holds because η∗>0. Lemma 2. Deﬁne ⟨U,V⟩= vec (U)⊤vec (V) i.e. the Frobenious inner product, then sign (η∗) = sign (⟨∇lm(A),∇ls(A)⟩) . (21) Proof. By simple algebra, ⟨∇lm(A),∇ls(A)⟩ = ⟨ ( y1 −v⊤Ax )( −vx⊤) , ( y2 −w⊤Ax )( −wx⊤) ⟩ = ( y1 −v⊤Ax )( y2 −w⊤Ax ) Tr ( xv⊤wx⊤) = ( y1 −v⊤Ax )( y2 −w⊤Ax ) v⊤wx⊤x, which has the same sign as η∗. A3.2. Proof of Theorem 1 For any η, by smoothness and convexity, lm(x,y; θ(x)) = lm(x,y; θ−η∇ls(x; θ)) ≤lm(x,y; θ) + η⟨∇lm(x,y; θ),∇ls(x,θ)⟩ + η2β 2 ∥∇ls(x; θ)∥2 . Denote η∗= ⟨∇lm(x,y; θ),∇ls(x,θ)⟩ β∥∇ls(x; θ)∥2 . Then Equation 22 becomes lm(x,y; θ−η∗∇ls(x; θ)) (22) ≤lm(x,y; θ) −⟨∇lm(x,y; θ),∇ls(x,θ)⟩2 2β∥∇ls(x; θ)∥2 . (23) And by our assumptions on the gradient norm and gradient inner product, lm(x,y; θ) −lm(x,y; θ−η∗∇ls(x; θ)) ≥ ϵ2 2βG2 . (24) Because we cannot observe η∗in practice, we instead use a ﬁxed learning rate η = ϵ βG2 , as stated in Theorem 1. Now we argue that this ﬁxed learning rate still improves performance on the main task. By our assumptions, η∗ ≥ ϵ βG2 , so η ∈(0,η∗]. Denote g= ∇ls(x; θ), then by convexity of lm, lm(x,y; θ(x)) = lm(x,y; θ−ηg) (25) = lm ( x,y; ( 1 − η η∗ ) θ+ η η∗(θ−η∗g) ) (26) ≤ ( 1 − η η∗ ) lm(x,y; θ) + η η∗lm(x,y; θ−η∗g) (27) Combining with Equation 24, we have lm(x,y; θ(x)) ≤ ( 1 − η η∗ ) lm(x,y; θ) + η η∗ ( lm(x,y; θ) − ϵ2 2βG2 ) = lm(x,y; θ) − η η∗ ϵ2 2βG2 Since η/η∗>0, we have shown that lm(x,y; θ) −lm(x,y; θ(x)) >0. (28)Test-Time Training with Self-Supervision for Generalization under Distribution Shifts A4. Additional Results on the Common Corruptions Dataset For table aethetics, we use the following abbreviations: B for baseline, JT for joint training, TTT for Test-Time Train- ing standard version, and TTT-Online for online Test-Time Training i.e. the online version. We have abbreviated the names of the corruptions, in order: original test set, Gaussian noise, shot noise, impulse noise, defocus blur, glass blue, motion blur, zoom blur, snow, frost, fog, brightness, contrast, elastic transformation, pixelation, and JPEG compression. A4.1. Results Using Batch Normalization As discussed in the results section, Batch Normalization (BN) is ineffective for small batches, which are the inputs for Test-Time Training (both standard and online version) since there is only one sample available when forming each batch; therefore, our main results are based on a ResNet using Group Normalization (GN). Figure A2 and Table A1 show results of our method on CIFAR-10-C level 5, with a ResNet using Batch Normalization (BN). These results are only meant to be a point of reference for the curious readers. In the early stage of this project, we have experimented with two potential solutions to the small batches problem with BN. The naive solution is to ﬁx the BN layers during Test-Time Training. but this diminishes the performance gains since there are fewer shared parameters. The better solution, adopted for the results below, is hard example mining: instead of updating on all inputs, we only update on inputs that incur large self-supervised task loss ls, where the large improvements might counter the negative effects of inaccurate statistics. Test-Time Training (standard version) is still very effective with BN. In fact, some of the improvements are quite dra- matic, such as on contrast (34%), defocus blue (18%) and Gaussian noise (22% comparing to joint-training, and 16% comparing to the baseline). Performance on the original distribution is still almost the same, and the original error with BN is in fact slightly lower than with GN, and takes half as many epochs to converge. We did not further experiment with BN because of two rea- sons: 1) The online version does not work with BN, because the problem with inaccurate batch statistics is exacerbated when training online for many (e.g. 10000) steps. 2) The baseline error for almost every corruption type is signiﬁ- cantly higher with BN than with GN. Although unrelated to the main idea of our paper, we make the interesting note that GN signiﬁcantly improves model robustness. A4.2. Additional Baseline: Adversarial Logit Pairing As discussed in the results section, Hendrycks & Dietterich (2019) point to Adversarial Logit Pairing (ALP) (Kannan et al., 2018) as an effective method for improving model robustness to corruptions and perturbations, even though it was designed to defend against adversarial attacks. We take ALP as an additional baseline on all benchmarks based on CIFAR-10 (using GN), following the training proce- dure in Kannan et al. (2018) and their recommended hyper- parameters. The implementation of the adversarial attack comes from the codebase of Ding et al. (2019). We did not run ALP on ImageNet because the two papers we reference for this method, Kannan et al. (2018) and Hendrycks & Di- etterich (2019), did not run on ImageNet or make any claim or recommendation. A4.3. Results on CIFAR-10-C and ImageNet-C, Level 5 Table A2 and Table A3 correspond to the bar plots in the results section. Two rows of Table A2 have been presented as Table 1 in the main text. A4.4. Results on CIFAR-10-C, Levels 1-4 The following bar plots and tables are on levels 1-4 of CIFAR-10-C. The original distribution is the same for all levels, so are our results on the original distribution. A4.5. Direct Comparison with Hendrycks et al. (2019a) The following comparison has been requested by an anony- mous reviewer for our ﬁnal version. Our joint training baseline is based on Hendrycks et al. (2019a), but also incor- porates some architectural changes (see below). We found these changes improved the robustness of our method, and felt that it was important to give the baseline the same ben- eﬁt. Note that our joint training baseline overall performs better than Hendrycks: Compare Table S2 to Figure 3 of Hendrycks et al. (2019a) (provided by the authors), our baseline has average error of 22.8% across all corruptions and levels, while their average error is 28.6%. Summary of architectural changes: 1) Group Normalization (GN) instead of Batch Normalization (BN). For complete- ness, the results with BN are provided in Table S1; c.f. GN results in Table S2 which signiﬁcantly improves robustness, with or without self-supervision. 2) We split after the sec- ond residual group, while they split after the third residual group right before the linear layer. This consistently gives about 0.5% - 1% improvement. 3) We use a ResNet-26, while they use a 40-2 Wide ResNet. But our baseline still performs better than their method even though our network is 4x smaller, due to the two tricks above.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts Gaussian Noise  Shot Noise  Impulse Noise  Defocus Blur  Frosted Glass Blur Motion Blur  Zoom Blur  Snow  Frost  Fog Brightness  Contrast  Elastic  Pixelate  JPEG Figure A1.Sample images from the Common Corruptions Benchmark, taken from the original paper by Hendrycks & Dietterich (2019). originalgauss shot impulsedefocus glass motion zoom snow frost fog bright contrastelasticpixelate jpeg 0 20 40 60Error (%) Object recognition task only Joint training (Hendrycks et al. 2019) TTT Figure A2.Test error (%) on CIFAR-10-C, level 5, ResNet-26 with Batch Normalization. orig gauss shot impul defoc glass motn zoom snow frost fog brit contr elast pixel jpeg B 7.9 63.9 58.8 64.3 46.3 54.6 41.6 45.9 31.9 44.0 37.5 13.0 69.2 33.8 61.4 31.7 JT 7.5 70.7 65.6 67.2 43.1 55.4 40.9 42.7 30.3 44.5 42.5 12.7 58.6 30.7 62.6 31.9 TTT 7.9 47.9 45.2 54.8 27.6 50.4 31.5 30.9 28.7 34.3 26.9 12.6 35.2 30.6 51.2 31.3 Table A1.Test error (%) on CIFAR-10-C, level 5, ResNet-26 with Batch Normalization. orig gauss shot impul defoc glass motn zoom snow frost fog brit contr elast pixel jpeg B 8.9 50.5 47.2 56.1 23.7 51.7 24.3 26.3 25.6 34.4 28.1 13.5 25.0 27.4 55.8 29.8 JT 8.1 49.4 45.3 53.4 24.2 48.5 24.8 26.4 25.0 32.5 27.5 12.6 25.3 24.0 51.6 28.7 TTT 7.9 45.6 41.8 50.0 21.8 46.1 23.0 23.9 23.9 30.0 25.1 12.2 23.9 22.6 47.2 27.2 TTT-Online 8.2 25.8 22.6 30.6 14.6 34.4 18.3 17.1 20.0 18.0 16.9 11.2 15.6 21.6 18.1 21.2 UDA-SS 9.0 28.2 26.5 20.8 15.6 43.7 24.5 23.8 25.0 24.9 17.2 12.7 11.6 22.1 20.3 22.6 ALP 16.5 22.7 22.9 28.3 25.0 25.6 27.4 23.1 25.2 27.2 64.8 21.7 73.6 23.0 20.2 18.9 Table A2.Test error (%) on CIFAR-10-C, level 5, ResNet-26. orig gauss shot impul defoc glass motn zoom snow frost fog brit contr elast pixel jpeg B 68.9 1.3 2.0 1.3 7.5 6.6 11.8 16.2 15.7 14.9 15.3 43.9 9.7 16.5 15.3 23.4 JT 69.1 2.1 3.1 2.1 8.7 6.7 12.3 16.0 15.3 15.8 17.0 45.3 11.0 18.4 19.7 22.9 TTT 69.0 3.1 4.5 3.5 10.1 6.8 13.5 18.5 17.1 17.9 20.0 47.0 14.4 20.9 22.8 25.3 TTT-Online 68.8 26.3 28.6 26.9 23.7 6.6 28.7 33.4 35.6 18.7 47.6 58.3 35.3 44.3 47.8 44.3 Table A3.Test accuracy (%) on ImageNet-C, level 5, ResNet-18.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts originalgauss shot impulsedefocus glass motion zoom snow frost fog bright contrastelasticpixelate jpeg 0 10 20 30 40 50Error (%) Object recognition task only Joint training (Hendrycks et al. 2019) TTT TTT-Online Figure A3.Test error (%) on CIFAR-10-C, level 4. See the results section for details. orig gauss shot impul defoc glass motn zoom snow frost fog brit contr elast pixel jpeg B 8.9 46.4 39.2 44.8 15.3 52.5 19.1 20.5 21.3 26.9 13.3 10.5 13.7 20.8 35.3 26.9 JT 8.1 45.0 38.3 42.2 16.4 50.2 20.7 20.5 21.1 25.4 14.1 10.0 14.7 19.0 33.2 25.1 TTT 7.9 41.5 35.4 39.8 15.0 47.8 19.1 18.4 20.1 24.0 13.5 10.0 14.1 17.7 29.4 24.5 TTT-Online 8.2 22.9 20.0 23.9 11.2 35.1 15.6 13.8 18.6 15.9 12.3 9.7 11.9 16.7 13.6 19.8 ALP 16.5 21.3 20.5 24.5 20.7 25.9 23.7 21.4 24.2 23.9 42.2 17.5 53.7 22.1 19.1 18.5 Table A4.Test error (%) on CIFAR-10-C, level 4, ResNet-26. originalgauss shot impulsedefocus glass motion zoom snow frost fog bright contrastelasticpixelate jpeg 0 10 20 30 40Error (%) Object recognition task only Joint training (Hendrycks et al. 2019) TTT TTT-Online Figure A4.Test error (%) on CIFAR-10-C, level 3. See the results section for details. orig gauss shot impul defoc glass motn zoom snow frost fog brit contr elast pixel jpeg B 8.9 42.2 35.1 30.7 12.2 41.7 18.6 17.5 19.0 25.3 10.8 9.7 11.6 15.3 21.7 24.6 JT 8.1 40.2 34.4 29.9 12.2 37.9 20.8 17.3 18.4 25.0 11.4 9.2 12.0 15.2 20.8 22.8 TTT 7.9 37.2 31.6 28.6 11.5 35.8 19.1 15.8 17.8 23.3 11.0 9.1 11.6 14.3 18.9 22.3 TTT-Online 8.2 21.3 17.7 17.9 9.0 23.4 15.3 12.5 16.4 15.8 10.9 9.0 10.7 12.8 12.2 18.7 ALP 16.5 20.0 19.3 20.5 19.2 21.2 24.0 20.5 20.9 24.2 30.1 16.6 39.6 20.9 17.8 18.0 Table A5.Test error (%) on CIFAR-10-C, level 3, ResNet-26.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts originalgauss shot impulsedefocus glass motion zoom snow frost fog bright contrastelasticpixelate jpeg 0 10 20 30 40Error (%) Object recognition task only Joint training (Hendrycks et al. 2019) TTT TTT-Online Figure A5.Test error (%) on CIFAR-10-C, level 2. See the results section for details. orig gauss shot impul defoc glass motn zoom snow frost fog brit contr elast pixel jpeg B 8.9 31.7 22.6 24.3 9.9 42.6 14.9 14.7 21.7 18.4 9.8 9.1 10.0 13.1 17.1 22.4 JT 8.1 31.0 22.6 23.4 9.1 39.2 16.4 14.2 21.2 17.5 9.4 8.3 10.6 12.8 15.9 20.5 TTT 7.9 28.8 20.7 23.0 9.0 36.6 15.4 13.1 20.2 16.9 9.2 8.3 10.2 12.5 14.8 19.7 TTT-Online 8.2 16.8 13.8 15.5 8.5 23.4 13.3 11.5 16.8 12.7 9.4 8.4 9.7 12.4 11.5 17.0 ALP 16.5 18.0 17.2 19.0 17.8 20.7 21.2 19.3 19.0 20.1 22.4 16.3 29.2 20.3 17.4 17.8 Table A6.Test error (%) on CIFAR-10-C, level 2, ResNet-26. originalgauss shot impulsedefocus glass motion zoom snow frost fog bright contrastelasticpixelate jpeg 0 10 20 30 40Error (%) Object recognition task only Joint training (Hendrycks et al. 2019) TTT TTT-Online Figure A6.Test error (%) on CIFAR-10-C, level 1. See the results section for details. orig gauss shot impul defoc glass motn zoom snow frost fog brit contr elast pixel jpeg B 8.9 21.7 17.1 17.0 9.0 44.0 12.1 13.9 14.3 13.4 9.2 8.9 9.0 13.2 12.0 17.3 JT 8.1 20.4 16.6 16.9 8.2 40.5 12.2 13.0 13.1 12.3 8.4 8.1 8.5 12.9 11.3 15.9 TTT 7.9 19.1 15.8 16.5 8.0 37.9 11.7 12.2 12.8 11.9 8.2 8.0 8.3 12.6 11.1 15.5 TTT-Online 8.2 13.8 11.9 12.2 8.5 24.4 10.5 11.5 12.4 10.7 8.5 8.3 8.6 12.4 10.7 14.4 ALP 17.0 16.8 17.6 16.8 20.9 18.7 19.0 17.3 17.5 17.4 16.1 18.4 20.4 17.0 17.2 17.5 Table A7.Test error (%) on CIFAR-10-C, level 1, ResNet-26.Test-Time Training with Self-Supervision for Generalization under Distribution Shifts Figure A7.Sample Images from the VID-Robust dataset (Shankar et al., 2019) in the results section adapted to CIFAR-10. Each row shows eight sample images from one class. The seven classes shown are, in order: airplane, bird, car, dog, cat, horse, ship.",
      "meta_data": {
        "arxiv_id": "1909.13231v3",
        "authors": [
          "Yu Sun",
          "Xiaolong Wang",
          "Zhuang Liu",
          "John Miller",
          "Alexei A. Efros",
          "Moritz Hardt"
        ],
        "published_date": "2019-09-29T08:09:15Z",
        "pdf_url": "https://arxiv.org/pdf/1909.13231v3.pdf"
      },
      "llm_extracted_info": {
        "main_contributions": "Introduces Test-Time Training (TTT), a simple yet general procedure that adapts a pre-trained model to each unseen test input using a self-supervised auxiliary task, thereby improving robustness to unknown distribution shifts. Provides an online variant that continually updates on a stream of inputs, delivers substantial gains over strong baselines on multiple vision robustness benchmarks, and offers theoretical analysis linking success to positive gradient correlation between main and self-supervised losses.",
        "methodology": "1) Jointly train a backbone network on the supervised main task and a self-supervised auxiliary task (image rotation prediction). Shared layers θ_e form a feature extractor; task-specific heads are separate. 2) At test time, create a self-supervised problem from the unlabeled test image: generate rotated versions, compute rotation loss, and take gradient steps (10 for standard TTT; 1 for online) on θ_e only, leaving classifier head fixed. 3) For streams, keep updated weights to accumulate knowledge across samples. 4) Use ResNets with Group Normalization; SGD without momentum/weight decay during test-time updates. 5) Provide convex-model proof that positive inner-product of gradients guarantees loss reduction after one update.",
        "experimental_setup": "Datasets/Benchmarks: (i) CIFAR-10-C (15 corruption types × 5 severity levels). (ii) ImageNet-C. (iii) VID-Robust (video frames). (iv) CIFAR-10.1 (new test set). Models: ResNet-26 (CIFAR) and ResNet-18 (ImageNet) with GN. Baselines: plain supervised model, joint training with self-supervision but no test-time updates, Adversarial Logit Pairing, and UDA-SS (oracle unsupervised domain adaptation). Metrics: classification error/accuracy on corrupted and clean data. Validation: compare performance before and after TTT/TTT-Online; sliding-window plots for online adaptation; multiple corruption levels evaluated.",
        "limitations": "• Requires a self-supervised task that is informative for the current data; rotation fails on classes where orientation is ambiguous (e.g., airplanes). • Adds significant test-time computation (multiple forward/backward passes); incompatible with small-latency settings. • Depends on layers without BatchNorm or on alternative normalisation; BN degrades performance with single-image batches. • Theoretical guarantees apply only to convex, smooth losses; practical deep nets lack such guarantees. • Assumes test inputs come from a single or slowly drifting distribution; abrupt large shifts may break adaptation. • Gains on subtle shifts (CIFAR-10.1) are modest.",
        "future_research_directions": "1) Design and learn adaptive or task-specific self-supervised objectives to cover a wider range of modalities and classes. 2) Develop computationally efficient TTT (e.g., meta-learned fast update rules, fewer gradient steps, or lightweight heads). 3) Extend to tasks beyond image classification—detection, segmentation, video, speech, NLP. 4) Integrate with Batch Normalization or alternative statistics estimators for single-sample updates. 5) Provide theoretical analysis for non-convex deep networks and study stability/forgetting trade-offs. 6) Combine with continual-learning or domain-generalization frameworks to balance past and future distribution shifts."
      }
    },
    {
      "title": "Robust Test-Time Adaptation in Dynamic Scenarios",
      "abstract": "Test-time adaptation (TTA) intends to adapt the pretrained model to test\ndistributions with only unlabeled test data streams. Most of the previous TTA\nmethods have achieved great success on simple test data streams such as\nindependently sampled data from single or multiple distributions. However,\nthese attempts may fail in dynamic scenarios of real-world applications like\nautonomous driving, where the environments gradually change and the test data\nis sampled correlatively over time. In this work, we explore such practical\ntest data streams to deploy the model on the fly, namely practical test-time\nadaptation (PTTA). To do so, we elaborate a Robust Test-Time Adaptation (RoTTA)\nmethod against the complex data stream in PTTA. More specifically, we present a\nrobust batch normalization scheme to estimate the normalization statistics.\nMeanwhile, a memory bank is utilized to sample category-balanced data with\nconsideration of timeliness and uncertainty. Further, to stabilize the training\nprocedure, we develop a time-aware reweighting strategy with a teacher-student\nmodel. Extensive experiments prove that RoTTA enables continual testtime\nadaptation on the correlatively sampled data streams. Our method is easy to\nimplement, making it a good choice for rapid deployment. The code is publicly\navailable at https://github.com/BIT-DA/RoTTA",
      "full_text": "Robust Test-Time Adaptation in Dynamic Scenarios Longhui Yuan Binhui Xie Shuang Li \f School of Computer Science and Technology, Beijing Institute of Technology {longhuiyuan,binhuixie,shuangli}@bit.edu.cn Abstract Test-time adaptation (TTA) intends to adapt the pre- trained model to test distributions with only unlabeled test data streams. Most of the previous TTA methods have achieved great success on simple test data streams such as independently sampled data from single or multiple distri- butions. However, these attempts may fail in dynamic sce- narios of real-world applications like autonomous driving, where the environments gradually change and the test data is sampled correlatively over time. In this work, we ex- plore such practical test data streams to deploy the model on the fly, namely practical test-time adaptation (PTTA). To do so, we elaborate a Robust Test-Time Adaptation (RoTTA) method against the complex data stream in PTTA. More specifically, we present a robust batch normalization scheme to estimate the normalization statistics. Meanwhile, a memory bank is utilized to sample category-balanced data with consideration of timeliness and uncertainty. Further, to stabilize the training procedure, we develop a time-aware reweighting strategy with a teacher-student model. Exten- sive experiments prove that RoTTA enables continual test- time adaptation on the correlatively sampled data streams. Our method is easy to implement, making it a good choice for rapid deployment. The code is publicly available at https://github.com/BIT-DA/RoTTA 1. Introduction In recent years, many machine learning problems have made considerable headway with the success of deep neu- ral networks [13, 22, 33, 38]. Unfortunately, the perfor- mance of deep models drops significantly when training data and testing data come from different distributions [59], which limits their utility in real-world applications. To re- duce the distribution shift, a handful of works focus on transfer learning field [56], in particular, domain adapta- tion (DA) [17, 42, 45, 48, 69, 72] or domain generalization (DG) [40, 41, 52, 71, 83], in which one or more different but \fCorresponding author Test data stream Continual TTANon-i.i.d.TTAPractical  TTACategoryDistribution Fully TTA Correlation samplingDistributionchanging Figure 1. We consider the practical test-time adaptation (TTA) setup and compare it with related ones. First, Fully TTA [70] adapts models on a fixed test distribution with an independently sampled test stream. Then, on this basis, Continual TTA [73] takes the continually changing distributions into consideration. Next, Non-i.i.d. TTA [19] tries to tackle the correlatively sampled test streams on a single test distribution, where the label distribution among a batch of data deviates from that of the test distribution. To be more practical, Practical TTA strives to connect both worlds: distribution changing and correlation sampling. related labeled datasets (a.k.a. source domain) are collected to help the model generalize well to unlabeled or unseen samples in new datasets (a.k.a. target domain). While both DA and DG have extensively studied the problem of distribution shifts, they typically assume acces- sibility to the raw source data. However, in many practical scenarios like personal consumption records, the raw data should not be publicly available due to data protection reg- ulations. Further, existing methods have to perform heavy backward computation, resulting in unbearable training costs. Test-time adaptation (TTA) [3,11,16,24,26,54,65,81] attempts to address the distribution shift online at test time with only unlabeled test data streams. Unequivocally, TTA has drawn widespread attention in a variety of applications, e.g., 2D/3D visual recognition [2, 29, 49, 65, 82], multi- modality [63, 64] and document understanding [15]. Prior TTA studies [7, 20, 70, 73] mostly concentrate on a simple adaptation scenario, where test samples are inde- pendently sampled from a fixed target domain. To name a few, Sun et al. [65] adapt to online test samples drawn from a constant or smoothly changing distribution with an auxil- iary self-supervised task. Wang et al. [70] adapt to a fixed arXiv:2303.13899v1  [cs.CV]  24 Mar 2023Table 1. Comparison between our proposed practical test-time adaptation (PTTA) and related adaptation settings. Setting Adaptation StageAvailable Data Test Data Stream Train Test Source Target Distribution Sampling Protocol Domain Adaptation ! % ! ! - - Domain Generalization ! % ! % - - Test-Time Training [65] ! ! ! ! stationary independently Fully Test-Time Adaptation [70] % ! % ! stationary independently Continual Test-Time Adaptation [73]% ! % ! continually changing independently Non-i.i.d. Test-Time Adaptation [5, 19]% ! % ! stationary correlatively Practical Test-Time Adaptation (Ours)% ! % ! continually changing correlatively target distribution by performing entropy minimization on- line. However, such an assumption is violated when the test environments change frequently [73]. Later on, Boudiaf et al. [5] and Gonget al. [19] consider the temporal correlation ship within test samples. For example, in autonomous driv- ing, test samples are highly correlated over time as the car will follow more vehicles on the highway or will encounter more pedestrians in the streets. More realistically, the data distribution changes as the surrounding environment alerts in weather, location, or other factors. In a word, distribution change and data correlation occur simultaneously in reality. Confronting continually changing distributions, tradi- tional algorithms like pseudo labeling or entropy minimiza- tion become more unreliable as the error gradients cumu- late. Moreover, the high correlation among test samples re- sults in the erroneous estimation of statistics for batch nor- malization and collapse of the model. Driven by this analy- sis, adapting to such data streams will encounter two major obstacles: 1) incorrect estimation in the batch normaliza- tion statistics leads to erroneous predictions of test samples, consequently resulting in invalid adaptation; 2) the model will easily or quickly overfit to the distribution caused by the correlative sampling. Thus, such dynamic scenarios are pressing for a new TTA paradigm to realize robust adapta- tion. In this work, we launch a more realistic TTA setting, where distribution changing and correlative sampling oc- cur simultaneously at the test phase. We call this Practical Test-Time Adaptation, or briefly,PTTA. To understand more clearly the similarities and differences between PTTA and the previous setups, we visualize them in Figure 1 and sum- marize them in Table 1. To conquer this challenging prob- lem, we propose a Robust Test-Time Adaptation (RoTTA) method, which consists of three parts: 1) robust statistics es- timation, 2) category-balanced sampling considering time- liness and uncertainty and 3) time-aware robust training. More concretely, we first replace the erroneous statistics of the current batch with global ones maintained by the expo- nential moving average. It is a more stable manner to esti- mate the statistics in BatchNorm layers. Then, we simulate a batch of independent-like data in memory with category- balanced sampling while considering the timeliness and un- certainty of the buffered samples. That is, samples that are newer and less uncertain are kept in memory with higher priority. With this batch of category-balanced, timely and confident samples, we can obtain a snapshot of the current distribution. Finally, we introduce a time-aware reweight- ing strategy that considers the timeliness of the samples in the memory bank, with a teacher-student model to perform robust adaptation. With extensive experiments, we demon- strate that RoTTA can robustly adapt in the practical setup, i.e., PTTA. In a nutshell, our contributions can be summarized as: • We propose a new test-time adaptation setup that is more suitable for real-world applications, namely practical test-time adaptation (PTTA). PTTA considers both distribution changing and correlation sampling. • We benchmark the performance of prior methods in PTTA and uncover that they only consider one aspect of the problem, resulting in ineffective adaptation. • We propose a robust test-time adaptation method (RoTTA), which has a more comprehensive considera- tion of PTTA challenges. Ease of implementation and effectiveness make it a practical deployment option. • We extensively demonstrate the practicality of PTTA and the effectiveness of RoTTA on common TTA benchmarks [23], i.e., CIFAR-10-C and CIFAR-100- C and a large-scale DomainNet [58] dataset. RoTTA obtains state-of-the-art results, outperforming the best baseline by a large margin (reducing the averaged classification error by over 5.9%, 5.5% and 2.2% on CIFAR-10-C, CIFAR-100-C and DomainNet, respec- tively). 2. Related Work Domain adaptation (DA) studies the problem of transfer- ring the knowledge learned from a labeled source dataset to an unlabeled target dataset [8, 17, 43, 51, 67, 68]. Represen- tative techniques include latent distribution alignment [48, 77], adversarial training [17, 62], or self-training [75, 85]. The limitation of this setting, however, is that an unlabeled test dataset (target domain) is needed at training time, in addition to a labeled training dataset (source domain). Ac- cordingly, it might fail to handle more practical scenariosFeature 𝐹Robust batch normalization (RBN)Update𝜇௚, 𝜎௚ଶNormalizeFeature𝐹′Update bank with current sample  Training lossℒ௥in Eq. (7) Teacher StudentAdaptation with RBNMemorybankEMA 𝑡A stream of online dataUpdateTest timeCorrelationsamplingStrong & weakaugmentation flowDistributionsCategoryTeacherMajor classhas highest ℋin majorRemoveAddWhen ℋ>ℋSamples to beadded& removed Figure 2. Framework overview. Firstly, we replace the batch normalization layer with RBN which robustly normalizes the feature map. During the inference of the online test stream of PTTA, we utilize the predictions of samples to maintain a memory bank by category- balanced sampling with timeliness and uncertainty. Finally, we use the category-balanced, timely and confident data in the memory bank combined with a robust loss to adapt the model at test time. like test-time adaptation. Our practical test-time adaptation setting can be viewed as performing correlatively sample adaptation on the fly. It is worth noting that standard domain adaptation techniques might collapse when only continual data streams from multiple target domains are accessible. Domain generalization (DG) assumes that multiple source domains are available for model training and tries to learn models that can generalize well to any unseen domains [4, 26,40,41,52,84]. A broad spectrum of methodologies based on data augmentation [78, 84], meta-learning [14, 40], or domain alignment [50,52] has made great progress. In con- trast, this work instead aims to improve the performance of source pre-trained models at the test time by using unla- beled online data streams from multiple continually chang- ing target domains. Continual learning (CL) (also known as incremental learning, life-long learning) addresses the problem of learn- ing a model for many tasks sequentially without forgetting knowledge obtained from the preceding tasks. [1, 6, 31, 37, 60]. CL methods can often be categorized into replay- based [60, 66] and regularization-based [31, 44] methods. Ideas from continual learning are also adopted for continu- ous domain adaptation approaches [34, 74] In our work, we share the same motivation as CL and point out that prac- tical test-time adaptation (PTTA) also suffers catastrophic forgetting (i.e., performance degradation on new test sam- ples due to correlation sampling), which makes test-time adaptation approaches are unstable to deploy. Test-time adaptation (TTA) focus on more challenging settings where only source model and unlabeled target data are available [9, 18, 27, 28, 35, 46, 61]. A similar paradigm is source-free domain adaptation (SFDA) [10, 36, 47, 79], which also requires no access to the training (source) data. To name a few, Liang et al . [45] fit the source hypoth- esis by exploiting the information maximization and self- supervised pseudo-labeling. Kundu et al. [35] formalize a unified solution that explores SFDA without any category- gap knowledge. To fully utilize any arbitrary pre-trained model, Sun et al. [65] propose conducting adaptation on the fly with an auxiliary self-supervised task. Later on, Wanget al. [70] take a source pre-trained model and adapt it to the test data by updating a few trainable parameters in Batch- Norm layers [25] using entropy minimization [21]. While standard TTA has been widely studied in many tasks [2, 20, 63, 64, 70, 82], the fact remains that both dis- tribution changing [73] and data correlation sampling [19] has only been considered in isolation. For example, Gong et al. [19] propose instance-aware batch normalization and prediction-balanced reservoir sampling to address the chal- lenges of correlatively sampled test streams, however, it does not consider unstable adaptation resulting from long- term adaptation on continually changing distributions. On the other hand, Wang et al. [73] assume that the target test data is streamed from a continually changing environment and continually adapt an off-the-shelf source pre-trained model to the current test data. In this work, we launch PTTA, a more practical TTA setting to connect both worlds: distribution changing and correlation sampling. 3. Method 3.1. Problem Definition and Motivation Given a model fθ0 with parameter θ0 pre-trained on source domain DS = {(xS, yS)}, the proposed practical test-time adaptation (PTTA) aims to adapt fθ0 to a stream of online unlabeled samples X0, X1, ...,XT , where Xt is a batch of highly correlated samples from the distribution Ptest that changes with time t continually. More specifi- cally, at test time, with time going on, the test distribution Ptest changes continually as P0, P1, ...,P∞. At time step t, we will receive a batch of unlabeled and correlated samplesmotion distribution changing snow time  Distributions and Labels of PTTA T est Stream uniform 10 1 0.1 0.01 0.001 Dirichlet Parameter  Figure 3. Illustration of the labels and distributions of the test stream of CIFAR10-C under the setup PTTA. And we adopt Dirichlet distribution to simulate the process of correlative sam- pling. It is clear that as the concentration parameter δ decreases, the correlation among sampled data increases, which is reflected in the increasing aggregation of categories. Xt from Ptest. Next, Xt is fed into the model fθt and the model needs to adapt itself to the current test data streams and make predictions fθt (Xt) on the fly. As a matter of fact, this setup is largely driven the prac- tical demands of deploying models in dynamic scenarios. Taking for example the case of autonomous driving men- tioned in § 1, test samples are highly correlated and the data distribution changes continually with the weather or loca- tion. Another example is the situation of intelligent moni- toring, the camera will continuously capture more people at certain times, such as after work, but fewer of them during work time. Meanwhile, the light condition changes con- tinually from day to night. The deployed model should be robustly adapted in such dynamic scenarios. In a word, dis- tribution change and data correlation often happen simul- taneously in the real world. For this reason, existing TTA methods [7,9,19,28,70,73,81] might become unstable when the test stream is sampled from such dynamic scenarios. To obtain the test stream of PTTA, we adopt Dirich- let Distribution with parameter δ to simulate the correla- tion among test samples. We present the test data streams corresponding to different values of δ on the CIFAR10-C dataset in Figure 3. We can observe that the smaller δ is, the higher the correlation will be. For the sake of unity, we set δ = 0.1 as the default for all experiments. In the follow- ing, we present a robust test-time adaptation framework for the practical test-time adaptation setup defined above. An overview of our RoTTA is illustrated in Figure 2. 3.2. Robust Test-Time Adaptation Motivated by the fact that the statistics of current batch data, which are commonly used in previous TTA meth- ods [7, 20, 65, 70, 73], become unreliable when they en- counter correlative test data streams, we first turn to the global robust statistics for normalization. Then, to effec- tively adapt to the current distribution, we maintain a mem- ory bank by category-balanced sampling with considering timeliness and uncertainty, which captures a more stable snapshot of the distribution. Finally, we utilize the teacher- student model and design a timeliness-based reweighting strategy to train the model robustly. Robust batch normalization (RBN). Batch Normaliza- tion (BN) [25] is a widely-used training technique as it can accelerate the training and convergence speed of networks and stabilize the training process by reducing the risk of gradient explosion and vanishing. Given the feature map F ∈ RB×C×H×W as the input for a BN layer when train- ing, the channel-wise mean µ ∈ RC and variance σ2 ∈ RC are calculated as follows: µc = 1 BHW BX b=1 HX h=1 WX w=1 F(b,c,h,w) , (1) σ2 c = 1 BHW BX b=1 HX h=1 WX w=1 (F(b,c,h,w) − µc)2 . (2) Then the feature map is normalized and refined in a channel-wise manner as BN (F(b,c,h,w); µ, σ2) =γc F(b,c,h,w) − µc √σ2c + ϵ + βc , (3) where γ, β∈ RC are learnable parameters in the layer and ϵ > 0 is a constant for numerical stability. Meanwhile, during training, the BN layer maintains a group of global running mean and running variance (µs, σ2 s) for inference. Due to the domain shift at test time, the global statis- tics (µs, σ2 s) normalize test features inaccurately, causing significant performance degradation. To tackle the prob- lem above, some methods [55, 70, 73] use the statistics of the current batch to perform normalization. Unfortunately, when the test samples have a high correlation under PTTA setup, the statistics of the current batch also fail to correctly normalize the feature map, as demonstrated in Figure 4c. Specifically, the performance of BN [53] decreases rapidly as the data correlation increases. Based on the analysis above, we propose a robust batch normalization (RBN) module, which maintains a group of global statistics (µg, σ2 g) to normalize the feature map ro- bustly. Before the whole test-time adaptation, (µg, σ2 g) is initialized as the running mean and variance (µs, σ2 s) of the pre-trained model. When adapting the model, we update the global statistics first by exponential moving average as µg = (1− α)µg + αµ , (4) σ2 g = (1− α)σ2 g + ασ2 , (5) where (µ, σ2) is the statistics of the buffered samples in the memory bank. Then we normalize and affine the feature as Eq. (3) with (µg, σ2 g). When inferring for test samples, we directly utilize (µg, σ2 g) to calculate the output as Eq (3). Al- though simple, RBN is effective enough to tackle the prob- lem of normalization on test streams of PTTA.Category-balanced sampling with timeliness and uncer- tainty (CSTU). In the PTTA setup, the correlation among test samples Xt at time t leads to a deviation between the observed distribution bPtest and the test distribution Ptest. Specifically, the marginal label distribution p(y|t) tends to differ from p(y). Continuously learning with Xt over time t can lead to model adaptation to an unreliable distribution bPtest, resulting in ineffective adaptation and an increased risk of model collapse. To address this issue, we propose a category-balanced memory bank M with a capacity of N, which takes into account the timeliness and uncertainty of samples when up- dating. In particular, we adopt the predictions of test sam- ples as pseudo labels to guide the update ofM. Meanwhile, to guarantee the balance among categories, we distribute the capacity of M equally to each category, and samples of the major categories will be replaced first (refer to lines 5-9 in Algorithm 1). Furthermore, due to the continually changing test distribution, old samples in M are limited in value, and could even impair the ability of the model to adapt to the current distribution. Additionally, samples of high uncer- tainty always produce erroneous gradient information that can hinder model adaptation, as suggested by [55]. With this in mind, we attach each sample in M with a group of heuristics (A, U), where A, initialized as 0 and in- creasing with time t, is the age of the sample, and U the un- certainty calculated as the entropy of the prediction. Next, we combine the timeliness and uncertainty to calculate a heuristic score, i.e., category-balanced sampling with time- liness and uncertainty (CSTU), as follows: H = λt 1 1 + exp(−A/N) + λu U log C , (6) where λt and λu make the trade-off between timeliness and uncertainty, and for simplicity, λt and λu are set to 1.0 for all experiments, andC is the number of categories. We sum- marize our sampling algorithm in Algorithm 1. With CSTU, we can obtain a robust snapshot of the current test distribu- tion Ptest, and effectively adapt the model to it. Robust training with timeliness. Actually, after replacing BN layers with our RBN and obtaining the memory bank selected via CSTU, we can directly adopt the widely used techniques like pseudo labeling or entropy minimization to perform test-time adaptation. However, we notice that too old or unreliable instances still have the opportunity to stay in M since keeping the category balance is assigned the top priority. In addition, too aggressive updates of the model will make the category balance ofM unreliable, resulting in unstable adaptation. Meanwhile, error accumulation caused by the distribution change also makes the aforementioned approaches unworkable. To further reduce the risk of error gradients information from old and unreliable instances and stabilize the adapta- tion, we turn to the robust unsupervised learning method Algorithm 1: CSTU for one test sample. 1 Input: a test sample x and the teacher model fθT . 2 Define: memory bank M and its capacity N, number of classes C, per class occupation O ∈RC, total occupation Ω, classes to pop instance D. 3 Infer as p(y|x) =Softmax(fθT (x)). 4 Calculate the predicted category of x as ˆy = arg maxc p(c|x), the uncertainty as Ux = −PC c=1 p(c|x) log(p(c|x)), the age as Ax = 0, and the heuristic score Hx of x with Eq (6) 5 if Oˆy < N C then 6 if Ω <N: Search range D = ∅. 7 else: Search range D = {j|j = arg maxc Oc} 8 else 9 Search range D = {ˆy} 10 if D is ∅ then 11 Add (x, ˆy, Hx, Ux) into M. 12 else 13 Find the instance (ˆx, yˆx, Aˆx, Uˆx) with the highest value in Eq (6) Hˆx among D. 14 if Hx < Hˆx then 15 Remove (ˆx, yˆx, Aˆx, Uˆx) from M. 16 Add (x, ˆy, Hx, Ux) into M. 17 else 18 Discard x. 19 Increase the age of all instances in M. teacher-student model and propose a timeliness reweight- ing strategy. In addition, for the sake of time efficiency and stability, only affine parameters in RBN are trained during adaptation. At time step t, after inferring for the correlated data Xt with the teacher model fθT t and updating the memory bank M with Xt, we begin updating the student model fθS t and the teacher model fθT t . Firstly, we update parameters of stu- dent model θS t → θS t+1 by minimizing the following loss: Lr = 1 Ω ΩX i=1 L(xM i , Ai; θT t , θS t ) , (7) where Ω = |M| is the total occupation of the memory bank, and xM i and Ai(i = 1, ..., Ω) are instances in the memory bank and their age respectively. Subsequently, the teacher model is updated by exponential moving average as θT t+1 = (1− ν)θT t + νθS t+1 . (8) To calculate the loss value of an instancexM i from the mem- ory bank, the timeliness reweighting term is computed as E(Ai) = exp(−Ai/N) 1 + exp(−Ai/N) , (9)where Ai is the age of xM i , and N is the capacity of the bank. And then we calculate the cross entropy between the soft-max prediction pS(y|x′′ i ) of the strong-augmented view x′′ i from the student model and that pT (y|x′ i) of the weak- augmented view 1 x′ i from the teacher model as follows: ℓ(x′ i, x′′ i ) =−1 C CX c=1 pT (c|x′ i) logpS(c|x′′ i ) . (10) Finally, equipped with Eq. (9) and Eq. (10), the right-hand side of Eq. (7) reduces to L(xM i , Ai; θT t , θS t ) =E(Ai)ℓ(x′ i, x′′ i ) . (11) To sum up, equipped with RBN, CSTU, and robust training with timeliness, our RoTTA is capable of effectively adapt- ing any pre-trained models in dynamic scenarios. 4. Experiments 4.1. Setup Datasets. CIFAR10-C and CIFAR100-C [23] are the com- monly used TTA benchmarks to testify the robustness un- der corruptions. Both of them are obtained by applying 15 kinds of corruption with 5 different degrees of severity on their clean test images of original datasets CIFAR10 and CIFAR100 respectively. CIFAR10/CIFAR100 [32] have 50,000/10,000 training/test images, all of which fall into 10/100 categories. DomainNet [58] is the largest and hard- est dataset to date for domain adaptation and consists of about 0.6 million images with 345 classes. It consists of six different domains including Clipart (clp), Infograph (inf), Painting (pnt), Quickdraw (qdr), Real (rel), and Sketch (skt). We first pre-train a source model on the train set in one of six domains and testify all baseline methods on the test set of the remaining five domains. Implementation details. All experiments are conducted with PyTorch [57] framework. In the case of robustness to corruption, following the previous methods [55, 70, 73], we obtain the pre-trained model from RobustBench bench- mark [12], including the WildResNet-28 [80] for CIFAR10 → CIFAR10-C, and the ResNeXt-29 [76] for CIFAR100 → CIFAR100-C. Then, we change the test corruption at the highest severity 5 one by one to simulate that the test distri- bution continually changes with time in PTTA. And in the case of generalization under the huge domain gap, we train a ResNet-101 [22] by standard classification loss for each domain in DomainNet and adapt them continually to differ- ent domains except the source domain. Meanwhile, we uti- lize the Dirichlet distribution to simulate the correlatively sampled test stream for all datasets. For optimization, we adopt Adam [30] optimizer with learning rate 1.0 × 10−3, 1Weak augmentation is ReSize+CenterCrop. Strong augmentation is a combination nine operations like Clip, ColorJitter, and RandomAffine. β = 0.9. For a fair comparison, we set the batch size for all methods as 64 and the capacity of the memory bank of RoTTA as N = 64. Concerning the hyperparameters, we adopt a unified set of values for RoTTA across all experi- ments including α = 0.05, ν = 0.001, λt = 1.0, λu = 1.0, and δ = 0.1. More details are provided in the appendix. 4.2. Comparisons with the State-of-the-arts Robustness under corruptions. The classification error on CIFAR10→CIFAR10-C and CIFAR100→CIFAR100-C are shown in Table 2 and Table 3 respectively. We change the type of the current corruption at the highest severity 5 as time goes on, and sample data correlatively for infer- ence and adaptation simultaneously. The same test stream is shared across all compared methods. From Table 2 and Table 3, we can see that RoTTA achieves the best performance compared to previous meth- ods. Moreover, RoTTA has a significant performance gain to the second-best method that 5.9% improvement on CIFAR10 →CIFAR10-C and 5.5% improvement on CIFAR100→CIFAR100-C respectively, verifying the effec- tiveness of RoTTA to adapt the model under PTTA. In more detail, we can observe that BN [53], PL [39], TENT [70] and CoTTA [73] negatively adapt the model to the test streams of both datasets compared to Source (−6.5 ∼ −46.4%). This is attributed to the fact that these methods overlook the issues posed by correlation sampling, which can result in highly correlated data within a batch. As a consequence, traditional normalization statistics may be ineffective in appropriately normalizing the feature maps. Equipped with RBN and CSTU, RoTTA no longer suffers from this issue. Meanwhile, in Table 3, if focus on the adaptation procedure, we can see that the performance of PL [39], TENT [70] and NOTE [19] becomes worse and worse, and eventually, the model even collapses (error rate > 97%). This reveals that the impact of error accumula- tion on long-term adaptation can be catastrophic. To tackle this problem, RoTTA turns to robustly adapt the model with timeliness reweighting and confident samples in the mem- ory bank, and superior performance throughout the adapta- tion process demonstrates its effectiveness. In addition, we find that although LAME [5] never tunes the parameters of the model, it is still a competi- tive baseline for example it achieves the second-best result on CIFAR100→CIFAR100-C. However, its performance is very dependent on the performance of the pre-trained model e.g. negligible improvement on difficult corruptions (shot, gaussian, pixelate). On the contrary, our RoTTA is more flexible and achieves better and more robust results. Generalization under domain shift. We also evalu- ate RoTTA under a more challenging dataset DomainNet, where we continually adapt a source pre-trained model to correlatively sampled test streams of the rest domains. AsTable 2. Average classification error of the task CIFAR10→ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time t− − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − → Method motionsnow fog shot defocuscontrastzoom brightnessfrost elasticglass gaussianpixelatejpeg impulse Avg. Source 34.8 25.1 26.0 65.7 46.9 46.7 42.0 9.3 41.3 26.6 54.3 72.3 58.5 30.3 72.9 43.5BN [53] 73.2 73.4 72.7 77.2 73.7 72.5 72.9 71.0 74.1 77.7 80.0 76.9 75.5 78.3 79.0 75.2PL [39] 73.9 75.0 75.6 81.0 79.9 80.6 82.0 83.2 85.3 87.3 88.3 87.5 87.5 87.5 88.2 82.9TENT [70] 74.3 77.4 80.1 86.2 86.7 87.3 87.9 87.4 88.2 89.0 89.2 89.0 88.3 89.7 89.2 86.0LAME [5] 29.5 19.0 20.3 65.3 42.4 43.4 36.8 5.4 37.2 18.6 51.2 73.2 57.0 22.6 71.3 39.5CoTTA [73]77.1 80.6 83.1 84.4 83.9 84.2 83.1 82.6 84.4 84.2 84.5 84.6 82.7 83.8 84.9 83.2NOTE [19] 18.0 22.1 20.6 35.6 26.9 13.6 26.5 17.3 27.2 37.0 48.3 38.8 42.6 41.9 49.7 31.1 RoTTA 18.1 21.3 18.8 33.6 23.6 16.5 15.1 11.2 21.9 30.7 39.6 26.8 33.7 27.8 39.5 25.2(+5.9) Table 3. Average classification error of the task CIFAR100 → CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time t− − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − → Method motionsnow fog shot defocuscontrastzoom brightnessfrost elasticglass gaussianpixelatejpeg impulse Avg. Source 30.8 39.5 50.3 68.0 29.3 55.1 28.8 29.5 45.8 37.2 54.1 73.0 74.7 41.2 39.4 46.4BN [53] 48.5 54.0 58.9 56.2 46.4 48.0 47.0 45.4 52.9 53.4 57.1 58.2 51.7 57.1 58.8 52.9PL [39] 50.6 62.1 73.9 87.8 90.8 96.0 94.8 96.4 97.4 97.2 97.4 97.4 97.3 97.4 97.4 88.9TENT [70] 53.3 77.6 93.0 96.5 96.7 97.5 97.1 97.5 97.3 97.2 97.1 97.7 97.6 98.0 98.3 92.8LAME [5] 22.4 30.4 43.9 66.3 21.3 51.7 20.6 21.8 39.6 28.0 48.7 72.8 74.6 33.1 32.3 40.5CoTTA [73]49.2 52.7 56.8 53.0 48.7 51.7 49.4 48.7 52.5 52.2 54.3 54.9 49.6 53.4 56.2 52.2NOTE [19] 45.7 53.0 58.2 65.6 54.2 52.0 59.8 63.5 74.8 91.8 98.1 98.3 96.8 97.0 98.2 73.8 RoTTA 31.8 36.7 40.9 42.1 30.0 33.6 27.9 25.4 32.3 34.0 38.8 38.7 31.3 38.0 42.9 35.0(+5.5) Table 4. Average classification error of DomainNet while continually adapting to different domains with correlatively sampled test stream. Timet− − − − − − − − − − − − − − − − − − →Timet− − − − − − − − − − − − − − − − − − →Timet− − − − − − − − − − − − − − − − − − →Timet− − − − − − − − − − − − − − − − − − →Sourceclp inf pnt qdr rel sktAvg. BN clp inf pnt qdr rel sktAvg. PL clp inf pnt qdr rel sktAvg.TENTclp inf pnt qdr rel sktAvg. clp N/A 83.9 65.4 88.6 48.0 59.1 69.0clp N/A 88.6 70.7 90.5 65.4 67.0 76.5clp N/A 94.5 98.9 99.5 99.7 99.7 98.5clp N/A 87.5 71.9 94.2 96.2 98.9 89.7inf 61.8 N/A 66.9 96.0 50.0 70.6 69.1inf 68.6 N/A 74.2 96.2 69.9 76.8 77.1inf 82.6 N/A 99.2 99.6 99.7 99.3 96.1inf 68.6 N/A 75.0 97.3 95.9 98.7 87.1pnt 56.5 83.7 N/A 94.2 42.6 63.4 68.1pnt 60.8 87.9 N/A 94.3 62.3 68.7 74.8pnt 78.6 99.4 N/A 99.7 99.6 99.7 95.4pnt 61.7 87.1 N/A 96.4 95.3 98.8 87.8qdr 89.2 99.0 98.6 N/A 95.0 92.3 94.8qdr 80.3 97.7 92.6 N/A 88.7 88.1 89.5qdr 81.7 99.5 99.6 N/A 99.7 99.8 96.1qdr 78.9 97.1 91.6 N/A 89.2 88.7 89.1rel 49.4 80.4 51.5 93.4 N/A 63.3 67.6rel 57.9 87.1 63.1 94.3 N/A 70.8 74.6rel 73.5 99.4 99.2 99.6 N/A 99.7 94.3rel 57.8 86.4 68.1 96.9 N/A 96.7 81.2skt 47.5 88.2 62.9 87.1 51.8 N/A 67.5skt 50.4 87.6 64.6 89.6 63.1 N/A 71.1skt 64.8 99.2 99.4 99.7 99.7 N/A 92.6skt 51.9 87.2 69.1 95.3 97.3 N/A 80.1Avg.60.9 87.0 69.1 91.9 57.5 69.7 72.7Avg.63.6 89.8 73.0 93.0 69.9 74.3 77.3Avg.76.2 98.4 99.3 99.6 99.7 99.6 95.5Avg.63.8 89.0 75.1 96.0 94.8 96.4 85.8 Timet− − − − − − − − − − − − − − − − − − →Timet− − − − − − − − − − − − − − − − − − →Timet− − − − − − − − − − − − − − − − − − →Timet− − − − − − − − − − − − − − − − − − →LAMEclp inf pnt qdr rel sktAvg.COTTAclp inf pnt qdr rel sktAvg.NOTEclp inf pnt qdr rel sktAvg.RoTTAclp inf pnt qdr rel sktAvg. clp N/A 82.2 64.5 87.7 46.9 58.9 68.0clp N/A 90.6 77.9 89.3 76.3 72.7 81.4clp N/A 89.2 73.0 94.8 98.4 99.4 91.0clp N/A 85.5 62.0 82.0 49.3 59.8 67.7inf 60.1 N/A 65.7 95.4 48.5 69.4 67.8inf 74.5 N/A 82.0 95.7 80.2 81.5 82.8inf 75.4 N/A 78.7 98.7 98.1 99.5 90.1inf 61.8 N/A 63.7 91.5 52.5 67.6 67.4pnt 55.8 81.5 N/A 93.3 41.3 62.1 66.8pnt 66.3 89.8 N/A 93.4 74.0 75.4 79.8pnt 64.7 89.8 N/A 97.8 98.4 99.2 90.0pnt 53.3 84.1 N/A 89.1 47.3 61.4 67.0qdr 88.3 99.1 99.0 N/A 94.9 92.2 94.7qdr 82.3 98.2 94.6 N/A 92.5 90.1 91.5qdr 74.7 97.2 92.2 N/A 93.5 99.6 91.4qdr 77.5 97.0 89.8 N/A 80.3 82.2 85.3rel 48.0 79.3 50.1 91.6 N/A 60.2 65.8rel 64.0 90.3 73.2 93.5 N/A 77.6 79.7rel 61.3 89.2 68.9 98.8 N/A 99.2 83.5rel 49.1 82.3 50.3 88.0 N/A 61.1 66.2skt 45.6 87.1 59.5 83.9 49.9 N/A 65.2skt 56.1 89.2 71.9 89.2 73.5 N/A 76.0skt 55.2 89.7 70.1 96.9 98.3 N/A 82.0skt 42.6 83.7 54.4 80.9 47.5 N/A 61.8Avg.59.6 85.8 67.8 90.4 56.3 68.6 71.4Avg.68.6 91.6 79.9 92.2 79.3 79.5 81.9Avg.66.3 91.0 76.6 97.4 97.3 99.4 88.0Avg.56.8 86.5 64.0 86.3 55.4 66.469.2(+2.2) shown in Table 4, consistent with the previous analysis, most of the methods include BN [53], PL [39], TENT [70], CoTTA [73] and NOTE [19] even perform worse than the Source model ( −4.6 ∼ −22.8%). RoTTA consistently achieves the best performance and has 2.2% gain than the second method LAME [5], demonstrating RoTTA’s effec- tiveness again. 4.3. Ablation Study Effect of each component. To further investigate the effi- cacy of each component, we replace each part with the nor- mally used solutions to obtain three variants: (1) RoTTA w/o RBN, replace RBN with test-time BN in TENT [70]; (2) RoTTA w/o CSTU, directly adapt the model on test stream; (3) RoTTA w/o robust training (RT), directly adapt the model only with entropy minimization. As shown in Table 5, we can observe that significant performance degra- dation occurs for all variants, proving that every part of our proposed method is valid for PTTA. Take one com- ponent for a detailed example, without RBN robustly nor- malizing feature maps, the performance of RoTTA drops 50.2% and 16.3% on CIFAR10-C and CIFAR100-C respec- tively, proving that RBN is robust enough to tackle the prob- lem of normalization of correlatively sampled data streams. CSTU enables RoTTA to adapt to a more stable distribu- tion by maintaining a timely and confident snapshot of the test distribution. Meanwhile, robust training with timeliness greatly reduces the accumulation of errors. Every compo- nent behaves significantly to enable effective adaptation un- der PTTA. Effect of the distribution changing order. To exclude the effect of a fixed order of distribution changing, we con- ducted experiments on ten different sequences of changes on CIFAR10-C and CIFAR100-C with independently andBN PL TENT LAME CoTTA NOTE RoTTA0 10 20 30 40 50 60 70 80Classification error (%) Source CIFAR-10  CIFAR-10-C Independent Correlative (a) CIFAR10-C. BN PL TENT LAME CoTTA NOTE RoTTA0 20 40 60 80Classification error (%) Source CIFAR-100  CIFAR-100-C Independent Correlative (b) CIFAR100-C. uniform 10 1 0.1 0.01 0.001 30 40 50 60 70 80 90 100Classification error (%) Source BN PL TENT LAME CoTTA NOTE RoTTA (c) δ. 16 32 64 128 256 512 40 50 60 70 80 90 100Classification error (%) Source BN PL TENT LAME CoTTA NOTE RoTTA (d) Batch size. Figure 4. (a) & (b) we adapt the model continually to different corruptions of 10 different orders with independently and correlatively sampled test streams on CIFAR10-C and CFAR100-C respectively and report their average classification error. (c) & (d) we verify the effect of δ and batch size to different methods on CIFAR100-C respectively. Table 5. Classification error of different variants of our RoTTA. Variant CIFAR10-C CIFAR100-C Avg. RoTTA w/o RBN 75.4 51.3 63.4 RoTTA w/o CSTU 47.1 46.3 46.7 RoTTA w/o RT 78.2 95.0 81.6 RoTTA 25.2 35.0 30.1 correlatively sampled test streams respectively. As shown in Figure 4a and 4b, no matter what kind of setup, RoTTA can achieve excellent results. The detailed results on the correlatively sampled test streams are shown in Table 6, RoTTA achieves 4.3% and 4.7% progress on CIFAR10- C and CIFAR100-C respectively. This shows that RoTTA can adapt the model robustly and effectively in long-term scenarios where distribution continually changes and test streams are sampled either independently or correlatively, making it a good choice for model deployment. Effect of Dirichlet concentration parameter δ. We vary the value of δ on CIFAR100-C and compare RoTTA with other approaches in Figure 4c. As the value of δ increases, the performance of BN [53], PL [39], TENT [70] and CoTTA [73] drops quickly, because they never consider the increasing correlation among test samples. NOTE [19] is stable to correlatively sampled test streams but does not consider the distribution changing, causing ineffective adaptation. Meanwhile, the higher correlation between test samples will make the propagation of labels more accurate, which is why the result of LAME [5] slightly improves. Fi- nally, excellent and stable results once again prove the sta- bility and effectiveness of RoTTA. Effect of batch size. In real scenarios, considering deploy- ment environments may use different test batch sizes, we conduct experiments with different values of test batch sizes and results are shown in Figure 4d. For a fair comparison, we control the frequency of updating the model of RoTTA so that the number of samples involved in back-propagation is the same. As the batch size increases, we can see that all of the compared methods have a significant improvement except for lame which has a slight decrease. This is be- cause the number of categories in a batch increases with the Table 6. Average classification error of tasks CIFAR10 → CIFAR10-C and CIFAR100 → CIFAR100-C while continually adapting to different corruptions of 10 different orders at the high- est severity 5 with correlatively sampled test stream. Method CIFAR10-C CIFAR100-C Avg. Source 43.5 46.4 46.9 BN [53] 75.2 52.9 64.1 PL [39] 75.2 52.9 60.1 TENT [70] 82.3 93.2 87.8 LAME [5] 39.5 40.6 40.1 NOTE [19] 30.5 76.1 53.3 CoTTA [73] 83.1 52.8 67.9 RoTTA 26.2(+4.3) 35.9(+4.7) 31.1(+9.0) increasing batch size, causing the overall correlation to be- come lower but the propagation of labels to become more difficult. Most significantly, RoTTA achieves the best re- sults across different batch sizes, demonstrating its robust- ness in dynamic scenarios once again. 5. Conclusion This work proposes a more realistic TTA setting where distribution changing and correlative sampling occur si- multaneously at the test phase, namely Practical Test-Time Adaptation (PTTA). To tackle the problems of PTTA, we propose Robust Test-Time Adaptation (RoTTA) method against the complex data stream. More specifically, a group of robust statistics for the normalization of feature maps is estimated by robust batch normalization. Meanwhile, a memory bank is adopted to capture a snapshot of the test distribution by category-balanced sampling with consider- ing timeliness and uncertainty. Further, we develop a time- aware reweighting strategy with a teacher-student model to stabilize the adaptation process. Extensive experiments and ablation studies are conducted to verify the robustness and effectiveness of the proposed method. We believe this work will pave the way for thinking about adapting models into real-world applications by test-time adaptation algorithm. Acknowledgements. This paper was supported by National Key R&D Program of China (No. 2021YFB3301503), and also supported by the National Natural Science Foundation of China under Grant No. 61902028.References [1] Rahaf Aljundi, Min Lin, Baptiste Goujaud, and Yoshua Ben- gio. Gradient based sample selection for online continual learning. In NeurIPS, pages 11816–11825, 2019. 3 [2] Fatemeh Azimi, Sebastian Palacio, Federico Raue, J ¨orn Hees, Luca Bertinetto, and Andreas Dengel. Self-supervised test-time adaptation on video data. In WACV, pages 2603– 2612, 2022. 1, 3 [3] Mathilde Bateson, Herve Lombaert, and Ismail Ben Ayed. Test-time adaptation with shape moments for image segmen- tation. In MICCAI, pages 736–745, 2022. 1 [4] Gilles Blanchard, Gyemin Lee, and Clayton Scott. General- izing from several related classification tasks to a new unla- beled sample. In NeurIPS, pages 2178–2186, 2011. 3 [5] Malik Boudiaf, Romain Mueller, Ismail Ben Ayed, and Luca Bertinetto. Parameter-free online test-time adaptation. In CVPR, pages 8344–8353, 2022. 2, 6, 7, 8, 13, 14, 15, 16, 17 [6] Francisco M Castro, Manuel J Mar ´ın-Jim´enez, Nicol´as Guil, Cordelia Schmid, and Karteek Alahari. End-to-end incre- mental learning. In ECCV, pages 233–248, 2018. 3 [7] Dian Chen, Dequan Wang, Trevor Darrell, and Sayna Ebrahimi. Contrastive test-time adaptation. In CVPR, pages 295–305, 2022. 1, 4 [8] Yuhua Chen, Wen Li, Christos Sakaridis, Dengxin Dai, and Luc Van Gool. Domain adaptive faster r-cnn for object de- tection in the wild. In CVPR, pages 3339–3348, 2018. 2 [9] Zhixiang Chi, Yang Wang, Yuanhao Yu, and Jin Tang. Test- time fast adaptation for dynamic scene deblurring via meta- auxiliary learning. In CVPR, pages 9137–9146, 2021. 3, 4 [10] Boris Chidlovskii, St ´ephane Clinchant, and Gabriela Csurka. Domain adaptation in the absence of source domain data. In KDD, pages 451–460, 2016. 3 [11] Sungha Choi, Seunghan Yang, Seokeon Choi, and Sun- grack Yun. Improving test-time adaptation via shift-agnostic weight regularization and nearest source prototypes. In ECCV, pages 440–458, 2022. 1 [12] Francesco Croce, Maksym Andriushchenko, Vikash Se- hwag, Edoardo Debenedetti, Nicolas Flammarion, Mung Chiang, Prateek Mittal, and Matthias Hein. Robustbench: a standardized adversarial robustness benchmark. In Neurips, 2021. 6 [13] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl- vain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. In ICLR, 2021. 1 [14] Ying-Jun Du, Jun Xu, Huan Xiong, Qiang Qiu, Xiantong Zhen, Cees G. M. Snoek, and Ling Shao. Learning to learn with variational information bottleneck for domain general- ization. In ECCV, pages 200–216, 2020. 3 [15] Sayna Ebrahimi, Sercan ¨O. Arik, and Tomas Pfister. Test- time adaptation for visual document understanding. CoRR, abs/2206.07240, 2022. 1 [16] Yossi Gandelsman, Yu Sun, Xinlei Chen, and Alexei A Efros. Test-time training with masked autoencoders. In NeurIPS, 2022. 1 [17] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pas- cal Germain, Hugo Larochelle, Franc ¸ois Laviolette, Mario Marchand, and Victor S. Lempitsky. Domain-adversarial training of neural networks. J. Mach. Learn. Res., 17:59:1– 59:35, 2016. 1, 2 [18] Yunhe Gao, Xingjian Shi, Yi Zhu, Hao Wang, Zhiqiang Tang, Xiong Zhou, Mu Li, and Dimitris N. Metaxas. Vi- sual prompt tuning for test-time domain adaptation. CoRR, abs/2210.04831, 2022. 3 [19] Taesik Gong, Jongheon Jeong, Taewon Kim, Yewon Kim, Jinwoo Shin, and Sung-Ju Lee. Robust continual test- time adaptation: Instance-aware BN and prediction-balanced memory. In NeurIPS, 2022. 1, 2, 3, 4, 6, 7, 8, 13, 14, 15, 16, 17 [20] Sachin Goyal, Mingjie Sun, Aditi Raghunathan, and J Zico Kolter. Test time adaptation via conjugate pseudo-labels. In NeurIPS, 2022. 1, 3, 4 [21] Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. In NeurIPS, pages 529– 536, 2004. 3 [22] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, pages 770–778, 2016. 1, 6 [23] Dan Hendrycks and Thomas G. Dietterich. Benchmarking neural network robustness to common corruptions and per- turbations. In ICLR, 2019. 2, 6 [24] Hengguan Huang, Xiangming Gu, Hao Wang, Chang Xiao, Hongfu Liu, and Ye Wang. Extrapolative continuous-time bayesian neural network for fast training-free test-time adap- tation. In NeurIPS, 2022. 1 [25] Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal co- variate shift. In ICML, pages 448–456, 2015. 3, 4 [26] Yusuke Iwasawa and Yutaka Matsuo. Test-time classifier ad- justment module for model-agnostic domain generalization. In NeurIPS, pages 2427–2440, 2021. 1, 3 [27] Vidit Jain and Erik Learned-Miller. Online domain adapta- tion of a pre-trained cascade of classifiers. In CVPR, pages 577–584, 2011. 3 [28] Minguk Jang and Sae-Young Chung. Test-time adaptation via self-training with nearest neighbor information. CoRR, abs/2207.10792, 2022. 3, 4 [29] Junho Kim, Inwoo Hwang, and Young Min Kim. Ev-tta: Test-time adaptation for event-based object recognition. In CVPR, pages 17724–17733, 2022. 1 [30] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015. 6 [31] James Kirkpatrick, Razvan Pascanu, Neil C. Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A. Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska- Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Ku- maran, and Raia Hadsell. Overcoming catastrophic forget- ting in neural networks. CoRR, abs/1612.00796, 2016. 3 [32] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009. 6[33] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep convolutional neural net- works. In NeurIPS, pages 1097–1105, 2012. 1 [34] Ananya Kumar, Tengyu Ma, and Percy Liang. Understand- ing self-training for gradual domain adaptation. In ICML, pages 5468–5479, 2020. 3 [35] Jogendra Nath Kundu, Naveen Venkat, Rahul M. V ., and R. Venkatesh Babu. Universal source-free domain adapta- tion. In CVPR, pages 4543–4552, 2020. 3 [36] Vinod K Kurmi, Venkatesh K Subramanian, and Vinay P Namboodiri. Domain impression: A source data free do- main adaptation method. In WACV, pages 615–625, 2021. 3 [37] Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Ales Leonardis, Gregory G. Slabaugh, and Tinne Tuytelaars. A continual learning survey: Defying for- getting in classification tasks. IEEE Trans. Pattern Anal. Mach. Intell., 44(7):3366–3385, 2022. 3 [38] Yann LeCun, Yoshua Bengio, and Geoffrey E. Hinton. Deep learning. Nat., 521(7553):436–444, 2015. 1 [39] Dong-Hyun Lee et al. Pseudo-label: The simple and effi- cient semi-supervised learning method for deep neural net- works. In Workshop on challenges in representation learn- ing, ICML, volume 3, page 896, 2013. 6, 7, 8, 12, 14, 15, 16, 17 [40] Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M. Hospedales. Learning to generalize: Meta-learning for do- main generalization. In AAAI, pages 3490–3497, 2018. 1, 3 [41] Haoliang Li, Sinno Jialin Pan, Shiqi Wang, and Alex C. Kot. Domain generalization with adversarial feature learning. In CVPR, pages 5400–5409, 2018. 1, 3 [42] Shuang Li, Binhui Xie, Qiuxia Lin, Chi Harold Liu, Gao Huang, and Guoren Wang. Generalized domain conditioned adaptation network. IEEE Trans. Pattern Anal. Mach. Intell., 44(8):4093–4109, 2022. 1 [43] Shuang Li, Mixue Xie, Kaixiong Gong, Chi Harold Liu, Yulin Wang, and Wei Li. Transferable semantic augmen- tation for domain adaptation. In CVPR, pages 11516–11525, 2021. 2 [44] Zhizhong Li and Derek Hoiem. Learning without forgetting. IEEE Trans. Pattern Anal. Mach. Intell., 40(12):2935–2947, 2018. 3 [45] Jian Liang, Dapeng Hu, and Jiashi Feng. Do we really need to access the source data? source hypothesis transfer for un- supervised domain adaptation. In ICML, pages 6028–6039, 2020. 1, 3 [46] Yuejiang Liu, Parth Kothari, Bastien van Delft, Baptiste Bellot-Gurlet, Taylor Mordan, and Alexandre Alahi. TTT++: when does self-supervised test-time training fail or thrive? In NeurIPS, pages 21808–21820, 2021. 3 [47] Yuang Liu, Wei Zhang, and Jun Wang. Source-free do- main adaptation for semantic segmentation. In CVPR, pages 1215–1224, 2021. 3 [48] Mingsheng Long, Yue Cao, Zhangjie Cao, Jianmin Wang, and Michael I. Jordan. Transferable representation learning with deep adaptation networks. IEEE Trans. Pattern Anal. Mach. Intell., 41(12):3071–3085, 2019. 1, 2 [49] Wenao Ma, Cheng Chen, Shuang Zheng, Jing Qin, Huimao Zhang, and Qi Dou. Test-time adaptation with calibration of medical image classification nets for label distribution shift. In MICCAI, pages 313–323, 2022. 1 [50] Divyat Mahajan, Shruti Tople, and Amit Sharma. Domain generalization using causal matching. In ICML, pages 7313– 7324, 2021. 3 [51] Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh. Domain adaptation: Learning bounds and algorithms. In COLT, 2009. 2 [52] Krikamol Muandet, David Balduzzi, and Bernhard Sch¨olkopf. Domain generalization via invariant fea- ture representation. In ICML, pages 10–18, 2013. 1, 3 [53] Zachary Nado, Shreyas Padhy, D. Sculley, Alexander D’Amour, Balaji Lakshminarayanan, and Jasper Snoek. Evaluating prediction-time batch normalization for robust- ness under covariate shift. CoRR, abs/2006.10963, 2020. 4, 6, 7, 8, 12, 14, 15, 16, 17 [54] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan. Efficient test- time model adaptation without forgetting. In ICML, pages 16888–16905, 2022. 1 [55] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan. Efficient test- time model adaptation without forgetting. In ICML, volume 162, pages 16888–16905, 2022. 4, 5, 6 [56] Sinno Jialin Pan and Qiang Yang. A survey on transfer learning. IEEE Trans. Knowl. Data Eng., 22(10):1345–1359, 2010. 1 [57] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. In NeurIPS, pages 8024–8035, 2019. 6 [58] Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, and Bo Wang. Moment matching for multi-source domain adaptation. In ICCV, pages 1406–1415, 2019. 2, 6 [59] Joaquin Quinonero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil D Lawrence. Dataset shift in ma- chine learning. 2008. 1 [60] Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, and Christoph H. Lampert. icarl: Incremental classi- fier and representation learning. InCVPR, pages 5533–5542, 2017. 3 [61] Amelie Royer and Christoph H Lampert. Classifier adapta- tion at prediction time. In CVPR, pages 1401–1409, 2015. 3 [62] Kuniaki Saito, Kohei Watanabe, Yoshitaka Ushiku, and Tat- suya Harada. Maximum classifier discrepancy for unsuper- vised domain adaptation. In CVPR, pages 3723–3732, 2018. 2 [63] Inkyu Shin, Yi-Hsuan Tsai, Bingbing Zhuang, Samuel Schulter, Buyu Liu, Sparsh Garg, In So Kweon, and Kuk- Jin Yoon. MM-TTA: multi-modal test-time adaptation for 3d semantic segmentation. In CVPR, pages 16907–16916, 2022. 1, 3[64] Manli Shu, Weili Nie, De-An Huang, Zhiding Yu, Tom Goldstein, Anima Anandkumar, and Chaowei Xiao. Test- time prompt tuning for zero-shot generalization in vision- language models. In NeurIPS, 2022. 1, 3 [65] Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt. Test-time training with self- supervision for generalization under distribution shifts. In ICML, pages 9229–9248, 2020. 1, 2, 3, 4 [66] Rishabh Tiwari, KrishnaTeja Killamsetty, Rishabh K. Iyer, and Pradeep Shenoy. GCR: gradient coreset based replay buffer selection for continual learning. In CVPR, pages 99– 108, 2022. 3 [67] Yi-Hsuan Tsai, Wei-Chih Hung, Samuel Schulter, Ki- hyuk Sohn, Ming-Hsuan Yang, and Manmohan Chandraker. Learning to adapt structured output space for semantic seg- mentation. In CVPR, pages 7472–7481, 2018. 2 [68] Eric Tzeng, Judy Hoffman, Trevor Darrell, and Kate Saenko. Simultaneous deep transfer across domains and tasks. In ICCV, pages 4068–4076, 2015. 2 [69] Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell. Adversarial discriminative domain adaptation. In CVPR, pages 2962–2971, 2017. 1 [70] Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno A. Ol- shausen, and Trevor Darrell. Tent: Fully test-time adaptation by entropy minimization. In ICLR, 2021. 1, 2, 3, 4, 6, 7, 8, 12, 13, 14, 15, 16, 17 [71] Jindong Wang, Cuiling Lan, Chang Liu, Yidong Ouyang, Tao Qin, Wang Lu, Yiqiang Chen, Wenjun Zeng, and Philip Yu. Generalizing to unseen domains: A survey on domain generalization. IEEE Trans. Knowl. Data Eng., 2022. 1 [72] Mei Wang and Weihong Deng. Deep visual domain adapta- tion: A survey. Neurocomputing, 312:135–153, 2018. 1 [73] Qin Wang, Olga Fink, Luc Van Gool, and Dengxin Dai. Con- tinual test-time domain adaptation. In CVPR, pages 7191– 7201, 2022. 1, 2, 3, 4, 6, 7, 8, 13, 14, 15, 16, 17 [74] Markus Wulfmeier, Alex Bewley, and Ingmar Posner. Incre- mental adversarial domain adaptation for continually chang- ing environments. In ICRA, pages 4489–4495, 2018. 3 [75] Binhui Xie, Shuang Li, Mingjia Li, Chi Harold Liu, Gao Huang, and Guoren Wang. Sepico: Semantic-guided pixel contrast for domain adaptive semantic segmentation. IEEE Trans. Pattern Anal. Mach. Intell., pages 1–17, 2023. 2 [76] Saining Xie, Ross Girshick, Piotr Doll ´ar, Zhuowen Tu, and Kaiming He. Aggregated residual transformations for deep neural networks. In CVPR, pages 5987–5995, 2017. 6 [77] Ruijia Xu, Guanbin Li, Jihan Yang, and Liang Lin. Larger norm more transferable: An adaptive feature norm approach for unsupervised domain adaptation. In ICCV, pages 1426– 1435, 2019. 2 [78] Zhenlin Xu, Deyi Liu, Junlin Yang, Colin Raffel, and Marc Niethammer. Robust and generalizable visual representation learning via random convolutions. In ICLR, 2021. 3 [79] Shiqi Yang, Yaxing Wang, Joost van de Weijer, Luis Herranz, and Shangling Jui. Generalized source-free domain adapta- tion. In ICCV, pages 8978–8987, 2021. 3 [80] Sergey Zagoruyko and Nikos Komodakis. Wide residual net- works. In BMVC, 2016. 6 [81] Marvin Mengxin Zhang, Sergey Levine, and Chelsea Finn. MEMO: Test time robustness via adaptation and augmenta- tion. In NeurIPS, 2022. 1, 4 [82] Yizhe Zhang, Shubhankar Borse, Hong Cai, and Fatih Porikli. Auxadapt: Stable and efficient test-time adaptation for temporally consistent video semantic segmentation. In WACV, pages 2633–2642, 2022. 1, 3 [83] Kaiyang Zhou, Ziwei Liu, Yu Qiao, Tao Xiang, and Chen Change Loy. Domain generalization: A survey. IEEE Trans. Pattern Anal. Mach. Intell., 2022. 1 [84] Kaiyang Zhou, Yongxin Yang, Yu Qiao, and Tao Xiang. Do- main generalization with mixstyle. In ICLR, 2021. 3 [85] Yang Zou, Zhiding Yu, BVK Vijaya Kumar, and Jinsong Wang. Unsupervised domain adaptation for semantic seg- mentation via class-balanced self-training. In ECCV, pages 289–305, 2018. 26. Appendix 6.1. Discussion Societal impact. RoTTA enables adapting pre-trained models on continually changing distributions with correl- atively sampled test streams without any more raw data or label requirements. Thus, our work may have a positive im- pact on communities to effectively deploy and adapt models in various real-world scenarios, which is economically and environmentally friendly. And since no training data is re- quired, this protects data privacy and has potential commer- cial value. We carry out experiments on benchmark datasets and do not notice any societal issues. It does not involve sensitive attributes. Future work. Our work suggests a few promising direc- tions for future work. Firstly, the proposed RoTTA is a preliminary attempt to perform test-time adaptation for the more realistic test stream under the setup PTTA. One could experiment to improve the algorithm by replacing some parts of RoTTA. More importantly, we hope that with this work, we can open a path to the original goal of test-time adaptation, which is performing test-time adaptation in real- world scenarios. Thus, one could improve PTTA to make it more realistic. Limitations. RoTTA achieves excellent performance on various tasks under the setup PTTA as demonstrated in Sec- tion 4 in the main paper, but we still find some limitations of it. Firstly, the adopted robust batch normalization (RBN) is a naive solution to the normalization of the correlatively sampled batch of data. This requires careful design of the value of α in RBN. Secondly, we observe that during the adaptation procedure of some methods like PL [39] and TENT [70], the model collapse finally. Although we de- sign many strategies to stabilize the adaptation and model collapse never occurs in the experiments of RoTTA, we are still missing a way to recover the model from the collapse state as a remedy. Thirdly, category similarity is only one kind of correlation. Although we conduct experiments on different datasets with Dirichlet distribution to simulate cor- relatively sampled test streams, we still need to validate our approach in some real-world scenarios. 6.2. Sensitivity to different hyper-parameters In this section, we conduct a detailed sensitivity analy- sis of the hyperparameters involved in RoTTA. All experi- ments are conducted on CIFAR100→CIFAR100-C, and the corruptions changes as motion, snow, fog, shot, defocus, contrast, zoom, brightness, frost, elastic, glass, gaussian, pixelate, jpeg, and impulse, and test streams are sampled correlatively with the Dirichlet parameter δ = 0.1. When we investigate the sensitivity to a specific hyperparameter, other hyperparameters are fixed to the default values, i.e., λt = 1.0, λu = 1.0, α = 0.05, and ν = 0.001, for all experiments. Table 7. Classification error with different value of λt/λu. λt/λu 0.0/2.0 0.5/1.5 1.0/1.0 1.5/ 0.5 2.0/ 0.0 CIFAR100-C 57.5 36.9 35.0 35.9 38.9 Trade-off between timeliness and uncertainty. When updating the memory bank, we take the timeliness and uncertainty of samples into account simultaneously, and λt and λu will make a trade-off between them. In Table 7, we show the results of RoTTA with varying λt/λu, i.e., λt/λu ∈ {0.0/2.0, 0.5/1.5, 1.0/1.0, 1.5/0.5, 2.0/0.0}. When we consider both of them, the results are relatively stable (35.0-36.9%). When we only think about one side, the performance drops significantly. For example, when we set λt/λu = 0.0/2.0 which means only considering uncer- tainty, the performance drops 22.5%. That’s because some confident samples get stuck in the memory bank, making it not work the way we design it. Table 8. Classification error with varying α α 0.5 0.1 0.05 0.01 0.005 0.001 CIFAR100-C 39.0 36.0 35.0 36.0 38.1 41.5 Sensitivity to α. We show the results of RoTTA with vary- ing α, i.e., α ∈ {0.5, 0.1, 0.05, 0.01, 0.005, 0.001} in Ta- ble 8. A larger value of α means updating the global statis- tics faster and vice versa. We can see that RoTTA achieves competitive results (35.0 − 36.0%) at appropriate values of α, i.e., α ∈ {0.1, 0.05, 0.01}. Updating too aggressively or too gently can lead to unreliable estimates of statistics. Table 9. Classification error with varying ν ν 0.05 0.01 0.005 0.001 0.0005 0.0001 CIFAR100-C 44.8 39.1 37.1 35.0 37.6 43.6 Sensitivity to ν. We show the results of RoTTA with vary- ing ν, i.e., ν ∈ {0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001} in Table 9. As we can see, the best performance is achieved at ν = 0.001. Updating the teacher model too quickly or too slowly can cause performance degradation. 6.3. Additional experiment details and results 6.3.1 Compared methods BN [53] utilizes statistics of the current batch of data to nor- malize their feature maps without tuning any parameters. PL [39] is based on BN [53], and adopts pseudo labels to train the affine parameters in BN layers.TENT [70] is the first to propose fully test-time adaptation. It adopts test-time batch normalization and utilizes entropy minimization to train the affine parameters of BN layers. We reimplement it following the released code https:// github.com/DequanWang/tent. LAME [5] adapts the output of the pre-trained model by optimizing a group of latent variables without tuning any in- ner parts of the model. We reimplement it following the re- leased code https://github.com/fiveai/LAME. CoTTA [73] considers performing test-time adapta- tion on continually changing distributions and pro- pose augmentation-averaged pseudo-labels and stochastic restoration to address error accumulation and catastrophic forgetting. We reimplement it following the released code https://github.com/qinenergy/cotta. NOTE [19] proposes instance-aware normalization and prediction-balanced reservoir sampling to stable the adapta- tion on temporally correlated test streams. We reimplement it following the released code https://github.com/ TaesikGong/NOTE. 6.3.2 Simulate correlatively sampling As we described in the scenarios of autonomous driving that the car will follow more vehicles on the highway or will en- counter more pedestrians on the sidewalk, so we use the same category to simulate correlation. From a macro point of view, the test distribution Ptest changes continually as P0, P1, ...,P∞. During the period when Ptest = Pt, we adopt Dirichlet distribution to simulate correlatively sam- pled test stream. More specifically, we consider dividing samples of C classes into T slots. Firstly, we utilize Dirich- let distribution with parameter γ to generate the partition criterion q ∈ RC×T . Then for each class c, we split samples into T parts according to qc and assign each part to each slot respectively. Finally, we concatenate all slots to sim- ulate the correlatively sampled test stream for Ptest = Pt. And as Ptest changes, we use the above method again to generate the test stream. 6.3.3 Detailed results of different orders We report the average classification error of ten different distribution changing orders in Table 6 of the main pa- per. And then we present the specific results here, includ- ing Table 10, 11, 12, 13, 14, 15, 16, 17, 18, and 19 for CIFAR10→CIFAR10-C and Table 20, 21, 22, 23, 24, 25, 26, 27, 28, and 29 for CIFAR100 →CIFAR100-C. We can see consistently superior performance of RoTTA. One thing to mention is that on DomainNet we use alphabetical order to determine the order of domain changes.Table 10. Average classification error of the task CIFAR10→ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time t− − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − → Method brightnesspixelategaussianmotionzoom glass impulsejpeg defocuselasticshot frost snow fog contrast Avg. Source 9.3 58.5 72.3 34.8 42.0 54.3 72.9 30.3 46.9 26.6 65.7 41.3 25.1 26.0 46.7 43.5BN [53] 71.1 75.2 76.8 74.2 73.7 80.1 79.3 77.5 73.8 77.7 77.2 73.3 73.8 72.7 71.7 75.2PL [39] 71.7 75.9 80.2 78.4 80.2 85.2 85.3 85.4 85.1 86.7 87.9 87.9 88.1 88.3 87.9 83.6TENT [70] 71.6 75.9 81.3 80.5 82.3 85.6 87.1 87.0 87.1 88.1 88.2 87.8 87.9 88.3 88.2 84.4LAME [5] 5.4 56.8 73.1 29.1 37.0 50.5 71.4 22.3 42.8 18.6 65.5 37.3 18.8 20.4 43.6 39.5CoTTA [73] 75.0 79.8 83.1 83.4 83.2 84.0 84.5 83.2 83.5 83.3 83.6 83.0 83.0 83.4 83.7 82.6NOTE [19] 10.1 29.9 47.1 23.4 28.4 48.4 46.1 41.8 26.9 36.1 37.5 25.0 25.0 23.2 14.2 30.9 RoTTA 10.4 26.6 37.5 23.9 17.0 40.9 39.7 30.1 18.0 29.9 30.1 23.6 21.7 17.6 19.0 25.7(+5.2) Table 11. Average classification error of the task CIFAR10→ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time t− − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − → Method jpeg shot zoom frost contrastfog defocuselasticgaussianbrightnessglass impulsepixelatesnow motion Avg. Source 30.3 65.7 42.0 41.3 46.7 26.0 46.9 26.6 72.3 9.3 54.3 72.9 58.5 25.1 34.8 43.5BN [53] 77.6 75.8 73.4 74.1 73.1 72.5 72.9 77.1 77.2 72.2 79.9 79.9 75.5 74.6 72.9 75.2PL [39] 77.6 77.1 76.6 78.3 77.5 79.8 82.0 84.8 86.1 83.5 87.8 87.1 86.5 85.6 85.7 82.4TENT [70] 78.5 78.2 79.2 81.8 84.8 84.8 86.4 87.3 87.9 86.7 87.3 87.8 87.2 87.5 87.1 84.8LAME [5] 22.5 65.2 37.0 37.1 44.0 20.3 41.7 18.7 72.8 5.2 51.2 71.5 57.0 19.0 29.4 39.5CoTTA [73]78.5 81.0 82.8 84.1 84.9 83.4 83.5 83.5 84.5 83.3 84.7 84.6 83.0 84.4 83.4 83.3NOTE [19]35.4 36.1 22.1 21.3 11.6 24.8 24.5 36.0 37.7 18.4 49.0 47.4 43.9 30.4 29.2 31.2 RoTTA 33.2 33.3 19.8 24.1 24.9 20.5 16.2 31.7 28.4 11.8 43.1 36.9 32.5 20.7 20.6 26.5(+4.7) Table 12. Average classification error of the task CIFAR10→ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time t− − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − → Method contrastdefocusgaussianshot snow frost glass zoom elasticjpeg pixelatebrightnessimpulsemotion fog Avg. Source 46.7 46.9 72.3 65.7 25.1 41.3 54.3 42.0 26.6 30.3 58.5 9.3 72.9 34.8 26.0 43.5BN [53] 72.3 72.6 76.9 77.1 74.8 73.5 80.0 73.2 77.4 78.6 76.4 71.0 79.1 73.9 71.5 75.2PL [39] 72.4 75.3 80.7 82.6 83.3 83.5 86.6 85.7 86.6 88.4 87.5 86.6 88.3 88.2 86.8 84.1TENT [70] 73.5 77.9 85.5 86.9 87.6 87.8 88.3 87.7 88.6 89.2 88.5 88.5 89.3 88.6 88.6 86.4LAME [5] 43.5 42.3 73.1 65.3 19.2 37.3 51.1 36.8 18.5 22.5 56.9 5.5 71.1 29.1 20.5 39.5CoTTA [73]79.4 80.3 83.8 83.9 83.9 83.4 85.0 83.2 85.1 84.3 83.9 83.3 84.7 83.9 82.5 83.4NOTE [19] 9.6 21.8 40.1 31.0 25.5 22.6 44.8 22.8 33.2 39.4 33.2 18.1 50.0 28.3 29.8 30.0 RoTTA 18.4 17.9 38.4 31.9 23.3 19.8 40.7 17.4 31.4 29.8 27.8 11.3 43.8 19.7 18.8 26.0(+4.0) Table 13. Average classification error of the task CIFAR10→ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time t− − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − → Method shot fog glass pixelatesnow elasticbrightnessimpulsedefocusfrost contrastgaussianmotionjpeg zoom Avg. Source 65.7 26.0 54.3 58.5 25.1 26.6 9.3 72.9 46.9 41.3 46.7 72.3 34.8 30.3 42.0 43.5BN [53] 76.4 72.0 80.4 76.2 74.8 77.0 71.1 79.6 73.8 74.4 73.0 77.0 72.5 78.3 72.5 75.3PL [39] 77.0 73.3 82.4 79.8 81.0 82.3 79.5 84.4 82.7 83.5 83.5 85.5 84.8 87.0 84.5 82.1TENT [70]76.9 74.6 82.3 81.7 82.0 84.9 84.8 87.3 86.6 87.3 87.6 89.2 88.3 88.9 87.3 84.6LAME [5] 65.3 20.6 50.9 56.7 19.2 18.8 5.4 71.8 42.8 37.2 43.3 73.2 29.4 22.6 36.9 39.6CoTTA [73]77.4 77.6 83.8 81.9 82.2 82.6 80.4 83.3 82.3 81.5 82.7 82.6 81.1 82.9 81.0 81.6NOTE [19]34.0 20.9 43.1 36.6 24.0 36.4 12.1 48.0 25.9 23.9 13.4 38.1 25.0 43.2 24.2 29.9 RoTTA 35.0 21.1 43.9 29.2 22.1 29.7 10.8 44.6 25.3 22.7 24.6 29.4 26.9 34.4 16.1 27.7(+2.2) Table 14. Average classification error of the task CIFAR10→ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time t− − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − → Method pixelateglass zoomsnow fog impulsebrightnessmotionfrost jpeg gaussianshot contrastdefocus elastic Avg. Source 58.5 54.3 42.0 25.1 26.0 72.9 9.3 34.8 41.3 30.3 72.3 65.7 46.7 46.9 26.6 43.5BN [53] 76.0 79.6 73.3 75.2 72.9 79.8 71.1 73.5 74.1 78.6 77.4 76.1 72.0 73.8 76.4 75.3PL [39] 76.7 81.3 77.4 80.3 81.2 86.3 83.3 85.9 86.2 87.7 88.1 88.4 87.4 87.6 87.7 84.4TENT [70] 76.4 80.2 77.8 81.2 83.0 87.1 85.6 87.2 87.6 88.7 88.6 88.9 88.5 88.6 88.2 85.2LAME [5] 56.9 50.7 37.0 19.0 20.3 71.5 5.4 29.2 37.2 22.5 73.0 65.3 43.8 42.4 18.7 39.5CoTTA [73]77.1 83.6 84.1 84.8 84.4 85.2 84.0 84.3 84.9 84.9 85.0 84.7 85.3 84.4 84.3 84.1NOTE [19] 27.8 52.2 24.5 22.3 21.6 44.5 14.5 21.3 25.9 42.5 38.8 36.0 16.7 28.1 40.6 30.5 RoTTA 25.9 43.3 17.7 22.1 20.2 41.5 12.2 22.9 22.5 31.2 33.8 26.0 31.4 17.7 27.6 26.4(+4.1)Table 15. Average classification error of the task CIFAR10→ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time t− − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − → Method motionsnow fog shot defocuscontrastzoom brightnessfrost elasticglass gaussianpixelatejpeg impulse Avg. Source 34.8 25.1 26.0 65.7 46.9 46.7 42.0 9.3 41.3 26.6 54.3 72.3 58.5 30.3 72.9 43.5BN [53] 73.2 73.4 72.7 77.2 73.7 72.5 72.9 71.0 74.1 77.7 80.0 76.9 75.5 78.3 79.0 75.2PL [39] 73.9 75.0 75.6 81.0 79.9 80.6 82.0 83.2 85.3 87.3 88.3 87.5 87.5 87.5 88.2 82.9TENT [70] 74.3 77.4 80.1 86.2 86.7 87.3 87.9 87.4 88.2 89.0 89.2 89.0 88.3 89.7 89.2 86.0LAME [5] 29.5 19.0 20.3 65.3 42.4 43.4 36.8 5.4 37.2 18.6 51.2 73.2 57.0 22.6 71.3 39.5CoTTA [73]77.1 80.6 83.1 84.4 83.9 84.2 83.1 82.6 84.4 84.2 84.5 84.6 82.7 83.8 84.9 83.2NOTE [19] 18.0 22.1 20.6 35.6 26.9 13.6 26.5 17.3 27.2 37.0 48.3 38.8 42.6 41.9 49.7 31.1 RoTTA 18.1 21.3 18.8 33.6 23.6 16.5 15.1 11.2 21.9 30.7 39.6 26.8 33.7 27.8 39.5 25.2(+5.9) Table 16. Average classification error of the task CIFAR10→ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time t− − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − → Method frost impulsejpeg contrastzoom glass pixelatesnow defocusmotionbrightnesselasticshot fog gaussian Avg. Source 41.3 72.9 30.3 46.7 42.0 54.3 58.5 25.1 46.9 34.8 9.3 26.6 65.7 26.0 72.3 43.5BN [53] 73.8 79.1 77.9 73.0 73.7 80.1 75.7 74.4 73.7 74.0 71.7 77.0 75.9 72.8 76.2 75.3PL [39] 74.2 80.9 80.4 79.5 81.8 85.9 83.9 85.1 84.7 85.9 85.9 86.7 87.2 87.0 87.8 83.8TENT [70]73.9 80.3 81.8 81.6 83.6 86.3 85.6 85.7 86.4 87.7 87.4 88.8 88.8 88.5 88.4 85.0LAME [5] 37.4 71.8 22.4 43.5 37.0 50.5 57.0 19.0 42.8 29.1 5.4 18.7 65.2 20.4 72.9 39.5CoTTA [73]76.5 82.2 82.8 85.0 82.9 85.0 83.0 82.9 83.5 83.4 82.6 83.7 83.2 83.3 83.6 82.9NOTE [19]21.1 41.4 36.3 10.2 21.7 46.7 37.5 26.4 26.1 21.4 14.3 37.9 38.5 24.4 40.7 29.6 RoTTA 22.2 44.9 35.2 18.8 19.7 41.5 28.5 23.2 21.2 18.6 12.4 30.0 27.4 20.0 31.2 26.3(+3.3) Table 17. Average classification error of the task CIFAR10→ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time t− − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − → Method defocusmotionzoom shot gaussianglass jpeg fog contrastpixelatefrost snow brightnesselastic impulse Avg. Source 46.9 34.8 42.0 65.7 72.3 54.3 30.3 26.0 46.7 58.5 41.3 25.1 9.3 26.6 72.9 43.5BN [53] 72.8 72.7 73.3 77.2 77.3 80.0 77.6 72.6 73.3 76.6 73.8 74.1 70.3 77.5 79.0 75.2PL [39] 73.2 74.6 76.5 81.7 82.8 84.6 85.1 84.6 86.2 86.4 86.1 87.1 86.8 88.4 88.1 83.5TENT [70] 73.7 74.3 77.1 82.5 84.3 86.9 87.4 86.6 88.0 88.5 88.1 88.5 88.4 89.4 88.9 84.8LAME [5] 42.5 29.3 37.0 65.3 73.2 50.5 22.5 20.5 43.5 56.9 37.1 18.9 5.4 18.5 71.3 39.5CoTTA [73]76.3 79.8 82.4 83.3 83.8 84.5 83.1 82.7 84.7 82.9 83.0 83.3 81.4 83.8 83.8 82.6NOTE [19] 18.5 18.8 23.6 36.5 33.7 47.8 38.6 22.8 13.0 40.0 29.2 26.3 17.5 44.0 52.9 30.9 RoTTA 17.0 17.5 16.5 33.8 33.3 42.7 29.4 18.0 19.6 29.5 20.7 22.1 11.5 29.5 38.1 25.3(+5.6) Table 18. Average classification error of the task CIFAR10→ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time t− − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − → Method glass zoom impulsefog snow jpeg gaussianfrost shot brightnesscontrastmotionpixelatedefocus elastic Avg. Source 54.3 42.0 72.9 26.0 25.1 30.3 72.3 41.3 65.7 9.3 46.7 34.8 58.5 46.9 26.6 43.5BN [53] 79.7 72.3 79.8 73.2 74.7 77.7 76.6 73.2 77.1 72.2 73.0 73.3 75.5 73.8 76.4 75.2PL [39] 79.6 73.2 81.3 77.3 79.1 83.0 83.2 83.0 85.5 84.3 87.0 86.9 86.4 86.5 87.6 82.9TENT [70] 79.5 74.1 84.2 82.2 84.5 86.5 86.7 85.9 87.2 86.6 86.8 87.3 86.9 87.4 87.3 84.9LAME [5] 50.8 36.9 71.3 20.6 19.2 22.4 72.5 37.2 65.4 5.2 43.3 29.1 57.0 42.4 18.7 39.5CoTTA [73]81.5 79.4 85.2 84.1 84.5 84.2 84.8 84.0 84.8 83.2 85.2 83.8 83.2 84.6 83.6 83.7NOTE [19]45.0 21.2 42.3 21.0 21.6 38.4 36.4 21.4 33.1 16.7 14.6 25.4 43.5 29.1 38.5 29.9 RoTTA 42.6 17.6 48.1 23.9 21.9 32.6 32.1 20.7 30.2 12.0 21.9 20.0 33.7 16.4 28.1 26.8(+3.1) Table 19. Average classification error of the task CIFAR10→ CIFAR10-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time t− − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − → Method contrastgaussiandefocuszoom frost glass jpeg fog pixelateelasticshot impulsesnow motion brightness Avg. Source 46.7 72.3 46.9 42.0 41.3 54.3 30.3 26.0 58.5 26.6 65.7 72.9 25.1 34.8 9.3 43.5BN [53] 72.4 76.2 73.2 73.7 73.6 80.0 77.6 72.6 76.4 77.7 77.2 79.9 73.8 73.9 70.0 75.2PL [39] 73.0 78.2 76.7 79.7 81.6 85.6 86.0 85.3 87.2 88.2 88.3 88.9 88.5 89.2 88.2 84.3TENT [70] 73.6 80.9 83.1 85.6 87.1 88.5 88.8 88.4 89.2 89.3 89.0 89.0 89.3 89.9 89.1 86.7LAME [5] 43.5 73.2 42.3 37.0 37.2 50.5 22.5 20.5 57.0 18.6 65.5 71.5 18.8 29.1 5.6 39.5CoTTA [73]79.5 81.4 83.4 83.6 83.9 85.0 84.0 82.8 84.8 84.8 84.5 84.7 84.1 84.4 82.8 83.6NOTE [19] 9.6 43.6 26.5 24.8 23.9 46.9 38.0 23.4 34.0 41.2 41.5 45.0 27.6 25.8 19.0 31.4 RoTTA 18.4 36.0 21.1 15.6 23.0 41.7 30.8 19.1 34.1 31.1 31.3 39.9 26.0 18.8 12.8 26.6(+4.8)Table 20. Average classification error of the task CIFAR100 → CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time t− − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − → Method brightnesspixelategaussianmotionzoom glass impulsejpeg defocuselasticshot frost snow fog contrast Avg. Source 29.5 74.7 73.0 30.8 28.8 54.1 39.4 41.2 29.3 37.2 68.0 45.8 39.5 50.3 55.1 46.4BN [53] 46.5 52.0 58.6 47.4 47.4 57.6 58.2 56.9 47.0 53.4 56.0 52.5 53.1 57.7 49.1 52.9PL [39] 48.5 60.7 77.1 85.9 91.5 95.5 95.8 96.6 96.8 96.9 97.3 97.5 97.6 97.7 97.9 88.9TENT [70] 49.8 69.4 92.2 96.0 96.7 97.3 97.5 97.9 97.5 97.9 98.0 98.2 98.2 98.2 98.2 92.2LAME [5] 21.7 75.1 72.7 22.9 20.6 49.0 32.1 33.3 21.2 28.0 66.8 40.0 30.6 43.9 51.3 40.6CoTTA [73] 46.8 48.4 54.7 48.7 48.6 53.5 55.4 52.8 49.8 51.8 53.5 52.9 54.1 56.7 53.6 52.1NOTE [19] 42.6 53.0 69.9 52.1 53.3 70.4 73.1 76.7 80.8 96.0 97.7 97.1 96.6 97.2 95.8 76.8 RoTTA 28.4 37.3 44.6 31.9 28.3 41.8 43.6 39.9 28.0 35.2 38.2 33.7 33.0 39.5 31.0 35.6(+5.0) Table 21. Average classification error of the task CIFAR100 → CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time t− − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − → Method jpeg shot zoom frost contrastfog defocuselasticgaussianbrightnessglass impulsepixelatesnow motion Avg. Source 41.2 68.0 28.8 45.8 55.1 50.3 29.3 37.2 73.0 29.5 54.1 39.4 74.7 39.5 30.8 46.4BN [53] 58.3 56.8 47.8 51.8 48.9 57.3 46.8 53.5 57.8 45.5 57.1 58.5 51.7 53.3 48.8 52.9PL [39] 59.4 66.3 74.9 87.5 94.2 95.5 96.2 97.1 97.4 97.2 97.5 97.7 98.0 98.2 98.2 90.4TENT [70] 62.0 79.3 91.7 95.8 96.9 97.0 97.4 97.7 97.6 97.7 97.9 97.9 98.0 97.9 97.9 93.5LAME [5] 33.6 66.7 21.1 39.9 50.6 43.9 21.0 28.6 72.5 21.6 48.6 32.5 74.5 30.6 22.5 40.6CoTTA [73]54.6 54.1 49.6 52.1 52.7 58.0 50.3 53.3 55.0 49.1 55.4 55.7 51.0 54.6 52.1 53.2NOTE [19]60.4 63.0 49.9 55.7 47.0 65.2 59.4 76.6 90.9 87.2 96.8 97.0 97.3 96.7 96.8 76.0 RoTTA 43.9 45.3 31.0 37.3 35.7 41.2 27.7 34.8 39.7 26.6 39.5 41.9 32.0 33.0 30.5 36.0(+4.6) Table 22. Average classification error of the task CIFAR100 → CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time t− − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − → Method contrastdefocusgaussianshot snow frost glass zoom elasticjpeg pixelatebrightnessimpulsemotion fog Avg. Source 55.1 29.3 73.0 68.0 39.5 45.8 54.1 28.8 37.2 41.2 74.7 29.5 39.4 30.8 50.3 46.4BN [53] 49.4 47.2 58.6 56.2 52.7 52.0 57.9 46.1 54.4 57.7 50.5 46.2 58.2 47.6 58.5 52.9PL [39] 54.8 64.2 83.3 92.4 95.5 96.5 96.9 96.4 97.2 97.4 97.8 97.8 97.9 97.7 98.0 90.9TENT [70] 60.2 83.1 95.2 96.5 96.9 97.3 97.0 97.3 97.8 97.8 97.6 97.9 97.8 97.9 98.1 93.9LAME [5] 51.3 21.3 72.7 66.3 30.2 40.0 48.6 20.9 27.7 33.3 75.0 21.5 32.2 22.5 43.8 40.5CoTTA [73]52.1 48.6 55.1 52.7 53.4 51.9 55.9 49.2 53.2 52.8 49.2 49.7 56.2 50.7 58.1 52.6NOTE [19] 39.5 45.9 68.8 61.8 57.4 58.5 71.4 66.5 80.8 90.9 94.2 94.9 97.0 95.5 96.6 74.6 RoTTA 41.7 30.5 44.9 40.5 35.4 34.1 40.5 28.2 34.5 39.5 31.1 26.7 43.3 31.4 38.8 36.1(+4.4) Table 23. Average classification error of the task CIFAR100 → CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time t− − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − → Method shot fog glass pixelatesnow elasticbrightnessimpulsedefocusfrost contrastgaussianmotionjpeg zoom Avg. Source 68.0 50.3 54.1 74.7 39.5 37.2 29.5 39.4 29.3 45.8 55.1 73.0 30.8 41.2 28.8 46.4BN [53] 57.5 58.6 58.5 50.5 52.7 53.1 45.9 57.9 47.0 51.5 47.8 58.2 48.2 57.1 47.7 52.8PL [39] 59.5 72.9 85.1 89.6 94.5 96.8 97.1 97.9 97.8 98.0 98.3 98.2 98.0 98.0 98.2 92.0TENT [70]60.3 81.4 95.0 96.6 97.0 97.3 97.3 97.7 97.7 97.7 97.8 97.7 97.6 97.6 97.9 93.8LAME [5] 66.4 43.2 49.0 75.2 30.2 28.5 21.6 32.5 21.2 39.5 52.0 72.8 22.3 33.1 20.5 40.5CoTTA [73]54.5 58.4 55.6 50.0 53.9 53.4 50.3 56.7 51.3 53.2 53.7 56.1 52.0 54.5 51.5 53.7NOTE [19]61.8 60.2 63.4 55.6 59.8 65.9 58.6 75.1 77.8 93.8 94.2 97.0 95.0 95.5 94.4 76.5 RoTTA 45.5 44.5 43.5 35.6 35.1 35.7 26.2 44.0 29.7 34.2 32.0 40.7 31.4 39.4 27.7 36.3(+4.2) Table 24. Average classification error of the task CIFAR100 → CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time t− − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − → Method pixelateglass zoomsnow fog impulsebrightnessmotionfrost jpeg gaussianshot contrastdefocus elastic Avg. Source 74.7 54.1 28.8 39.5 50.3 39.4 29.5 30.8 45.8 41.2 73.0 68.0 55.1 29.3 37.2 46.4BN [53] 51.7 58.6 47.8 52.9 57.1 58.2 45.9 47.6 52.9 57.8 57.5 56.7 49.5 46.1 54.0 52.9PL [39] 52.4 68.0 73.4 87.9 93.7 96.1 95.7 96.0 96.5 96.7 97.5 97.7 97.7 97.3 97.7 89.6TENT [70] 53.5 77.8 91.1 96.0 97.0 97.6 97.4 97.6 97.9 98.1 98.1 98.0 98.1 97.9 98.1 92.9LAME [5] 74.8 48.2 21.1 30.6 43.4 32.5 21.6 23.0 39.6 33.3 72.7 66.5 51.5 20.7 27.5 40.5CoTTA [73]49.3 55.1 49.1 52.9 56.8 55.7 49.5 50.0 53.6 53.4 54.9 53.9 53.8 50.1 53.5 52.8NOTE [19] 52.2 64.9 47.5 57.0 61.9 67.3 60.4 67.8 77.4 90.6 97.1 96.8 92.8 95.9 96.6 75.1 RoTTA 36.4 44.4 29.7 36.5 41.0 44.1 26.8 29.5 33.0 40.3 40.3 38.2 33.9 28.5 34.9 35.8(+4.7)Table 25. Average classification error of the task CIFAR100 → CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time t− − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − → Method motionsnow fog shot defocuscontrastzoom brightnessfrost elasticglass gaussianpixelatejpeg impulse Avg. Source 30.8 39.5 50.3 68.0 29.3 55.1 28.8 29.5 45.8 37.2 54.1 73.0 74.7 41.2 39.4 46.4BN [53] 48.5 54.0 58.9 56.2 46.4 48.0 47.0 45.4 52.9 53.4 57.1 58.2 51.7 57.1 58.8 52.9PL [39] 50.6 62.1 73.9 87.8 90.8 96.0 94.8 96.4 97.4 97.2 97.4 97.4 97.3 97.4 97.4 88.9TENT [70] 53.3 77.6 93.0 96.5 96.7 97.5 97.1 97.5 97.3 97.2 97.1 97.7 97.6 98.0 98.3 92.8LAME [5] 22.4 30.4 43.9 66.3 21.3 51.7 20.6 21.8 39.6 28.0 48.7 72.8 74.6 33.1 32.3 40.5CoTTA [73]49.2 52.7 56.8 53.0 48.7 51.7 49.4 48.7 52.5 52.2 54.3 54.9 49.6 53.4 56.2 52.2NOTE [19] 45.7 53.0 58.2 65.6 54.2 52.0 59.8 63.5 74.8 91.8 98.1 98.3 96.8 97.0 98.2 73.8 RoTTA 31.8 36.7 40.9 42.1 30.0 33.6 27.9 25.4 32.3 34.0 38.8 38.7 31.3 38.0 42.9 35.0(+5.5) Table 26. Average classification error of the task CIFAR100 → CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time t− − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − → Method frost impulsejpeg contrastzoom glass pixelatesnow defocusmotionbrightnesselasticshot fog gaussian Avg. Source 45.8 39.4 41.2 55.1 28.8 54.1 74.7 39.5 29.3 30.8 29.5 37.2 68.0 50.3 73.0 46.4BN [53] 52.9 58.8 57.6 48.2 47.4 57.6 50.9 52.4 47.0 47.2 45.1 54.0 56.4 57.7 58.2 52.8PL [39] 56.9 73.3 86.7 94.4 95.8 97.3 97.2 97.4 97.6 97.4 97.7 97.6 97.8 98.3 98.1 92.2TENT [70]60.1 84.2 95.7 97.2 97.4 97.9 97.8 98.0 98.1 98.2 98.3 98.4 98.4 98.4 98.4 94.4LAME [5] 39.9 32.4 33.4 51.4 20.6 49.0 74.4 31.3 21.2 22.6 21.9 28.1 66.9 43.9 72.5 40.6CoTTA [73]51.5 55.3 54.3 51.8 49.4 55.3 50.7 54.2 51.4 50.6 49.5 53.6 55.0 57.1 55.8 53.0NOTE [19]51.6 60.9 60.3 45.4 54.3 70.8 68.8 75.0 75.7 87.1 94.7 95.6 96.7 96.4 97.2 75.4 RoTTA 40.0 46.3 42.8 36.4 29.2 42.3 33.2 34.4 28.4 29.2 26.4 34.5 38.5 39.8 39.3 36.0(+4.6) Table 27. Average classification error of the task CIFAR100 → CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time t− − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − → Method defocusmotionzoom shot gaussianglass jpeg fog contrastpixelatefrost snow brightnesselastic impulse Avg. Source 29.3 30.8 28.8 68.0 73.0 54.1 41.2 50.3 55.1 74.7 45.8 39.5 29.5 37.2 39.4 46.4BN [53] 47.1 48.6 47.8 56.2 57.6 57.6 57.6 57.5 48.7 50.6 51.8 53.2 46.9 53.5 58.8 52.9PL [39] 48.8 58.7 69.9 88.0 95.1 96.6 96.7 96.9 97.4 97.4 98.2 98.2 98.2 98.3 98.5 89.1TENT [70] 51.0 67.6 85.8 95.9 97.2 97.5 97.2 97.7 98.1 97.9 97.7 97.7 98.0 98.0 98.2 91.7LAME [5] 21.2 22.8 21.1 66.3 72.8 49.0 33.3 44.8 51.7 74.9 39.8 31.2 21.3 27.3 32.3 40.6CoTTA [73]48.4 48.8 48.2 52.9 54.0 53.8 52.7 57.2 52.6 48.6 51.8 53.9 49.4 52.3 56.0 52.0NOTE [19] 45.1 46.7 49.1 67.3 65.5 69.4 75.5 80.3 83.8 96.0 97.6 97.1 96.1 97.9 98.7 77.7 RoTTA 29.6 31.3 28.8 43.9 41.5 41.3 40.9 39.8 32.1 32.6 33.1 33.0 26.5 34.5 42.9 35.4(+5.2) Table 28. Average classification error of the task CIFAR100 → CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time t− − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − → Method glass zoom impulsefog snow jpeg gaussianfrost shot brightnesscontrastmotionpixelatedefocus elastic Avg. Source 54.1 28.8 39.4 50.3 39.5 41.2 73.0 45.8 68.0 29.5 55.1 30.8 74.7 29.3 37.2 46.4BN [53] 58.8 47.7 59.2 57.6 52.7 56.9 58.2 52.0 56.7 45.5 47.8 48.2 51.7 46.1 54.0 52.9PL [39] 60.1 59.5 75.1 85.7 91.5 94.6 96.5 97.1 97.4 97.3 98.0 97.7 97.9 97.8 97.7 89.6TENT [70] 61.6 71.5 91.0 95.9 96.6 97.1 96.9 97.3 97.4 97.2 97.9 98.0 98.1 97.9 97.8 92.8LAME [5] 48.6 20.6 32.3 44.4 30.2 33.6 72.4 40.0 66.3 21.6 52.0 22.8 74.6 20.7 27.5 40.5CoTTA [73]56.4 48.9 56.1 57.8 54.1 54.2 56.2 53.6 55.4 50.0 53.6 51.6 51.2 50.7 54.4 53.6NOTE [19]62.5 46.3 61.5 61.1 58.6 68.4 76.1 78.3 92.0 93.4 96.1 95.4 96.2 95.8 96.4 78.5 RoTTA 45.5 30.0 45.9 42.6 35.3 41.8 42.2 34.5 40.2 27.3 31.3 30.2 32.7 28.1 34.9 36.2(+4.3) Table 29. Average classification error of the task CIFAR100 → CIFAR100-C while continually adapting to different corruptions at the highest severity 5 with correlatively sampled test stream under the proposed setup PTTA. Time t− − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − → Method contrastgaussiandefocuszoom frost glass jpeg fog pixelateelasticshot impulsesnow motion brightness Avg. Source 55.1 73.0 29.3 28.8 45.8 54.1 41.2 50.3 74.7 37.2 68.0 39.4 39.5 30.8 29.5 46.4BN [53] 49.5 58.8 47.0 46.5 52.2 57.6 57.6 57.6 51.7 53.5 56.0 58.5 53.1 47.6 46.3 52.9PL [39] 53.6 70.4 76.0 85.1 91.2 95.2 96.0 97.0 96.9 97.3 97.3 97.6 97.5 97.6 97.7 89.8TENT [70] 60.2 89.1 95.0 96.2 96.9 97.0 96.5 97.0 97.0 97.2 97.6 97.8 97.5 97.9 97.7 94.0LAME [5] 51.3 72.5 21.5 21.0 39.6 49.0 33.3 44.8 74.8 28.0 66.8 32.5 30.6 22.5 21.4 40.6CoTTA [73]52.3 55.3 49.5 48.1 52.1 54.8 52.7 56.9 50.6 52.6 53.7 55.8 54.6 50.6 50.5 52.7NOTE [19] 39.1 64.7 48.9 50.6 59.1 70.1 71.7 75.0 85.2 95.7 96.9 98.4 96.0 95.9 94.9 76.1 RoTTA 41.4 46.2 30.5 28.5 36.0 40.9 40.5 39.6 33.0 35.0 38.2 43.1 33.9 30.7 27.1 36.3(+4.3)",
      "meta_data": {
        "arxiv_id": "2303.13899v1",
        "authors": [
          "Longhui Yuan",
          "Binhui Xie",
          "Shuang Li"
        ],
        "published_date": "2023-03-24T10:19:14Z",
        "pdf_url": "https://arxiv.org/pdf/2303.13899v1.pdf",
        "github_url": "https://github.com/BIT-DA/RoTTA"
      },
      "llm_extracted_info": {
        "main_contributions": "1. Introduces Practical Test-Time Adaptation (PTTA), a new deployment scenario where the test distribution changes continually while test samples within each time step are temporally correlated.\n2. Analyses why existing TTA methods fail under PTTA (wrong BN statistics, error accumulation, over-fitting to correlated data).\n3. Proposes Robust Test-Time Adaptation (RoTTA) comprising: (a) Robust Batch Normalization (RBN) with EMA global statistics, (b) a category-balanced memory bank updated via timeliness- & uncertainty-aware sampling (CSTU), and (c) time-aware re-weighting in a teacher-student learning scheme that adapts only BN affine parameters.\n4. Provides extensive experiments on CIFAR-10-C, CIFAR-100-C, and DomainNet showing large error reductions (≈5–6% on CIFAR-C, 2.2% on DomainNet) over strong TTA baselines.",
        "methodology": "• Robust Batch Normalization (RBN): replaces batch statistics with global mean/variance updated by exponential moving average (α) of statistics computed on buffered samples, ensuring stable normalization under correlated mini-batches.\n• Category-balanced Sampling with Timeliness & Uncertainty (CSTU): maintains a memory bank of size N, equally partitioned per class; when adding a new sample, a heuristic H = λ_t·sigmoid(age)+λ_u·normalized_entropy selects which sample to evict, favouring recent and confident examples to approximate current distribution.\n• Teacher-Student Adaptation: teacher is EMA of student parameters (ν). Loss is timeliness-weighted cross-entropy between teacher predictions on weakly-augmented view and student predictions on strongly-augmented view of each memory sample. Only γ/β in RBN are updated, limiting catastrophic forgetting.",
        "experimental_setup": "Datasets & tasks: (1) CIFAR-10-C and CIFAR-100-C (15 corruptions×severity 5); model pretrained on clean CIFAR (WildResNet-28, ResNeXt-29). Test stream created by cycling corruption types and sampling each batch via Dirichlet(δ=0.1) to induce correlation. (2) DomainNet; source model ResNet-101 trained on one domain, adapted to streams from other five domains in alphabetical order.\nImplementation: batch size 64; memory bank N=64; hyper-parameters α=0.05, ν=0.001, λ_t=λ_u=1.0; Adam lr 1e-3. Evaluation metric: classification error over entire adaptation stream. Baselines: Source, BN, PL, TENT, LAME, CoTTA, NOTE.",
        "limitations": "• RBN relies on fixed EMA rate; inappropriate α degrades performance and may need tuning per scenario.\n• No recovery mechanism if model collapse still occurs; assumes adaptation remains stable.\n• Correlated sampling is simulated with Dirichlet distribution; real-world temporal correlations may differ.\n• Evaluation limited to image classification; method’s effectiveness on detection, segmentation, or non-vision modalities untested.\n• Memory bank size and λ_t/λ_u trade-off are fixed globally, may not be optimal for all data streams.",
        "future_research_directions": "1. Design adaptive or data-driven strategies for updating BN statistics (dynamic α) and for automatically tuning memory/heuristic weights.\n2. Develop safeguards or rollback mechanisms to detect and recover from catastrophic failures during long-term adaptation.\n3. Validate PTTA and RoTTA on genuine streaming datasets (e.g., autonomous-driving video, surveillance) with natural temporal correlations.\n4. Extend PTTA framework to other tasks such as semantic segmentation, object detection, and multimodal learning.\n5. Explore alternative memory selection policies (e.g., diversity-based, importance sampling) and scalable memory management for large-scale deployments.",
        "experimental_code": "# --------------------------- Robust Batch Normalization (RBN) ---------------------------\n#  File: core/utils/bn_layers.py (excerpt)\nimport torch\nimport torch.nn as nn\nfrom copy import deepcopy\n\nclass MomentumBN(nn.Module):\n    \"\"\"Parent of RobustBN1d/2d – keeps a moving estimate of the *global* statistics.\n    The running source statistics are updated with an exponential moving average\n    controlled by `self.momentum = α` (see paper).\"\"\"\n    def __init__(self, bn_layer: nn.Module, momentum: float):\n        super().__init__()\n        self.num_features = bn_layer.num_features\n        self.momentum = momentum  # α in the paper\n\n        # copy (frozen) source statistics/affine params\n        self.register_buffer(\"source_mean\", deepcopy(bn_layer.running_mean))\n        self.register_buffer(\"source_var\",  deepcopy(bn_layer.running_var))\n        self.weight = deepcopy(bn_layer.weight)\n        self.bias   = deepcopy(bn_layer.bias)\n        self.eps    = bn_layer.eps\n\n    def _update_stats(self, batch_mean, batch_var):\n        mean = (1 - self.momentum) * self.source_mean + self.momentum * batch_mean\n        var  = (1 - self.momentum) * self.source_var  + self.momentum * batch_var\n        self.source_mean.copy_(mean.detach())\n        self.source_var.copy_(var.detach())\n        return mean, var\n\nclass RobustBN1d(MomentumBN):\n    def forward(self, x):  # x:(B,C)\n        if self.training:                     # correlated mini-batches allowed\n            b_var, b_mean = torch.var_mean(x, dim=0, unbiased=False)\n            mean, var = self._update_stats(b_mean, b_var)\n            mean, var = mean.view(1,-1), var.view(1,-1)\n        else:\n            mean, var = self.source_mean.view(1,-1), self.source_var.view(1,-1)\n        x = (x - mean) / torch.sqrt(var + self.eps)\n        return x * self.weight.view(1,-1) + self.bias.view(1,-1)\n\nclass RobustBN2d(MomentumBN):\n    def forward(self, x):  # x:(B,C,H,W)\n        if self.training:\n            b_var, b_mean = torch.var_mean(x, dim=[0,2,3], unbiased=False)\n            mean, var = self._update_stats(b_mean, b_var)\n            mean, var = mean.view(1,-1,1,1), var.view(1,-1,1,1)\n        else:\n            mean, var = self.source_mean.view(1,-1,1,1), self.source_var.view(1,-1,1,1)\n        x = (x - mean) / torch.sqrt(var + self.eps)\n        return x * self.weight.view(1,-1,1,1) + self.bias.view(1,-1,1,1)\n\n\n# ---------------- Category-balanced Sampling with Timeliness & Uncertainty (CSTU) --------\n#  File: core/utils/memory.py (excerpt)\nimport math\nclass MemoryItem:\n    def __init__(self, data=None, uncertainty=0., age=0):\n        self.data = data          # stored image tensor\n        self.uncertainty = uncertainty\n        self.age = age            # #updates since insertion\n    def increase_age(self):\n        self.age += 1\n    def empty(self):\n        return self.data == \"empty\"\n\nclass CSTU:\n    \"\"\"Fixed-size memory divided equally per class; eviction based on\n    H = λ_t·sigmoid(age) + λ_u·entropy\"\"\"\n    def __init__(self, capacity:int, num_class:int, lambda_t:float=1., lambda_u:float=1.):\n        self.capacity   = capacity\n        self.num_class  = num_class\n        self.per_class  = capacity/num_class\n        self.lambda_t   = lambda_t\n        self.lambda_u   = lambda_u\n        self.data = [[] for _ in range(num_class)]  # list[list[MemoryItem]]\n\n    # ------------- public API -------------\n    def add_instance(self, instance):\n        x, cls, unc = instance  # (image, predicted_label, entropy)\n        item = MemoryItem(x, unc, 0)\n        new_score = self._score(age=0, uncertainty=unc)\n        if self._evict_or_not(cls, new_score):\n            self.data[cls].append(item)\n        self._increase_age()\n\n    def get_memory(self):\n        imgs, ages = [], []\n        for cls_list in self.data:\n            for it in cls_list:\n                imgs.append(it.data); ages.append(it.age/self.capacity)\n        return imgs, ages\n\n    # ------------- internals --------------\n    def _score(self, age, uncertainty):\n        return self.lambda_t * 1/(1+math.exp(-age/self.capacity)) + \\\n               self.lambda_u * uncertainty/math.log(self.num_class)\n\n    def _evict_or_not(self, cls, new_score):\n        cls_list = self.data[cls]\n        if len(cls_list) < self.per_class:\n            if self._total() < self.capacity:\n                return True\n            else:\n                return self._evict_from(self._majority_classes(), new_score)\n        else:\n            return self._evict_from([cls], new_score)\n\n    def _evict_from(self, classes, score_base):\n        worst_cls, worst_idx, worst_score = None, None, None\n        for c in classes:\n            for i,item in enumerate(self.data[c]):\n                sc = self._score(item.age, item.uncertainty)\n                if worst_score is None or sc > worst_score:\n                    worst_cls, worst_idx, worst_score = c, i, sc\n        if worst_cls is not None and worst_score > score_base:\n            self.data[worst_cls].pop(worst_idx)\n            return True\n        return worst_cls is None  # if nothing to remove but room exists\n\n    def _majority_classes(self):\n        occ = [len(c) for c in self.data]; mx=max(occ)\n        return [i for i,o in enumerate(occ) if o==mx]\n\n    def _increase_age(self):\n        for cls_list in self.data:\n            for it in cls_list: it.increase_age()\n    def _total(self):\n        return sum(len(c) for c in self.data)\n\n\n# --------------------------- Teacher-Student Adaptation -------------------------------\n#  File: core/adapter/rotta.py (excerpt)\nimport torch, torch.nn as nn\nfrom copy import deepcopy\nfrom core.utils.bn_layers import RobustBN1d, RobustBN2d\nfrom core.utils.memory import CSTU\nfrom core.utils.custom_transforms import get_tta_transforms\n\n@torch.jit.script\ndef _softmax_entropy(x, x_ema):\n    return -(x_ema.softmax(1) * x.log_softmax(1)).sum(1)\n\ndef timeliness_reweighting(ages:torch.Tensor):\n    return torch.exp(-ages) / (1 + torch.exp(-ages))\n\nclass RoTTA(nn.Module):\n    \"\"\"Main TTA algorithm combining RBN + CSTU + EMA teacher/student\"\"\"\n    def __init__(self, cfg, model, build_optimizer):\n        super().__init__()\n        # 1) replace all BN with RobustBN (α)\n        self.model = self._patch_bn(model, alpha=cfg.ADAPTER.RoTTA.ALPHA)\n        self.model.cuda().eval()\n\n        # 2) CSTU memory\n        self.mem = CSTU(capacity=cfg.ADAPTER.RoTTA.MEMORY_SIZE,\n                        num_class=cfg.CORRUPTION.NUM_CLASS,\n                        lambda_t=cfg.ADAPTER.RoTTA.LAMBDA_T,\n                        lambda_u=cfg.ADAPTER.RoTTA.LAMBDA_U)\n\n        # 3) EMA teacher network (ν)\n        self.teacher = deepcopy(self.model).eval()\n        for p in self.teacher.parameters(): p.requires_grad=False\n        self.nu = cfg.ADAPTER.RoTTA.NU\n\n        # optimizer – only γ/β of RBN are trainable\n        params = [p for p in self.model.parameters() if p.requires_grad]\n        self.optimizer = build_optimizer(params)\n\n        # misc\n        self.transform = get_tta_transforms(cfg)\n        self.update_freq = cfg.ADAPTER.RoTTA.UPDATE_FREQUENCY\n        self.counter = 0\n\n    # ----------------------------- forward ---------------------------------\n    @torch.no_grad()\n    def forward(self, x):\n        self.model.eval(); self.teacher.eval()\n        t_out = self.teacher(x)\n        probs = torch.softmax(t_out, dim=1)\n        labels = probs.argmax(1)\n        entropy = - (probs*probs.log()).sum(1)\n        # push each sample into memory\n        for img, y_hat, ent in zip(x, labels, entropy):\n            self.mem.add_instance((img, y_hat.item(), ent.item()))\n            self.counter += 1\n            if self.counter % self.update_freq == 0:\n                self._adapt()\n        return t_out  # always return teacher prediction\n\n    # --------------------------- adaptation step ---------------------------\n    def _adapt(self):\n        imgs, ages = self.mem.get_memory()\n        if len(imgs)==0: return\n        sup = torch.stack(imgs).cuda()\n        strong = self.transform(sup)\n        with torch.no_grad(): ema_out = self.teacher(sup)\n        stu_out = self.model(strong)\n        loss = (_softmax_entropy(stu_out, ema_out) * timeliness_reweighting(torch.tensor(ages).cuda())).mean()\n        self.optimizer.zero_grad(); loss.backward(); self.optimizer.step()\n        self._update_ema()\n\n    # -------------------------- helpers ------------------------------------\n    def _update_ema(self):\n        for t,p in zip(self.teacher.parameters(), self.model.parameters()):\n            t.data.mul_(1-self.nu).add_(self.nu*p.data)\n\n    def _patch_bn(self, model:nn.Module, alpha:float):\n        for name, module in model.named_modules():\n            if isinstance(module, (nn.BatchNorm1d, nn.BatchNorm2d)):\n                new_bn = RobustBN1d(module, alpha) if isinstance(module, nn.BatchNorm1d) else RobustBN2d(module, alpha)\n                # replace in parent\n                parent = model\n                path = name.split('.')\n                for p in path[:-1]: parent = getattr(parent, p)\n                setattr(parent, path[-1], new_bn)\n        # only γ/β are learnable\n        model.requires_grad_(False)\n        for m in model.modules():\n            if isinstance(m, (RobustBN1d, RobustBN2d)):\n                m.weight.requires_grad = True\n                m.bias.requires_grad = True\n        return model\n",
        "experimental_info": "Default hyper-parameters for the above components (core/configs/defaults.py):\n\n1. Robust Batch Normalization (RBN)\n   • α (EMA momentum): 0.05  → cfg.ADAPTER.RoTTA.ALPHA\n   • Only γ/β are updated (others frozen).\n\n2. Category-balanced Sampling (CSTU)\n   • Memory size N: 64        → cfg.ADAPTER.RoTTA.MEMORY_SIZE\n   • Per-class quota: N / (#classes)\n   • λ_t (timeliness weight): 1.0  → cfg.ADAPTER.RoTTA.LAMBDA_T\n   • λ_u (uncertainty weight): 1.0 → cfg.ADAPTER.RoTTA.LAMBDA_U\n\n3. Teacher-Student Adaptation\n   • ν (EMA of parameters): 0.001 → cfg.ADAPTER.RoTTA.NU\n   • Update frequency: 64 steps   → cfg.ADAPTER.RoTTA.UPDATE_FREQUENCY (matches memory size)\n   • Loss: timeliness-weighted cross-entropy between teacher (weak view) & student (strong view).\n\n4. Optimizer / LR\n   • Method: Adam (default)\n   • LR: 1e-3 (cfg.OPTIM.LR)\n   • Only executed for RBN γ/β.\n\n5. Data / Augmentation for strong view\n   • get_tta_transforms(cfg) – strong color jitter, affine, blur, noise, etc.\n\nThese settings reproduce the behaviour described in the \"Method\" section."
      }
    },
    {
      "title": "TTN: A Domain-Shift Aware Batch Normalization in Test-Time Adaptation",
      "abstract": "This paper proposes a novel batch normalization strategy for test-time\nadaptation. Recent test-time adaptation methods heavily rely on the modified\nbatch normalization, i.e., transductive batch normalization (TBN), which\ncalculates the mean and the variance from the current test batch rather than\nusing the running mean and variance obtained from the source data, i.e.,\nconventional batch normalization (CBN). Adopting TBN that employs test batch\nstatistics mitigates the performance degradation caused by the domain shift.\nHowever, re-estimating normalization statistics using test data depends on\nimpractical assumptions that a test batch should be large enough and be drawn\nfrom i.i.d. stream, and we observed that the previous methods with TBN show\ncritical performance drop without the assumptions. In this paper, we identify\nthat CBN and TBN are in a trade-off relationship and present a new test-time\nnormalization (TTN) method that interpolates the statistics by adjusting the\nimportance between CBN and TBN according to the domain-shift sensitivity of\neach BN layer. Our proposed TTN improves model robustness to shifted domains\nacross a wide range of batch sizes and in various realistic evaluation\nscenarios. TTN is widely applicable to other test-time adaptation methods that\nrely on updating model parameters via backpropagation. We demonstrate that\nadopting TTN further improves their performance and achieves state-of-the-art\nperformance in various standard benchmarks.",
      "full_text": "Published as a conference paper at ICLR 2023 TTN: A D OMAIN -SHIFT AWARE BATCH NORMALIZA - TION IN TEST-TIME ADAPTATION Hyesu Lim1,2∗, Byeonggeun Kim ∗, Jaegul Choo 2, Sungha Choi 1‡ 1Qualcomm AI Research†, 2KAIST ABSTRACT This paper proposes a novel batch normalization strategy for test-time adaptation. Recent test-time adaptation methods heavily rely on the modiﬁed batch normal- ization, i.e., transductive batch normalization (TBN), which calculates the mean and the variance from the current test batch rather than using the running mean and variance obtained from source data,i.e., conventional batch normalization (CBN). Adopting TBN that employs test batch statistics mitigates the performance degra- dation caused by the domain shift. However, re-estimating normalization statistics using test data depends on impractical assumptions that a test batch should be large enough and be drawn from i.i.d. stream, and we observed that the previous meth- ods with TBN show critical performance drop without the assumptions. In this paper, we identify that CBN and TBN are in a trade-off relationship and present a new test-time normalization(TTN) method that interpolates the standardization statistics by adjusting the importance between CBN and TBN according to the domain-shift sensitivity of each BN layer. Our proposed TTN improves model robustness to shifted domains across a wide range of batch sizes and in various realistic evaluation scenarios. TTN is widely applicable to other test-time adap- tation methods that rely on updating model parameters via backpropagation. We demonstrate that adopting TTN further improves their performance and achieves state-of-the-art performance in various standard benchmarks. 1 I NTRODUCTION When we deploy deep neural networks (DNNs) trained on the source domain into test environments (i.e., target domains), the model performance on the target domain deteriorates due to the domain shift from the source domain. For instance, in autonomous driving, a well-trained DNNs model may exhibit signiﬁcant performance degradation at test time due to environmental changes, such as camera sensors, weather, and region (Choi et al., 2021; Lee et al., 2022; Kim et al., 2022b). Test-time adaptation (TTA) has emerged to tackle the distribution shift between source and target domains during test time (Sun et al., 2020; Wang et al., 2020). Recent TTA approaches (Wang et al., 2020; Choi et al., 2022; Liu et al., 2021) address this issue by 1) (re-)estimating normaliza- tion statistics from current test input and 2) optimizing model parameters in unsupervised manner, such as entropy minimization (Grandvalet & Bengio, 2004; Long et al., 2016; Vu et al., 2019) and self-supervised losses (Sun et al., 2020; Liu et al., 2021). In particular, the former focused on the weakness of conventional batch normalization (CBN) (Ioffe & Szegedy, 2015) for domain shift in a test time. As described in Fig. 1(b), when standardizing target feature activations using source statistics, which are collected from the training data, the activations can be transformed into an un- intended feature space, resulting in misclassiﬁcation. To this end, the TTA approaches (Wang et al., 2020; Choi et al., 2022; Wang et al., 2022) have heavily depended on the direct use of test batch statistics to ﬁx such an invalid transformation in BN layers, called transductive BN (TBN) (Nado et al., 2020; Schneider et al., 2020; Bronskill et al., 2020) (see Fig. 1(c)). The approaches utilizing TBN showed promising results but have mainly been assessed in limited evaluation settings (Wang et al., 2020; Choi et al., 2022; Liu et al., 2021). For instance, such evalua- tion settings assume large test batch sizes (e.g., 200 or more) and a single stationary distribution shift ∗Work completed while at Qualcomm Technologies, Inc. ‡Corresponding author. †Qualcomm AI Research is an initiative of Qualcomm Technologies, Inc. 1 arXiv:2302.05155v2  [cs.CV]  18 Feb 2023Published as a conference paper at ICLR 2023 0 20 40 60 80 100 CBN TBN Ours TENT TENT+Ours SWR SWR+Ours Error rate (%) 200 64 16 4 2 1 TTN(Ours) TENT+TTN(Ours) SWR+TTN(Ours) Test batch size (a) Valid output using CBN (b) Invalid output using CBN (c) Valid output using TBN (d) Performance drops in small test batches using TBN ● Class A ● Class B Source mean● Source features Test features⨯ Test meanStandardize Figure 1: Trade-off between CBN & TBN.In conceptual illustrations (a), (b), and (c), the depicted standardization only considers making the feature distribution have a zero mean, disregarding mak- ing it have unit variance. When the source and test distributions are different, and the test batch size is large, (b) test features can be wrongly standardized when using CBN (Ioffe & Szegedy, 2015), but (c) TBN (Nado et al., 2020) can provide a valid output. (d) Error rates (↓) on shifted domains (CIFAR-10-C). TBN and TBN applied (TENT (Wang et al., 2020), SWR (Choi et al., 2022)) meth- ods suffer from severe performance drop when the batch size becomes small, while TTN (Ours) improves overall performance. (i.e., single corruption). Recent studies suggest more practical evaluation scenarios based on small batch sizes (Mirza et al., 2022; Hu et al., 2021; Khurana et al., 2021) or continuously changing data distribution during test time (Wang et al., 2022). We show that the performance of existing methods signiﬁcantly drops once their impractical assumptions of the evaluation settings are violated. For example, as shown in Fig. 1(d), TBN (Nado et al., 2020) and TBN applied methods suffer from severe performance drop when the test batch size becomes small, while CBN is irrelevant to the test batch sizes. We identify that CBN and TBN are in a trade-off relationship (Fig. 1), in the sense that one of each shows its strength when the other falls apart. To tackle this problem, we present a novel test-time normalization (TTN)strategy that controls the trade-off between CBN and TBN by adjusting the importance of source and test batch statistics according to the domain-shift sensitivity of each BN layer. Intuitively, we linearly interpolate be- tween CBN and TBN so that TBN has a larger weight than CBN if the standardization needs to be adapted toward the test data. We optimize the interpolating weight after the pre-training but before the test time, which we refer to as the post-training phase. Speciﬁcally, given a pre-trained model, we ﬁrst estimate channel-wise sensitivity of the afﬁne parameters in BN layers to domain shift by analyzing the gradients from the back-propagation of two input images, clean input and its aug- mented one (simulating unseen distribution). Afterward, we optimize the interpolating weight using the channel-wise sensitivity replacing BN with the TTN layers. It is noteworthy that none of the pre-trained model weights are modiﬁed, but we only train newly added interpolating weight. We empirically show that TTN outperforms existing TTA methods in realistic evaluation settings, i.e., with a wide range of test batch sizes for single, mixed, and continuously changing domain adaptation through extensive experiments on image classiﬁcation and semantic segmentation tasks. TTN as a stand-alone method shows compatible results with the state-of-the-art methods and com- bining our TTN with the baselines even boosts their performance in overall scenarios. Moreover, TTN applied methods ﬂexibly adapt to new target domains while sufﬁciently preserving the source knowledge. No action other than computing per batch statistics (which can be done simultaneously to the inference) is needed in test-time; TTN is compatible with other TTA methods without requir- ing additional computation cost. Our contributions are summarized as follows: • We propose a novel domain-shift aware test-time normalization (TTN) layer that combines source and test batch statistics using channel-wise interpolating weights considering the sensitivity to domain shift in order to ﬂexibly adapt to new target domains while preserving the well-trained source knowledge. 2Published as a conference paper at ICLR 2023 Per-batch        Frozen        Optimize S Standardize Ƹ𝑧 = 𝑧𝑖𝑛 −𝜇 𝜎 T Affine Transform 𝑧𝑜𝑢𝑡 = 𝛾⋅ Ƹ𝑧+𝛽 … … CBN CBN CBN … Pre-train (CBN) (a-1) Post-train (TTN)          Test time (TTN) (a) Overall procedure of train and test phases (b) Comparison of BN layers 𝑧𝑖𝑛 S Ƹ𝑧 T 𝑧𝑜𝑢𝑡 𝛾,𝛽+ 1−𝛼 𝜇𝑠,𝜎𝑠𝜇𝑖𝑛,𝜎𝑖𝑛 𝑧𝑖𝑛 S Ƹ𝑧 T 𝑧𝑜𝑢𝑡 𝜇𝑠,𝜎𝑠 𝛾,𝛽 CBN in test time TBN in test time (b-1) TTN(Ours) in post-train 𝑧𝑖𝑛 S Ƹ𝑧 T 𝑧𝑜𝑢𝑡 𝜇𝑖𝑛,𝜎𝑖𝑛 𝛾,𝛽 𝛼 𝑧𝑖𝑛 S Ƹ𝑧 T 𝑧𝑜𝑢𝑡 𝛾,𝛽+ 1−𝛼 𝜇𝑠,𝜎𝑠𝜇𝑖𝑛,𝜎𝑖𝑛 (b-2) TTN(Ours) in test time 𝛼 Figure 2: Method overview. (a) We introduce an additional training phase between pre-train and test time called (a-1) post-training phase. (b) Our proposed TTN layer combines per-batch statistics and frozen source statistics with interpolating weight α, which is (b-1) optimized in post-training phase and (b-2) ﬁxed in test time. • To show the broad applicability of our proposed TTN, which does not alter training or test- time schemes, we show that adding TTN to existing TTA methods signiﬁcantly improves the performance across a wide range of test batch sizes (from 200 to 1) and in three realistic evaluation scenarios; stationary, continuously changing, and mixed domain adaptation. • We evaluate our method through extensive experiments on image classiﬁcation using CIFAR-10/100-C, and ImageNet-C (Hendrycks & Dietterich, 2018) and semantic segmen- tation task using CityScapes (Cordts et al., 2016), BDD-100K (Yu et al., 2020), Mapil- lary (Neuhold et al., 2017), GTA V (Richter et al., 2016), and SYNTHIA (Ros et al., 2016). 2 M ETHODOLOGY In this section, we describe our method, the Test-Time Normalization(TTN) layer, whose design is suitable for test-time adaptation (TTA) in practical usages out of the large batch size and i.i.d assumptions during a test time. We ﬁrst deﬁne the problem setup in Section 2.1 and present our pro- posed TTN layers in Section 2.2. Finally, we discuss how we optimize TTN layers in Sections 2.3. 2.1 P ROBLEM SETUP Let the train and test data be DS and DT and the corresponding probability distributions be PS and PT, respectively, where DS and DT share the output space, i.e., {yi}∼D S = {yi}∼D T. The covariate shift in TTA is deﬁned asPS(x) ̸= PT(x) where PS(y|x) =PT(y|x) (Quinonero-Candela et al., 2008). A model, fθ, with parameters θ, is trained with a mini-batch, BS = {(xi,yi)}|BS| i=1 , from source data DS, where xi is an example and yi is the corresponding label. During the test, fθ encounters a test batch BT ∼DT, and the objective of TTA is correctly managing the test batch from the different distribution. To simulate more practical TTA, we mainly consider two modiﬁcations: (1) various test batch sizes, |BT|, where small batch size indicates small latency while handling the test data online, and (2) multi, N-target domains, DT = {DT,i}N i=1. Under this setting, each test batch BT is drawn by one of the test domains inDT, where DT may consist of a single target domain, multiple target domains, or mixture of target domains. 2.2 T EST-TIME NORMALIZATION LAYER We denote an input of a BN layer as z ∈RBCHW , forming a mini-batch size of B. The mean and variance of z are µand σ2, respectively, which are computed as follows: µc = 1 BHW B∑ b H∑ h W∑ w zbchw, σ 2 c = 1 BHW B∑ b H∑ h W∑ w (zbchw −µc)2, (1) where µand σ2 are in RC, and C, H, and W stand for the number of channels, dimension of height, and that of width, respectively. Based on µand σ2, the source statistics µs,σ2 s ∈RC are usually estimated with exponential moving average over the training data. 3Published as a conference paper at ICLR 2023 Conv CBN ReLU Conv ReLU Conv CBN ReLU FC… CBN 𝑥′ ℒ𝐶𝐸 (a-1) Gradient of affine parameters 𝛾,𝛽 ∇𝛾 (1),∇𝛽 (1) ∇𝛾 (2),∇𝛽 (2) ∇𝛾 (𝐿),∇𝛽 (𝐿) ∇𝛾′ (1),∇𝛽′ (1) ∇𝛾′ (2),∇𝛽′ (2) ∇𝛾′ (𝐿),∇𝛽′ (𝐿) Conv CBN ReLU Conv ReLU Conv CBN ReLU FC… CBN 𝑥 ℒ𝐶𝐸 (a-2) Prior 𝒜 (b-1) Initialize 𝛼 with prior 𝒜 … 1       0 (a) Obtain prior 𝒜 (b) Optimize 𝛼 Per-batch statistics        Frozen source statistics        Gradient flow Conv ReLU Conv ReLU Conv ReLU FC…𝑥′ ℒ𝐶𝐸 +ℒ𝑀𝑆𝐸 TTNTTNTTN 𝛼 1−𝛼 TTN 𝜇𝑠 (𝑙) 𝜇𝑖𝑛 (𝑙) 𝐶𝑙 𝛼(𝑙,𝑐) + 1−𝛼(𝑙,𝑐) … … ++ 𝛼(𝑙,𝐶𝑙) 1−𝛼(𝑙,𝐶𝑙) (b-2) Optimize 𝛼 C1 C2 C𝐿 Figure 3: Two stages in post-training phase. (a) Given a pre-trained model, which uses CBN, and its training data, we obtain prior knowledge of each BN layer. (a-1) We ﬁrst compute gradients of afﬁne parameters in each BN layer from clean x and augmented input x′and obtain the gradient distance score (Eq. 4). (a-2) For BN layers with larger distance score, we put more importance on current batch statistics than source statistics ( i.e., large α), and we deﬁne prior Aaccordingly (Eq. 5). (b) After obtaining prior A, we substitute BN layers from CBN to TTN.(b-1) Initializing α with prior A, (b-2) we optimize αusing CE and MSE loss (Eq. 6) with augmented training data x′. In BN layers, input z is ﬁrst standardized with statistics µand σ2 and then is scaled and shifted with learnable parameters γ and β in RC. The standardization uses current input batch statistics during training and uses estimated source statistics µs and σ2 s at test time (Fig. 2(b)). To address domain shifts in test time, we adjust the source statistics by combining the source and the test mini-batch statistics (Singh & Shrivastava, 2019; Summers & Dinneen, 2019) with a learnable interpolating weight α∈RC ranges [0,1]. Precisely, TTN standardizes a feature with ˜µ= αµ+ (1−α)µs, ˜σ2 = ασ2 + (1−α)σ2 s + α(1 −α)(µ−µs)2, (2) while using the same afﬁne parameters, γ and β. Note that we have different mixing ratios αc for every layer and channel. 2.3 P OST TRAINING Like Choi et al. (2022), we introduce an additional training phase, the post-training (after pre- training but before testing), to optimize the mixing parameters α in Eq. 2 (Fig. 2(a)). Note that all parameters except αare frozen and we have access to the labeled source data during the post- training. We ﬁrst obtain prior knowledge Aof αby identifying which layers and their channels are sensitive to domain shifts. Then, we optimizeαwith the prior knowledge and an additional objective term. The overall procedure is depicted in Fig. 3 and the pseudocode is provided in appendix A.3. Obtain Prior A. To identify which BN layers and corresponding channels are sensitive to domain shifts, we simulate the domain shifts by augmenting1 the clean image, i.e., original training data, and make a pair of (clean x, domain-shifted x′) images, where the semantic information is shared. To analyze in which layer and channel the standardization statistics should be corrected, we consider the standardized features ˆz(l,c) of z(l,c), for a channel index cat a layer l, whose input is clean x. We compare ˆz(l,c) to that of domain-shifted one, ˆz′(l,c) from x′. Since the pre-trained CBN uses the same µ(l,c) s and σ(l,c) s for both inputs, the difference between ˆz(l,c) and ˆz′(l,c) is caused by the domain discrepancy between xand x′. We argue that if the difference is signiﬁcant, the parameter at (l,c) is sensitive to the domain shift, i.e., intensely affected by the domain shift, and hence the standardization statistics at (l,c) should be adapted towards the shifted input. Drawing inspiration from Choi et al. (2022), we measure the domain-shift sensitivity by comparing gradients. Since the standardized feature ˆz is scaled and shifted by γ and β in each BN layer, we compare the gradients of afﬁne parameters γ and β, ∇γ and ∇β, respectively, to measure the dissimilarity of ˆzand ˆz′. As described in Fig. 3(a-1), we collect the ∇γ and ∇β using cross-entropy 1It is noteworthy that the post-training phase is robust to the choice of data augmentation types. Ablation study results and discussions are provided in the appendix B.4. 4Published as a conference paper at ICLR 2023 loss, LCE. To this end, we introduce a gradient distance score, d(l,c) ∈R for each channel cat layer las follows: s= 1 N N∑ i=1 gi ·g′ i ∥gi∥∥g′ i∥, (3) d(l,c) = 1−1 2 ( s(l,c) γ + s(l,c) β ) , (4) where (g,g′) is (∇(l,c) γ ,∇(l,c) γ′ ) and (∇(l,c) β ,∇(l,c) β′ ) for s(l,c) γ and s(l,c) β , respectively,N is the number of training data, and the resulting d(l,c) ∈[0,1]. Once we obtain sγ and sβ from Eq. 3, we conduct min-max normalization over all s(l,c) γ and s(l,c) β , before computing Eq. 4. To magnify the relative difference, we take the square as a ﬁnal step and denote the result as a prior A(Fig. 3(a-2)): A= [d(1,.),d(2,.),...,d (L,.)]2, (5) where d(l,.) = [d(l,c)]Cl c=1. Optimize α. The goal of optimizing α is to make the combined statistics correctly standardize the features when the input is sampled from an arbitrary target domain. After obtaining the prior A, we replace CBN with TTN layers while keeping the afﬁne parameters. Then, we initialize the interpolating weights α with A, which represents in which layer and channel the standardization statistics need to be adapted using test batch statistics (see Fig. 3(b-1)). To simulate distribution shifts, we use augmented training data. Expecting the model to make consistent predictions either given clean or augmented inputs, we use cross-entropy loss LCE. Furthermore, to prevent αfrom moving too far from the initial value A, we use mean-squared error loss LMSE between αand the prior A, i.e., LMSE = ∥α−A∥2 as a constraint. Total lossLcan be written asL= LCE +λLMSE (6), where λis a weighting hyperparameter (Details are provided in the appendix A.1 & B.1). 3 E XPERIMENTS In image classiﬁcation, we evaluate TTN for corruption robustness in realistic evaluation settings, i.e., where the test batch size can be variant and where the target domain can be either stationary, continuously changing, or mixed with multiple domains. Additionally, we further validate TTN on domain generalization benchmarks incorporating natural domain shifts ( e.g., changes in camera sensors, weather, time, and region) in semantic segmentation. 3.1 E XPERIMENTAL SETUP Given models pre-trained on clean source data, we optimize TTN parameter αwith the augmented source data in the post-training phase. Afterward, we evaluate our post-trained model on the cor- rupted target data. Implementation details are provided in the appendix A.1. Datasets and models. We use corruption benchmark datasets CIFAR-10/100-C and ImageNet-C, which consist of 15 types of common corruptions at ﬁve severity levels (Hendrycks & Dietterich, 2018). Each corruption is applied to test images of the clean datasets (CIFAR-10/100 and Ima- geNet). We use a training set of the clean dataset for post-training and the corrupted dataset for evaluation. As backbone models, we used WideResNet-40-2 (Hendrycks et al., 2019) trained on CIFAR-10/100, and ResNet-50 (He et al., 2016) trained on ImageNet. To validate our method in se- mantic segmentation, we conduct experiments on Cityscapes (Cordts et al., 2016), BDD-100K (Yu et al., 2020), Mapillary (Neuhold et al., 2017), GTA V (Richter et al., 2016), and SYNTHIA (Ros et al., 2016) datasets, in accordance with the experimental setup for domain generalization proposed in RobustNet (Choi et al., 2021). Baselines. To demonstrate that TTN successfully controls the trade-off between CBN and TBN, we compare TTN with (1) AdaptiveBN (Schneider et al., 2020), (2) α-BN (You et al., 2021) and (3) MixNorm (Hu et al., 2021), which combines or takes the moving average of the source and the test batch statistics with a pre-deﬁned hyperparameter ( i.e., a constant α). The following baselines are suggested on top of TBN (Nado et al., 2020); (4) TENT (Wang et al., 2020) optimizes BN afﬁne parameters via entropy minimization. (5) SWR (Choi et al., 2022) updates the entire model parame- ters considering the domain-shift sensitivity. (6) CoTTA (Wang et al., 2022) ensembles the output of 5Published as a conference paper at ICLR 2023 Table 1: Single domain adaptation on corruption benchmark. Error rate ( ↓) averaged over 15 corruptions with severity level 5 using WideResNet-40-2 as a backbone for each test batch size. We used reported results of MixNorm with ﬁxed parameters from the original paper and denoted as ∗. In appendix B.3, we provide variants of TTN, which show stronger performance for small test batch. CIFAR-10-C CIFAR-100-C Method 200 64 16 4 2 1 Avg. 200 64 16 4 2 1 Avg. Source (CBN)18.27 18.27 18.27 18.27 18.27 18.27 18.27 46.75 46.75 46.75 46.75 46.75 46.7546.75 Norm TBN 14.49 15.02 17.10 26.28 35.65 90.00 33.09 39.25 40.21 44.03 59.10 80.65 99.0460.38 AdaptiveBN12.21 12.31 12.89 14.51 15.79 16.14 13.98 36.56 36.85 38.19 41.18 43.2644.0140.01 α-BN 13.78 13.77 13.89 14.54 15.1615.4714.44 39.72 39.85 39.99 41.3442.6645.6441.53 MixNorm∗ 13.85 14.41 14.23 14.60 (B=5) - 15.0914.44 - - - - - - - Ours (TTN)11.6711.8012.13 13.93 15.8317.99 13.8935.5835.8436.7341.0846.6757.7142.27 Optim. TENT 12.08 14.78 16.90 25.61 35.69 90.00 32.51 35.52 39.90 43.78 59.02 80.68 99.0259.65 +Ours (TTN)11.2811.5212.04 13.95 15.8417.9413.77 35.1635.5736.5541.1846.6358.3342.24 SWR 10.26 13.51 16.61 27.33 40.48 90.04 33.04 32.6837.41 43.15 59.90 87.07 99.0559.88 +Ours (TTN)9.92 11.7713.41 18.02 24.0961.5623.13 32.8635.1338.6649.8060.7280.9049.68 Table 2: Continuously changing domain adaptation on corruption benchmark. Error rate (↓) averaged over 15 corruptions with severity level 5 using WideResNet-40-2 as backbone for each test batch size. We omitted ‘Norm’ methods results in this table since they are eqaul to that of Table 1. CIFAR-10-C CIFAR-100-C Method 200 64 16 4 2 1 Avg. 200 64 16 4 2 1 Avg. Source (CBN)18.27 18.27 18.27 18.27 18.27 18.2718.27 46.75 46.75 46.75 46.75 46.75 46.7546.75 Ours (TTN)11.6711.80 12.13 13.9315.8317.9913.89 35.58 35.84 36.73 41.08 46.67 57.71 42.27 Optim. CoTTA 12.46 14.60 21.26 45.69 58.87 90.0040.48 39.75 42.20 52.94 73.69 87.66 98.9965.87 TENT 12.54 13.52 15.69 26.23 35.77 90.0032.29 36.11 37.90 43.78 58.71 81.76 99.0459.55 +Ours (TTN)11.4411.60 12.08 16.1418.3622.4015.33 43.50 37.60 38.28 44.60 54.2980.63 49.82 SWR 11.04 11.53 13.90 23.99 34.02 90.0030.75 34.16 35.79 40.71 58.15 80.55 99.0362.56 +Ours (TTN)10.09 10.5111.28 14.2916.6784.1224.49 33.0934.07 36.15 42.41 53.63 93.08 48.74 augmented test inputs, updates the entire model parameters using a consistency loss between student and teacher models, and stochastically restores the pre-trained model. We refer to TBN, (1), (2), and (3) as normalization-based methods (Norm), the other as optimization-based methods (Optim.), and denote the pre-trained model using CBN as ‘source’. Evaluation scenarios. To show that TTN performs robust on various test batch sizes, we conduct experiments with test batch sizes of 200, 64, 16, 4, 2, and 1. We evaluate our method in three evalu- ation scenarios; single, continuously changing, and mixed domain adaptation. In the single domain adaptation, the model is optimized for one corruption type and then reset before adapting to the subsequent corruption, following the evaluation setting from TENT and SWR. In the continuously changing adaptation (Wang et al., 2022), the model is continuously adapted to 15 corruption types (w/o the reset), which is more realistic because it is impractical to precisely indicate when the data distribution has shifted in the real world. Finally, to simulate the non-stationary target domain where various domains coexist, we evaluate methods in the mixed domain adaptation setting, where a sin- gle batch contains multiple domains. We use a severity level of 5 (Hendrycks & Dietterich, 2018) for all experiments. It is noteworthy that we use a single checkpoint of TTN parameter αfor each dataset across all experimental settings. 3.2 E XPERIMENTS ON IMAGE CLASSIFICATION Tables 1, 2, and 3 show error rates on corruption benchmark datasets in three different evaluation scenarios; single domain, continuously changing, and mixed domain adaptation, respectively. Note that the performance of normalization-based methods in the single (Table 1) and in the continu- ously changing (Table 2) settings are identical. Tables 4 and 5 show the adaptation performance on the source and class imbalanced target domains, respectively. More results and discussions are provided in the appendix B, importantly, including results on ImageNet-C (B.5). Robustness to practical settings. In Table 1, 2, and 3, TTN and TTN applied methods show robust performance over the test batch size ranges from 200 to 1. Comparing with normalization-based baselines, we demonstrate that TTN, which uses channel-wisely optimized combining rateα, shows better results than deﬁning α as a constant hyperparameter, which can be considered as a special 6Published as a conference paper at ICLR 2023 Table 3: Mixed domain adaptation on corruption benchmark. Error rate (↓) of mixed domain with severity level 5 using WideResNet-40-2 as backbone for each test batch size. We used the reported results of MixNorm with ﬁxed parameters from the original paper and denoted them as ∗. CIFAR-10-C CIFAR-100-C Method 200 64 16 4 2 1 Avg. 200 64 16 4 2 1 Avg. Source (CBN)18.27 18.27 18.27 18.27 18.27 18.2718.27 46.75 46.75 46.75 46.75 46.75 46.7546.75 Norm TBN 14.99 15.29 17.38 26.65 35.59 90.0033.31 39.88 40.48 43.73 59.11 80.30 98.9160.40 AdaptiveBN12.62 12.48 12.97 14.59 15.74 16.0214.07 36.88 36.86 38.49 41.43 43.38 44.3140.23 α-BN 13.78 13.78 13.99 14.6115.07 15.2014.41 40.25 40.11 40.47 41.6442.39 43.8141.45 MixNorm∗ 18.80 18.80 18.80 18.80 18.80 18.8018.80 - - - - - - - Ours (TTN)12.1612.1912.3413.9615.5517.8314.00 36.2436.2336.8541.0145.8555.5241.95 Optim. TENT 14.33 14.97 17.30 26.07 35.37 90.0033.01 39.36 40.01 43.33 58.98 80.55 98.9260.19 +Ours (TTN)12.0212.0412.2013.7715.4216.4013.64 36.2936.2336.8941.3846.6557.9542.57 SWR 13.24 13.06 16.57 26.08 38.65 91.0359.54 37.84 37.93 44.37 59.50 78.66 98.9533.10 +Ours (TTN)11.8911.6513.3717.0523.5064.1050.29 36.4936.5139.6046.2058.2084.7623.59 case of TTN; TBN and α-BN corresponds to α = 1and 0.1, respectively. More comparisons with different constant αare provided in the appendix B.2. It is noteworthy that TTN as a stand-alone method favorably compares with optimization-based baselines in all three scenarios. Table 4: Source domain adaptation. Error rate (↓) on CIFAR-10 using WideResNet-40-2. Method Test batch size Avg.200 64 16 4 2 1 Source (CBN)4.92 4.92 4.92 4.92 4.92 4.924.92 Norm TBN 6.41 6.60 8.64 17.65 26.08 90.0025.90Ours (TTN)4.885.115.357.27 9.45 9.96 7.00 Optim. TENT 6.15 6.45 8.61 17.61 26.20 90.0032.2+Ours (TTN)4.935.115.327.22 9.3810.217.02 SWR 5.63 6.01 8.25 17.49 26.32 90.0025.62+Ours (TTN)4.795.025.516.68 7.91 9.34 6.54 Table 5: Class imbalanced target domain. Error rate (↓) averaged over 15 corruptions of CIFAR- 10-C with severity level 5 using WideResNet-40- 2. Details are provided in the appendix A.2. Method Test batch size Avg.200 64 16 4 2 1 Source (CBN)18.27 18.27 18.27 18.27 18.27 18.2718.27 TBN 77.60 76.66 77.72 78.59 77.84 90.0079.74Ours (TTN)35.7535.1334.9232.5128.6017.9930.82 Adopting TTN improves other TTA methods. We compare optimization-based methods with and without TTN layers. Since TENT, SWR, and CoTTA optimize model parameters on top of using TBN layers, they also suffer from performance drops when the test batch size becomes small. Adopting TTN reduces the dependency on large test batch size, i.e., makes robust to small batch size, and even improves their performance when using large test batch. Furthermore, in continual (Table 2) and mixed domain (Table 3) adaptation scenario, TENT and SWR shows higher error rate than in single domain (Table 1) adaptation. We interpret that because they update the model parameters based on the current output and predict the next input batch using the updated model, the model will not perform well if the consecutive batches have different corruption types ( i.e., mixed domain adaptation). Moreover, the error from the previous input batch propagates to the future input stream, and thus they may fall apart rapidly once they have a strongly wrong signal, which can happen in continual adaptation ( i.e., long-term adaptation without resetting). Applying TTN signiﬁcantly accelerates their model performance regardless of the evaluation scenarios. TTN preserves knowledge on source domain. In practice, data driven from the source domain (or a merely different domain) can be re-encountered in test time. We used clean domain test data in the single domain adaptation scenario to show how TTN and other TTA methods adapt to the seen source domain data (but unseen instance). As shown in Table 4, all baseline methods using TBN layers, show performance drops even with large batch sizes. We can conclude that it is still better to rely on source statistics collected from the large training data than using only current input statistics, even if its batch size is large enough to obtain reliable statistics ( i.e., 200). However, since TTN utilizes source statistics while leveraging the current input, TTN itself and TTN adopted methods well preserve the source knowledge compared to the TBN-based methods. With a batch size of 200, we observe that combining the source and a current test batch statistics outperforms the source model (see 3rd row of Table 4). TTN is robust to class imbalanced scenario. Heavily depending on current test batch statistics are especially vulnerable when the class labels are imbalanced (Boudiaf et al., 2022; Gong et al., 2022). To simulate this situation, we sorted test images in class label order and then sampled test batches following the sorted data order. In Table 5, we observe that TTN is more robust to the class imbalanced scenario than utilizing only test batch statistics (i.e., TBN). As explained in Section 3.5, 7Published as a conference paper at ICLR 2023 Table 6: Adaptation on DG benchmarks in semantic segmentation. mIoU(↑) on four unseen domains with test batch size of 2 using ResNet-50 based DeepLabV3+ as a backbone. Method(Cityscapes→) BDD-100K Mapillary GTA V SYNTHIA Cityscapes Source (Chen et al., 2018) 43.50 54.37 43.71 22.78 76.15 Norm TBN 43.12 47.61 42.51 25.71 72.94 Ours (TTN) 47.40 56.92 44.71 26.68 75.09 Optim. TENT 43.30 47.80 43.57 25.92 72.93 + Ours (TTN) 47.89 57.84 46.18 27.29 75.04 SWR 43.40 47.95 42.88 25.97 72.93 + Ours (TTN) 48.85 59.09 46.71 29.16 74.89 we are putting more importance on CBN than TBN, where semantic information is mainly handled, i.e., in deeper layers, so we can understand that TTN is less impacted by skewed label distribution. 3.3 E XPERIMENTS ON SEMANTIC SEGMENTATION We additionally conduct experiments on domain generalization (DG) benchmarks (Choi et al., 2021; Pan et al., 2018) for semantic segmentation, including natural domain shifts ( e.g., Cityscapes→BDD-100K), to demonstrate the broad applicability of TTN. Table 6 shows the results of evaluating the ResNet-50-based DeepLabV3+ (Chen et al., 2018) model trained on the Cityscapes training set using the validation set of real-world datasets such as Cityscapes, BDD-100K, and Map- illary, and synthetic datasets including GTA V and SYNTHIA. We employ a test batch size of 2 for test-time adaptation in semantic segmentation. We observe that even when exploiting test batch statistics for standardization in BN layers (TBN) or updating the model parameters on top of TBN (TENT, SWR) does not improve the model performance (i.e., perform worse than the source model), adopting TTN helps the model make good use of the strength of the test batch statistics. Implemen- tation details and additional results are provided in the appendix A.1 and B.7, respectively. 3.4 A BLATION STUDIES Prior Aregularizes αto be robust to overall test batch sizes. We conduct an ablation study on the importance of each proposed component,i.e., initializing αwith prior A, optimizing αusing CE and MSE losses, and the results are shown in Table 7. Using Afor initialization and MSE loss aims to optimize αfollowing our intuition that we discussed in Section 2.3. Optimizing αusing CE loss improves the overall performance, but without regularizing with MSE loss, αmay overﬁt to large batch size (rows 2 & 3). Initialization with Aor not does not show a signiﬁcant difference, but A provides a better starting point than random initialization when comparing the left and right of the 2nd row. We observe that when using MSE loss, regardless of initialization using A, the optimized αsufﬁciently reﬂects our intuition resulting in a low error rate to overall batch sizes (row 3). Table 7: Ablation study on importance of each component Method Test batch size Avg. Method Test batch size Avg.Init. CE MSE200 64 16 4 2 1 Init. CE MSE200 64 16 4 2 1 - - \u0013 13.36 13.43 13.85 15.50 17.43 20.0715.61 \u0013 - - 13.37 13.43 13.85 15.50 17.44 20.0715.61 - \u0013 - 11.64 11.7312.26 14.46 16.94 19.8814.49 \u0013 \u0013 - 11.73 11.82 12.23 14.18 16.41 19.2714.27 - \u0013 \u0013 11.6411.7812.21 13.97 15.86 18.0013.91 \u0013 \u0013 \u0013 11.67 11.80 12.13 13.93 15.83 17.9913.89 3.5 V ISUALIZATION OF α Fig. 4 shows the visualization of optimized αfor CIFAR-10 using WideResNet-40-2. We observe that α decreases from shallow to deep layers (left to right), which means CBN is more active in deeper layers, and TBN is vice versa. As shown in Table 4 and 6, CBN employing source statistics is superior to TBN when the distribution shift between source and target domains is small. Assum- ing that the αwe obtained is optimal, we can conjecture that CBN is more active ( i.e., αcloser to 0) in deeper layers because domain information causing the distribution shift has been diminished. In contrast, TBN has a larger weight ( i.e., α closer to 1) in shallower layers since the domain in- formation induces a large distribution shift. This interpretation is consistent with the observations of previous studies (Pan et al., 2018; Wang et al., 2021; Kim et al., 2022a) that style information mainly exists in shallower layers, whereas only content information remains in deeper layers. 8Published as a conference paper at ICLR 2023 𝐶𝑙 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Channel-wise 𝛼 Channel mean 𝛼 per layer Channels in all layers1 2661 Figure 4: Optimized α. x- and y-axes indicate all channels in order from shallow to deep layers and the interpolating weight α, respectively. Cl denotes the channel size of layer l. 4 R ELATED WORK Test-time adaptation/training (TTA) aims to adapt models towards test data to overcome the per- formance degradation caused by distribution shifts (Sun et al., 2020; Wang et al., 2020). There are other related problems, unsupervised domain adaptation (UDA) (Sun & Saenko, 2016; Ganin et al., 2016) and source-free domain adaptation (SFDA) (Liang et al., 2020; Huang et al., 2021; Liu et al., 2021). Both UDA and SFDA have access to sufﬁciently large enough unlabeled target datasets, and their objective is to achieve high performance on that particular target domain. Unlike UDA and SFDA, TTA utilizes test data in an online manner. There are two key factors of recent approaches: adapting standardization statistics in normalization layers and adapting model parameters. Normalization in Test Time. Nado et al. (2020) suggested prediction-time BN, which uses test batch statistics for standardization and Schneider et al. (2020) introduced to adapt BN statistics by combining source and test batch statistics considering the the test batch size to mitigate the inter- mediate covariate shift. In this paper, we refer to the former method as TBN. Similarly, You et al. (2021) and Khurana et al. (2021) mixed the statistics using predeﬁned hyperparameter. Also, Mirza et al. (2022) and Hu et al. (2021) adapted the statistics using moving average while augmenting the input to form a pseudo test batch when only a single instance is given. The primary difference with the existing approaches is that we consider the channel-wise domain-shift sensitivity of BN layers to optimize the interpolating weights between CBN and TBN. Concurrently, Zou et al. (2022) pro- posed to adjust the standardization statistics using a learnable calibration strength and showed its effectiveness focusing on the semantic segmentation task. Optimization in Test Time.TENT (Wang et al., 2020), SWR (Choi et al., 2022), and CoTTA (Wang et al., 2022) updated model parameters while using TBN. TENT optimized afﬁne parameters in BN layers using entropy minimization while freezing the others. To maximize the adaptability, SWR updated the entire model parameters minimizing the entropy loss based on the domain-shift sensitivity. To stabilize the adaptation in continuously changing domains, CoTTA used consistency loss between student and teacher models and stochastically restored random parts of the pre-trained model. Liu et al. (2021) and Chen et al. (2022) suggested to update the model through contrastive learning. We focus on correcting the standardization statistics using domain-shift aware interpolating weight α. Similar to Choi et al. (2022), we measure the domain-shift sensitivity by comparing gradients. The principle difference is that we use channel-wise sensitivity when optimizing αin post-training, while SWR used layer-wise sensitivity regularizing the entire model update in test time. 5 C ONCLUSIONS This paper proposes TTN, a novel domain-shift aware batch normalization layer, which combines the beneﬁts of CBN and TBN that have a trade-off relationship. We present a strategy for mixing CBN and TBN based on the interpolating weight derived from the optimization procedure utilizing the sensitivity to domain shift and show that our method signiﬁcantly outperforms other normaliza- tion techniques in various realistic evaluation settings. Additionally, our method is highly practical because it can complement other optimization-based TTA methods. The oracle mixing ratio between CBN and TBN can vary depending on the domain gap difference. However, our proposed method employs a ﬁxed mixing ratio during test time, where the mixing ratio is optimized before model deployment. If we could ﬁnd the optimal mixing ratio according to the distribution shift during test time, we can expect further performance improvement. We consider it as future work. In this regard, our efforts encourage this ﬁeld to become more practical and inspire new lines of research. 9Published as a conference paper at ICLR 2023 REPRODUCIBILITY STATEMENT To ensure the reproducibility of our method, we provide the experimental setup in Section 3.1. Moreover, the details on implementation and evaluation settings can be found in the appendix A.1 and A.2, respectively. The pseudocode for overall training and testing scheme is provided in the appendix A.3. Together with related references and publicly available codes, we believe our paper contains sufﬁcient information for reimplementation. ACKNOWLEDGEMENT We would like to thank Kyuwoong Hwang, Simyung Chang, and Seunghan Yang of the Qualcomm AI Research team for their valuable discussions. REFERENCES Malik Boudiaf, Romain Mueller, Ismail Ben Ayed, and Luca Bertinetto. Parameter-free online test-time adaptation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022. John Bronskill, Jonathan Gordon, James Requeima, Sebastian Nowozin, and Richard Turner. Tas- knorm: Rethinking batch normalization for meta-learning. In International Conference on Ma- chine Learning (ICML). PMLR, 2020. Dian Chen, Dequan Wang, Trevor Darrell, and Sayna Ebrahimi. Contrastive test-time adaptation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022. Liang-Chieh Chen, Yukun Zhu, George Papandreou, Florian Schroff, and Hartwig Adam. Encoder- decoder with atrous separable convolution for semantic image segmentation. In Proceedings of the European conference on computer vision (ECCV), 2018. Sungha Choi, Sanghun Jung, Huiwon Yun, Joanne T Kim, Seungryong Kim, and Jaegul Choo. Robustnet: Improving domain generalization in urban-scene segmentation via instance selective whitening. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2021. Sungha Choi, Seunghan Yang, Seokeon Choi, and Sungrack Yun. Improving test-time adaptation via shift-agnostic weight regularization and nearest source prototypes. In European Conference on Computer Vision (ECCV), 2022. Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. The cityscapes dataset for semantic urban scene understanding. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016. Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Franc ¸ois Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural net- works. The journal of machine learning research, 2016. Taesik Gong, Jongheon Jeong, Taewon Kim, Yewon Kim, Jinwoo Shin, and Sung-Ju Lee. Note:robust continual test-time adaptation against temporal correlation. Advances in Neural In- formation Processing Systems (NeurIPS), 2022. Priya Goyal, Piotr Doll´ar, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, An- drew Tulloch, Yangqing Jia, and Kaiming He. Accurate, large minibatch sgd: Training imagenet in 1 hour. arXiv preprint arXiv:1706.02677, 2017. Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. In Ad- vances in Neural Information Processing Systems (NeurIPS), 2004. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog- nition. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016. 10Published as a conference paper at ICLR 2023 Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common cor- ruptions and perturbations. In International Conference on Learning Representations (ICLR), 2018. Dan Hendrycks, Norman Mu, Ekin Dogus Cubuk, Barret Zoph, Justin Gilmer, and Balaji Lakshmi- narayanan. Augmix: A simple data processing method to improve robustness and uncertainty. In International Conference on Learning Representations (ICLR), 2019. Xuefeng Hu, Gokhan Uzunbas, Sirius Chen, Rui Wang, Ashish Shah, Ram Nevatia, and Ser-Nam Lim. Mixnorm: Test-time adaptation through online normalization estimation. arXiv preprint arXiv:2110.11478, 2021. Jiaxing Huang, Dayan Guan, Aoran Xiao, and Shijian Lu. Model adaptation: Historical contrastive learning for unsupervised domain adaptation without source data. 2021. Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. InInternational Conference on Machine Learning (ICML), 2015. Ansh Khurana, Sujoy Paul, Piyush Rai, Soma Biswas, and Gaurav Aggarwal. Sita: Single image test-time adaptation. arXiv preprint arXiv:2112.02355, 2021. Byeonggeun Kim, Seunghan Yang, Jangho Kim, Hyunsin Park, Juntae Lee, and Simyung Chang. Domain Generalization with Relaxed Instance Frequency-wise Normalization for Multi-device Acoustic Scene Classiﬁcation. In Conference of the International Speech Communication Asso- ciation (INTERSPEECH), 2022a. Jin Kim, Jiyoung Lee, Jungin Park, Dongbo Min, and Kwanghoon Sohn. Pin the memory: Learn- ing to generalize semantic segmentation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022b. Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. 2015. Suhyeon Lee, Hongje Seong, Seongwon Lee, and Euntai Kim. Wildnet: Learning domain general- ized semantic segmentation from the wild. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022. Jian Liang, Dapeng Hu, and Jiashi Feng. Do we really need to access the source data? source hypothesis transfer for unsupervised domain adaptation. In International Conference on Machine Learning (ICML). PMLR, 2020. Yuejiang Liu, Parth Kothari, Bastien van Delft, Baptiste Bellot-Gurlet, Taylor Mordan, and Alexan- dre Alahi. Ttt++: When does self-supervised test-time training fail or thrive? Advances in Neural Information Processing Systems (NeurIPS), 2021. Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I Jordan. Unsupervised domain adap- tation with residual transfer networks. In Advances in Neural Information Processing Systems (NeurIPS), 2016. Ilya Loshchilov and Frank Hutter. Sgdr: Stochastic gradient descent with warm restarts. 2017. M Jehanzeb Mirza, Jakub Micorek, Horst Possegger, and Horst Bischof. The norm must go on: Dynamic unsupervised domain adaptation by normalization. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022. Zachary Nado, Shreyas Padhy, D Sculley, Alexander D’Amour, Balaji Lakshminarayanan, and Jasper Snoek. Evaluating prediction-time batch normalization for robustness under covariate shift. arXiv preprint arXiv:2006.10963, 2020. Gerhard Neuhold, Tobias Ollmann, Samuel Rota Bulo, and Peter Kontschieder. The mapillary vistas dataset for semantic understanding of street scenes. In International Conference on Computer Vision (ICCV), 2017. Xingang Pan, Ping Luo, Jianping Shi, and Xiaoou Tang. Two at once: Enhancing learning and generalization capacities via ibn-net. InEuropean Conference on Computer Vision (ECCV), 2018. 11Published as a conference paper at ICLR 2023 Joaquin Quinonero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil D Lawrence. Dataset shift in machine learning. Mit Press, 2008. Stephan R. Richter, Vibhav Vineet, Stefan Roth, and Vladlen Koltun. Playing for data: Ground truth from computer games. In European Conference on Computer Vision (ECCV), 2016. German Ros, Laura Sellart, Joanna Materzynska, David Vazquez, and Antonio M Lopez. The synthia dataset: A large collection of synthetic images for semantic segmentation of urban scenes. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016. Steffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bringmann, Wieland Brendel, and Matthias Bethge. Improving robustness against common corruptions by covariate shift adaptation. Ad- vances in Neural Information Processing Systems (NeurIPS), 2020. Saurabh Singh and Abhinav Shrivastava. Evalnorm: Estimating batch normalization statistics for evaluation. In International Conference on Computer Vision (ICCV), 2019. Cecilia Summers and Michael J Dinneen. Four things everyone should know to improve batch normalization. In International Conference on Learning Representations (ICLR), 2019. Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation. In European Conference on Computer Vision (ECCV), 2016. Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt. Test-time train- ing with self-supervision for generalization under distribution shifts. In International Conference on Machine Learning (ICML), 2020. Tuan-Hung Vu, Himalaya Jain, Maxime Bucher, Matthieu Cord, and Patrick P´erez. Advent: Adver- sarial entropy minimization for domain adaptation in semantic segmentation. InIEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019. Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, and Trevor Darrell. Tent: Fully test-time adaptation by entropy minimization. In International Conference on Learning Repre- sentations (ICLR), 2020. Qin Wang, Olga Fink, Luc Van Gool, and Dengxin Dai. Continual test-time domain adaptation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022. Yulin Wang, Zanlin Ni, Shiji Song, Le Yang, and Gao Huang. Revisiting locally supervised learning: an alternative to end-to-end training. In International Conference on Learning Representations (ICLR), 2021. Fuming You, Jingjing Li, and Zhou Zhao. Test-time batch statistics calibration for covariate shift. arXiv preprint arXiv:2110.04065, 2021. Fisher Yu, Haofeng Chen, Xin Wang, Wenqi Xian, Yingying Chen, Fangchen Liu, Vashisht Madha- van, and Trevor Darrell. Bdd100k: A diverse driving dataset for heterogeneous multitask learning. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020. Yuliang Zou, Zizhao Zhang, Chun-Liang Li, Han Zhang, Tomas Pﬁster, and Jia-Bin Huang. Learn- ing instance-speciﬁc adaptation for cross-domain segmentation. European Conference on Com- puter Vision (ECCV), 2022. 12Published as a conference paper at ICLR 2023 A A PPENDIX : F OR REPRODUCIBILITY This section provides supplemental material for Section 2 and 3.1. A.1 I MPLEMENTATION DETAILS Datasets and Models. For CIFAR-10/100-C, we optimized α using augmented CIFAR-10/100 training set on the pre-trained WideResNet-40-2 (WRN-40) (Hendrycks et al., 2019). For ImageNet- C, we used augmented ImageNet training set (randomly sampled 64000 instances per epoch) on the pre-trained ResNet-50. Augmentation. Following the setting of SWR (Choi et al., 2022), we used color jittering, random invert and random grayscale when obtaining the prior A. When optimizing α, we followed the augmentation choice of CoTTA (Wang et al., 2022), which are color jittering, padding, random afﬁne, gaussian blur, center crop and random horizontal ﬂip. We excluded for gaussian noise to avoid any overlap with corruption type of common corruptions (Hendrycks & Dietterich, 2018). For ImageNet, we only used the same augmentation both for obtaining Aand optimizing αfollowing the SWR augmentation choices. Post-training. When obtaining prior, we used randomly selected 1024 samples from the training set, following the setting of SWR. We used Adam (Kingma & Ba, 2015) optimizer using a learning rate (LR) of 1e-3, which is decayed with cosine schedule (Loshchilov & Hutter, 2017) for 30 epochs and used 200 training batch for CIFAR-10/100. For ImageNet, we lowered LR to 2.5e-4 and used 64 batch size. For semantic segmentation task, we trained TTN using Cityscapes training set, and training batch size of 2. We resized the image height to 800 while preserving the original aspect ratio Cordts et al. (2016). We can terminate the training when MSE loss saturates (We observed that αdoes not show signiﬁcant difference after the MSE loss is saturated). We used the weighting hyperparmeter to MSE loss λas 1. Test time. For AdaptiveBN, which adjusts the interpolating weight using two factors: hyperpa- rameter N and test batch size n, we followed the suggested N, which is empirically obtained best hyperparameter from the original paper, for each n(Figure 11, ResNet architecture from Schneider et al. (2020)). In detail, we set N as 256, 128, 64, 32, and 16 for test batch size 200, 64, 16, 4, 2, and 1, which yields αas 0.44, 0.33, 0.2, 0.11, 0.06, and 0.06, respectively. For optimization-based TTA methods, we followed default setting in TENT, SWR, and CoTTA for test-time adaptation. We used LR of 1e-3 to test batch size of 200 for CIFAR-10/100-C in single domain (TENT, SWR) and continuously changing domain (CoTTA) scenarios. To avoid rapid error accumulation, we lowered LR to 1e-4 for TENT and SWR in continual and mixed do- main scenarios. Moreover, we updated model parameters after accumulating the gradients for 200 samples for CIFAR-10/100-C. In other words, we compute gradients per batch, but update, i.e., optimizer.step(), after seeing 200 data samples. Exceptionally, we used LR of 5e-5 for SWR and SWR+TTN in mixed domain setting. Additionally, in continuously changing and mixed domain scenarios, we used the stable version of SWR, which updates the model parameter based on the frozen source parameters instead of previously updated parameters (original SWR). For semantic segmentation, we set the test batch size as 2 and learning rate for optimization-based methods as 1e-6 for all datasets. For SWR, we set the importance of the regularization term λr as 500. The other hyperparameters are kept the same as Choi et al. (2022) choices. For all test-time adaptation, we used constant learning rate without scheduling. A.2 E VALUATION SCENARIO DETAILS Class imbalanced setting. In the main paper Table 5, we show the results under class imbalanced settings. In the setting, we sorted the test dataset of each corruption in the order of class labels, i.e., from class 0 to 9 for CIFAR-10-C. Then, we comprised test batches following the sorted order. Therefore, most batches consist of single class input data, which leads to biased test batch statistics. For larger batch size, the statistics are more likely to be extremely skewed, and that explains why error rates are higher with larger batch sizes than with the small ones. 13Published as a conference paper at ICLR 2023 A.3 P SEUDOCODE Pseudocode for post-training, i.e., obtaining Aand optimizing α, is provided in Algorithms 1 and 2, respectively, and that for test time is in Algorithm 3. Moreover, we provide PyTorch-friendly pseudocode for obtaining Ain Listing 1. Please see Section 2 for equations and terminologies used in the algorithms. Algorithm 1 Obtain prior A 1: Require: Pre-trained model fθ; source training data DS = (X,Y ) 2: Output: Prior A 3: for all (x,y) in DS do 4: Augment x: x′ 5: Collect gradients (∇γ,∇γ′ ) and (∇β,∇β′ ) from fθ using clean xand augmented x′ 6: end for 7: Compute gradient distance score dusing Eq. 4 8: Deﬁne prior Ausing Eq. 5 Algorithm 2 Post-train 1: Require: Pre-trained model fθ; source training data DS = (X,Y ); step size hyperparameter η; regularization weight hyperparameter λ 2: Output: Optimized interpolating weight α 3: Obtain prior Ausing Algorithm 1 4: Initialize αwith prior A 5: Replace all BN layers of fθ to TTN layers using αand Eq. 2 6: while not done do 7: Sample minibatches BS from DS 8: for all minibatches do 9: Augment all xin BS: x′ 10: Evaluate ∇αLusing fθ given {(x′ i,yi)}|BS| i=1 using Eq. 6 while adapting standardization statistics using Eq. 2 11: Update α←α−η∇αL 12: end for 13: end while Algorithm 3 Inference (Test time) 1: Require: Pre-trained model fθ; optimized α, target test data DT = (X); 2: Replace all BN layers of fθ to TTN layers using αand Eq. 2 3: Sample minibatches BT from DT 4: for all minibatches do 5: Make prediction using fθ given BT while adapting standardization statistics using Eq. 2 6: end for 1 def obtain_prior(model, train_data): 2 # make weight and bias of BN layers requires_grad=True, otherwise False 3 params = {n: p for n, p in model.named_parameters() if p.requires_grad} 4 5 grad_sim = {} 6 for x, y in train_data: 7 # collect gradients for clean and augmented input 8 grad_org = collect_grad(model, x, y, params) 9 grad_aug = collect_grad(model, augment(x), y, params) 10 11 # compute grad similarity 12 for n, p in params.items(): 13 grad_sim[n].data = cosine_sim(grad_org, grad_aug) 14 14Published as a conference paper at ICLR 2023 15 # average over data samples 16 for n, p in params.items(): 17 grad_sim[n].data /= len(train_data) 18 19 # min max normalization 20 max_grad = get_max_value(grad_sim) # scalar 21 min_grad = get_min_value(grad_sim) # scalar 22 grad_dist = {} 23 for n, p in grad_sim.items(): 24 grad_dist[n] = (p - min_grad) / (max_grad - min_grad) 25 26 prior = [] 27 j = 0 28 # integrate gradients of weight(gamma) and bias(beta) for each BN layer 29 for n, p in grad_dist.items(): 30 if \"weight\" in n: 31 prior.append(p) 32 elif \"bias\" in n: 33 prior[j] += p 34 prior[j] /= 2 35 prior[j] = (1-prior[j])**2 36 j += 1 37 38 return prior 39 40 def collect_grad(model, x, y, params): 41 model.zero_grad() 42 out = model(x) 43 loss = ce_loss(out, y) 44 loss.backward() 45 46 grad = {} 47 for n, p in params.items(): 48 grad[n].data = p.data 49 50 return grad Listing 1: PyTorch-friendly pseudo code for obtaining prior B A PPENDIX : E XPERIMENTAL RESULTS B.1 A BLATION STUDIES Channel-wise α. In Table 8, we compared different granularity levels of interpolating weightα, i.e., channel-wise, layer-wise, and a constant value with CIFAR-10-C and backbone WRN-40. We ob- served that channel-wise optimized αshows the best performance. We take average of the channel- wisely optimized α (the 1st row) over channels to make a layer-wise α (the 2nd row), and take average over all channels and layers to make a constant value (the 3rd row). αof the 1st and 2nd rows are visualized in the main paper Figure 4 colored in blue and red, respectively. The constant value α(the 3rd row) is 0.3988. We also optimized αlayer-wisely (the 4th row). Table 8: Ablation study on granularity level of α # Method Test batch size Avg. 200 64 16 4 2 1 1 Channel-wise (Optimized) 11.67 11.80 12.13 13.93 15.83 17.99 13.89 2 Layer-wise (Channel mean) 12.75 12.84 13.16 14.66 16.40 18.82 14.77 3 Constant (Mean) 12.07 12.21 13.05 16.72 20.04 21.26 15.89 4 Layer-wise (Optimized) 13.11 13.21 13.51 14.84 16.46 18.62 14.96 15Published as a conference paper at ICLR 2023 MSE loss strength λ. We empirically set the MSE loss strengthλin Eq. 6 as 1 through the ablation study using CIFAR-10-C and WRN-40 (Table 9). Using the MSE regularizer prevents the learnable αfrom moving too far from the prior, thus letting αfollow our intuition, i.e., putting smaller im- portance on the test batch statistics if the layer or channel is invariant to domain shifts. However, with too strong regularization (λ=10.0), the overall error rates are high, which means the αneeds to be sufﬁciently optimized. On the other hand, with too small regularization, the αmay overﬁt to the training batch size (B=200) and lose the generalizability to the smaller batch size. Table 9: MSE loss strength λ λ Test batch size Avg. 200 64 16 4 2 1 0.0 11.73 11.82 12.23 14.18 16.41 19.27 14.27 0.1 11.65 11.91 12.09 13.84 15.71 18.24 13.91 1.0 11.67 11.80 12.13 13.93 15.83 17.99 13.89 10.0 12.45 12.63 12.82 14.55 16.32 18.56 14.56 B.2 M ORE COMPARISONS ON CIFAR10-C Constant α. Table 10 shows results of simple baseline for normalization-based methods where the αis a constant value ranging from 0 to 1. α= 0 is identical to CBN (Ioffe & Szegedy, 2015), and α = 1 is identical to TBN (Nado et al., 2020). We observe that the lower α, i.e., using less test batch statistics, shows better performance for small test batch sizes. This observation is analogous to the ﬁnding of the previous work (Schneider et al., 2020). Table 10: Constant α. Error rate (↓) averaged over 15 corruptions of CIFAR-10-C (WRN-40). α Test batch size Avg. 200 64 16 4 2 1 0 18.26 18.39 18.26 18.26 18.25 18.25 18.28 0.1 13.95 14.1 14.05 14.65 15.14 15.45 14.56 0.2 12.46 12.66 12.89 14.30 15.53 15.64 13.91 0.3 12.05 12.29 12.72 15.18 17.35 17.42 14.50 0.4 12.13 12.41 13.12 16.69 19.81 20.51 15.78 0.5 12.42 12.78 13.73 18.32 22.52 24.88 17.44 0.6 12.88 13.32 14.48 20.02 25.17 31.97 19.64 0.7 13.37 13.9 15.23 21.75 27.91 46.65 23.14 0.8 13.82 14.37 15.94 23.44 30.59 77.15 29.22 0.9 14.18 14.8 16.58 24.94 33.12 89.81 32.24 1 14.50 15.15 17.10 26.29 35.67 90.00 33.12 B.3 V ARIANTS OF TTN FOR SMALL TEST BATCH SIZE Online TTN. TTN interpolating weight αcan also be adapted during test time. Table 11 shows the results of the TTN online version, which further optimizes the post-trained alpha using the entropy minimization and mean-squared error (MSE) loss between the updated alpha and the initial post- trained alpha. We followed entropy minimization loss used in TENT (Wang et al., 2020), and the MSE loss can be written as LMSE = ∥α−α0∥2, where α0 is the post-trained α. We set the learning rate as 1e-2, 2.5e-3, 5e-4, 1e-4, 5e-5, and 2.5e-5 by linearly decreasing according to the test batch size of 200, 64, 16, 4, 2, and 1 (Goyal et al., 2017). The online TTN shows improvements compared to the ofﬂine TTN in all three evaluation scenarios (single, continuously changing, and mixed). Scaled TTN. Following the observation from Table 10, we lowered the interpolating weight by mul- tiplying a constant scale value, ranging (0,1), to the optimized TTN α. In Table 11, we empirically set the scale value as 0.4. Dynamic training batch size. We observe that using the dynamic batch size in the post-training stage also improves the performance for small test batch sizes (2 or 1), while slightly deteriorating the performance for large test batch sizes (200 or 64). We randomly sampled training batch size from the range of [4,200] for each iteration. Other hyperparameters are kept as the same. 16Published as a conference paper at ICLR 2023 Table 11: TTN variants. Error rate (↓) averaged over 15 corruptions of CIFAR-10-C (WRN-40). Test batch size Avg. Method Eval. setting 200 64 16 4 2 1 TTN (ofﬂine, default) Single & Cont.11.67 11.80 12.13 13.93 15.83 17.99 13.89 TTN (ofﬂine, default) Mixed 12.16 12.19 12.34 13.96 15.55 17.83 14.00 TTN (online) Single 11.39 11.64 11.97 13.70 15.41 17.49 13.60 TTN (online) Cont. 11.67 11.96 12.15 13.90 15.67 17.72 13.85 TTN (online) Mixed 12.04 12.04 12.06 13.90 15.46 17.62 13.85 TTN (scaled) Single & Cont.13.20 13.38 13.35 13.88 14.54 15.17 13.92 TTN (scaled) Mixed 13.17 13.05 13.17 13.74 14.36 15.09 13.76 TTN (dynamic train batch size)Single & Cont.11.82 12.04 12.17 13.60 15.13 17.22 13.66 TTN (dynamic train batch size)Mixed 12.12 12.01 11.91 13.43 14.76 17.23 13.58 B.4 S TUDY ON AUGMENTATION TYPE TTN is robust to the data augmentation. We used data augmentation in the post-training phase to simulate domain shifts. The rationale for the simulation is to expose the model to different input domains. Especially when obtaining the prior, we compare the outputs from shifted domains with the clean (original) domain in order to analyze which part of the model is affected by the domain discrepancy. Therefore, changing the domain itself is what matters, not which domain the input is shifted to. We demonstrated this by conducting ablation studies by varying the augmentation type. We analyzed various augmentation types when obtaining prior and when optimizing alpha and the results are shown in Figure 5 (a) and (b), respectively. We use a true corruption, i.e., one of 15 corruption types in the corruption benchmark, as an augmentation type in the post-training phase to analyze how TTN works if the augmentation type and test corruption type are misaligned or perfectly aligned. Speciﬁcally, we used the true corruption when obtaining the prior while keeping the augmentation choices when optimizing alpha as described in the appendix A.1, and vice versa. Expectedly, the diagonal elements, i.e., where the same corruption type is used both for in post- training and in test time, tend to show the lowest error rate in Figure 5(b). The row-wise standard deviation is lower than 1 in most cases and even lower than 0.5 in Figure 5(a), which means the prior is invariant to the augmentation choice. Moreover, we observe that the average error rate over all elements, 11.74% in ablation for obtaining prior and 11.67% in ablation for optimizing alpha, is almost as same as TTN result 11.67% (See Table 14 and Figure 5). Moreover, we conducted an ablation study on the choice of the augmentation type using CIFAR-10-C and WRN-40 (Table12). We observe that obtaining prior and optimizing alpha steps are robust to the augmentation types. Table 12: Ablation study on augmentation choice. From left to right one augmentation type is added at a time. Default setting, which we used in all experiments, is colored in gray. Prioraugmentation type color jitter + grayscale + invert + gaussian blur + horizontal ﬂip 12.03 11.83 11.67 11.59 11.58 Optimizingαaugmentation type color jitter + padding + afﬁne + gaussian blur + horizontal ﬂip 11.78 11.78 11.7 11.70 11.67 B.5 R ESULTS ON IMAGE NET-C Table 13 shows the experimental results using ResNet-50 (He et al., 2016) on ImageNet- C (Hendrycks & Dietterich, 2018) dataset. We emphasized the effectiveness of our proposed method by showing the signiﬁcant improvement in large-scale dataset experiment. Similar to the results in CIFAR-10/100-C, TTN showed the best performance compared to normalization-based methods (TBN (Nado et al., 2020), AdaptiveBN Schneider et al. (2020), and α-BN (You et al., 2021)) and improved TTA performance when it is applied to optimization-based methods (TENT (Wang et al., 2020) and SWR (Choi et al., 2022)). During post-training, we used LR of 2.5e-4 and batch size of 64. In test time, we used the learning rate of 2.5e-4 for TENT following the setting from the original paper, and used 5e-6 for TENT+TTN. For SWR and SWR+TTN, we used learning rate of 2.5e-4 for B=64, and 2.5e-6 for B=16, 4, 2, and 1. We had to carefully tune the learning rate especially for SWR, since the method updates the 17Published as a conference paper at ICLR 2023 entire model parameters in an unsupervised manner and hence is very sensitive to the learning rate when the test batch size becomes small. Other hyperparameters and details are kept same (See the appendix A.1 for more details). Moreover, to avoid rapid accumulation, we stored gradients for sufﬁciently large test samples and then updated the model parameters (for example, we conducted adaptation in every 64 iterations in the case of batch size of 1) in both TENT and SWR. Table 13: Single domain adaptation on ImageNet-C (ResNet-50). Error rate (↓) averaged over 15 corruption types with severity level 5 is reported for each test batch size. Method Test batch size Avg. Error 64 16 4 2 1 Source (CBN)93.34 93.34 93.34 93.34 93.34 93.34 Norm TBN 74.24 76.81 85.74 95.35 99.86 86.40 AdaptiveBN 77.86 81.47 86.71 90.15 91.11 85.46 α-BN 86.06 86.32 87.16 88.33 90.45 87.66 Ours (TTN) 72.21 73.18 76.98 81.52 88.49 78.48 Optim. TENT 66.56 72.61 93.37 99.46 99.90 86.41 +Ours (TTN)71.42 72.45 76.66 81.89 91.00 78.68 SWR 64.41 74.19 84.30 93.05 99.86 83.16 +Ours (TTN)55.68 69.25 78.48 86.37 94.08 76.77 B.6 E RROR RATES OF EACH CORRUPTION In Table 14, we show the error rates of TTN for each corruption of CIFAR-10-C using the WRN-40 backbone. The averaged results over the corruptions are in Table 1. Table 14: Results of each corruption (CIFAR-10-C) batch sizegauss. shot impulse defocus glass motion zoom snow frost fog brightness contrast elastic pixel. jpeg.Avg. 200 14.81 12.78 17.32 7.37 17.87 8.51 7.23 10.29 9.88 11.29 6.06 8.36 13.42 14.89 14.94 11.6764 14.81 12.81 17.42 7.41 18.21 8.66 7.41 10.44 9.93 11.63 6.11 8.35 13.59 15.18 15.02 11.8016 15.23 13.00 17.98 7.71 18.46 8.95 7.68 10.85 10.17 12.21 6.25 8.54 13.95 15.67 15.3412.134 17.03 15.29 19.75 9.26 20.93 10.01 9.62 12.58 11.85 13.65 7.69 9.25 16.21 18.08 17.7013.932 19.21 16.80 21.86 10.70 23.74 11.39 11.92 14.00 13.39 15.38 8.95 10.13 18.92 20.68 20.4015.831 22.03 19.97 25.24 12.41 26.99 12.22 14.39 14.73 14.60 17.27 10.16 9.51 22.10 24.12 24.0917.99 B.7 S EGMENTATION RESULTS For more comparisons, we add segmentation results for TBN and TTN using test batch size (B) of 4 and 8 (Table 15). The results demonstrate that TTN is robust to the test batch sizes. In other words, the performance difference across the test batch size is small when using TTN (TTN with B=2, 4, and 8). The results are averaged over 3 runs (i.e., using 3 independently optimized α), and the standard deviation is denoted with a ±sign. We omitted the standard deviation for TBN, which is 0.0 for every result since no optimization is required. Since the backbone network is trained with a train batch size of 8, we assume that test batch statistics estimated from the test batch with B=8 are sufﬁciently reliable. Accordingly, TBN with B=8 shows compatible results. However, when B becomes small (i.e., in a more practical scenario), problematic test batch statistics are estimated, and thus TBN suffers from the performance drop while TTN keeps showing robust performance. It is worth noting that TTN outperforms TBN by 3.77% in average accuracy when B=2, i.e., in the most practical evaluation setting, and by 2.54% and 1.99% for B=4 and 8, respectively. Table 15: Adaptation on DG benchmarks in semantic segmentation. mIoU(↑) on four unseen domains with test batch size of 2, 4, and 8 using ResNet-50 based DeepLabV3+ as a backbone. Method(Cityscapes→) BDD-100K Mapillary GTA V SYNTHIA Cityscapes Norm TBN (B=2) 43.12 47.61 42.51 25.71 72.94 Ours (TTN)(B=2) 47.40(±0.02) 56.88(±0.04) 44.69(±0.03) 26.68(±0.01) 75.09(±0.01) TBN (B=4) 45.64 49.17 44.26 25.96 74.29 Ours (TTN)(B=4) 47.72(±0.01) 57.11(±0.01) 45.08(±0.02) 26.52(±0.01) 75.56(±0.01) TBN (B=8) 46.42 49.38 44.81 25.97 75.42 Ours (TTN)(B=8) 47.25(±0.02) 57.28(±0.02) 45.13(±0.03) 26.45(±0.01) 75.82(±0.01) 18Published as a conference paper at ICLR 2023 (b)Augmentation type used for optimizing alpha Test corruption type Error rate. Colored by normalized value (across test corruption type)avg.std.14.550.8612.640.6116.770.927.660.3117.750.738.760.297.490.2510.330.279.710.3212.401.466.110.098.260.4913.350.3714.581.2714.730.3911.67 (a)Augmentation type used for obtaining prior Test corruption type Error rate. Colored by normalized value (across test corruption type) avg.std.15.030.3412.790.2217.240.167.410.0617.910.148.480.087.260.0310.440.149.980.1411.550.106.050.048.570.4013.340.0715.211.5914.830.1111.74 Figure 5: True test corruption as augmentation. Each column represents the augmentation type used (a) when obtaining prior or (b) when optimizing α. Each row represents the test corruption type. The error rate (↓) of CIFAR-10-C with severity level 5 and test batch size 200 using WRN-40 is annotated in each element. Element (i,j) represents the error rate when j-th corruption type is used for augmenting the clean train data during post-training and tested on i-th corruption test set. The heatmap is colored by error rate normalized across the test corruption type (row-wise normalization). 19",
      "meta_data": {
        "arxiv_id": "2302.05155v2",
        "authors": [
          "Hyesu Lim",
          "Byeonggeun Kim",
          "Jaegul Choo",
          "Sungha Choi"
        ],
        "published_date": "2023-02-10T10:25:29Z",
        "pdf_url": "https://arxiv.org/pdf/2302.05155v2.pdf"
      },
      "llm_extracted_info": {
        "main_contributions": "Identifies the trade-off between conventional batch normalization (CBN) and transductive batch normalization (TBN) under domain shift and introduces Test-Time Normalization (TTN), a new BN layer that linearly interpolates source and test statistics with learnable, channel-wise weights. TTN is optimized once in a post-training phase and then used at inference, yielding robustness across small/large test batches, stationary, mixed, and continuously-shifting target domains, and boosting existing test-time adaptation (TTA) methods to state-of-the-art results on image classification and semantic segmentation benchmarks.",
        "methodology": "1) Compute domain-shift sensitivity per BN channel by back-propagating clean vs. augmented source images and measuring cosine distance between gradients of BN affine parameters (γ,β).\n2) Use these sensitivities to build a prior and initialize interpolating weights α (0≤α≤1) that mix source (μ_s,σ_s^2) and current batch (μ,σ^2) statistics:\n   μ̃=αμ+(1−α)μ_s ,  σ̃^2=ασ^2+(1−α)σ_s^2+α(1−α)(μ−μ_s)^2.\n3) In post-training, freeze all original network weights, replace BN with TTN layers, and optimize α via cross-entropy on augmented data plus an MSE regularizer to stay close to the prior.\n4) At test time, no further optimization is required; TTN can also be combined with optimization-based TTA methods (e.g., TENT, SWR) by simply replacing BN.",
        "experimental_setup": "Datasets: CIFAR-10/100-C, ImageNet-C (15 corruption types ×5 severities); models WideResNet-40-2 and ResNet-50. Evaluation batch sizes 200,64,16,4,2,1 under three scenarios: single corruption, continuously changing corruptions, and mixed corruptions. Baselines: Source (CBN), TBN, AdaptiveBN, α-BN, MixNorm, TENT, SWR, CoTTA. Metrics: top-1 error rate.\nSemantic segmentation: Cityscapes (train), BDD-100K, Mapillary, GTA-V, SYNTHIA (test) using DeepLabV3+ (ResNet-50). Metric: mIoU. Post-training uses source data with data augmentation; hyperparameters include learning rate 1e-3 (CIFAR) / 2.5e-4 (ImageNet), 30 epochs, λ=1 for MSE term.",
        "limitations": "• Mixing weights α are fixed after post-training; they cannot adjust to unknown future shifts.\n• Post-training requires access to labeled source data and additional compute time.\n• Assumes availability of BN layers; effectiveness for architectures without BN is untested.\n• Performance still degrades when batch size is extremely small, though less than TBN.\n• Hyperparameter choices (augmentation types, λ, learning rates) may need tuning per dataset.",
        "future_research_directions": "1) Develop online or instance-wise adaptation of α to dynamically track changing domain shifts.\n2) Extend the approach to architectures using alternative normalizations (LayerNorm, GroupNorm).\n3) Investigate source-free variants that estimate α without labeled source data.\n4) Explore joint optimization of α with other model parameters in a unified framework.\n5) Apply TTN to additional tasks such as object detection, video understanding, and continual learning scenarios."
      }
    },
    {
      "title": "Improved Test-Time Adaptation for Domain Generalization",
      "abstract": "The main challenge in domain generalization (DG) is to handle the\ndistribution shift problem that lies between the training and test data. Recent\nstudies suggest that test-time training (TTT), which adapts the learned model\nwith test data, might be a promising solution to the problem. Generally, a TTT\nstrategy hinges its performance on two main factors: selecting an appropriate\nauxiliary TTT task for updating and identifying reliable parameters to update\nduring the test phase. Both previous arts and our experiments indicate that TTT\nmay not improve but be detrimental to the learned model if those two factors\nare not properly considered. This work addresses those two factors by proposing\nan Improved Test-Time Adaptation (ITTA) method. First, instead of heuristically\ndefining an auxiliary objective, we propose a learnable consistency loss for\nthe TTT task, which contains learnable parameters that can be adjusted toward\nbetter alignment between our TTT task and the main prediction task. Second, we\nintroduce additional adaptive parameters for the trained model, and we suggest\nonly updating the adaptive parameters during the test phase. Through extensive\nexperiments, we show that the proposed two strategies are beneficial for the\nlearned model (see Figure 1), and ITTA could achieve superior performance to\nthe current state-of-the-art methods on several DG benchmarks. Code is\navailable at https://github.com/liangchen527/ITTA.",
      "full_text": "Improved Test-Time Adaptation for Domain Generalization Liang Chen1 Yong Zhang2* Yibing Song3 Ying Shan2 Lingqiao Liu1∗ 1 The University of Adelaide 2 Tencent AI Lab 3 AI3 Institute, Fudan University {liangchen527, zhangyong201303, yibingsong.cv}@gmail.com yingsshan@tencent.com lingqiao.liu@adelaide.edu.au Abstract The main challenge in domain generalization (DG) is to handle the distribution shift problem that lies between the training and test data. Recent studies suggest that test-time training (TTT), which adapts the learned model with test data, might be a promising solution to the problem. Gen- erally, a TTT strategy hinges its performance on two main factors: selecting an appropriate auxiliary TTT task for up- dating and identifying reliable parameters to update during the test phase. Both previous arts and our experiments in- dicate that TTT may not improve but be detrimental to the learned model if those two factors are not properly consid- ered. This work addresses those two factors by proposing an Improved Test-Time Adaptation (ITTA) method. First, in- stead of heuristically defining an auxiliary objective, we pro- pose a learnable consistency loss for the TTT task, which con- tains learnable parameters that can be adjusted toward bet- ter alignment between our TTT task and the main prediction task. Second, we introduce additional adaptive parameters for the trained model, and we suggest only updating the adap- tive parameters during the test phase. Through extensive ex- periments, we show that the proposed two strategies are ben- eficial for the learned model (see Figure 1), and ITTA could achieve superior performance to the current state-of-the-art methods on several DG benchmarks. Code is available at https://github.com/liangchen527/ITTA. 1. Introduction Recent years have witnessed the rapid development of deep learning models, which often assume the training and test data are from the same domain and follow the same distribution. However, this assumption does not always hold in real-world scenarios. Distribution shift among the source and target domains is ubiquitous in related areas [35], such as autonomous driving or object recognition tasks, resulting *Corresponding authors. This work is done when L. Chen is an intern in Tencent AI Lab. 0.5 1.1 0.5 1.2 0.5 0.5 0.5 1.4 0.4 0.4 0.4 0.3 art cartoon photo sketch 79.9 75.4 94.4 75.8 83.3 76.0 94.4 76.7 84.7 78.0 94.5 78.2 Figure 1. Performance improvements from the proposed two strate- gies (i.e. introducing a learnable consistency loss and including additional adaptive parameters to improve TTT) for the baseline model (i.e. ResNet18 [30] with existing augmentation strategy [75]). Experiments are conducted on the PACS dataset [37] with the leave- one-out setting. Following [27], we use 60 sets of random seeds and hyper-parameters for each target domain. The reported average accuracy and error bars verify the effectiveness of our method. in poor performances for delicately designed models and hindering the further application of deep learning techniques. Domain generalization (DG) [2,8,16,23,24,31,38 –40,40, 44, 47, 51, 52, 69], designed to generalize a learned model to unseen target domains, has attracted a great deal of attention in the research community. The problem can be traced back to a decade ago [7], and various approaches have been pro- posed to push the DG boundary ever since. Those efforts in- clude invariant representation learning [28,47,49,58], adver- sarial learning [23,40,44,69], augmentation [9,41,42,66,75], or meta-learning [2, 16, 38, 39]. Despite successes on certain occasions, a recent study [27] shows that, under a rigorous evaluation protocol, most of these arts are inferior to the baseline empirical risk minimization (ERM) method [61]. This finding is not surprising, as most current arts strive to decrease the distribution shift only through the training data while overlooking the contributions from test samples. Recently, the test-time training (TTT) technique [60] has been gaining momentum for easing the distribution shift problem. TTT lies its success in enabling dynamic tuning of the pretrained model with the test samples via an auxil- iary TTT task, which seems to be a promising effort when arXiv:2304.04494v2  [cs.CV]  16 Apr 2023confronting data from different domains. However, TTT is not guaranteed to improve the performance. Previous arts [46, 63] indicate that selecting an appropriate auxiliary TTT task is crucial, and an inappropriate one that does not align with the main loss may deteriorate instead of improv- ing the performance. Meanwhile, it is pointed out in [63] that identifying reliable parameters to update is also essential for generalization, which is in line with our experimental findings in Sec. 5.3. Both of these two tasks are non-trivial, and there are limited efforts made to address them. This paper aims to improve the TTT strategy for better DG. First, different from previous works that empirically define auxiliary objectives and assume they are aligned with the main task, our work does not make such assumptions. Instead, we suggest learning an appropriate auxiliary loss for test-time updating. Specifically, encouraged by recent successes in multi-view consistency learning [13,26,29], we propose to augment the consistency loss by adding learn- able parameters based on the original implementation, where the parameters can be adjusted to assure our TTT task can be more aligned with the main task and are updated by en- forcing the two tasks share the same optimization direction. Second, considering that identifying reliable parameters to update is an everlasting job given the growing size of current deep models, we suggest introducing new adaptive param- eters after each block during the test phase, and we only tune the new parameters by the learned consistency loss while leaving the original parameters unchanged. Through extensive evaluations on the current benchmark [27], we illustrate that the learnable consistency loss performs more effectively than the self-supervised TTT tasks adopted in previous arts [60, 63], and by tuning only the new adaptive parameters, our method is superior to existing strategies that update all the parameters or part of them. This work aims to ease the distribution shift problem by improving TTT, and the main contributions are three-fold: • We introduce a learnable consistency loss for test-time adaptation, which can be enforced to be more aligned with the main loss by tuning its learnable parameters. • We introduce new adaptive parameters for the trained model and only update them during the test phase. • We conduct experiments on various DG benchmarks and illustrate that our ITTA performs competitively against current arts under the rigorous setting [27] for both the multi-source and single-source DG tasks. 2. Related Works 2.1. Domain Generalization. Being able to generalize to new environments while de- ploying is a challenging and practical requirement for cur- rent deep models. Existing DG approaches can be roughly categorized into three types. (1) Invariant representation learning: The pioneering work [5] theoretically proves that if the features remain invariant across different domains, then they are general and transferable to different domains. Guided by this finding, [47] uses maximum mean discrep- ancy (MMD) to align the learned features, and [25] proposes to use a multi-domain reconstruction auto-encoder to obtain invariant features. More recently, [58] suggests maximiz- ing the inner product of gradients from different domains to enforce invariance, and a similar idea is proposed in [52] where these gradients are expected to be similar to their mean values. (2) Optimization algorithms: Among the different optimization techniques adopted in DG, prevail- ing approaches resort to adversarial learning [23, 40, 44, 69] and meta-learning [2, 16, 38, 39]. Adversarial training is often used to enforce the learned features to be agnostic about the domain information. In [23], a domain-adversarial neural network (DANN) is implemented by asking the main- stream feature to maximize the domain classification loss. This idea is also adopted in [44], where adversarial training and an MMD constraint are employed to update an auto- encoder. Meanwhile, the meta-learning technique is used to simulate the distribution shifts between seen and unseen environments [2, 16, 38, 39], and most of these works are developed based on the MAML framework [20]. (3) Aug- mentation: Most augmentation skills applied in the general- ization tasks are operated in the feature level [34, 41, 48, 75] except for [11,66,68] which mix images [68] or its phase [66] to synthesize new data. To enable contrastive learning, we incorporate an existing augmentation strategy [75] in our framework. This method originated from AdaIN [32], which synthesizes new domain information by mixing the statistics of the features. Similar ideas can be found in [42, 48]. 2.2. Test-Time Training and Adaptation Test-Time Training (TTT) is first introduced in [60]. The basic paradigm is to employ a test-time task besides the main task during the training phase and update the pre- trained model using the test data with only the test-time objective before the final prediction step. The idea is empir- ically proved effective [60] and further developed in other related areas [3, 10, 12, 14, 21, 22, 43, 56, 63, 65, 73, 74]. Most current works focus on finding auxiliary tasks for updat- ing during the test phase, and the efforts derive from self- supervion [3, 10, 21, 22, 43, 60], meta-learning [65, 73, 74], information entropy [63], pseudo-labeling [12, 14], to name a few. However, not all empirically selected test-time tasks are effective. A recent study [46] indicates that only when the auxiliary loss aligns with the main loss can TTT improve the trained model. Inspired by that, we propose a learnable consistency loss and enforce alignment between the two ob- jectives. Results show that our strategy can be beneficial for the trained model (see Figure 1).subtract Figure 2. Training process of ITTA. We use x from the source domain as input for the feature extractor fθ(·) to obtain the repre- sentation z and its augmented version z′, where the augmentation skill from [75] is applied. The classifier fϕ(·) and weight subnet- work fw(·) are used to compute the main loss Lmain and learnable consistency loss Lwcont. Please refer to our text for details. Meanwhile, [63] suggests that auxiliary loss is not the only factor that affects the performance. Selecting reliable parameters to update is also crucial within the TTT frame- work. Given the large size of current models, correctly iden- tifying these parameters may require tremendous amounts of effort. To this end, instead of heuristically selecting candi- dates, we propose to include new adaptive parameters for up- dating during the test phase. Experimental results show that the proposed method can obtain comparable performances against existing skills. 3. Methodology In the task of DG, we are often given access to data from S (S ≥ 1) source domains Ds = {D1, D2, ..., DS} and expect a model to make good prediction on unseen target domains Dt = {D1, D2, ..., DT } (T ≥ 1). Our method aims to improve the test-time training (TTT) strategy for better DG. The improvements are two-fold. First, we pro- pose a learnable consistency loss for the TTT task, which could be enforced to align with the main objective by tuning its learnable weights. Second, we suggest including addi- tional adaptive parameters and only updating these adaptive parameters during the test phase. 3.1. A Learnable Consistency Loss for TTT The TTT strategies have shown promising performances when dealing with distribution shift problems [43, 63]. How- ever, their successes are depended on the empirically selected auxiliary TTT tasks, which may deteriorate the performances if chosen improperly. Motivated by the recent successes in multi-view consistency learning [13, 26, 29], we suggest adopting a consistency loss in our TTT task. Note that the naive consistency loss is still not guaranteed to be effective as prior art [46] indicates that only when the auxiliary loss aligns with the main loss, can TTT improves the perfor- mance. To this end, we propose to augment the auxiliary loss with learnable parameters that could be adjusted toward a better alignment between the TTT and main tasks. In our case, we make the adopted consistency loss learnable by introducing a weight subnetwork that allows flexible ways Algorithm 1 Pseudo code of the training phase of ITTA in a PyTorch-like style. # fθ, fϕ, fw: feature extractor, classifier, weight subnetwork # α, 0: weight paramter, all zero tensor # training process for x, yin training loader: # load a minibatch with N samples def forward process(x, y): z, z′ = fθ.forward(x) # computing losses Lmain = CrossEntropyLoss(fϕ.forward(z), y) Lmain+ =CrossEntropyLoss(fϕ.forward(z′), y) Lwcont = MSELoss(fw.forward(z − z′), 0) return Lmain, Lwcont # SGD update: feature extractor and classifier Lmain, Lwcont = forward process(x, y) ([fθ.params, fϕ.params]).zero grad() (Lmain + αLwcont).backward() update( \u0002 fθ.params, fϕ.params \u0003 ) # compute objectives for updating weight subnetwork Lmain, Lwcont = forward process(x, y) Lmain.backward() ˆgmain = fθ.params.grad.clone().normalize() fθ.params.zero grad() Lwcont.backward() ˆgwcont = fθ.params.grad.clone().normalize() # SGD update: weight subnetwork MSELoss(ˆgmain, ˆgwcont).backward() fw.params.zero grad() update(fw.params) to measure the consistency between two views of the same instance. We first introduce the pipeline of our training framework. Given the D dimensional representation z ∈ RD1 and its corresponding augmented version z′ that are obtained from a feature extractor (i.e. {z, z′} = fθ(x), where x is an input image from Ds, and fθ(·) is the feature extractor parame- terized by θ. In our implementation, we use the existing augmentation method [75] to obtain z′ by modifying the intermediate activation in fθ(x). We show in our supplemen- tary material that our framework can also thrive with other augmentation strategies), our learnable consistency loss is given by, Lwcont = ∥fw(z − z′)∥, (1) where ∥ · ∥denotes the L2 norm; fw(·) is the weight sub- network parameterized by w. To make the training process more stable and potentially achieve better performance, we apply a dimension-wise nonlinear function to map each di- mension of z − z′ before calculating the L2 norm. That is, ∀h ∈ RD, fw(h) is implemented by stacking layers of a nonlinear function: ReLU(a ∗ h + b), where a ∈ RD and b ∈ RD are the weight and bias from the nonlinear function, 1We omit the batch dimensions of the variables for simplicity.… … subtract Figure 3. Test adaptation process of ITTA. Different from that in the training stage, we include additional adaptive parameters fΘ after each block of the feature extractor fθ. For each test sample x, the intermediate representations zi and z′i obtained from fi θ are passed to fi Θ before going to the next block fi+1 θ . We use the learnable consistency loss Lwcont as the objective to update fΘ. Please refer to our text for details. and different layers of a, bform the parameter w in fw. In effect, this creates a piecewise-linear mapping function for h: depending on the value of h, the output could be 0, a constant, or a scaling-and-shifted version of h. More studies about the design of fw are provided in our supplementary material. Compared to the naive consistency learning with- out fw, our Lwcont can be more flexible with an adjustable fw, which we show in the following is the key for learning an appropriate loss in the improved TTT framework. Combining Lwcont with the main loss Lmain which applies the cross-entropy loss (CE) for both the origi- nal and augmented inputs ( i.e. Lmain = CE(fϕ(z), y) + CE(fϕ(z′), y), where fϕ is the classifier parameterized by ϕ, and y is the corresponding label), the objective for the feature extractor and classifier can be formulated into, min{θ,ϕ} Lmain + αLwcont, (2) where α is the weight parameter that balances the contri- butions from the two terms. A simple illustration of the workflow is shown in Figure 2. From Eq. (2), the expected gradients for the feature ex- tractor from Lmain and Lwcont can be represented as, \u001a gmain = ∇θ(CE(fϕ(z), y) + CE(fϕ(z′), y)), (3) gwcont = ∇θ∥fw(z − z′)∥. (4) We observe that the direction of gwcont is also determined by the weight subnetwork fw(·), which should be close with gmain to ensure alignment between Lmain and Lwcont [46, 60]. To this end, we propose a straightforward solution by enforcing equality between the normalized versions of gmain and gwcont, and we use this term as the objective for updating fw(·), which gives, min w Lalign, s.t. Lalign = ∥ˆgmain − ˆgwcont∥, (5) where ˆgmain = gmain−Egmain σgmain , and similar for ˆgwcont. In our implementation, we update {θ, ϕ} and w in an alternative manner. Pseudo code of the training process are shown in Algorithm 1. Algorithm 2 Pseudo code of the test phase of ITTA in a PyTorch-like style. # fθ, fϕ: feature extractor, classifier # fw, fΘ: weight subnetwork, additional adaptive blocks # m, 0: total number of blocks in fθ, all zero tensor # test process for x in test loader: # load a test batch def forward process(x): z1, z′1 = f1 Θ.forward((f1 θ .forward(x))) # first blocks for i in range(2, m + 1): # the following m − 1 blocks zi, z′i = fi θ.forward(zi−1), fi θ.forward(z′i−1) zi, z′i = fi Θ.forward(zi), fi Θ.forward(z′i) return zi, z′i # test adaptation phase: SGD update additional adaptive parameters z, z′ = forward process(x) Lwcont = MSELoss(fw.forward(z − z′), 0) fΘ.params.zero grad() Lwcont.backward() update(fΘ.params) # final prediction z, = forward process(x) result = fϕ.forward(z) 3.2. Including Additional Adaptive Parameters Selecting expressive and reliable parameters to update during the test phase is also essential in the TTT frame- work [63]. Some strategies decide to update all the parame- ters from the feature extractor [3, 43], while others use only the parameters from the specific layers for updating [63, 71]. Given the fact that the sizes of current deep models are often very large and still growing, exhaustively trying different combinations among the millions of candidates seems to be an everlasting job. As there are no consensuses on which parameter should be updated, we suggest another easy alter- native in this work. Specifically, assuming there are a total of m blocks in the pretrained feature extractor fθ(·), and the i-th block can be denoted as fi θ(·). Then the intermediate representation zi from fi θ(·) can be formulated as, zi = fi θ(zi−1), s.t. z1 = f1 θ (x). (6) We propose to include additional adaptive blockfΘ that is parameterized by Θ after each block of fθ during the test- time adaptation phase, which reformulates Eq. (6) into, zi = fi Θ(fi θ(zi−1)), s.t. z1 = f1 Θ(f1 θ (x)), (7) where fΘ(·) does not change the dimension and sizes of the intermediate representations. In our work, we use a structure similar to fw to implement fΘ. Note zm is simplified as z in this phase, and the same process is applied for obtaining z′. Then, in the test-time adaptation phase, we suggest only updating the new adaptive parameters via the learned con- sistency loss. The optimization process can be written as,Table 1. Multi sources domain generalization. Experiments are conducted on the DomainBed benchmark [27]. All methods are examined for 60 trials in each unseen domain. Top5 accumulates the number of datasets where a method achieves the top 5 performances. The score here accumulates the numbers of the dataset where a specific art obtains larger accuracy than ERM on account of the variance. Best results are colored as red. Among the 22 methods compared, less than a quarter outperforms ERM in most datasets (Score ≥ 3). PACS VLCS OfficeHome TerraInc DomainNet Avg. Top5↑ Score↑ MMD [40] 81.3 ± 0.8 74.9 ± 0.5 59.9 ± 0.4 42.0 ± 1.0 7.9 ± 6.2 53.2 1 2 RSC [33] 80.5 ± 0.2 75.4 ± 0.3 58.4 ± 0.6 39.4 ± 1.3 27.9 ± 2.0 56.3 0 1 IRM [1] 80.9 ± 0.5 75.1 ± 0.1 58.0 ± 0.1 38.4 ± 0.9 30.4 ± 1.0 56.6 0 1 ARM [72] 80.6 ± 0.5 75.9 ± 0.3 59.6 ± 0.3 37.4 ± 1.9 29.9 ± 0.1 56.7 0 0 DANN [23] 79.2 ± 0.3 76.3 ± 0.2 59.5 ± 0.5 37.9 ± 0.9 31.5 ± 0.1 56.9 1 1 GroupGRO [55] 80.7 ± 0.4 75.4 ± 1.0 60.6 ± 0.3 41.5 ± 2.0 27.5 ± 0.1 57.1 0 1 CDANN [44] 80.3 ± 0.5 76.0 ± 0.5 59.3 ± 0.4 38.6 ± 2.3 31.8 ± 0.2 57.2 0 0 VREx [36] 80.2 ± 0.5 75.3 ± 0.6 59.5 ± 0.1 43.2 ± 0.3 28.1 ± 1.0 57.3 1 1 CAD [53] 81.9 ± 0.3 75.2 ± 0.6 60.5 ± 0.3 40.5 ± 0.4 31.0 ± 0.8 57.8 1 2 CondCAD [53] 80.8 ± 0.5 76.1 ± 0.3 61.0 ± 0.4 39.7 ± 0.4 31.9 ± 0.7 57.9 0 1 MTL [6] 80.1 ± 0.8 75.2 ± 0.3 59.9 ± 0.5 40.4 ± 1.0 35.0 ± 0.0 58.1 0 0 ERM [61] 79.8 ± 0.4 75.8 ± 0.2 60.6 ± 0.2 38.8 ± 1.0 35.3 ± 0.1 58.1 1 - MixStyle [75] 82.6 ± 0.4 75.2 ± 0.7 59.6 ± 0.8 40.9 ± 1.1 33.9 ± 0.1 58.4 1 1 MLDG [38] 81.3 ± 0.2 75.2 ± 0.3 60.9 ± 0.2 40.1 ± 0.9 35.4 ± 0.0 58.6 1 1 Mixup [68] 79.2 ± 0.9 76.2 ± 0.3 61.7 ± 0.5 42.1 ± 0.7 34.0 ± 0.0 58.6 2 2 Fishr [52] 81.3 ± 0.3 76.2 ± 0.3 60.9 ± 0.3 42.6 ± 1.0 34.2 ± 0.3 59.0 2 2 SagNet [48] 81.7 ± 0.6 75.4 ± 0.8 62.5 ± 0.3 40.6 ± 1.5 35.3 ± 0.1 59.1 1 2 SelfReg [34] 81.8 ± 0.3 76.4 ± 0.7 62.4 ± 0.1 41.3 ± 0.3 34.7 ± 0.2 59.3 2 3 Fish [58] 82.0 ± 0.3 76.9 ± 0.2 62.0 ± 0.6 40.2 ± 0.6 35.5 ± 0.0 59.3 3 4 CORAL [59] 81.7 ± 0.0 75.5 ± 0.4 62.4 ± 0.4 41.4 ± 1.8 36.1 ± 0.2 59.4 2 3 SD [51] 81.9 ± 0.3 75.5 ± 0.4 62.9 ± 0.2 42.0 ± 1.0 36.3 ± 0.2 59.7 4 4 Ours 83.8 ± 0.3 76.9 ± 0.6 62.0 ± 0.2 43.2 ± 0.5 34.9 ± 0.1 60.2 4 4 min Θ ∥fw(z − z′)∥, s.t. {z, z′} = fΘ(fθ(x)). (8) Note that different from the training phase, x in this stage is from the target domain Dt, and we use the online setting in [60] for updating. A simple illustration of the test adaptation pipeline is shown in Figure 3. For the final step, we use the original representation ob- tained from the pretrained feature extractor and the adapted adaptive parameters for prediction. Pseudo code of the test stage are shown in Algorithm 2. 4. Experiments 4.1. Settings Datasets. We evalute ITTA on five benchmark datasets: PACS [37] which consists of 9,991 images from 7 cate- gories. This dataset is probably the most widely-used DG benchmark owing to its large distributional shift across 4 do- mains including art painting, cartoon, photo, and sketch; VLCS [18] contains 10,729 images of 5 classes from 4 different datasets (i.e. domains) including PASCAL VOC 2007 [17], LabelMe [54], Caltech [19], and Sun [64] where each dataset is considered a domain in DG;OfficeHome [62] is composed of 15,588 images from 65 classes in office and home environments, and those images can be categorized into 4 domains (i.e. artistic, clipart, product, and real world); TerraInc [4] has 24,788 images from 10 classes. Those images are wild animals taken from 4 different locations (i.e. domains) including L100, L38, L43, and L46; Domain- Net [50] which contains 586,575 images from 345 classes, and the images in it can be depicted in 6 styles (i.e. clipart, infograph, painting, quickdraw, real, and sketch). Implementation details. For all the experiments, we use the ImageNet [15] pretrained ResNet18 [30] backbone that with 4 blocks as the feature extractor fθ, which could en- large the gaps in DG compared to larger models [70]. Corre- spondingly, we also include 4 blocks of additional adaptive parameters (i.e. fΘ), and each block is implemented with 5 layers of learnable parameters with weight initialized as all ones and bias initialized as all zeros. For the weight subnet- work fw, we use 10 layers of learnable parameters with the initialization skill similar to that of fΘ. The classifier fϕ is an MLP layer provided by the Domainbed benchmark [27]. For the weight parameter α in Eq. (2), we set it to be 1 for all experiments (please refer to our supplementary material for analysis). The random seeds, learning rates, batch size, and augmentation skills are all dynamically set for all the compared arts according to [27].Table 2. Single source domain generalization. Experiments are conducted on the PACS dataset [37]. Here A, C, P, and S are the art, cartoon, photo, and sketch domains in PACS. A→C represents models trained on the art domain and tested on the cartoon domain, and similar for others. All methods are examined for 60 trials in each unseen domain. Best results are colored as red. A→C A →P A →S C →A C →P C →S P →A P →C P →S S →A S →C S →P Avg. RSC 66.3 ±1.3 88.2±0.6 57.2±3.1 65.8±1.5 82.4±0.6 68.7±2.5 60.5±2.0 41.3±6.0 53.1±2.8 53.8±1.6 65.9±0.7 48.4±1.9 62.6 Fish 67.1 ±0.5 89.2±1.8 57.0±0.2 66.7±1.0 85.6±0.4 64.5±3.6 55.1±2.1 33.9±2.3 51.2±4.2 59.1±3.2 67.1±0.9 58.4±1.2 62.9 CDANN 66.5±1.7 92.2±0.6 65.0±0.9 70.6±0.1 82.9±1.4 67.7±3.0 60.6±0.3 42.2±6.4 46.9±9.9 51.4±2.3 60.7±1.2 51.9±0.4 63.2 SelfReg 63.9±1.9 90.1±1.0 56.8±2.2 70.2±2.3 85.4±0.3 70.2±2.2 60.9±2.6 38.8±4.0 50.5±3.2 54.5±4.7 66.2±1.2 51.7±4.1 63.3 DANN 67.5 ±1.6 91.2±1.3 67.5±1.3 70.6±1.0 81.4±0.4 66.6±1.1 54.1±2.3 33.5±2.7 52.8±2.3 53.8±1.7 64.4±0.7 58.9±0.8 63.5 CAD 67.1 ±1.5 89.6±0.4 60.2±0.2 67.7±3.1 83.7±1.4 70.2±2.6 60.6±2.6 38.3±3.7 53.8±3.2 50.7±1.6 65.8±1.3 54.4±1.7 63.5 GroupGRO66.5±1.2 90.5±1.5 58.9±2.5 70.8±0.9 85.7±1.2 69.7±1.8 62.3±2.1 41.1±2.7 48.2±4.1 54.8±0.5 65.2±1.6 53.9±1.4 64.0 MTL 67.3 ±1.0 90.1±1.0 58.9±0.7 70.2±1.8 84.2±2.2 71.9±0.7 58.3±2.7 38.5±2.7 52.8±1.5 55.4±3.1 66.1±1.3 55.2±2.6 64.1 IRM 67.5 ±1.8 93.0±0.5 62.9±4.7 67.6±1.3 83.8±0.4 68.9±0.8 63.7±1.8 39.9±3.7 49.0±5.4 54.9±1.4 63.1±2.1 54.9±1.4 64.1 ARM 66.0 ±2.4 91.2±0.7 58.7±6.9 70.6±0.8 84.2±1.0 69.1±0.9 59.2±1.8 42.1±5.6 52.1±3.0 60.0±0.6 62.9±3.3 53.8±2.0 64.2 Mixup 65.5 ±0.8 87.8±0.3 57.2±1.0 71.4±1.1 83.1±1.8 68.0±3.0 59.6±1.7 37.2±2.7 56.5±3.8 55.0±2.2 66.2±1.5 62.7±4.2 64.2 CORAL 66.8±0.5 90.3±0.7 61.5±1.9 67.9±2.1 85.4±0.3 70.4±1.3 55.9±2.9 40.4±4.9 49.8±8.5 55.8±2.1 67.6±0.9 58.9±3.8 64.2 SD 67.1 ±1.3 91.7±1.2 63.7±4.1 70.3±0.9 84.4±0.7 69.4±2.3 57.5±2.5 42.6±0.8 47.7±1.7 55.9±2.4 65.7±0.8 55.8±2.1 64.3 MMD 67.1 ±1.4 88.0±0.8 63.6±1.6 70.0±1.1 83.6±0.2 70.2±1.0 58.8±2.6 40.3±1.0 52.3±2.4 57.4±1.9 68.7±0.9 52.7±3.7 64.4 MLDG 67.3±2.0 90.8±0.5 64.4±0.9 70.8±1.0 84.2±0.3 69.7±1.8 61.6±1.0 41.3±5.1 50.4±0.2 49.9±2.5 66.8±0.4 58.7±3.4 64.7 CondCAD66.9±1.4 92.3±0.7 60.8±4.5 71.0±0.6 84.7±1.1 72.6±0.5 61.2±1.5 40.7±3.6 55.7±1.6 52.3±1.7 64.2±0.4 55.3±1.2 64.8 ERM 67.3 ±0.7 91.7±0.9 60.1±4.7 70.4±0.6 82.3±2.7 68.1±0.9 59.6±1.8 44.7±2.8 56.5±2.7 52.8±2.3 68.1±0.7 58.4±0.9 65.0 VREx 67.1 ±1.5 91.0±1.0 62.6±3.5 71.1±2.4 84.1±0.9 71.7±1.3 62.4±3.1 37.7±3.3 53.6±2.3 60.6±1.6 66.7±0.8 57.5±1.4 65.5 Fishr 67.9 ±1.9 92.7±0.3 62.4±4.7 71.2±0.5 83.4±0.6 70.2±1.1 60.0±2.3 42.7±3.2 57.1±3.9 55.7±3.7 68.4±1.0 62.0±3.1 66.1 SagNet 67.6±1.4 92.3±0.5 59.5±1.7 71.8±0.3 82.8±0.6 69.9±1.8 62.5±2.5 45.2±2.5 64.1±2.0 55.8±1.1 65.7±1.4 55.9±3.5 66.1 MixStyle 68.5±2.0 91.2±1.6 65.1±0.7 73.2±1.3 85.0±0.8 71.7±1.5 63.6±1.7 46.3±1.1 51.6±3.7 54.2±1.5 67.0±3.4 58.3±1.4 66.3 Ours 68.9 ±0.6 92.4±0.1 62.5±0.6 75.3±0.4 85.9±0.3 70.2±1.4 66.5±1.1 52.2±2.7 63.8±1.1 57.6±3.7 68.0±1.3 57.9±2.0 68.4 Training and evaluation details. For all the compared methods, we conduct 60 trials on each source domain, and each with 5,000 iteration steps. During the training stage, we split the examples from training domains to 8:2 (train:val) where the training and validation samples are dynamically selected among different training trials. During test, we select the model that performs the best in the validation samples and test it on the target domains. The strategy is referred to as the “training-domain validate set” model selec- tion method in [27]. For each domain in different datasets, the final performance is the average accuracy from the 60 trials. 4.2. Multi-Source Generalization In these experiments, all five benchmark datasets afore- mentioned are used for evaluation, and the leave-one-out strategy is adopted for training (i.e. with S = |Ds ∪Dt|2 −1, and T = 1). Results are shown in Table 1. We note that ERM method obtains favorable performance against existing arts. In fact, as a strong baseline, ERM is superior to half of the methods in the term of average accuracy, and only 5 arts (i.e. SelfReg [34], Fish [58], CORAL [59], SD [51], and ours) among the compared 22 methods outperforms ERM in most datasets (i.e. with Score ≥ 3). In comparison, the proposed ITTA is more effective than all other models on average. In particular, ITTA achieves the best performances in 3 out of the 5 benchmarks (i.e. PACS, VLCS, and TerraInc datasets) and 4 in the top 5. Note that although our method does not obtain the best performances in the OfficeHome and DomainNet benchmarks, it still outperforms more than half 2We use | · |to denote the number of domains in the environment. of the existing models. The results validate the effectiveness of our method when tested in the multi-source setting. We present results of average accuracy in each domain from different datasets in the supplementary material. Please refer to it for details. 4.3. Single-Source Generalization In these experiments, we adopt the widely-used PACS [37] benchmark for evaluation, and the models are trained on one domain while tested on the remaining three (i.e. with S = 1, and T = 3). Although some approaches, such as MLDG [38] and Fishr [52], may require more than one domain information for their trainings, we can simu- late multi-domain information using only the source domain, and thus the experimental settings are still feasible for them. Compared to the multi-source generalization task, the single- source generalization is considered more difficult due to the limited domain information during the training phase. Evalu- ation results are presented in Table 2. We note that the ERM method outperforms most state-of-the-art models, and only 5 models, including VREx [36], Fishr [52], SagNet [48], MixStyle [75], and the proposed ITTA, can obtain better re- sults than ERM in the term of average accuracy. Meanwhile, our method achieves the best performances when trained in 5 out of the 12 source domain, and it obtains the best perfor- mance on average, leading more than 2% than the second best (i.e. MixStyle [75]) and 3% the ERM method. In line with the findings in [27], we notice that the naive ERM method [61] can indeed perform favorably against most existing models under rigorous evaluation protocol. As a matter of fact, the proposed method is the only one that consistently outperforms ERM in both the multi-sourceTable 3. Evaluations of different TTT-based models in the unseen domain from PACS [37]. The reported accuracies (%) and standard deviations are computed from 60 trials in each target domain. Model Target domain Avg.Art Cartoon Photo Sketch Baseline 79.9 ±0.5 75.4±1.1 94.4±0.5 75.8±1.2 81.4±0.5 TTT [60] 81.5±0.8 77.6±0.6 94.3±0.2 78.4±0.7 83.0±0.2 MT3 [3] 82.0 ±1.0 76.5±1.0 94.1±0.2 77.7±1.3 82.6±0.6 TENT [63] 80.2±0.9 77.2±0.8 94.4±0.2 77.4±0.1 82.3±0.5 Ours 84.7 ±0.4 78.0±0.4 94.5±0.4 78.2±0.3 83.8±0.3 and single-source settings. These results indicate that DG remains challenging for current efforts that aim to ease the distribution shift only through training data, and using the proposed improved TTT strategy may be a promising direc- tion for solving DG. 5. Analysis All experiments in this section are conducted on the widely-used PACS benchmark [37] with the leave-one-out strategy. The experimental settings are the same as that illus- trated in Sec. 4.1. Please refer to our supplementary material for more analysis. 5.1. Compared with Other TTT-Based Models Using test-time adaptation to ease the distribution shift problem has been explored in previous works, such as the original TTT method [60] and MT3 [3]. Their differences lie in that TTT uses a rotation estimation task for the test-time objective, and MT3 adopts a contrastive loss for the task and implements the overall framework using MAML [20]. There is also a recently proposed TENT [63] that aims to minimize the entropy of the final results by tuning the parameters from the batch normalization (BN) layers. To analyze the overall effectiveness of our method, we compare ITTA with these arts using the same baseline (i.e. ResNet18 [30] backbone with the existing augmentation skill [75]). Results are shown in Table 3. We observe that all the com- pared TTT-based methods can improve the baseline model in almost all target domains except for the “Photo” domain, which might be due to the ImageNet pretraining [67]. This phenomenon demonstrates that the TTT strategy may be a promising effort for easing the distribution shift problem. Meanwhile, we observe that the proposed ITTA is superior to all other approaches in most target domains and leads in the term of average accuracy. The main reason is that compared to the empirically designed TTT tasks adopted in previous works, the proposed learnable consistency loss is enforced to be more aligned with the main loss, thus more suitable for the test-time adaptation task [46]. Meanwhile, compared to the strategies that update the original param- eters from the trained model, the adaptation of the newly included parameters is also more effective for the overall (a) Input (b) Ours w/o fw (c) Ours (d) Main Figure 4. Grad-CAM [57] visualizations from different loss terms. We use images with varying class labels from the four target do- mains of PACS [37] as inputs (i.e. art, cartoon, photo, and sketch domains from top to bottom). Ours w/o fw is the naive consis- tency loss with fw disabled in Eq. (1). The proposed learnable consistency loss can align well with the main classification task. TTT framework. In the following, we provide more analysis to support these claims. 5.2. Effectiveness of the Learnable Consistency Loss To examine the effectiveness of our learnable consistency loss, we conduct ablation studies by comparing our method with the following variants. (1) Ours w/o fw: we disable fw when computing the learnable consistency loss in Eq. (1), which uses the naive consistency loss for the auxiliary TTT task. (2) Ours w/ Ent.: after training the model using the baseline settings (i.e. ResNet18 with the augmentation strat- egy [75]), we use the entropy minimization task in [63] for the TTT task. (3) Ours w/ Rot.: we use the rotation estimation task in [60] for the TTT task. To ensure fair com- parisons, we use the same baseline settings and include the same additional adaptive parameters for all the variants. Results are shown in the 4th to 6th rows Table 4. We find that the results from the naive consistency loss ( i.e. Ours w/o fw) are slightly better than that from the other two specially-designed objectives (i.e. Ours w/ Ent. and Ours w/ Rot.) on average. Besides the possibility of deteriorating the performance [46], our results indicate that empirically select- ing a TTT task may also be far from optimal. Meanwhile, we observe that when enabling fw, the proposed learnable consistency loss is superior to that withoutfw in all target do-Table 4. Comparison between different TTT tasks and parameter selecting strategies in the unseen domain from the PACS benchmark [37]. Here the “Ent.”, “Rot.”, and “Lwcont” denotes the entropy minimization task in [63], the rotation estimation task in [60], and the proposed learnable consistency objective, the “All”, “BN”, and “Ada.” are the strategies that update all the parameters, parameters from the batch normalization layer, and the proposed strategy that updates only the new additional adaptive parameters. The reported accuracies (%) and standard deviations are computed from 60 trials in each target domain. Model TTT tasks Param selectings Target domain Avg.Ent. Rot. Lwcont All BN Ada. Art Cartoon Photo Sketch Ours − − ✓ − − ✓ 84.7±0.4 78.0 ±0.4 94.5 ±0.4 78.2 ±0.3 83.8 ±0.3 Ours w/ofw − − − − − ✓ 83.1±0.4 74.6 ±0.6 94.0 ±0.5 78.0 ±0.8 82.5 ±0.1 Ours w/ Ent. ✓ − − − − ✓ 79.9±2.4 77.3 ±0.3 94.8 ±0.8 77.6 ±0.4 82.4 ±0.8 Ours w/ Rot. − ✓ − − − ✓ 81.1±1.0 75.2 ±0.5 94.9 ±0.3 77.3 ±0.6 82.1 ±0.3 Ours w/o TTT − − ✓ − − − 83.3±0.5 76.0 ±0.5 94.4 ±0.5 76.7 ±1.4 82.8 ±0.3 Ours w/ All − − ✓ ✓ − − 83.0±0.7 77.0 ±1.4 94.5 ±0.7 77.4 ±0.9 83.0 ±0.2 Ours w/ BN − − ✓ − ✓ − 81.8±0.5 75.6 ±0.3 94.4 ±0.3 77.9 ±1.1 82.4 ±0.5 mains, and it leads in the term of average accuracy among the variants compared, illustrating its advantage against other adopted TTT tasks. These results are not surprising. By comparing the Grad-CAM [57] visualizations from the main classification task with the learnable and naive consistency losses in Figure 4, we find that the proposed learnable objec- tive can well align with the main loss when fw is enabled as the hot zones activated by these two tasks are similar, which guarantees the improvement for the test-time adapta- tion [46, 60]. Please refer to our supplementary material for more visualizations. 5.3. Effectiveness of the Adaptive Parameters We compare ITTA with three variants to demonstrate the effectiveness of the proposed additional adaptive parameters. (1) Ours w/o TTT: we do not update any parameters during the test phase. This variant is used to verify whether TTT can improve the pretrained model. (2) Ours w/ ALL: similar to the updating strategy in the original TTT method [60], we update all the parameters from the feature extractor during the test phase. (3) Ours w/ BN: following the suggestion from TENT [63], only parameters from the BN layers of the feature extractor are updated. Note the same pretrained model is shared for all variants in these experiments, and the objectives during the test adaptation phase are to minimize the same learned consistency loss. We list the results in the last three rows in Table 4. We observe that when only updating parameters from the BN layers, the performance is inferior to the strategy without test-time adaptation, and updating all the parameters does not ensure improvements in all target domains. The observations are in line with the findings in [63] that selecting reliable parameters to update is essential in the TTT system and may also interact with the choice of the TTT task. In comparison, when including additional adaptive parameters for updating, the pretrained model can be boosted in all environments. The results validate that our adaptive parameters are more effective than that selected with existing strategies [60, 63] when applied with the proposed learnable test-time objective. 5.4. Limitation Although the proposed learned loss can bring satisfaction improvements, we are aware that the lunch is not free. When the weight subnetwork fw is disabled, updating the joint loss in Eq. (2) only costs 1 forward and 1 backward. However, in order to update fw, we have to compute the second-order derivative in Eq. (5), which will require 1 more forward and 3 more backward processes, bringing extra burden to the system. Our future efforts aim to simplify the overall optimization process and reduce the cost for ITTA. 6. Conclusion In this paper, we aim to improve the current TTT strategy for alleviating the distribution shift problem in DG. First, given that the auxiliary TTT task plays a vital role in the over- all framework, and an empirically selecting one that does not align with the main task may potentially deteriorate instead of improving the performance, we propose a learnable con- sistency loss that can be enforced to be more aligned with the main loss by adjusting its learnable parameters. This strategy is ensured to improve the model and shows favorable perfor- mance against some specially-designed objectives. Second, considering that selecting reliable and effective parameters to update during the test phase is also essential while exhaus- tively trying different combinations may require tremendous effort, we propose a new alternative by including new ad- ditional adaptive parameters for adaptation during the test phase. This alternative is shown to outperform some pre- vious parameter selecting strategies via our experimental findings. By conducting extensive experiments under a rig- orous evaluation protocol, we show that our method can achieve superior performance against existing arts in both the multi-source and single-source DG tasks. Acknowledgements. Liang Chen is supported by the ChinaScholarship Council (CSC Student ID 202008440331). References [1] Martin Arjovsky, L´eon Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization. arXiv preprint arXiv:1907.02893, 2019. 5, 15, 16, 17 [2] Yogesh Balaji, Swami Sankaranarayanan, and Rama Chel- lappa. Metareg: Towards domain generalization using meta- regularization. In NeurIPS, 2018. 1, 2, 14, 15 [3] Alexander Bartler, Andre B¨uhler, Felix Wiewel, Mario D¨obler, and Bin Yang. Mt3: Meta test-time training for self- supervised test-time adaption. In AISTATS, 2022. 2, 4, 7 [4] Sara Beery, Grant Van Horn, and Pietro Perona. Recognition in terra incognita. In ECCV, 2018. 5, 17 [5] Shai Ben-David, John Blitzer, Koby Crammer, and Fernando Pereira. Analysis of representations for domain adaptation. In NeurIPS, 2006. 2 [6] Gilles Blanchard, Aniket Anand Deshmukh, Urun Dogan, Gyemin Lee, and Clayton Scott. Domain generalization by marginal transfer learning. arXiv preprint arXiv:1711.07910, 2017. 5, 15, 16, 17 [7] Gilles Blanchard, Gyemin Lee, and Clayton Scott. Generaliz- ing from several related classification tasks to a new unlabeled sample. In NeurIPS, 2011. 1 [8] Chaoqi Chen, Jiongcheng Li, Xiaoguang Han, Xiaoqing Liu, and Yizhou Yu. Compound domain generalization via meta- knowledge encoding. In CVPR, 2022. 1 [9] Chaoqi Chen, Luyao Tang, Feng Liu, Gangming Zhao, Yue Huang, and Yizhou Yu. Mix and reason: Reasoning over se- mantic topology with data mixing for domain generalization. In NeurIPS, 2022. 1 [10] Dian Chen, Dequan Wang, Trevor Darrell, and Sayna Ebrahimi. Contrastive test-time adaptation. In CVPR, 2022. 2 [11] Liang Chen, Yong Zhang, Yibing Song, Lingqiao Liu, and Jue Wang. Self-supervised learning of adversarial example: Towards good generalizations for deepfake detection. In CVPR, 2022. 2 [12] Liang Chen, Yong Zhang, Yibing Song, Jue Wang, and Lingqiao Liu. Ost: Improving generalization of deepfake detection via one-shot test-time training. In NeurIPS, 2022. 2, 12 [13] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geof- frey Hinton. A simple framework for contrastive learning of visual representations. In ICML, 2020. 2, 3 [14] Sungha Choi, Seunghan Yang, Seokeon Choi, and Sungrack Yun. Improving test-time adaptation via shift-agnostic weight regularization and nearest source prototypes. In ECCV, 2022. 2 [15] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In CVPR, 2009. 5 [16] Qi Dou, Daniel Coelho de Castro, Konstantinos Kamnitsas, and Ben Glocker. Domain generalization via model-agnostic learning of semantic features. In NeurIPS, 2019. 1, 2 [17] Mark Everingham, Luc Van Gool, Christopher KI Williams, John Winn, and Andrew Zisserman. The pascal visual object classes (voc) challenge. IJCV, 88(2):303–338, 2010. 5 [18] Chen Fang, Ye Xu, and Daniel N Rockmore. Unbiased metric learning: On the utilization of multiple datasets and web images for softening bias. In ICCV, 2013. 5, 16 [19] Li Fei-Fei, Rob Fergus, and Pietro Perona. Learning gener- ative visual models from few training examples: An incre- mental bayesian approach tested on 101 object categories. In CVPR worksho, 2004. 5 [20] Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model- agnostic meta-learning for fast adaptation of deep networks. In ICML, 2017. 2, 7 [21] Francois Fleuret et al. Uncertainty reduction for model adap- tation in semantic segmentation. In CVPR, 2021. 2 [22] Yossi Gandelsman, Yu Sun, Xinlei Chen, and Alexei A Efros. Test-time training with masked autoencoders. In NeurIPS, 2022. 2 [23] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Franc ¸ois Laviolette, Mario Marc- hand, and Victor Lempitsky. Domain-adversarial training of neural networks. JMLR, 17(1):2096–2030, 2016. 1, 2, 5, 15, 16, 17 [24] Muhammad Ghifary, David Balduzzi, W Bastiaan Kleijn, and Mengjie Zhang. Scatter component analysis: A unified framework for domain adaptation and domain generalization. IEEE TPAMI, 39(7):1414–1430, 2016. 1 [25] Muhammad Ghifary, W Bastiaan Kleijn, Mengjie Zhang, and David Balduzzi. Domain generalization for object recognition with multi-task autoencoders. In ICCV, 2015. 2 [26] Jean-Bastien Grill, Florian Strub, Florent Altch ´e, Corentin Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doer- sch, Bernardo Avila Pires, Zhaohan Guo, Mohammad Ghesh- laghi Azar, et al. Bootstrap your own latent-a new approach to self-supervised learning. In NeurIPS, 2020. 2, 3 [27] Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. In ICLR, 2021. 1, 2, 5, 6, 14, 15, 16, 17 [28] Sivan Harary, Eli Schwartz, Assaf Arbelle, Peter Staar, Shady Abu-Hussein, Elad Amrani, Roei Herzig, Amit Alfassy, Raja Giryes, Hilde Kuehne, et al. Unsupervised domain general- ization by learning a bridge across domains. In CVPR, 2022. 1 [29] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual repre- sentation learning. In CVPR, 2020. 2, 3 [30] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, 2016. 1, 5, 7, 14 [31] Shoubo Hu, Kun Zhang, Zhitang Chen, and Laiwan Chan. Domain generalization via multidomain discriminant analysis. In UAI, 2020. 1 [32] Xun Huang and Serge Belongie. Arbitrary style transfer in real-time with adaptive instance normalization. In ICCV, 2017. 2 [33] Zeyi Huang, Haohan Wang, Eric P Xing, and Dong Huang. Self-challenging improves cross-domain generalization. In ECCV, 2020. 5, 15, 16, 17[34] Daehee Kim, Youngjun Yoo, Seunghyun Park, Jinkyu Kim, and Jaekoo Lee. Selfreg: Self-supervised contrastive regular- ization for domain generalization. In ICCV, 2021. 2, 5, 6, 15, 16, 17 [35] Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, et al. Wilds: A benchmark of in-the-wild distribu- tion shifts. In ICML, 2021. 1 [36] David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai Zhang, Remi Le Priol, and Aaron Courville. Out-of-distribution generalization via risk extrapolation (rex). In ICML, 2021. 5, 6, 15, 16, 17 [37] Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M Hospedales. Deeper, broader and artier domain generalization. In ICCV, 2017. 1, 5, 6, 7, 8, 12, 13, 14, 15 [38] Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M Hospedales. Learning to generalize: Meta-learning for do- main generalization. In AAAI, 2018. 1, 2, 5, 6, 15, 16, 17 [39] Da Li, Jianshu Zhang, Yongxin Yang, Cong Liu, Yi-Zhe Song, and Timothy M Hospedales. Episodic training for domain generalization. In ICCV, 2019. 1, 2 [40] Haoliang Li, Sinno Jialin Pan, Shiqi Wang, and Alex C Kot. Domain generalization with adversarial feature learning. In CVPR, 2018. 1, 2, 5, 15, 16, 17 [41] Pan Li, Da Li, Wei Li, Shaogang Gong, Yanwei Fu, and Timothy M Hospedales. A simple feature augmentation for domain generalization. In ICCV, 2021. 1, 2, 12, 14 [42] Xiaotong Li, Yongxing Dai, Yixiao Ge, Jun Liu, Ying Shan, and Ling-Yu Duan. Uncertainty modeling for out- of-distribution generalization. In ICLR, 2022. 1, 2 [43] Yizhuo Li, Miao Hao, Zonglin Di, Nitesh Bharadwaj Gun- davarapu, and Xiaolong Wang. Test-time personalization with a transformer for human pose estimation. In NeurIPS, 2021. 2, 3, 4 [44] Ya Li, Xinmei Tian, Mingming Gong, Yajing Liu, Tongliang Liu, Kun Zhang, and Dacheng Tao. Deep domain generaliza- tion via conditional invariant adversarial networks. In ECCV, 2018. 1, 2, 5, 15, 16, 17 [45] Yiying Li, Yongxin Yang, Wei Zhou, and Timothy Hospedales. Feature-critic networks for heterogeneous do- main generalization. In ICML, 2019. 14, 15 [46] Yuejiang Liu, Parth Kothari, Bastien van Delft, Baptiste Bellot-Gurlet, Taylor Mordan, and Alexandre Alahi. Ttt++: When does self-supervised test-time training fail or thrive? In NeurIPS, 2021. 2, 3, 4, 7, 8, 12, 14, 15 [47] Krikamol Muandet, David Balduzzi, and Bernhard Sch¨olkopf. Domain generalization via invariant feature representation. In ICML, 2013. 1, 2 [48] Hyeonseob Nam, HyunJae Lee, Jongchan Park, Wonjun Yoon, and Donggeun Yoo. Reducing domain gap by reducing style bias. In CVPR, 2021. 2, 5, 6, 15, 16, 17 [49] Prashant Pandey, Mrigank Raman, Sumanth Varambally, and Prathosh Ap. Generalization on unseen domains via inference- time label-preserving target projections. In CVPR, 2021. 1 [50] Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, and Bo Wang. Moment matching for multi-source domain adaptation. In ICCV, 2019. 5, 17 [51] Mohammad Pezeshki, Oumar Kaba, Yoshua Bengio, Aaron C Courville, Doina Precup, and Guillaume Lajoie. Gradient star- vation: A learning proclivity in neural networks. In NeurIPS, 2021. 1, 5, 6, 15, 16, 17 [52] Alexandre Rame, Corentin Dancette, and Matthieu Cord. Fishr: Invariant gradient variances for out-of-distribution gen- eralization. In ICML, 2022. 1, 2, 5, 6, 15, 16, 17 [53] Yangjun Ruan, Yann Dubois, and Chris J Maddison. Optimal representations for covariate shift. In ICLR, 2022. 5, 15, 16, 17 [54] Bryan C Russell, Antonio Torralba, Kevin P Murphy, and William T Freeman. Labelme: a database and web-based tool for image annotation. IJCV, 77(1):157–173, 2008. 5 [55] Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust neural networks for group shifts: On the importance of regularization for worst- case generalization. In ICLR, 2020. 5, 15, 16, 17 [56] Steffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bring- mann, Wieland Brendel, and Matthias Bethge. Improving robustness against common corruptions by covariate shift adaptation. In NeurIPS, 2020. 2 [57] Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra. Grad- cam: Visual explanations from deep networks via gradient- based localization. In ICCV, 2017. 7, 8, 11, 13 [58] Yuge Shi, Jeffrey Seely, Philip HS Torr, N Siddharth, Awni Hannun, Nicolas Usunier, and Gabriel Synnaeve. Gradient matching for domain generalization. In ICLR, 2021. 1, 2, 5, 6, 15, 16, 17 [59] Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation. In ECCV, 2016. 5, 6, 15, 16, 17 [60] Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt. Test-time training with self- supervision for generalization under distribution shifts. In ICML, 2020. 1, 2, 4, 5, 7, 8, 11, 12, 13 [61] Vladimir Vapnik. The nature of statistical learning theory . Springer science & business media, 1999. 1, 5, 6, 15, 16, 17 [62] Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman Panchanathan. Deep hashing network for unsupervised domain adaptation. In CVPR, 2017. 5, 16 [63] Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Ol- shausen, and Trevor Darrell. Tent: Fully test-time adaptation by entropy minimization. In ICLR, 2021. 2, 3, 4, 7, 8, 11, 12, 13 [64] Jianxiong Xiao, James Hays, Krista A Ehinger, Aude Oliva, and Antonio Torralba. Sun database: Large-scale scene recog- nition from abbey to zoo. In CVPR, 2010. 5 [65] Zehao Xiao, Xiantong Zhen, Ling Shao, and Cees GM Snoek. Learning to generalize across domains on single test samples. In ICLR, 2022. 2 [66] Qinwei Xu, Ruipeng Zhang, Ya Zhang, Yanfeng Wang, and Qi Tian. A fourier-based framework for domain generaliza- tion. In CVPR, 2021. 1, 2 [67] Zhenlin Xu, Deyi Liu, Junlin Yang, Colin Raffel, and Marc Niethammer. Robust and generalizable visual representation learning via random convolutions. In ICLR, 2021. 7[68] Shen Yan, Huan Song, Nanxiang Li, Lincan Zou, and Liu Ren. Improve unsupervised domain adaptation with mixup training. arXiv preprint arXiv:2001.00677, 2020. 2, 5, 15, 16, 17 [69] Fu-En Yang, Yuan-Chia Cheng, Zu-Yun Shiau, and Yu- Chiang Frank Wang. Adversarial teacher-student representa- tion learning for domain generalization. In NeurIPS, 2021. 1, 2 [70] Nanyang Ye, Kaican Li, Haoyue Bai, Runpeng Yu, Lanqing Hong, Fengwei Zhou, Zhenguo Li, and Jun Zhu. Ood-bench: Quantifying and understanding two dimensions of out-of- distribution generalization. In CVPR, 2022. 5 [71] Fuming You, Jingjing Li, and Zhou Zhao. Test-time batch statistics calibration for covariate shift. arXiv preprint arXiv:2110.04065, 2021. 4 [72] Marvin Zhang, Henrik Marklund, Nikita Dhawan, Abhishek Gupta, Sergey Levine, and Chelsea Finn. Adaptive risk mini- mization: A meta-learning approach for tackling group distri- bution shift. arXiv preprint arXiv:2007.02931, 2020. 5, 15, 16, 17 [73] Marvin Zhang, Henrik Marklund, Nikita Dhawan, Abhishek Gupta, Sergey Levine, and Chelsea Finn. Adaptive risk mini- mization: Learning to adapt to domain shift. NeurIPS, 2021. 2 [74] Tao Zhong, Zhixiang Chi, Li Gu, Yang Wang, Yuanhao Yu, and Jin Tang. Meta-dmoe: Adapting to domain shift by meta- distillation from mixture-of-experts. In NeurIPS, 2022. 2 [75] Kaiyang Zhou, Yongxin Yang, Yu Qiao, and Tao Xiang. Do- main generalization with mixstyle. In ICLR, 2021. 1, 2, 3, 5, 6, 7, 12, 15, 16, 17 Appendix In this supplementary material, we provide, 1. Resource usage for ITTA in Section 7. 2. Grad-CAM visualizations of different loss terms in Section 8. 3. Parameter analysis of ITTA in Section 9; 4. Using a different augmentation skill for ITTA in Sec- tion 10. 5. Using different updating steps or a strategy for ITTA during the test phase in Section 11. 6. Using different network structures for the learnable consistency loss and adaptive parameters in Section 12. 7. Comparisons with other related methods in Section 13. 8. Detailed experimental results in the DomainBed bench- mark in Section 14. 7. Resource Usage Comparisons Between ITTA and the Baseline Model Requiring extra resources for our ITTA is a common lim- itation for existing test-time-based arts. To further evaluate our method, in this section, we compare FLOPS, model size, and inference time in Table 5. We compare only with ERM as most existing methods utilize the same network during in- ferences. We note that compare to the baseline model, ITTA requires extra Flops and processing time, this is because the adaptation process uses extra forward and backward steps during the test phase. While the parameters between the two models are similar because the newly included adaptive blocks are much smaller in size compared to the original model. Table 5. Resource comparisons during testing. Here inc. and exc. columns in ITTA indicate to include and exclude the TTA phase. Model Flops (G) Params (M) Time (s) Baseline 1.82 11.18 0.004 ITTA (inc.| exc.) 6.12 | 1.83 14.95 | 14.94 0.021 | 0.005 8. Grad-CAM Visualizations of Different Self- Supervised Objectives In Section 5 of the manuscript, we provide Grad-CAM [57] visualizations of our learnable consistency and the main losses to illustrate their alignment. To further show the differences between several TTT tasks [60, 63], we present more visual examples in this section. Results are shown in Figure 5. We observe that the entropy minimization [63] and rotation estimation [60] objectives do not activate the same regions as the main loss. As shown in the first row, for the class label of giraffe, both the main loss and our learned loss can correctly locate the two giraffes in the image, while the rotation estimation task can only locate one target, the same observation can be found when the learned weightsare disabled in our loss term. Meanwhile, although the two objects can be found for the entropy minimization task, the corresponding hot region does not align with that of the main loss. Similar phenomena can be observed in other samples. These visual examples demonstrate that our learned objective can better align with the main task than the TTT tasks adopted in previous works [60, 63], explaining why using the proposed learnable consistency loss can better improve TTT. 9. Parameter Analysis In this section, we analyze the hyper-parameter used in ITTA. We use the weight parameterα to balance the contri- butions from the main loss and weighted consistency loss (i.e. Lmain + αLwcont in Eq. (2) of our manuscript). To analyze the sensitivity of ITTA regarding different values of α, we conduct ablation studies in the PACS benchmark [37]. Results are listed in Table 6. We observe that the proposed ITTA can obtain favorable performances when α is in the range of 0.1 to 10, and it performs the best on average when setting as 1. We thus fix the parameter as 1 in all experi- ments. 10. A Different Augmentation Skill for ITTA In our manuscript, we use the existing augmentation strat- egy from [75] to obtain the augmented feature. In this sec- tion, we replace this implementation with that from [41] to further verify if our ITTA can still thrive with another aug- mentation skill. Different from [75] that mixes the statics of the feature to synthesize new information, [41] uses an affine transformation to create new features, where the weight for the transformation is sampled from a normal distribution with the mean value of one and standard value of zero, and the bias for the transformation is sampled from a normal distribution with the mean and standard values both zero. Experiments are conducted on the PACS benchmark [37] with the leave-one-out strategy. We compare ITTA with several different variants. (1) Ours w/o fw & TTT: this variant is the baseline model which uses the naive consistency loss for training and does not include TTT during the test phase. (2) Ours w/o fw: we disable the fw in our consistency loss, which uses the naive consistency loss for the test-time updating. (3) Ours w/o TTT: we do not update any parameters during the test phase. This variant is used to verify whether TTT can improve the pretrained model when replacing the augmentation strategy. We also compare these variants with the ERM method to show their effectivenesses. Results are listed in Table 7. We observe that ERM per- forms favorably against the baseline model, indicating that this augmentation strategy may not be beneficial for the training process. Meanwhile, we observe that when fw is disabled, the performances seem to decrease in 3 out of 4 target domains, and the average accuracy is also inferior to the baseline (i.e. Ours w/o fw & TTT). This result is in line with the finding in [46] that an inappropriate TTT task may deteriorate the performance. In comparison, we note that the performances are both improved when fw is enabled (i.e. Ours w/o TTT and Ours), which once again demonstrates that the proposed learnable consistency loss can improve the trained model. Moreover, we can also observe that when combining fw and TTT, our model is superior to other vari- ants and the ERM method. These results demonstrate that the proposed two strategies can improve the current TTT framework despite a less effective augmentation strategy. 11. Different Updating Steps or Strategies for ITTA In the manuscript, we use one TTT step for ITTA before during the testing step. In this section, we conduct experi- ments to evaluate the performances of ITTA with different TTT steps. Experiments are conducted on the PACS bench- mark [37] with the leave-one-out strategy, and each target domain is examined with 60 sets of random seeds and hyper- parameter settings. Results are listed in Table 8. We observe that the average accuracies of using more TTT steps are not improved greatly while the computational times are propor- tional to the TTT steps. To this end, we use one TTT step for ITTA as a compromise between accuracy and efficiency. We use the online setting from TTT [60] for all arts, which assumes test samples arrive sequentially and updates the adaptive blocks based on the states optimized from a previous sample. In this section, we also test ITTA in an episodic manner (i.e. Epi) [12]. Results in Table 8 suggest that while the episodic updating strategy performs slightly worse than the current scheme, and it still outperforms the baseline. 12. Different Network Structures for the Learnable Consistency Loss and Adaptive Parameters In our implementation, we use 10 layers of learnable pa- rameters for fw, and we use 5 layers of learnable parameters for fΘ after each block. In this section, we evaluate our ITTA with different network structures for these two mod- ules. Specifically, we compare the original implementation with the variants that use 1, 5, and 15 layers for fw and 1, 10, and 15 layers for fΘ to evaluate the performances of dif- ferent structures. Similarly, we conduct experiments on the PACS benchmark [37] with the leave-one-out strategy, and each target domain is examined with 60 sets of random seeds and hyper-parameter settings. Evaluation results are listed in Table 9. We observe that their differences in the average accuracy are rather subtle on account of the variances. To(a) Input (b) Entropy (c) Rotation (d) Ours w/o fw (e) Ours (f) Main Figure 5. Grad-CAM [57] visualizations from different loss terms. We use images with varying class labels (i.e. giraffe, elephant, house, and horse from top to bottom) from the four target domains of PACS [37] as inputs (i.e. art, cartoon, photo, and sketch domains from top to bottom). “Entropy” and “Rotation” here denote the entropy minimization and rotation estimation tasks in [63] and [60]. Ours w/o fw is the learnable consistency loss in Eq. (1) in the manuscript (i.e. ∥fw(z − z′)∥) when fw is disabled. The proposed learnable consistency loss can align well with the main classification task. Table 6. Sensitivity analysis of ITTA regarding different values ofα in the unseen domain from PACS [37]. The reported accuracies (%) and standard deviations are computed from 60 trials in each target domain. Values Target domain Avg.Art Cartoon Photo Sketch α = 0.1 83.9 ± 0.7 76.2 ± 1.1 94.8 ± 0.2 78.8 ± 0.8 83.4 ± 0.2 α = 1 (Ours) 84.7 ± 0.4 78.0 ± 0.4 94.5 ± 0.4 78.2 ± 0.3 83.8 ± 0.3 α = 10 83.9 ± 0.5 77.4 ± 0.6 94.2 ± 0.7 77.3 ± 0.8 83.2 ± 0.3 α = 100 81.5 ± 1.2 77.0 ± 0.6 92.6 ± 0.7 78.9 ± 2.1 82.5 ± 0.9 this end, we use the original implementation with 10 layers of learnable parameters for fw and 5 layers of learnable pa- rameters for fΘ, which performs relatively better than other variants. Since the adaptive blocks fΘ are attached after each layer of the network, one may wonder how the varying locations of the adaptive blocks affect the performance of ITTA. To answer this question, we further conduct experiments by adding the adaptive blocks after different layers of the orig- inal network. Denoting as Loc = lan given the n layers in the original network, we note that the model performs less effectively when the adaptive block is placed after the 1st layer of the network, and using all four adaptive blocks (i.e. ours) is more effective than other alternatives. 13. Comparisons with Other Related Methods Apart from the proposed ITTA, some other works also propose to include learnable parameters in their auxiliaryTable 7. Performances of our method with another augmentation strategy from [41] in the unseen domain from PACS [37]. The reported accuracies (%) and standard deviations are computed from 60 trials in each target domain. Model Target domain Avg.Art Cartoon Photo Sketch ERM 78.0 ± 1.3 73.4 ± 0.8 94.1 ± 0.4 73.6 ± 2.2 79.8 ± 0.4 Ours w/o fw & TTT 74.9 ± 0.4 74.1 ± 0.8 90.6 ± 0.3 79.7 ± 0.7 79.8 ± 0.4 Ours w/o fw 77.1 ± 1.0 73.6 ± 1.1 89.9 ± 0.4 78.4 ± 0.8 79.7 ± 0.2 Ours w/o TTT 77.5 ± 0.3 73.2 ± 0.6 92.4 ± 0.4 78.0 ± 1.0 80.3 ± 0.3 Ours (w/ fw & TTT) 79.2 ± 0.8 74.9 ± 1.1 92.2 ± 0.3 76.9 ± 0.7 80.8 ± 0.4 Table 8. Evaluations of ITTA in the unseen domain from PACS [37] with different TTT steps and updating strategies during the testing phase. The reported accuracies (%) and standard deviations are computed from 60 trials in each target domain. The time consumption (TC) is computed using one image with the size of 224 × 224. Epi. denotes updating ITTA in an episodic manner. Steps Target domain Avg. TCArt Cartoon Photo Sketch 1 step (Ours) 84.7 ± 0.4 78.0 ± 0.4 94.5 ± 0.4 78.2 ± 0.3 83.8 ± 0.3 2.4 ms 2 step 84.2 ± 0.9 77.5 ± 0.6 94.4 ± 0.4 79.1 ± 1.0 83.8 ± 0.1 4.2 ms 3 step 84.5 ± 1.2 77.6 ± 0.6 94.0 ± 0.6 79.3 ± 0.1 83.9 ± 0.3 6.1 ms Epi. 83.6 ± 0.7 77.9 ± 0.5 95.2 ± 0.1 76.6 ± 0.5 83.3 ± 0.4 losses. Examples include MetaReg [2] and Feature-Critic [45] which both suggest using meta-learning to produce more general models. The main difference between these arts and ITTA is that parameters in the auxiliary loss from [2,45] are gradually refined by episode training, and they are updated via a gradient alignment step in ITTA (see Sec. 3.1 in the manuscript), which is much simpler. In this sec- tion, we compare ITTA with these two arts in the PACS dataset [37] using the same settings aforementioned. Be- cause MetaReg [2] does not release codes, we thus directly cite the data from their paper in the comparison. Different from others, the results in [2] are averaged by 5 trials accord- ing to their paper, which is much less than our experimental settings. Meanwhile, we also compare with TTT++ [46] which suggests storing the momentum of the features from the source domain and enforcing the similarity between mo- mentums of features from the source and target domains. We use the same setting in Section 5.1 from the manuscript to evaluate TTT++. Results are listed in Table 10. We observe that our method consistently outperforms that from [2,45,46] for both the cases with and without TTT, indicating that the proposed learnable consistency loss and updating method is not only simpler but also more effective than the losses in [2, 45]. 14. Detailed Results in the DomainBed Bench- mark [27] this section presents the average accuracy in each domain from different datasets. As shown in Table 11, 12, 13, 14, and 15, these results are detailed illustrations of the results in Table 2 in our manuscript. For all the experiments, we use the “training-domain validate set” as the model selection method. A total of 22 methods are examined for 60 trials in each unseen domain, and all methods are trained with the leave-one-out strategy using the ResNet18 [30] backbones.Table 9. Performances of our method with different network structures for the consistency loss (i.e. fw) and adaptive parameters (i.e. fΘ) in the unseen domain from PACS [37]. Here ‘Loc=lan’ locates the adaptive block after the n-th layer of the model (‘la4’ is the last layer). The reported accuracies (%) and standard deviations are computed from 60 trials in each target domain. Structures Target domain Avg.Art Cartoon Photo Sketch Structures offw 1 layer 83.5 ±1.2 76.0 ±1.0 95.3 ±0.2 78.7 ±1.5 83.4 ±0.4 5 layers 83.7 ±0.6 76.8 ±0.9 94.6 ±0.3 78.8 ±0.3 83.5 ±0.3 10 layers (Ours) 84.7 ±0.4 78.0 ±0.4 94.5 ±0.4 78.2 ±0.3 83.8 ±0.3 15 layers 84.1 ±0.4 75.8 ±0.2 94.3 ±0.3 79.5 ±0.4 83.4 ±0.2 Structures offΘ 1 layer 84.0 ±0.6 77.4 ±0.5 94.4 ±0.5 78.3 ±0.4 83.5 ±0.3 5 layers (Ours) 84.7 ±0.4 78.0 ±0.4 94.5 ±0.4 78.2 ±0.3 83.8 ±0.3 10 layers 84.8 ±0.3 76.0 ±0.6 94.1 ±0.5 78.3 ±0.1 83.3 ±0.3 15 layers 83.9 ±0.8 76.0 ±0.5 93.8 ±0.4 78.7 ±1.4 83.1 ±0.6 Locations offΘ Loc=la1 83.4±0.7 76.8 ±0.3 94.4 ±0.3 77.8 ±0.3 83.1 ±0.3 Loc=la2 83.4±0.6 77.7 ±0.6 94.2 ±0.5 78.0 ±0.5 83.3 ±0.3 Loc=la3 84.0±0.4 77.5 ±0.3 94.4 ±0.1 77.8 ±0.1 83.4 ±0.2 Loc=la4 84.1±0.7 77.8 ±0.5 94.8 ±0.2 76.9 ±1.5 83.4 ±0.4 Table 10. Compare with learnable losses in [2, 45] in the unseen domain from PACS [37]. The reported accuracies ( %) and standard deviations are computed from 60 trials in each target domain except for [2] where the numbers are directly cited from their paper. Model Target domain Avg.Art Cartoon Photo Sketch MetaReg [2] 83.7 ± 0.2 77.2 ± 0.3 95.5 ± 0.2 70.3 ± 0.3 81.7 Feture-Critic [45] 78.4 ± 1.6 75.4 ± 1.2 92.6 ± 0.5 73.3 ± 1.4 80.0 ± 0.3 TTT++ [46] 84.3 ± 0.1 78.4 ± 0.5 93.8 ± 1.3 73.2 ± 3.2 82.4 ± 1.1 Ours w/o TTT 83.3 ± 0.5 76.0 ± 0.5 94.4 ± 0.5 76.7 ± 1.4 82.8 ± 0.3 Ours 84.7 ± 0.4 78.0 ± 0.4 94.5 ± 0.4 78.2 ± 0.3 83.8 ± 0.3 Table 11. Average accuracies on the PACS [37] datasets using the default hyper-parameter settings in DomainBed [27]. art cartoon photo sketch Average ERM [61] 78.0 ± 1.3 73.4 ± 0.8 94.1 ± 0.4 73.6 ± 2.2 79.8 ± 0.4 IRM [1] 76.9 ± 2.6 75.1 ± 0.7 94.3 ± 0.4 77.4 ± 0.4 80.9 ± 0.5 GroupGRO [55] 77.7 ± 2.6 76.4 ± 0.3 94.0 ± 0.3 74.8 ± 1.3 80.7 ± 0.4 Mixup [68] 79.3 ± 1.1 74.2 ± 0.3 94.9 ± 0.3 68.3 ± 2.7 79.2 ± 0.9 MLDG [38] 78.4 ± 0.7 75.1 ± 0.5 94.8 ± 0.4 76.7 ± 0.8 81.3 ± 0.2 CORAL [59] 81.5 ± 0.5 75.4 ± 0.7 95.2 ± 0.5 74.8 ± 0.4 81.7 ± 0.0 MMD [40] 81.3 ± 0.6 75.5 ± 1.0 94.0 ± 0.5 74.3 ± 1.5 81.3 ± 0.8 DANN [23] 79.0 ± 0.6 72.5 ± 0.7 94.4 ± 0.5 70.8 ± 3.0 79.2 ± 0.3 CDANN [44] 80.4 ± 0.8 73.7 ± 0.3 93.1 ± 0.6 74.2 ± 1.7 80.3 ± 0.5 MTL [6] 78.7 ± 0.6 73.4 ± 1.0 94.1 ± 0.6 74.4 ± 3.0 80.1 ± 0.8 SagNet [48] 82.9 ± 0.4 73.2 ± 1.1 94.6 ± 0.5 76.1 ± 1.8 81.7 ± 0.6 ARM [72] 79.4 ± 0.6 75.0 ± 0.7 94.3 ± 0.6 73.8 ± 0.6 80.6 ± 0.5 VREx [36] 74.4 ± 0.7 75.0 ± 0.4 93.3 ± 0.3 78.1 ± 0.9 80.2 ± 0.5 RSC [33] 78.5 ± 1.1 73.3 ± 0.9 93.6 ± 0.6 76.5 ± 1.4 80.5 ± 0.2 SelfReg [34] 82.5 ± 0.8 74.4 ± 1.5 95.4 ± 0.5 74.9 ± 1.3 81.8 ± 0.3 MixStyle [75] 82.6 ± 1.2 76.3 ± 0.4 94.2 ± 0.3 77.5 ± 1.3 82.6 ± 0.4 Fish [58] 80.9 ± 1.0 75.9 ± 0.4 95.0 ± 0.4 76.2 ± 1.0 82.0 ± 0.3 SD [51] 83.2 ± 0.6 74.6 ± 0.3 94.6 ± 0.1 75.1 ± 1.6 81.9 ± 0.3 CAD [53] 83.9 ± 0.8 74.2 ± 0.4 94.6 ± 0.4 75.0 ± 1.2 81.9 ± 0.3 CondCAD [53] 79.7 ± 1.0 74.2 ± 0.9 94.6 ± 0.4 74.8 ± 1.4 80.8 ± 0.5 Fishr [52] 81.2 ± 0.4 75.8 ± 0.8 94.3 ± 0.3 73.8 ± 0.6 81.3 ± 0.3 Ours 84.7 ± 0.4 78.0 ± 0.4 94.5 ± 0.4 78.2 ± 0.3 83.8 ± 0.3Table 12. Average accuracies on the VLCS [18] datasets using the default hyper-parameter settings in DomainBed [27]. Caltech LabelMe Sun VOC Average ERM [61] 97.7 ± 0.3 62.1 ± 0.9 70.3 ± 0.9 73.2 ± 0.7 75.8 ± 0.2 IRM [1] 96.1 ± 0.8 62.5 ± 0.3 69.9 ± 0.7 72.0 ± 1.4 75.1 ± 0.1 GroupGRO [55] 96.7 ± 0.6 61.7 ± 1.5 70.2 ± 1.8 72.9 ± 0.6 75.4 ± 1.0 Mixup [68] 95.6 ± 1.5 62.7 ± 0.4 71.3 ± 0.3 75.4 ± 0.2 76.2 ± 0.3 MLDG [38] 95.8 ± 0.5 63.3 ± 0.8 68.5 ± 0.5 73.1 ± 0.8 75.2 ± 0.3 CORAL [59] 96.5 ± 0.3 62.8 ± 0.1 69.1 ± 0.6 73.8 ± 1.0 75.5 ± 0.4 MMD [40] 96.0 ± 0.8 64.3 ± 0.6 68.5 ± 0.6 70.8 ± 0.1 74.9 ± 0.5 DANN [23] 97.2 ± 0.1 63.3 ± 0.6 70.2 ± 0.9 74.4 ± 0.2 76.3 ± 0.2 CDANN [44] 95.4 ± 1.2 62.6 ± 0.6 69.9 ± 1.3 76.2 ± 0.5 76.0 ± 0.5 MTL [6] 94.4 ± 2.3 65.0 ± 0.6 69.6 ± 0.6 71.7 ± 1.3 75.2 ± 0.3 SagNet [48] 94.9 ± 0.7 61.9 ± 0.7 69.6 ± 1.3 75.2 ± 0.6 75.4 ± 0.8 ARM [72] 96.9 ± 0.5 61.9 ± 0.4 71.6 ± 0.1 73.3 ± 0.4 75.9 ± 0.3 VREx [36] 96.2 ± 0.0 62.5 ± 1.3 69.3 ± 0.9 73.1 ± 1.2 75.3 ± 0.6 RSC [33] 96.2 ± 0.0 63.6 ± 1.3 69.8 ± 1.0 72.0 ± 0.4 75.4 ± 0.3 SelfReg [34] 95.8 ± 0.6 63.4 ± 1.1 71.1 ± 0.6 75.3 ± 0.6 76.4 ± 0.7 MixStyle [75] 97.3 ± 0.3 61.6 ± 0.1 70.4 ± 0.7 71.3 ± 1.9 75.2 ± 0.7 Fish [58] 97.4 ± 0.2 63.4 ± 0.1 71.5 ± 0.4 75.2 ± 0.7 76.9 ± 0.2 SD [51] 96.5 ± 0.4 62.2 ± 0.0 69.7 ± 0.9 73.6 ± 0.4 75.5 ± 0.4 CAD [53] 94.5 ± 0.9 63.5 ± 0.6 70.4 ± 1.2 72.4 ± 1.3 75.2 ± 0.6 CondCAD [53] 96.5 ± 0.8 62.6 ± 0.4 69.1 ± 0.2 76.0 ± 0.2 76.1 ± 0.3 Fishr [52] 97.2 ± 0.6 63.3 ± 0.7 70.4 ± 0.6 74.0 ± 0.8 76.2 ± 0.3 Ours 96.9 ± 1.2 63.7 ± 1.1 72.0 ± 0.3 74.9 ± 0.8 76.9 ± 0.6 Table 13. Average accuracies on the OfficeHome [62] datasets using the default hyper-parameter settings in DomainBed [27]. art clipart product real Average ERM [61] 52.2 ± 0.2 48.7 ± 0.5 69.9 ± 0.5 71.7 ± 0.5 60.6 ± 0.2 IRM [1] 49.7 ± 0.2 46.8 ± 0.5 67.5 ± 0.4 68.1 ± 0.6 58.0 ± 0.1 GroupGRO [55] 52.6 ± 1.1 48.2 ± 0.9 69.9 ± 0.4 71.5 ± 0.8 60.6 ± 0.3 Mixup [68] 54.0 ± 0.7 49.3 ± 0.7 70.7 ± 0.7 72.6 ± 0.3 61.7 ± 0.5 MLDG [38] 53.1 ± 0.3 48.4 ± 0.3 70.5 ± 0.7 71.7 ± 0.4 60.9 ± 0.2 CORAL [59] 55.1 ± 0.7 49.7 ± 0.9 71.8 ± 0.2 73.1 ± 0.5 62.4 ± 0.4 MMD [40] 50.9 ± 1.0 48.7 ± 0.3 69.3 ± 0.7 70.7 ± 1.3 59.9 ± 0.4 DANN [23] 51.8 ± 0.5 47.1 ± 0.1 69.1 ± 0.7 70.2 ± 0.7 59.5 ± 0.5 CDANN [44] 51.4 ± 0.5 46.9 ± 0.6 68.4 ± 0.5 70.4 ± 0.4 59.3 ± 0.4 MTL [6] 51.6 ± 1.5 47.7 ± 0.5 69.1 ± 0.3 71.0 ± 0.6 59.9 ± 0.5 SagNet [48] 55.3 ± 0.4 49.6 ± 0.2 72.1 ± 0.4 73.2 ± 0.4 62.5 ± 0.3 ARM [72] 51.3 ± 0.9 48.5 ± 0.4 68.0 ± 0.3 70.6 ± 0.1 59.6 ± 0.3 VREx [36] 51.1 ± 0.3 47.4 ± 0.6 69.0 ± 0.4 70.5 ± 0.4 59.5 ± 0.1 RSC [33] 49.0 ± 0.1 46.2 ± 1.5 67.8 ± 0.7 70.6 ± 0.3 58.4 ± 0.6 SelfReg [34] 55.1 ± 0.8 49.2 ± 0.6 72.2 ± 0.3 73.0 ± 0.3 62.4 ± 0.1 MixStyle [75] 50.8 ± 0.6 51.4 ± 1.1 67.6 ± 1.3 68.8 ± 0.5 59.6 ± 0.8 Fish [58] 54.6 ± 1.0 49.6 ± 1.0 71.3 ± 0.6 72.4 ± 0.2 62.0 ± 0.6 SD [51] 55.0 ± 0.4 51.3 ± 0.5 72.5 ± 0.2 72.7 ± 0.3 62.9 ± 0.2 CAD [53] 52.1 ± 0.6 48.3 ± 0.5 69.7 ± 0.3 71.9 ± 0.4 60.5 ± 0.3 CondCAD [53] 53.3 ± 0.6 48.4 ± 0.2 69.8 ± 0.9 72.6 ± 0.1 61.0 ± 0.4 Fishr [52] 52.6 ± 0.9 48.6 ± 0.3 69.9 ± 0.6 72.4 ± 0.4 60.9 ± 0.3 Ours 54.4 ± 0.2 52.3 ± 0.8 69.5 ± 0.3 71.7 ± 0.2 62.0 ± 0.2Table 14. Average accuracies on the TerraInc [4] datasets using the default hyper-parameter settings in DomainBed [27]. L100 L38 L43 L46 Average ERM [61] 42.1 ± 2.5 30.1 ± 1.2 48.9 ± 0.6 34.0 ± 1.1 38.8 ± 1.0 IRM [1] 41.8 ± 1.8 29.0 ± 3.6 49.6 ± 2.1 33.1 ± 1.5 38.4 ± 0.9 GroupGRO [55] 45.3 ± 4.6 36.1 ± 4.4 51.0 ± 0.8 33.7 ± 0.9 41.5 ± 2.0 Mixup [68] 49.4 ± 2.0 35.9 ± 1.8 53.0 ± 0.7 30.0 ± 0.9 42.1 ± 0.7 MLDG [38] 39.6 ± 2.3 33.2 ± 2.7 52.4 ± 0.5 35.1 ± 1.5 40.1 ± 0.9 CORAL [59] 46.7 ± 3.2 36.9 ± 4.3 49.5 ± 1.9 32.5 ± 0.7 41.4 ± 1.8 MMD [40] 49.1 ± 1.2 36.4 ± 4.8 50.4 ± 2.1 32.3 ± 1.5 42.0 ± 1.0 DANN [23] 44.3 ± 3.6 28.0 ± 1.5 47.9 ± 1.0 31.3 ± 0.6 37.9 ± 0.9 CDANN [44] 36.9 ± 6.4 32.7 ± 6.2 51.1 ± 1.3 33.5 ± 0.5 38.6 ± 2.3 MTL [6] 45.2 ± 2.6 31.0 ± 1.6 50.6 ± 1.1 34.9 ± 0.4 40.4 ± 1.0 SagNet [48] 36.3 ± 4.7 40.3 ± 2.0 52.5 ± 0.6 33.3 ± 1.3 40.6 ± 1.5 ARM [72] 41.5 ± 4.5 27.7 ± 2.4 50.9 ± 1.0 29.6 ± 1.5 37.4 ± 1.9 VREx [36] 48.0 ± 1.7 41.1 ± 1.5 51.8 ± 1.5 32.0 ± 1.2 43.2 ± 0.3 RSC [33] 42.8 ± 2.4 32.2 ± 3.8 49.6 ± 0.9 32.9 ± 1.2 39.4 ± 1.3 SelfReg [34] 46.1 ± 1.5 34.5 ± 1.6 49.8 ± 0.3 34.7 ± 1.5 41.3 ± 0.3 MixStyle [75] 50.6 ± 1.9 28.0 ± 4.5 52.1 ± 0.7 33.0 ± 0.2 40.9 ± 1.1 Fish [58] 46.3 ± 3.0 29.0 ± 1.1 52.7 ± 1.2 32.8 ± 1.0 40.2 ± 0.6 SD [51] 45.5 ± 1.9 33.2 ± 3.1 52.9 ± 0.7 36.4 ± 0.8 42.0 ± 1.0 CAD [53] 43.1 ± 2.6 31.1 ± 1.9 53.1 ± 1.6 34.7 ± 1.3 40.5 ± 0.4 CondCAD [53] 44.4 ± 2.9 32.9 ± 2.5 50.5 ± 1.3 30.8 ± 0.5 39.7 ± 0.4 Fishr [52] 49.9 ± 3.3 36.6 ± 0.9 49.8 ± 0.2 34.2 ± 1.3 42.6 ± 1.0 Ours 51.7 ± 2.4 37.6 ± 0.6 49.9 ± 0.6 33.6 ± 0.6 43.2 ± 0.5 Table 15. Average accuracies on the DomainNet [50] datasets using the default hyper-parameter settings in DomainBed [27]. clip info paint quick real sketch Average ERM [61] 50.4 ± 0.2 14.0 ± 0.2 40.3 ± 0.5 11.7 ± 0.2 52.0 ± 0.2 43.2 ± 0.3 35.3 ± 0.1 IRM [1] 43.2 ± 0.9 12.6 ± 0.3 35.0 ± 1.4 9.9 ± 0.4 43.4 ± 3.0 38.4 ± 0.4 30.4 ± 1.0 GroupGRO [55] 38.2 ± 0.5 13.0 ± 0.3 28.7 ± 0.3 8.2 ± 0.1 43.4 ± 0.5 33.7 ± 0.0 27.5 ± 0.1 Mixup [68] 48.9 ± 0.3 13.6 ± 0.3 39.5 ± 0.5 10.9 ± 0.4 49.9 ± 0.2 41.2 ± 0.2 34.0 ± 0.0 MLDG [38] 51.1 ± 0.3 14.1 ± 0.3 40.7 ± 0.3 11.7 ± 0.1 52.3 ± 0.3 42.7 ± 0.2 35.4 ± 0.0 CORAL [59] 51.2 ± 0.2 15.4 ± 0.2 42.0 ± 0.2 12.7 ± 0.1 52.0 ± 0.3 43.4 ± 0.0 36.1 ± 0.2 MMD [40] 16.6 ± 13.3 0.3 ± 0.0 12.8 ± 10.4 0.3 ± 0.0 17.1 ± 13.7 0.4 ± 0.0 7.9 ± 6.2 DANN [23] 45.0 ± 0.2 12.8 ± 0.2 36.0 ± 0.2 10.4 ± 0.3 46.7 ± 0.3 38.0 ± 0.3 31.5 ± 0.1 CDANN [44] 45.3 ± 0.2 12.6 ± 0.2 36.6 ± 0.2 10.3 ± 0.4 47.5 ± 0.1 38.9 ± 0.4 31.8 ± 0.2 MTL [6] 50.6 ± 0.2 14.0 ± 0.4 39.6 ± 0.3 12.0 ± 0.3 52.1 ± 0.1 41.5 ± 0.0 35.0 ± 0.0 SagNet [48] 51.0 ± 0.1 14.6 ± 0.1 40.2 ± 0.2 12.1 ± 0.2 51.5 ± 0.3 42.4 ± 0.1 35.3 ± 0.1 ARM [72] 43.0 ± 0.2 11.7 ± 0.2 34.6 ± 0.1 9.8 ± 0.4 43.2 ± 0.3 37.0 ± 0.3 29.9 ± 0.1 VREx [36] 39.2 ± 1.6 11.9 ± 0.4 31.2 ± 1.3 10.2 ± 0.4 41.5 ± 1.8 34.8 ± 0.8 28.1 ± 1.0 RSC [33] 39.5 ± 3.7 11.4 ± 0.8 30.5 ± 3.1 10.2 ± 0.8 41.0 ± 1.4 34.7 ± 2.6 27.9 ± 2.0 SelfReg [34] 47.9 ± 0.3 15.1 ± 0.3 41.2 ± 0.2 11.7 ± 0.3 48.8 ± 0.0 43.8 ± 0.3 34.7 ± 0.2 MixStyle [75] 49.1 ± 0.4 13.4 ± 0.0 39.3 ± 0.0 11.4 ± 0.4 47.7 ± 0.3 42.7 ± 0.1 33.9 ± 0.1 Fish [58] 51.5 ± 0.3 14.5 ± 0.2 40.4 ± 0.3 11.7 ± 0.5 52.6 ± 0.2 42.1 ± 0.1 35.5 ± 0.0 SD [51] 51.3 ± 0.3 15.5 ± 0.1 41.5 ± 0.3 12.6 ± 0.2 52.9 ± 0.2 44.0 ± 0.4 36.3 ± 0.2 CAD [53] 45.4 ± 1.0 12.1 ± 0.5 34.9 ± 1.1 10.2 ± 0.6 45.1 ± 1.6 38.5 ± 0.6 31.0 ± 0.8 CondCAD [53] 46.1 ± 1.0 13.3 ± 0.4 36.1 ± 1.4 10.7 ± 0.2 46.8 ± 1.3 38.7 ± 0.7 31.9 ± 0.7 Fishr [52] 47.8 ± 0.7 14.6 ± 0.2 40.0 ± 0.3 11.9 ± 0.2 49.2 ± 0.7 41.7 ± 0.1 34.2 ± 0.3 Ours 50.7 ± 0.7 13.9 ± 0.4 39.4 ± 0.5 11.9 ± 0.2 50.2 ± 0.3 43.5 ± 0.1 34.9 ± 0.1",
      "meta_data": {
        "arxiv_id": "2304.04494v2",
        "authors": [
          "Liang Chen",
          "Yong Zhang",
          "Yibing Song",
          "Ying Shan",
          "Lingqiao Liu"
        ],
        "published_date": "2023-04-10T10:12:38Z",
        "pdf_url": "https://arxiv.org/pdf/2304.04494v2.pdf",
        "github_url": "https://github.com/liangchen527/ITTA"
      },
      "llm_extracted_info": {
        "main_contributions": "Introduces Improved Test-Time Adaptation (ITTA) for domain generalization. Key novelties: (1) a learnable consistency loss used as test-time auxiliary task whose parameters are optimized to align with the main classification loss, and (2) insertion of lightweight adaptive parameters after each backbone block that are the only parameters updated online at test time. Together these strategies consistently outperform prior DG and TTT methods on five standard benchmarks in both multi-source and single-source settings.",
        "methodology": "Training: start with an ImageNet-pretrained ResNet-18 feature extractor and classifier. Apply MixStyle augmentation to obtain two feature views (z, z'). Main loss is cross-entropy on both views. Consistency loss Lwcont = ||fw(z−z')||_2 where fw is a small ReLU MLP. To enforce alignment, the gradients of Lwcont and the main loss w.r.t. backbone parameters are normalized and their L2 distance (Lalign) is minimized to update fw; θ,ϕ are updated with the combined loss Lmain+αLwcont (α=1). Testing: for each unseen sample insert adaptive blocks fΘ (small MLPs) after every backbone block; compute two views, optimize Θ for one step by minimizing learned consistency loss, keep original weights frozen, then predict with adapted features. Online per-sample adaptation.",
        "experimental_setup": "Evaluated with DomainBed protocol: datasets PACS, VLCS, OfficeHome, TerraIncognita, DomainNet. Leave-one-domain-out (multi-source) and single-source settings. 60 random seeds per target domain, 5000 training iterations, model selection by training-domain validation split (8/2). Backbone ResNet-18, batch size & learning rates as in DomainBed. Compared against 22 baselines including ERM, IRM, MixStyle, Fish, TENT, etc. Metrics: classification accuracy averaged over trials, domains, datasets.",
        "limitations": "Higher computational overhead: extra forward/backward passes for second-order gradient alignment during training and additional adaptation step plus adaptive blocks at inference; increases FLOPs, latency, and memory. Method demonstrated only on image classification with ResNet-18 and MixStyle augmentation; generality to other modalities, larger models, or tasks not verified.",
        "future_research_directions": "1) Reduce computational cost via approximate or first-order alignment objectives and more efficient adaptation blocks. 2) Explore applicability to larger backbones, other tasks (detection, segmentation) and non-vision domains. 3) Investigate alternative augmentation or consistency formulations to further boost alignment. 4) Study batch or episodic adaptation strategies and robustness to streaming or limited test data. 5) Theoretically analyze convergence and generalization guarantees of learnable loss alignment.",
        "experimental_code": "# ------------------------------  networks.py  ------------------------------\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models\nimport random\n\n# ---------- small utilities ----------\nclass Identity(nn.Module):\n    \"\"\"A thin wrapper that simply returns its input.\"\"\"\n    def forward(self, x):\n        return x\n\n# ---------------------------------------------------------------------------\n# 1.  ResNet-18 backbone that internally produces two feature views using\n#     MixStyle (the original view z, and the style-mixed view z').\n# ---------------------------------------------------------------------------\nclass ResNet_ITTA(nn.Module):\n    \"\"\"ImageNet pretrained ResNet-18 that outputs two feature views.\n    The first view (x) is the normal forward pass and the second view\n    (aug_x) is generated by a MixStyle operation applied after the first\n    residual block (layer1).\n    \"\"\"\n    def __init__(self, input_shape, hparams):\n        super().__init__()\n        self.network = torchvision.models.resnet18(pretrained=True)\n        self.n_outputs = 512                      # resnet18 penultimate dim\n        self.network.fc = Identity()              # discard classifier\n        self.dropout = nn.Dropout(hparams['resnet_dropout'])\n        self.eps = 1e-6\n        # freeze BN statistics (default in the original repo)\n        for m in self.network.modules():\n            if isinstance(m, nn.BatchNorm2d):\n                m.eval()\n\n    # ------------ MixStyle ------------\n    def _mixstyle(self, x, alpha=0.1):\n        B = x.size(0)\n        mu  = x.mean(dim=[2,3], keepdim=True)\n        var = x.var (dim=[2,3], keepdim=True)\n        sig = (var + self.eps).sqrt()\n        x_normed = (x - mu) / sig\n\n        lmda = torch.distributions.Beta(alpha, alpha).sample((B,1,1,1)).to(x)\n        perm = torch.randperm(B)\n        mu2 , sig2 = mu[perm], sig[perm]\n        mu_mix  = mu * lmda + mu2  * (1-lmda)\n        sig_mix = sig* lmda + sig2 * (1-lmda)\n        return x_normed*sig_mix + mu_mix\n\n    # public forward ‑- returns two feature maps after layer1\n    def forward(self, x):\n        x = self.network.conv1(x)\n        x = self.network.bn1(x)\n        x = self.network.relu(x)\n        x = self.network.maxpool(x)\n\n        x = self.network.layer1(x)\n        # probabilistically decide whether the second view should be augmented\n        if random.random() > 0.5:\n            aug_x = self._mixstyle(x)\n            self.is_aug = True\n        else:\n            aug_x = x\n            self.is_aug = False\n        return x, aug_x  # raw feature maps after layer1\n\n    # helper blocks to run deeper layers\n    def fea2(self, x, x_aug):\n        x     = self.network.layer2(x)\n        x_aug = self.network.layer2(x_aug)\n        if not self.is_aug:\n            x_aug = self._mixstyle(x_aug)\n        return x, x_aug\n\n    def fea3(self, x):\n        return self.network.layer3(x)\n\n    def fea4(self, x):\n        return self.network.layer4(x)\n\n    def flat(self, x):\n        x = self.network.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.dropout(self.network.fc(x))\n        return x\n\n# ---------------------------------------------------------------------------\n# 2.  Light-weight per-block adaptation modules f_Θ (one instance per block)\n# ---------------------------------------------------------------------------\nclass MappingNetwork(nn.Module):\n    \"\"\"A depth-D per-channel affine adaptor inserted after each resnet block.\"\"\"\n    def __init__(self, depth=5):\n        super().__init__()\n        self.depth = depth\n        sizes = {1:(64,56,56), 2:(128,28,28), 3:(256,14,14), 4:(512,7,7)}\n        self.params = nn.ModuleDict()\n        for blk,(c,h,w) in sizes.items():\n            self.params[f'w{blk}'] = nn.ParameterList([nn.Parameter(torch.ones(c,h,w)) for _ in range(depth)])\n            self.params[f'b{blk}'] = nn.ParameterList([nn.Parameter(torch.zeros(c,h,w)) for _ in range(depth)])\n        self.relu = nn.ReLU(inplace=True)\n\n    def _forward_block(self, x, w_list, b_list):\n        for i in range(self.depth-1):\n            x = self.relu(w_list[i]*x + b_list[i])\n        return w_list[-1]*x + b_list[-1]\n\n    def fea1(self, x): return self._forward_block(x, self.params['w1'], self.params['b1'])\n    def fea2(self, x): return self._forward_block(x, self.params['w2'], self.params['b2'])\n    def fea3(self, x): return self._forward_block(x, self.params['w3'], self.params['b3'])\n    def fea4(self, x): return self._forward_block(x, self.params['w4'], self.params['b4'])\n\n# ---------------------------------------------------------------------------\n# 3.  Learned consistency function  f_w  (here called Adaparams)\n# ---------------------------------------------------------------------------\nclass Adaparams(nn.Module):\n    def __init__(self, depth=10):\n        super().__init__()\n        self.depth = depth\n        self.relu = nn.ReLU(inplace=True)\n        self.weight = nn.ParameterList([nn.Parameter(torch.ones(512))  for _ in range(depth)])\n        self.bias   = nn.ParameterList([nn.Parameter(torch.zeros(512)) for _ in range(depth)])\n\n    def forward(self, x):\n        for i in range(self.depth-1):\n            x = self.relu(self.weight[i]*x + self.bias[i])\n        return self.weight[-1]*x + self.bias[-1]\n\n# ------------------------------  misc.py  -----------------------------------\n#   Distance between two sets of gradients (used for L_align)\n# ---------------------------------------------------------------------------\nimport torch\nfrom collections import OrderedDict\n\ndef l2_between_dicts(d1, d2, normalize=False):\n    assert len(d1) == len(d2)\n    v1 = torch.cat([t.reshape(-1) for t in [d1[k] for k in sorted(d1)]])\n    v2 = torch.cat([t.reshape(-1) for t in [d2[k] for k in sorted(d1)]])\n    if normalize:\n        v1 = (v1 - v1.mean())/v1.std()\n        v2 = (v2 - v2.mean())/v2.std()\n    return (v1 - v2).pow(2).mean()\n\n# ----------------------------  algorithms.py  -------------------------------\nimport torch\nimport torch.nn.functional as F\nfrom collections import OrderedDict\n\nclass ITTA(Algorithm):\n    \"\"\"Implementation of the proposed method (Instance-wise Test-Time Adaptation).\"\"\"\n    def __init__(self, input_shape, num_classes, num_domains, hparams):\n        super().__init__(input_shape, num_classes, num_domains, hparams)\n        self.featurizer  = ResNet_ITTA(input_shape, hparams)\n        self.classifier  = networks.Classifier(self.featurizer.n_outputs,\n                                               num_classes,\n                                               hparams['nonlinear_classifier'])\n        # train-time MLP implementing f_w\n        self.adaparams   = Adaparams()               # consistency head\n        # test-time per-block adaptors f_Θ\n        self.test_mapping = MappingNetwork()         \n\n        # optimizers -----------------------------------------------------------------\n        self.optimizer = torch.optim.Adam(list(self.featurizer.parameters())+\n                                          list(self.classifier.parameters()),\n                                          lr=hparams['lr'],\n                                          weight_decay=hparams['weight_decay'])\n        self.adaparams_opt     = torch.optim.Adam(self.adaparams.parameters(), lr=hparams['lr']*0.1)\n        self.test_optimizer    = torch.optim.Adam(self.test_mapping.parameters(), lr=hparams['lr']*0.1)\n        self.MSEloss = nn.MSELoss()\n\n    # -------------------------------------------------------------------------\n    # helper to compute individual grads of a loss w.r.t. backbone parameters\n    # -------------------------------------------------------------------------\n    def _get_grads(self, loss):\n        self.optimizer.zero_grad()\n        loss.backward(inputs=list(self.featurizer.parameters()), retain_graph=True, create_graph=True)\n        return OrderedDict([(n, p.grad.clone().view(p.grad.size(0), -1)) for n,p in self.featurizer.named_parameters()])\n\n    # -------------------------------------------------------------------------\n    # Training step (Alg.-1 in the paper)\n    # -------------------------------------------------------------------------\n    def update(self, minibatches, unlabeled=None):\n        x = torch.cat([mb[0] for mb in minibatches])\n        y = torch.cat([mb[1] for mb in minibatches])\n\n        # 1) forward two views through backbone\n        z_ori, z_aug = self.featurizer(x)                 # after layer1\n        z_ori, z_aug = self.featurizer.fea2(z_ori, z_aug) # after layer2\n        z_ori        = self.featurizer.fea3(z_ori)\n        z_aug        = self.featurizer.fea3(z_aug)\n        z_ori        = self.featurizer.fea4(z_ori)\n        z_aug        = self.featurizer.fea4(z_aug)\n        z_ori        = self.featurizer.flat(z_ori)\n        z_aug        = self.featurizer.flat(z_aug)\n\n        # 2) main loss (cross-entropy on both views)\n        loss_cla = F.cross_entropy(self.classifier(z_ori), y) + \\\n                   F.cross_entropy(self.classifier(z_aug), y)\n        # 3) learned consistency loss (   || f_w(z_aug - z_ori) ||_2   )\n        loss_reg = self.MSEloss(self.adaparams(z_aug - z_ori), torch.zeros_like(z_aug))\n\n        # 4) joint update of θ, ϕ  (backbone + classifier)\n        loss = loss_cla + loss_reg\n        self.optimizer.zero_grad()\n        loss.backward()\n        self.optimizer.step()\n\n        # 5)   update f_w   by aligning its gradients with those of CE loss\n        #     L_align = ||  ∇_θ L_reg  − ∇_θ L_ce  ||²\n        z_ori2, z_aug2 = self.featurizer(x)\n        z_ori2, z_aug2 = self.featurizer.fea2(z_ori2, z_aug2)\n        z_ori2, z_aug2 = self.featurizer.fea3(z_ori2), self.featurizer.fea3(z_aug2)\n        z_ori2, z_aug2 = self.featurizer.fea4(z_ori2), self.featurizer.fea4(z_aug2)\n        z_ori2, z_aug2 = self.featurizer.flat(z_ori2), self.featurizer.flat(z_aug2)\n\n        loss_cla2 = F.cross_entropy(self.classifier(z_ori2), y) + \\\n                    F.cross_entropy(self.classifier(z_aug2), y)\n        loss_reg2 = self.MSEloss(self.adaparams(z_aug2 - z_ori2), torch.zeros_like(z_aug2))\n\n        g_reg = self._get_grads(loss_reg2)\n        g_cla = self._get_grads(loss_cla2)\n        penalty = 0.1 * l2_between_dicts(g_reg, g_cla, normalize=True)\n\n        self.adaparams_opt.zero_grad()\n        penalty.backward(inputs=list(self.adaparams.parameters()))\n        self.adaparams_opt.step()\n\n        return {'loss': loss_cla.item(), 'reg': loss_reg.item()}\n\n    # -------------------------------------------------------------------------\n    # Online test-time adaptation (one gradient step on Θ for each sample)\n    # -------------------------------------------------------------------------\n    def test_adapt(self, x):\n        z_ori, z_aug = self.featurizer(x)\n        z_ori = self.test_mapping.fea1(z_ori)\n        z_aug = self.test_mapping.fea1(z_aug)\n        z_ori, z_aug = self.featurizer.fea2(z_ori, z_aug)\n        z_ori = self.test_mapping.fea2(z_ori)\n        z_ori = self.featurizer.fea3(z_ori)\n        z_aug = self.featurizer.fea3(z_aug)\n        z_ori = self.test_mapping.fea3(z_ori)\n        z_ori = self.featurizer.fea4(z_ori)\n        z_aug = self.featurizer.fea4(z_aug)\n        z_ori = self.test_mapping.fea4(z_ori)\n        z_ori = self.featurizer.flat(z_ori)\n        z_aug = self.featurizer.flat(z_aug)\n\n        loss_reg = self.MSEloss(self.adaparams(z_aug - z_ori), torch.zeros_like(z_ori)) * self.hparams['ada_lr']\n        self.test_optimizer.zero_grad()\n        loss_reg.backward(inputs=list(self.test_mapping.parameters()))\n        self.test_optimizer.step()\n\n    # prediction after test-time adaptation\n    def predict(self, x):\n        z_ori, z_aug = self.featurizer(x)\n        z_ori = self.test_mapping.fea1(z_ori)\n        z_ori, _ = self.featurizer.fea2(z_ori, z_aug)\n        z_ori = self.test_mapping.fea2(z_ori)\n        z_ori = self.featurizer.fea3(z_ori)\n        z_ori = self.test_mapping.fea3(z_ori)\n        z_ori = self.featurizer.fea4(z_ori)\n        z_ori = self.test_mapping.fea4(z_ori)\n        z_ori = self.featurizer.flat(z_ori)\n        return self.classifier(z_ori)\n",
        "experimental_info": "Default hyper-parameters for the method (defined in domainbed/hparams_registry.py):\n\n# ITTA specific\nif algorithm == 'ITTA':\n    # learning-rate used for test-time update of Θ (MappingNetwork)\n    # DomainNet requires a smaller value\n    if dataset == 'DomainNet':\n        ada_lr = 0.1\n    else:\n        ada_lr = 1e-6\n    hparams['ada_lr'] = ada_lr\n\n# Generic backbone/training hparams inherited from the parent registry\nhparams = {\n    'lr'            : 5e-5               # base learning rate\n    'weight_decay'  : 0.0\n    'batch_size'    : 32                # (224×224 datasets)\n    'resnet_dropout': 0.0\n    'nonlinear_classifier': False\n}\n\nTraining/Testing protocol (see domainbed/scripts/train.py):\n1.  Finetune backbone + classifier + f_w for N = dataset.N_STEPS steps with\n    cross-entropy + consistency + gradient-alignment losses (update()).\n2.  During evaluation of a test image:\n        a) call ITTA.test_adapt(x) – one gradient step on Θ (MappingNetwork)\n           using the learned consistency loss; backbone weights frozen.\n        b) call ITTA.predict(x)   – forward pass using adapted features.\n   This is executed online for every incoming test sample.\n\nThe method uses ImageNet-pretrained ResNet-18 as the feature extractor and\nMixStyle augmentation internally (implemented inside ResNet_ITTA)."
      }
    },
    {
      "title": "Improving the Gating Mechanism of Recurrent Neural Networks",
      "abstract": "Gating mechanisms are widely used in neural network models, where they allow\ngradients to backpropagate more easily through depth or time. However, their\nsaturation property introduces problems of its own. For example, in recurrent\nmodels these gates need to have outputs near 1 to propagate information over\nlong time-delays, which requires them to operate in their saturation regime and\nhinders gradient-based learning of the gate mechanism. We address this problem\nby deriving two synergistic modifications to the standard gating mechanism that\nare easy to implement, introduce no additional hyperparameters, and improve\nlearnability of the gates when they are close to saturation. We show how these\nchanges are related to and improve on alternative recently proposed gating\nmechanisms such as chrono initialization and Ordered Neurons. Empirically, our\nsimple gating mechanisms robustly improve the performance of recurrent models\non a range of applications, including synthetic memorization tasks, sequential\nimage classification, language modeling, and reinforcement learning,\nparticularly when long-term dependencies are involved.",
      "full_text": "Improving the Gating Mechanism of Recurrent Neural Networks Albert Gu1 Caglar Gulcehre2 Tom Paine2 Matt Hoffman2 Razvan Pascanu2 Abstract Gating mechanisms are widely used in neural network models, where they allow gradients to backpropagate more easily through depth or time. However, their saturation property introduces problems of its own. For example, in recurrent models these gates need to have outputs near 1 to propagate information over long time-delays, which requires them to operate in their saturation regime and hinders gradient-based learning of the gate mechanism. We address this problem by deriving two synergistic modiﬁcations to the stan- dard gating mechanism that are easy to implement, introduce no additional hyperparameters, and improve learnability of the gates when they are close to saturation. We show how these changes are related to and improve on alternative recently proposed gating mechanisms such as chrono initialization and Ordered Neurons. Empirically, our simple gating mechanisms robustly improve the performance of recurrent models on a range of applications, including synthetic memorization tasks, sequential image classiﬁcation, language modeling, and reinforcement learning, particularly when long-term dependencies are involved. 1. Introduction Recurrent neural networks (RNNs) are an established machine learning tool for learning from sequential data. However, RNNs are prone to the vanishing gradient problem, which occurs when the gradients of the recurrent weights be- come vanishingly small as they get backpropagated through time (Hochreiter, 1991; Bengio et al., 1994; Hochreiter et al., 2001). A common approach to alleviate the vanishing gradient problem is to use gating mechanisms, leading to models such as the long short term memory (Hochreiter & Schmidhuber, 1997, LSTM) and gated recurrent units 1Stanford University, USA 2DeepMind, London, UK. Corre- spondence to: Albert Gu<albertgu@stanford.edu>, Caglar Gul- cehre <caglarg@google.com>. Proceedings of the 37 th International Conference on Machine Learning, Vienna, Austria, PMLR 108, 2020. Copyright 2020 by the author(s). (Chung et al., 2014, GRUs). These gated RNNs have been very successful in several different application areas such as in reinforcement learning (Kapturowski et al., 2018; Espeholt et al., 2018) and natural language processing (Bahdanau et al., 2014; Koˇcisk`y et al., 2018). At every time step, gated recurrent networks use a weighted combination of the history summarized by the previous state, and a function of the incoming inputs, to create the next state. The values of the gates, which are the coefﬁcients of the weighted combination, control the length of temporal dependencies that can be addressed. This weighted update can be seen as an additive or residual connection on the recurrent state, which helps signals propagate through time without vanishing. However, the gates themselves are prone to a saturating property which can also hamper gradient-based learning. This can be problematic for RNNs, where carrying information for very long time delays requires gates to be very close to their saturated states. We address two particular problems that arise with the standard gating mechanism of recurrent models. Firstly, learning when gates are in their saturation regime is difﬁcult because gradients through the gates vanish as they saturate. We derive a modiﬁcation to standard gating mechanisms that uses an auxiliaryreﬁne gate(Section 3.1) to modulate a main gate. This mechanism allows the gates to have a wider range of activations without gradients vanishing as quickly. Secondly, typical initialization of the gates is relatively concentrated. This restricts the range of timescales the model can address at initialization, as the timescale of a particular unit is dictated by its gates. We proposeuniform gate initial- ization (Section 3.2) that addresses this problem by directly initializing the activations of these gates from a distribution that captures a wider spread of dependency lengths. The main contribution of this paper is thereﬁne gate mech- anism. As the reﬁne gate works better in tandem with uni- form gate initialization, we call this combination the UR gating mechanism. We focus on comparing the UR gating mechanism against other approaches in our experiments. These changes can be applied to any gate (i.e. parameterized bounded function) and have minimal to no overhead in terms of speed, memory, code complexity, parameters, or hyper parameters. We apply them to the forget gate of recurrent models, and evaluate on several benchmark tasks that re- arXiv:1910.09890v2  [cs.NE]  18 Jun 2020Improving the Gating Mechanism of Recurrent Neural Networks quire long-term memory including synthetic memory tasks, pixel-by-pixel image classiﬁcation, language modeling, and reinforcement learning. Finally, we connect our methods to other proposed gating modiﬁcations, introduce a framework that allows each component to be replaced with similar ones, and perform extensive ablations of our method. Empirically, the UR gating mechanism robustly improves on the standard forget and input gates of gated recurrent models. When ap- plied to the LSTM, these simple modiﬁcations solve synthetic memory tasks that are pathologically difﬁcult for the standard LSTM, achieve state-of-the-art results on sequential MNIST and CIFAR-10, and show consistent improvements in lan- guage modeling on the WikiText-103 dataset (Merity et al., 2016) and reinforcement learning tasks (Hung et al., 2018). 2. Gated Recurrent Neural Networks Broadly speaking, RNNs are used to sweep over a sequence of input data xt to produce a sequence of recurrent states ht ∈Rd summarizing information seen so far. At a high level, an RNN is just a parametrized function in which each sequential application of the network computes a state update u:(xt,ht−1)↦→ht. Gating mechanisms were introduced to address the vanishing gradient problem (Hochreiter, 1991; Bengio et al., 1994; Hochreiter et al., 2001), and have proven to be crucial to the success of RNNs. This mechanism essen- tially smooths out the update using the following equation, ht=ft(xt,ht−1)◦ht−1+it(xt,ht−1)◦u(xt,ht−1), (1) where the forget gate ft and input gate it are [0,1]d-valued functions that control how fast information is forgotten or allowed into the memory state. When the gates are tied, i.e. ft+it= 1as in GRUs, they behave as a low-pass ﬁlter, deciding the time-scale on which the unit will respond (Tallec & Ollivier, 2018). For example, large forget gate activations close to ft=1 are necessary for recurrent models to address long-term dependencies.1 We will introduce our improvements to the gating mechanism primarily in the context of the LSTM, which is the most popular recurrent model. ft=σ(Pf(xt,ht−1)), (2) it=σ(Pi(xt,ht−1)), (3) ut=tanh(Pu(xt,ht−1)), (4) ct=ft◦ct−1+it◦ut, (5) ot=σ(Po(xt,ht−1)), (6) ht=ottanh(ct). (7) A typical LSTM (equations(2)-(7)) is an RNN whose state is represented by a tuple (ht,ct) consisting of a “hidden” 1In this work, we use “gate” to alternatively refer to a [0,1]- valued function or the value (“activation”) of that function. Figure 1.Reﬁne mechanism. The reﬁne mechanism improves ﬂow of gradients through a saturating gatef. As fsaturates, its gradient vanishes, and its value is unlikely to change (see Figure 4). The reﬁne gate ris used to produce a bounded additive termφthat may push flower or higher as necessary. The resulting effective gateg can achieve values closer to0 and 1 and can change even whenfis stuck. We apply it to the forget gate of an LSTM. Thegis then used in place offin the state update (5). state and “cell” state. The state update equation(1) is used to create the next cell statect(5). Note that the gate and update activations are a function of the previous hidden stateht−1 instead of ct−1. Here, P⋆stands for a parameterized linear function of its inputs with biasb⋆, e.g. Pf(xt,ht−1)= Wfxxt+Wfhht−1+bf. (8) and σ(·) refers to the standard sigmoid activation function which we will assume is used for deﬁning [0,1]-valued ac- tivations in the rest of this paper. The gates of the LSTM were initially motivated as a binary mechanism, switching on or off, allowing information and gradients to pass through. However, in reality, this fails to happen due to a combination of two factors: initialization and saturation. This can be prob- lematic, such as when very long dependencies are present. 3. Our Proposed Gating Mechanisms We present two solutions that work in tandem to address the previously described issues. The ﬁrst is thereﬁne gate, which allows for better gradient ﬂow by reparameterizing a saturating gate, for example, the forget gate. The second is uniform gate initialization, which ensures a diverse range of gate values are captured at the start of training, which allows a recurrent model to have a multi-scale representation of an input sequence at initialization. 3.1. Reﬁne Gate Formally, the full mechanism of the reﬁne gate as applied to gated recurrent models is deﬁned in equations (9)-(11). Note that it is an isolated change where the forget gateftis modiﬁed to get the effective forget gate in(10) before apply- ing the the standard update(1). Figure 1 illustrates the reﬁne gate in an LSTM cell. Figure 3 illustrates how the reﬁne gate rtis deﬁned and how it changes the forget gateftto produce an effective gate gt. The reﬁne gate allows the effective gate gto reach much higher and lower activations than theImproving the Gating Mechanism of Recurrent Neural Networks constituent gates fand r, bypassing the saturating gradient problem. For example, this allows the effective forget gate to reach g=0.99 when the forget gate is onlyf=0.9. Finally, to simplify comparisons and ensure that we always use the same number of parameters as the standard gates, when using the reﬁne gate we tie the input gate to the effec- tive forget gate, it= 1−gt.2 However, we emphasize that these techniques can be applied to any gate (or more broadly, any bounded function) to improve initialization distribution and help optimization. For example, our methods can be combined in different ways in recurrent models, e.g. an inde- pendent input gate can be modiﬁed with its own reﬁne gate. rt=σ(Pr(xt,ht−1)), (9) gt=rt·(1−(1−ft)2)+(1 −rt)·f2 t, (10) ct=gtct−1+(1−gt)ut. (11) 3.2. Uniform Gate Initialization Standard initialization schemes for the gates can prevent the learning of long-term temporal correlations (Tallec & Ollivier, 2018). For example, supposing that a unit in the cell state has constant forget gate valueft, then the contribution of an inputxtin ktime steps will decay by(ft)k. This gives the unit an effectivedecay period or characteristic timescale of O( 1 1−ft ).3 Standard initialization of linear layersLsets the bias term to0, which causes the forget gate values(2) to concentrate around 0.5. A common trick of setting the forget gate bias tobf=1.0 (Jozefowicz et al., 2015) does increase the value of the decay period to 1 1−σ(1.0) ≈3.7. However, this is still relatively small and may hinder the model from learning dependencies at varying timescales easily. We instead propose to directly control the distribution of forget gates, and hence the corresponding distribution of decay periods. In particular, we propose to simply initialize the value of the forget gate activations ft according to a uniform distribution U(0,1)4, bf∼σ−1(U[ϵ,1−ϵ]). (12) An important difference between UGI and standard or other (e.g. Tallec & Ollivier, 2018) initializations is that negative forget biases are allowed. The effect of UGI is that all timescales are covered, from units with very high forget activations remembering information (nearly) indeﬁnitely, to those with low activations focusing solely on the incoming 2In our experiments, we found that tying input/forget gates makes negligible difference on downstream performance, consistent with previous ﬁndings in the literature (Greff et al., 2016; Melis et al., 2017). 3This corresponds to the number of timesteps it takes to decay by 1/e. 4Since σ−1(0)= −inf, we use the standard practice of thresh- olding with a smallϵfor stability. 0.0 0.2 0.4 0.6 0.8 1.0 Gate f 0.0 0.2 0.4 0.6 0.8 1.0Band range c(f) (a) 4  3  2  1  0 1 2 3 4 x 0.0 0.2 0.4 0.6 0.8 1.0g 1 1 + e x 1 (1 + e x)2 1 1 (1 + ex)2  (b) Figure 2.The adjustment function. (a) An adjustment function α(ft) satisfying natural properties is chosen to deﬁne a band within which the forget gate is reﬁned. (b) The forget gateft(x) is conven- tionally deﬁned with the sigmoid function (black). The reﬁne gate interpolates around the original gateft to yield an effective gategt within the upper and lower curves,gt ∈ft ±α(ft). input. Additionally, it introduces no additional parameters; it even can have less hyperparameters than the standard gate initialization, which sometimes tunes the forget bias bf (Jozefowicz et al., 2015). Appendix B.2 and B.3 further discuss the theoretical effects of UGI on timescales. 3.3. The URLSTM The URLSTM requires two small modiﬁcations to the vanilla LSTM. First, we present the way the biases of forget gates are initialized in Equation (12) with UGI. Second, the modiﬁcations on the standard LSTM equations to compute the reﬁne and effective forget gates are presented in Equations (9)-(11). However, we note that these methods can be used to modify any gate (or more generally, bounded function) in any model. In this context, the URLSTM is simply deﬁned by applying UGI and a reﬁne gate ron the original forget gate f to create an effective forget gate g (Equation (10)). This effective gate is then used in the cell state update (11). Empirically, these small modiﬁcations to an LSTM are enough to allow it to achieve nearly binary activations and solve difﬁcult memory problems (Figure 5). 3.4. A Formal Treatment of Reﬁne Gates Given a gate f = σ(Pf(x)) ∈[0,1], the reﬁne gate is an independent gate r=σ(Pr(x)) that modulates fto produce a valueg∈[0,1] which will be used in place offdownstream. It is motivated by considering how to modify the output of a gate fin a way that promotes gradient-based learning, derived below. An additive adjustment A root cause of the saturation problem is that the gradient ∇f of a gate can be written solely as a function of the activation value as f(1 −f), decays rapidly as f approaches to 0 or 1. Thus when the activation f is past a certain upper or lower threshold,Improving the Gating Mechanism of Recurrent Neural Networks (a) 0.0 0.2 0.4 0.6 0.8 1.0 Effective gate g 1.0 1.5 2.0 2.5 3.0 3.5Increase in gradient vs. standard gate (b) Figure 3.Reﬁne gate activations and gradients.: (a) Contours of the effective gate gt as a function of the forget and reﬁne gates ft,rt. High effective activations can be achieved with more modest ft,rt values. (b) The gradient ∇gt as a function of effective gate activation gt. [Black, blue]: Lower and upper bounds on the ratio of the gradient with a reﬁne gate vs. the gradient of a standard gate. For activation values near the extremes, the reﬁne gate can signiﬁcantly increase the gradients. learning effectively stops. This problem cannot be fully addressed only by modifying the input of the sigmoid, as in UGI and other techniques, as the gradient will still vanish by backpropagating through the activation function. Therefore to better control activations near the saturating regime, instead of changing the input to the sigmoid inf= σ(P(x)), we consider modifying the output. Modifying the gate with a multiplicative interaction can have unstable learn- ing dynamics since when the gates have very small values, the multiplicative factor may need to be very large to avoid the gradients of the gates shrinking to zero. As a result, we consider adjustingfwith an input-dependent additive update φ(f,x) for some function φ, to create an effective gateg= f+φ(f,x) that will be used in place offdownstream such as in the main state update(1). This sort of additive (“residual”) connection is a common technique to increase gradient ﬂow, and indeed was the motivation of the LSTM additive gated update (1) itself (Hochreiter & Schmidhuber, 1997). Choosing the adjustment function φ Although there might be many choices that seem plausible for choosing an appropriate additive updateφ, we ﬁrst identify the desirable properties of such a function and then discuss how our reﬁne gate mechanism satisﬁes those properties. The desired properties of φ emerge considering the applications of the gating mechanisms in recurrent models: • Boundedness: After the additive updates, the activations still need to be bounded between0 and 1. • Symmetricity: The resulting gating framework should be symmetric around0, as sigmoid does. • Smoothness: The reﬁning mechanism should be differentiable, since we will be using backpropagation and gradient based optimization methods. Let us note that, ft may need to be either increased or de- creased, regardless of what value it has. This is because the gradients through the gates can vanish either when the activa- tions get closer to0 or 1. Therefore, an additive update tof should create aneffective gate activationgtin the rangeft±α for some α. We assume that the allowed adjustment range, α=α(ft), needs to be a function offto keep thegbetween 0 and 1. Since 0 and 1 are symmetrical in the gating framework, our adjustment rate should also satisfyα(f)= α(1−f). Figure 2a illustrates the general appearance ofα(f) based on aforementioned properties. According to theBoundedness property, the adjustment rate should be be upper-bounded by min(f,1−f) to ensure thatg∈f±α(f) is bounded between 0 and 1. As a consequence of this property, its derivatives should also satisfy,α′(0) ≤1 and α′(1) ≥−1. Symetricity also implies α′(f)= −α′(1−f), and smoothness impliesα′ is continuous. The simplest such function satisfying all these properties is the linearα′(f)=1 −2f, yielding to our choice of adjustment function,α(f)= f−f2 =f(1−f). However, when fis bounded between0 and 1, α(f) will be positive. Recall that the goal is to produce an effective activation g=f+φ(f,x) such that g∈f±α(f) (Figure 2b) given. Our ﬁnal observation is that the simplest such function φsatis- fying this is φ(f,x) =α(f)ψ(f,x) where ψ(f,x) ∈[−1,1] decides the sign of adjustment, and it can also change its magnitude as well. The standard method of deﬁning [−1,1]-valued differentiable functions is achieved by using a tanh non-linearity, and this leads toφ(f,x)= α(f)(2r−1) for another gater=σ(P(x)). The full reﬁne update equation can be given as in Equation (13), g=f+α(f)(2r−1)= f+f(1−f)(2r−1) =(1 −r)·f2+r·(1−(1−f)2) (13) Equation (13) has the elegant interpretation that the gater linearly interpolates between the lower bandf−α(f)= f2 and the symmetric upper band f + α(f) = 1−(1 −f)2 (Figure 2b). In other words, the original gate f is the coarse-grained determinant of the effective gateg, while the gate r“reﬁnes” it. 4. Related Gating Mechanisms We highlight a few recent works that also propose small gate changes to address problems of long-term or variable-length dependencies. Like ours, they can be applied to any gated update equation. Tallec & Ollivier (2018) suggest an initialization strategy to capture long-term dependencies on the order of Tmax, by sampling the gate biases from bf ∼log U(1,Tmax−1). Although similar to UGI in deﬁnition,chrono initializationImproving the Gating Mechanism of Recurrent Neural Networks (CI) has critical differences in the timescales captured, for example, by using an explicit timescale parameter and having no negative biases. Due to its relation to UGI, we provide a more detailed comparison in Appendix B.3. As mentioned in Section 3.4, techniques such as these that only modify the input to a sigmoid gate do not adequately address the saturation problem. The Ordered Neuron (ON) LSTM introduced by (Shen et al., 2018) aims to induce an ordering over the units in the hidden states such that “higher-level” neurons retain information for longer and capture higher-level information. We highlight this work due to its recent success in NLP, and also because its novelties can be factored into introducing two mechanisms which only affect the forget and input gates, namely (i) the cumax := cumsum◦softmax activation function which creates a monotonically increasing vector in [0,1], and (ii) a pair of “master gates” which are ordered by cumax and ﬁne-tuned with another pair of gates. We observe that these are related to our techniques in that one controls the distribution of a gate activation, and the other is an auxiliary gate with modulating behavior. Despite its important novelties, we ﬁnd that the ON-LSTM has drawbacks, including speed and scaling issues of its gates. We provide the formal deﬁnition and detailed analysis of the ON-LSTM in Appendix B.4. For example, we comment on how UGI can also be motivated as a faster approximation of the cumax activation. We also ﬂesh out a deeper relationship between the master and reﬁne gates and show how they can be interchanged for each other. We include a more thorough overview of other related works on RNNs in Appendix B.1. These methods are mostly orthogonal to the isolated gate changes considered here and are not analyzed. We note that an important drawback common to all other approaches is the introduction of substantial hyperparameters in the form of constants, training protocol, and signiﬁcant architectural changes. For example, even for chrono initialization, one of the less intrusive proposals, we experimentally ﬁnd it to be particularly sensitive to the hyperparameterTmax(Section 5). 4.1. Gate Ablations Our insights about previous work with related gate compo- nents allow us to perform extensive ablations of our con- tributions. We observe two independent axes of variation, namely, activation function/initialization (cumax, constant bias sigmoid, CI, UGI) and auxiliary modulating gates (mas- ter, reﬁne), where different components can be replaced with each other. Therefore we propose several other gate combina- tions to isolate the effects of different gating mechanisms. We summarize a few ablations here; precise details are given in Appendix B.5. O-: Ordered gates. A natural simpliﬁcation of the main idea of ON-LSTM, while keeping the hierarchical Table 1.Summary of gate ablations. Summary of gating mecha- nisms considered in this work as applied to the forget/input gates of recurrent models. Some of these ablations correspond to previous work. -- standard LSTMs, C- (Tallec & Ollivier, 2018), and OM (Shen et al., 2018) Name Initialization/Activation Auxiliary Gate -- Standard initialization N/A C- Chrono initialization N/A O- cumax activation N/A U- Uniform initialization N/A -R Standard initialization Reﬁne gate OM cumax activation Master gate UM Uniform initialization Master gate OR cumax activation Reﬁne gate UR Uniform initialization Reﬁne gate bias on the forget activations, is to simply drop the auxiliary master gates and deﬁne ft,it (2)-(3) using the cumax acti- vation function. UM: UGI master gates. This variant of the ON-LSTM’s gates ablates thecumax operation on the master gates, replacing it with a sigmoid activation and UGI which maintains the same initial distribution on the activation values. OR: Reﬁne instead of master. A ﬁnal variant in between the UR gates and the ON-LSTM’s gates combinescumax with reﬁne gates. In this formulation, as in UR gates, the reﬁne gate modiﬁes the forget gate and the input gate is tied to the effective forget gate. The forget gate is ordered usingcumax. Table 1 summarizes the gating modiﬁcations we consider and their naming conventions. Note that we also denote the ON-LSTM method asOM for mnemonic ease. Finally, we remark that all methods here are controlled with the same number of parameters as the standard LSTM, aside from OM and UM which use an additional 1 2C-fraction parameters where C is the downsize factor on the master gates (Appendix B.4). C=1 unless noted otherwise. 5. Experiments We ﬁrst perform full ablations of the gating variants (Sec- tion 4.1) on two common benchmarks for testing memory models: synthetic memory tasks and pixel-by-pixel image classiﬁcation tasks. We then evaluate our main method on important applications for recurrent models including language modeling and reinforcement learning, comparing against baselines from literature where appropriate. The main claims we evaluate for each gating component are (i) the reﬁne gate is more effective than alternatives (the master gate, or no auxiliary gate), and (ii) UGI is more effective than standard initialization for sigmoid gates. In particular, we expect the *R gate to be more effective than *M or *- for any primary gate *, and we expect U* to be better than -* and comparable to O* for any auxiliary gate *. The standard LSTM (--) uses forget bias 1.0 (SectionImproving the Gating Mechanism of Recurrent Neural Networks Figure 4.Performance on synthetic memory: Copy task using sequences of length 500. Several methods including standard gates fail to make any progress (overlapping ﬂat curves at baseline). Note that methods that combine the reﬁne gate with a range of gate values (OR, UR) perform best. But the reﬁne gate on its own does not perform well. Adding task using sequences of length 2000. Most methods eventually make progress, but again methods that combine the reﬁne gate with a range of gate values (OR, UR) perform best. 2.2). When chrono initialization is used and not explicitly tuned, we set Tmax to be proportional to the hidden size. This heuristic uses the intuition that if dependencies of length T exist, then so should dependencies of all lengths ≤T. Moreover, the amount of information that can be remembered is proportional to the number of hidden units. All of our benchmarks have prior work with recurrent baselines, from which we used the same models, protocol, and hyperparameters whenever possible, changing only the gating mechanism without doing any additional tuning for the reﬁne gating mechanisms. Full protocols and details for all experiments are given in Appendix D. 5.1. Synthetic Memory Tasks Our ﬁrst set of experiments is on synthetic memory tasks (Hochreiter & Schmidhuber, 1997; Arjovsky et al., 2016) that are known to be hard for standard LSTMs to solve. For these tasks, we used single layer models with 256 hidden units, trained using Adam with learning rate10−3. Copy task. The input is a sequence ofN+20 digits where the ﬁrst 10 tokens(a0,a1,...,a9) are randomly chosen from {1,...,8}, the middle N tokens are set to 0, and the last ten tokens are 9. The goal of the recurrent model is to output (a0,...,a9) in order on the last 10 time steps, whenever the Figure 5.Distribution of forget gate activations before and after training. For the Copy task. We show the distribution of activations ft for four methods: -- cannot learn large enoughft and makes no progress on the task. C- initializes with extremal activations which barely change during training. U- makes progress by encouraging a range of forget gate values, but this distribution does not change signiﬁcantly during training due to saturation. UR starts with the same distribution as U- but is able to learn extreme gate values, which allows it to access the distal inputs, as necessary for this task. Appendix E.1 shows a reverse task where UR is able to un-learn from a saturated regime. cue token 9 is presented. We trained our models using cross-entropy with baseline losslog(8) (Appendix D.1). Adding task. The input consists of two sequences: 1. N numbers (a0,...,aN−1) sampled independently fromU[0,1] 2. an index i0 ∈[0,N/2) and i1 ∈[N/2,N), together encoded as a two-hot sequence. The target output isai0 +ai1 and models are evaluated by the mean squared error with baseline loss 1/6. Figure 4 shows the loss of various methods on the Copy and Adding tasks. The only gate combinations capable of solving Copy completely are OR, UR, O-, and C-. This conﬁrms the mechanism of their gates: these are the only methods capable of producing high enough forget gate values either through the cumax non-linearity, the reﬁne gate, or extremely high forget biases. U- is the only other method able to make progress, but converges slower as it suffers from gate satu- ration without the reﬁne gate. -- makes no progress. OM and UM also get stuck at the baseline loss, despite OM’scumax activation, which we hypothesize is due to the suboptimal magnitudes of the gates at initialization (Appendix B.4). On the Adding task, every method besides -- is able to eventually solve it, with all reﬁne gate variants fastest. Figure 5 shows the distributions of forget gate activations of sigmoid-activation methods, before and after training on the Copy task. It shows that activations near1.0 are important for a model’s ability to make progress or solve this task, and that adding the reﬁne gate makes this signiﬁcantly easier. 5.2. Pixel-by-pixel Image Classiﬁcation These tasks involve feeding a recurrent model the pixels of an image in a scanline order before producing a classiﬁcationImproving the Gating Mechanism of Recurrent Neural Networks Figure 6.Performance on pixel-by-pixel image classiﬁcation. Performance is consistent with synthetic tasks. -- performs the worst. Other gating variants improve performance. Note that meth- ods that combine the reﬁne gate with a range of gate values (OR, UR) perform best. label. We test on the sequential MNIST (sMNIST), permuted MNIST (pMNIST) (Le et al., 2015), and sequential CIFAR- 10 (sCIFAR-10) tasks. Each LSTM method was ran with a learning rate sweep with 3 seeds each. We found that many methods were quite unstable, with multiple seeds diverging. Figure 6 shows the accuracy curves of each method at their best stable learning rate. The basic LSTM is noticeably worse than all of the others. This suggests that any of the gate mod- iﬁcations, whether better initialization,cumax non-linearity, or master or reﬁne gates, are better than standard gates espe- cially when long-term dependencies are present. Addition- ally, the uniform gate initialization methods are generally bet- ter than the ordered and chrono initialization, and the reﬁne gate performs better than the master gate. Table 2 compares the test accuracy of our main model against other models from the literature. In addition, we tried variants of GRUs and the addition of a generic regularization technique—we chose Zoneout (Krueger et al., 2016) with default hyperparameters (zc=0.5, zh=0.05). This combination even outperformed non-recurrent models on sequential MNIST and CIFAR-10. From Sections 5.1 and 5.2, we draw a few conclusions about the comparative performance of different gate modiﬁcations. First, the reﬁne gate is consistently better than comparable master gates. C- solves the synthetic memory tasks but is worse than any other variant outside of those. We ﬁnd or- dered (cumax) gates to be effective, but speed issues prevent us from using them in more complicated tasks. UR gates are consistently among the best performing and most stable. Table 2.Comparison to prior methods for pixel-by-pixel image classiﬁcation. Test acc. on pixel-by-pixel image classiﬁcation benchmarks. Top: Recurrent baselines and variants. Middle: Non- recurrent sequence models with global receptive ﬁeld. r-LSTM has 2-layers with an auxiliary loss. Bottom: Our methods. Method sMNIST pMNIST sCIFAR-10 LSTM (ours) 98.9 95.11 63.01 Dilated GRU (Chang et al., 2017) 99.0 94.6 - IndRNN (Li et al., 2018a) 99.0 96.0 - r-LSTM (Trinh et al., 2018) 98.4 95.2 72.2 Transformer (Trinh et al., 2018) 98.9 97.9 62.2 Temporal ConvNet (Bai et al., 2018a) 99.0 97.2 - TrellisNet (Bai et al., 2018b) 99.20 98.13 73.42 URLSTM 99.28 96.96 71.00 URLSTM + Zoneout (Krueger et al., 2016) 99.21 97.58 74.34 URGRU + Zoneout 99.27 96.51 74.4 Table 3.Language modelling results. Perplexities on the WikiText-103 dataset. Method Valid Test -- 34.3 35.8 C- 35.0 36.4 C- Tmax =8 34.3 36.1 C- Tmax =11 34.6 35.8 OM 34.0 34.7 U- 33.8 34.9 UR 33.6 34.6 5.3. Language Modeling We consider word-level language modeling on the WikiText- 103 dataset, where (i) the dependency lengths are much shorter than in the synthetic tasks, (ii) language has an implicit hierarchical structure and timescales of varying lengths. We evaluate our gate modiﬁcations against the exact hyperparameters of a SOTA LSTM-based baseline (Rae et al., 2018) without additional tuning (Appendix D). Additionally, we compare against ON-LSTM, which was designed for this domain (Shen et al., 2018), and chrono initialization, which addresses dependencies of a particular timescale as opposed to timescale-agnostic UGI methods. In addition to our default hyperparameter-free initialization, we tested models with the chrono hyperparameterTmaxmanually set to 8 and 11, values previously used for language modeling to mimic ﬁxed biases of about1.0 and 2.0 respectively (Tallec & Ollivier, 2018). Table 3 shows Validation and Test set perplexities for various models. We ﬁnd that OM, U-, and UR improve over -- with no additional tuning. However, although OM was designed to capture the hierarchical nature of language with the cumax activation, it does not perform better than U- and UR. Appendix D, Figure 11 additionally shows validation perplexity curves, which indicate that UR overﬁts less than the other methods. The chrono initialization using our aforementioned initial-Improving the Gating Mechanism of Recurrent Neural Networks Figure 7.Active match. Hung et al. (2018). The agent navigates a 3D world using observations from a ﬁrst person camera. The task has three phases. In phase 1, the agent must search for a colored cue. In phase 2, the agent is exposed to apples which give distractor rewards. In phase 3, the agent must correctly recall the color of the cue and pick the sensor near the corresponding color to receive the task reward. An episode lasts between 450 and 600 steps, requiring long-term memory and credit assignment. ization strategy makes biases far too large. While manually tweaking the Tmaxhyperparameter helps, it is still far from any UGI-based methods. We attribute these observations to the nature of language having dependencies on multiple widely-varying timescales, and that UGI is enough to capture these without resorting to strictly enforced hierarchies such as in OM. 5.4. Reinforcement Learning Memory Tasks In most partially observable reinforcement learning (RL) tasks, the agent can observe only part of the environment at a time and thus requires a memory to summarize what it has seen previously. However, designing memory architectures for reinforcement learning problems has been a challenging task (Oh et al., 2016; Wayne et al., 2018). Many memory architectures for RL use an LSTM component to summarize what an agent has seen. We investigated if changing the gates of these LSTMs can improve the performance of RL agents, especially on difﬁcult tasks involving memory and long-term credit assignment. We chose thePassive matchand Active matchtasks from Hung et al. (2018) using A3C agents (Mnih et al., 2016). See Figure 7 for a description of Active match. Passive match is similar, except the agent always starts facing the colored cue. As a result, Passive Match only tests long term memory, not long- term credit assignment. Only the ﬁnal task reward is reported. Hung et al. (2018) evaluated agents with different recurrent cores: basic LSTM, LSTM+Mem (an LSTM with memory), and RMA (which also uses an LSTM core), and found the standard LSTM was not able to solve these tasks. We mod- iﬁed the LSTM agent with our gate mechanisms. Figure 8 shows the results of different methods on the Passive match and Active match tasks with distractors. These tasks are structurally similar to the synthetic tasks (Sec. 5.1) requiring retrieval of a memory over hundreds of steps to solve the Figure 8.Performance on reinforcement learning tasks that re- quire memory.We evaluated the image matching tasks from Hung et al. (2018), which test memorization and credit assignment, using an A3C agent (Mnih et al., 2016) with an LSTM policy core. We observe that general trends from the synthetic tasks (Section(5.1)) transfer to this reinforcement learning setting. task, and we found that those trends largely transferred to the RL setting even with several additional confounders present such as agents learning via RL algorithms, being required to learn relevant features from pixels rather than being given the relevant tokens, and being required to explore in the Active Match case. We found that the UR gates substantially improved the performance of the basic LSTM on both Passive Match and Active Match tasks with distractor rewards. The URLSTM was the was the only method able to get near optimal performance on both tasks, and achieved similar ﬁnal performance to the LSTM+Mem and RMA agents reported in (Hung et al., 2018). 5.5. Additional Results and Experimental Conclusions Appendix (E.1) shows an additional synthetic experiment investigating the effect of reﬁne gates on saturation. Ap- pendix (E.3) has results on a program execution task, which is interesting for having explicit long and variable-length dependencies and hierarchical structure. It additionally shows another very different gated recurrent model where the UR gates provide consistent improvement. Finally, we would like to comment on the longevity of the LSTM, which for example was frequently found to outperform newer competitors when better tuned (Melis et al., 2017; Merity, 2019). Although many improvements have been suggested over the years, none have been proven to be as robust as the LSTM across an enormously diverse range of sequence modeling tasks. By experimentally starting fromImproving the Gating Mechanism of Recurrent Neural Networks well-tuned LSTM baselines, we believe our simple isolated gate modiﬁcations to actually be robust improvements. In Appendix B.3 and B.4, we offer a few conclusions for the practitioner about the other gate components considered based on our experimental experience. 6. Discussion In this work, we introduce and evaluate several modiﬁcations to the ubiquitous gating mechanism that appears in recurrent neural networks. We describe methods that improve on the standard gating method by alleviating problems with initialization and optimization. The mechanisms considered include changes on independent axes, namely initialization/activations and auxiliary gates, and we perform extensive ablations on our improvements with previously considered modiﬁcations. Our main gate model robustly improves on standard gates across many different tasks and recurrent cores, while requiring less tuning. Finally, we emphasize that these improvements are entirely independent of the large body of research on neural network architectures that use gates, and hope that these insights can be applied to improve machine learning models at large. References Arjovsky, M., Shah, A., and Bengio, Y . Unitary evolution recurrent neural networks. In International Conference on Machine Learning, pp. 1120–1128, 2016. Bahdanau, D., Cho, K., and Bengio, Y . Neural machine translation by jointly learning to align and translate.arXiv preprint arXiv:1409.0473, 2014. Bai, S., Kolter, J. Z., and Koltun, V . An empirical evaluation of generic convolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:1803.01271, 2018a. Bai, S., Kolter, J. Z., and Koltun, V . Trellis networks for sequence modeling. arXiv preprint arXiv:1810.06682, 2018b. Bengio, Y ., Simard, P., Frasconi, P., et al. Learning long-term dependencies with gradient descent is difﬁcult. IEEE transactions on neural networks, 5(2):157–166, 1994. Chandar, S., Sankar, C., V orontsov, E., Kahou, S. E., and Bengio, Y . Towards non-saturating recurrent units for modelling long-term dependencies. arXiv preprint arXiv:1902.06704, 2019. Chang, S., Zhang, Y ., Han, W., Yu, M., Guo, X., Tan, W., Cui, X., Witbrock, M., Hasegawa-Johnson, M. A., and Huang, T. S. Dilated recurrent neural networks. In Advances in Neural Information Processing Systems, pp. 77–87, 2017. Cho, K., Van Merri ¨enboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., and Bengio, Y . Learning phrase representations using RNN encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078, 2014. Chung, J., Gulcehre, C., Cho, K., and Bengio, Y . Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:1412.3555, 2014. Chung, J., Ahn, S., and Bengio, Y . Hierarchical mul- tiscale recurrent neural networks. arXiv preprint arXiv:1609.01704, 2016. Dai, Z., Yang, Z., Yang, Y ., Cohen, W. W., Carbonell, J., Le, Q. V ., and Salakhutdinov, R. Transformer-xl: Attentive language models beyond a ﬁxed-length context. arXiv preprint arXiv:1901.02860, 2019. Espeholt, L., Soyer, H., Munos, R., Simonyan, K., Mnih, V ., Ward, T., Doron, Y ., Firoiu, V ., Harley, T., Dunning, I., et al. Impala: Scalable distributed deep-rl with importance weighted actor-learner architectures. In International Conference on Machine Learning, pp. 1406–1415, 2018. Graves, A., Wayne, G., and Danihelka, I. Neural turing machines. arXiv preprint arXiv:1410.5401, 2014. Greff, K., Srivastava, R. K., Koutn´ık, J., Steunebrink, B. R., and Schmidhuber, J. LSTM: A search space odyssey. IEEE transactions on neural networks and learning systems, 28(10):2222–2232, 2016. Gulcehre, C., Moczulski, M., Denil, M., and Bengio, Y . Noisy activation functions. In International conference on machine learning, pp. 3059–3068, 2016. Gulcehre, C., Chandar, S., and Bengio, Y . Memory augmented neural networks with wormhole connections. arXiv preprint arXiv:1701.08718, 2017. Henaff, M., Szlam, A., and LeCun, Y . Recurrent orthogonal networks and long-memory tasks. arXiv preprint arXiv:1602.06662, 2016. Hochreiter, S. Untersuchungen zu dynamischen neuronalen netzen. Diploma, Technische Universit¨at M¨unchen, 91 (1), 1991. Hochreiter, S. and Schmidhuber, J. Long short-term memory. Neural computation, 9(8):1735–1780, 1997. Hochreiter, S., Bengio, Y ., Frasconi, P., Schmidhuber, J., et al. Gradient ﬂow in recurrent nets: the difﬁculty of learning long-term dependencies, 2001. Hung, C.-C., Lillicrap, T., Abramson, J., Wu, Y ., Mirza, M., Carnevale, F., Ahuja, A., and Wayne, G. Optimizing agent behavior over long time scales by transporting value. arXiv preprint arXiv:1810.06721, 2018.Improving the Gating Mechanism of Recurrent Neural Networks Jang, E., Gu, S., and Poole, B. Categorical reparam- eterization with Gumbel-softmax. arXiv preprint arXiv:1611.01144, 2016. Jozefowicz, R., Zaremba, W., and Sutskever, I. An empirical exploration of recurrent network architectures. In International Conference on Machine Learning , pp. 2342–2350, 2015. Kapturowski, S., Ostrovski, G., Quan, J., Munos, R., and Dabney, W. Recurrent experience replay in distributed reinforcement learning. In The International Conference on Learning Representations (ICLR), 2018. Kingma, D. P. and Ba, J. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014. Koˇcisk`y, T., Schwarz, J., Blunsom, P., Dyer, C., Hermann, K. M., Melis, G., and Grefenstette, E. The NarrativeQA reading comprehension challenge. Transactions of the Association for Computational Linguistics , 6:317–328, 2018. Koutnik, J., Greff, K., Gomez, F., and Schmidhuber, J. A clockwork rnn. arXiv preprint arXiv:1402.3511, 2014. Krueger, D., Maharaj, T., Kram´ar, J., Pezeshki, M., Ballas, N., Ke, N. R., Goyal, A., Bengio, Y ., Courville, A., and Pal, C. Zoneout: Regularizing RNNs by randomly preserving hid- den activations. arXiv preprint arXiv:1606.01305, 2016. Le, Q. V ., Jaitly, N., and Hinton, G. E. A simple way to initialize recurrent networks of rectiﬁed linear units.arXiv preprint arXiv:1504.00941, 2015. Li, S., Li, W., Cook, C., Zhu, C., and Gao, Y . Independently recurrent neural network (IndRNN): Building a longer and deeper RNN. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 5457–5466, 2018a. Li, Z., He, D., Tian, F., Chen, W., Qin, T., Wang, L., and Liu, T.-Y . Towards binary-valued gates for robust LSTM training. arXiv preprint arXiv:1806.02988, 2018b. Maddison, C. J., Mnih, A., and Teh, Y . W. The concrete distribution: A continuous relaxation of discrete random variables. arXiv preprint arXiv:1611.00712, 2016. Melis, G., Dyer, C., and Blunsom, P. On the state of the art of evaluation in neural language models.arXiv preprint arXiv:1707.05589, 2017. Merity, S. Single headed attention rnn: Stop thinking with your head. arXiv preprint arXiv:1911.11423, 2019. Merity, S., Xiong, C., Bradbury, J., and Socher, R. Pointer sentinel mixture models. arXiv preprint arXiv:1609.07843, 2016. Mnih, V ., Badia, A. P., Mirza, M., Graves, A., Lillicrap, T., Harley, T., Silver, D., and Kavukcuoglu, K. Asynchronous methods for deep reinforcement learning. InInternational conference on machine learning, pp. 1928–1937, 2016. Oh, J., Chockalingam, V ., Singh, S., and Lee, H. Control of memory, active perception, and action in Minecraft.arXiv preprint arXiv:1605.09128, 2016. Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., and Sutskever, I. Language models are unsupervised multitask learners. OpenAI Blog, 1(8), 2019. Rae, J. W., Dyer, C., Dayan, P., and Lillicrap, T. P. Fast parametric learning with activation memorization.arXiv preprint arXiv:1803.10049, 2018. Santoro, A., Faulkner, R., Raposo, D., Rae, J., Chrzanowski, M., Weber, T., Wierstra, D., Vinyals, O., Pascanu, R., and Lillicrap, T. Relational recurrent neural networks. In Advances in Neural Information Processing Systems, pp. 7299–7310, 2018. Shen, Y ., Tan, S., Sordoni, A., and Courville, A. Ordered neurons: Integrating tree structures into recurrent neural networks. arXiv preprint arXiv:1810.09536, 2018. Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. Dropout: a simple way to prevent neural networks from overﬁtting. The journal of machine learning research, 15(1):1929–1958, 2014. Tallec, C. and Ollivier, Y . Can recurrent neural networks warp time? arXiv preprint arXiv:1804.11188, 2018. Trinh, T. H., Dai, A. M., Luong, M.-T., and Le, Q. V . Learning longer-term dependencies in RNNs with auxiliary losses. arXiv preprint arXiv:1803.00144, 2018. van der Westhuizen, J. and Lasenby, J. The unreason- able effectiveness of the forget gate. arXiv preprint arXiv:1804.04849, 2018. Wayne, G., Hung, C.-C., Amos, D., Mirza, M., Ahuja, A., Grabska-Barwinska, A., Rae, J., Mirowski, P., Leibo, J. Z., Santoro, A., et al. Unsupervised predictive memory in a goal-directed agent. arXiv preprint arXiv:1803.10760, 2018. Weston, J., Chopra, S., and Bordes, A. Memory networks. arXiv preprint arXiv:1410.3916, 2014. Zaremba, W. and Sutskever, I. Learning to execute. arXiv preprint arXiv:1410.4615, 2014. Zilly, J. G., Srivastava, R. K., Koutn´ık, J., and Schmidhuber, J. Recurrent highway networks. InProceedings of the 34th International Conference on Machine Learning-Volume 70, pp. 4189–4198. JMLR. org, 2017.Improving the Gating Mechanism of Recurrent Neural Networks A. Pseudocode We show how the gated update in a typical LSTM implementation can be easily replaced by UR- gates. The following snippets show pseudocode for the the gated state updates for a vanilla LSTM model (top) and UR-LSTM (bottom). forget_bias = 1.0 # hyperparameter ... f, i, u, o = Linear(x, prev_hidden) f_ = sigmoid(f + forget_bias) i_ = sigmoid(i) next_cell = f_ * prev_cell + i_ * tanh(u) next_hidden = sigmoid(o) * tanh(next_cell) Listing 1: LSTM # Initialization u = np.random.uniform(low=1/hidden_size, high=1-1/hidden_size, size=hidden_size) forget_bias = -np.log(1/u-1) ... # Recurrent update f, r, u, o = Linear(x, prev_hidden) f_ = sigmoid(f + forget_bias) r_ = sigmoid(r - forget_bias) g = 2*r_*f_ + (1-2*r_)*f_**2 next_cell = g * prev_cell + (1-g) * tanh(u) next_hidden = sigmoid(o) * tanh(next_cell) Listing 2: UR-LSTM B. Further discussion on related methods Section 4 brieﬂy introduced chrono initialization (Tallec & Ollivier, 2018) and the ON-LSTM (Shen et al., 2018), closely related methods that modify the gating mechanism of LSTMs. We provide more detailed discussion on these in Sec- tions B.3 and B.4 respectively. Section B.1 has a more thor- ough overview of related work on recurrent neural networks that address long-term dependencies or saturating gates. B.1. Related Work Several methods exist for addressing gate saturation or allow- ing more binary activations. Gulcehre et al. (2016) proposed to use piece-wise linear functions with noise in order to allow the gates to operate in saturated regimes. Li et al. (2018b) in- stead use the Gumbel trick (Maddison et al., 2016; Jang et al., 2016), a technique for learning discrete variables within a neu- ral network, to train LSTM models with discrete gates. These stochastic approaches can suffer from issues such as gradient estimation bias, unstable training, and limited expressivity from discrete instead of continuous gates. Additionally they require more involved training protocols with an additional temperature hyperparameter that needs to be tuned explicitly. Alternatively, gates can be removed entirely if strong con- straints are imposed on other parts of the model. (Li et al., 2018a) use diagonal weight matrices and require stacked RNN layers to combine information between hidden units. A long line of work has investigated the use of identity or orthog- onal initializations and constraints on the recurrent weights to control multiplicative gradients unrolled through time (Le et al., 2015; Arjovsky et al., 2016; Henaff et al., 2016). (Chan- dar et al., 2019) proposed another RNN architecture using additive state updates and non-saturating activation func- tions instead of gates. However, although these gate-less techniques can be used to alleviate the vanishing gradient problem with RNNs, unbounded activation functions can cause less stable learning dynamics and exploding gradients. As mentioned, a particular consequence of the inability of gates to approach extrema is that gated recurrent models struggle to capture very long dependencies. These problems have traditionally been addressed by introducing new components to the basic RNN setup. Some techniques include stacking layers in a hierarchy (Chung et al., 2016), adding skip connections and dilations (Koutnik et al., 2014; Chang et al., 2017), using an external memory (Graves et al., 2014; Weston et al., 2014; Wayne et al., 2018; Gulcehre et al., 2017), auxiliary semi-supervision (Trinh et al., 2018), and more. However, these approaches have not been widely adopted over the standard LSTM as they are often specialized for certain tasks, are not as robust, and introduce additional complexity. Recently the transformer model has been successful in many applications areas such as NLP (Radford et al., 2019; Dai et al., 2019). However, recurrent neural net- works are still important and commonly used due their faster inference without the need to maintain the entire sequence in memory. We emphasize that the vast majority of proposed RNN changes are completely orthogonal to the simple gate improvements in this work, and we do not focus on them. A few other recurrent cores that use the basic gated update(1) but use more sophisticated update functions uinclude the GRU, Reconstructive Memory Agent (RMA; Hung et al., 2018), and Relational Memory Core (RMC; Santoro et al., 2018), which we consider in our experiments. B.2. Effect of proposed methods on timescales We brieﬂy review the connection between our methods and the effective timescales that gated RNNs capture. Recall that Section 3.2 deﬁnes the characteristic timescale of a neuron with forget activationftas 1/(1−ft), which would be the number of timesteps it takes to decay that neuron by a constant.Improving the Gating Mechanism of Recurrent Neural Networks The fundamental principle of gated RNNs is that the activations of the gates affects the timescales that the model can address; for example, forget gate activations near1.0 are necessary to capture long-term dependencies. Thus, although our methods were deﬁned in terms of acti- vations gt, it is illustrative to reason with their characteristic timescales 1/(1−gt) instead, whence both UGI and reﬁne gate also have clean interpretations. First, UGI is equivalent to initializing the decay period from a particular heavy-tailed distribution, in contrast to standard initialization with a ﬁxed decay period(1−σ(bf))−1. Proposition 1. UGI is equivalent to to sampling the decay period D = 1/(1 −ft) from a distribution with density proportional to P(D = x) ∝ d dx(1 −1/x) = x−2, i.e. a Pareto(α=2) distribution. On the other hand, for any forget gate activation ft with timescale D= 1/(1 −ft), the reﬁne gate ﬁne-tunes it be- tween D=1/(1−f2 t)=1 /(1−ft)(1+ft) and 1/(1−ft)2. Proposition 2. Given a forget gate activation with timescale D, the reﬁne gate creates an effective forget gate with timescale in (D/2,D2). B.3. Chrono Initialization The chrono initialization bf∼log(U([1,Tmax−1])) (14) bi=−bf. (15) was the ﬁrst to explicitly attempt to initialize the activation of gates across a distributional range. It was motivated by matching the gate activations to the desired timescales. They also elucidate the beneﬁts of tying the input and forget gates, leading to the simple trick (15) for approximating tying the gates at initialization, which we borrow for UGI. (We remark that perfect tied initialization can be accomplished by fully tying the linear mapsLf,Li, but (15) is a good approximation.) However, the main drawback of CI is that the initialization distribution is too heavily biased toward large terms. This leads to empirical consequences such as difﬁcult tuning (due to most units starting in the saturation regime, requiring different learning rates) and high sensitivity to the hyperparameter Tmaxthat represents the maximum potential length of dependencies. For example, Tallec & Ollivier (2018) set this parameter according to a different protocol for every task, with values ranging from 8 to 2000. Our experiments used a hyperparameter-free method to initialize Tmax (Section 5), and we found that chrono initialization generally severely over-emphasizes long-term dependencies if Tmaxis not carefully controlled. A different workaround suggested by Tallec & Ollivier (2018) is to sample fromP(T=k)∝ 1 klog2(k+1) and setting bf=log(T). Note that such an initialization would be almost equivalent to sampling the decay period from the distribution with density P(D = x) ∝(xlog2 x)−1 (since the decay period is (1 −f)−1 = 1 + exp(bf)). This parameter-free initialization is thus similar in spirit to the uniform gate initialization (Proposition 1), but from a much heavier-tailed distribution that emphasizes very long-term dependencies. These interpretations suggest that it is plausible to deﬁne a family of Pareto-like distributions from which to draw the initial decay periods from, with this distribution treated as a hyperparameter. However, with no additional prior information on the task, we believe the uniform gate initialization to be the best candidate, as it 1. is a simple distribution with easy implementation, 2. has characteristic timescale distributed as an intermediate balance between the heavy-tailed chrono initialization and sharply decaying standard initialization, and 3. is similar to the ON-LSTM’s cumax activation, in particular matching the initialization distribution of thecumax activation. Table 4 summarizes the decay period distributions at initialization using different activations and initialization strategies. In general, our experimental recommendation for CI is that it can be better than standard initialization or UGI when certain conditions are met (tasks with long dependencies and nearly ﬁxed-length sequences as in Sections 5.1, 5.4) and/or when it can be explicitly tuned (both the hyperparameter Tmax, as well as the learning rate to compensate for almost all units starting in saturation). Otherwise, we recommend UGI or standard initialization. We found no scenarios where it outperformed UR- gates. B.4. ON-LSTM In this section we elaborate on the connection between the mechanism of (Shen et al., 2018) and our methods. We deﬁne the full ON-LSTM and show how its gating mechanisms can be improved. For example, there is a remarkable connection between its master gates and our reﬁne gates – independently of the derivation of reﬁne gates in Section 3.4, we show how a speciﬁc way of ﬁxing the normalization of master gates becomes equivalent to a single reﬁne gate. First, we formally deﬁne the full ON-LSTM. The master gates are acumax-activation gate ˜ft=cumax(L˜f(xt,ht−1)) (16) ˜it=1 −cumax(L˜i(xt,ht−1)). (17) These combine with an independent pair of forget and input gates ft,it, meant to control ﬁne-grained behavior, to create an effective forget/input gate ˆft,ˆitwhich are used to updateImproving the Gating Mechanism of Recurrent Neural Networks Table 4.Distribution of the decay periodD=(1 −f)−1 using different initialization strategies. Initialization method Timescale distribution Constant bias bf=b P(D=x)∝1{x=1+ eb} Chrono initialization (known timescaleTmax) P(D=x)∝1{x∈[2,Tmax]} Chrono initialization (unknown timescale) P(D=x)∝ 1 xlog2x Uniform gate initialization P(D=x)∝1 x2 cumax activation P(D=x)∝1 x2 the state (equation (1) or (5)). ωt= ˜ft◦˜it (18) ˆft=ft◦ωt+( ˜ft−ωt) (19) ˆit=it◦ωt+(˜it−ωt). (20) As mentioned in Section B.1, this model modiﬁes the standard forget/input gates in two main ways, namely ordering the gates via thecumax activation, and supplying an auxiliary set of gates controlling ﬁne-grained behavior. Both of these are important novelties and together allow recurrent models to better capture tree structures. However, the UGI and reﬁne gate can be viewed as improvements over each of these, respectively, demonstrated both theoretically (below) and empirically (Sections 5 and E.3), even on tasks involving hierarchical sequences. Ordered gates Despite having the same parameter count and asymptotic efﬁciency as standard sigmoid gates,cumax gates seem noticeably slower and less stable in practice for large hidden sizes. Additionally, using auxiliary master gates creates additional parameters compared to the basic LSTM. Shen et al. (2018) alleviated both of these problems by deﬁning a downsize operation, whereby neurons are grouped in chunks of sizeC, each of which share the same master gate values. However, this also creates an additional hyperparameter. The speed and stability issues can be ﬁxed by just using the sigmoid non-linearity instead ofcumax. To recover the most important properties of thecumax—activations at multiple timescales—the equivalent sigmoid gate can be initialized so as to match the distribution ofcumax gates at initialization. This is just uniform gate initialization (equation (12)). However, we believe that the cumax activation is still valuable in many situations if speed and instability are not issues. These include when the hidden size is small, when extremal gate activations are desired, or when ordering needs to be strictly enforced to induce explicit hierarchical structure. For example, Section (5.1) shows that they can solve hard memory tasks by themselves. Master gates We observe that the magnitudes of master gates are suboptimally normalized. A nice interpretation of gated recurrent models shows that they are a discretization of a continuous differential equation. This leads to the leaky RNN model ht+1 =(1 −α)ht+αut, where utis the update to the model such astanh(Wxxt+Whht+b). Learning α as a function of the current time step leads to the simplest gated recurrent model5 ft=σ(Lf(xt,ht−1)) ut=tanh(Lu(xt,ht−1)) ht=ftht−1+(1−ft)ut. Tallec & Ollivier (2018) show that this exactly corresponds to the discretization of a differential equation that is invariant to time warpings and time rescalings. In the context of the LSTM, this interpretation requires the values of the forget and input gates to be tied so that ft+ it = 1. This weight-tying is often enforced, for example in the most popular LSTM variant, the GRU (Cho et al., 2014), or our UR- gates. In a large-scale LSTM architecture search, it was found that removing the input gate was not signiﬁcantly detrimental (Greff et al., 2016). However, the ON-LSTM does not satisfy this conventional wisdom that the input and forget gates should sum to close to 1. Proposition 3. At initialization, the expected value of the average effective forget gate activationˆftis 5/6. Let us consider the sum of the effective forget and input gates at initialization. Adding equations(19) and (20) yields ˆft+ˆit=(ft+it)◦ωt+( ˜ft+˜it−2ωt) = ˜ft+˜it+(ft+it−2)◦ωt. Note that the master gates (16), (17) sum 1 in expectation at initialization, as do the original forget and input gates. Looking at individual units in the ordered master gates, we 5In the literature, this is called the JANET (van der Westhuizen & Lasenby, 2018), which is also equivalent to the GRU without a reset gate (Chung et al., 2014), or a recurrent highway network with depth L=1 (Zilly et al., 2017).Improving the Gating Mechanism of Recurrent Neural Networks have E ˆf(j) = j n,Eˆi(j) =1 −j n. Thus the above simpliﬁes to E[ ˆft+ˆit]=1 −Eωt E[ ˆf(j) t +ˆi(j) t ]=1 −j n(1−j n) E [ Ej∈[n] ˆf(j) t +ˆi(j) t ] ≈1− ∫ 1 0 xdx+ ∫ 1 0 x2dx = 5 6. The gate normalization can be ﬁxed by re-scaling equa- tions (19) and (20). It turns out that tying the master gates and re-scaling is exactly equivalent to the mechanism of a reﬁne gate. In this equivalence, the role of the master and forget gates of the ON-LSTM are played by our forget and reﬁne gate respectively. Proposition 4. Suppose the master gates ˜ft,˜itare tied and the equations (19)-(20) deﬁning the effective gates ˆft,ˆitare rescaled such as to ensure E[ ˆft+ˆit] = 1at initialization. The resulting gate mechanism is exactly equivalent to that of the reﬁne gate. Consider the following set of equations where the master gates are tied ( ˜ft + ˜it = 1,ft + it = 1) and (19)-(20) are modiﬁed with an extra coefﬁcient (rescaling in bold): ˜it=1 −˜ft (21) ωt= ˜ft·˜it (22) ˆft=2·ft·ωt+( ˜ft−ωt) (23) ˆit=2·it·ωt+(˜it−ωt) (24) Now we have ˆft+ˆit= ˜ft+˜it+2(ft+it−1)·ωt =1+2( ft+it−1)·ωt which has the correct scaling, i.e. E[ ˆft + ˆit] = 1 at initialization assuming thatE[ft+it]=1 at initialization. But (23) can be rewritten as follows: ˆf=2 ·f·ω+( ˜f−ω) =2 ·f·˜f·(1−˜f)+( ˜f−˜f·(1−˜f)) =2f·˜f−2f·˜f2+ ˜f2 =f·2 ˜f−f·˜f2−f·˜f2+ ˜f2 =f·(1−(1−˜f))2+(1−f)·˜f2. This is equivalent to the reﬁne gate, where the master gate plays the role of the forget gate and the forget gate plays the role of the reﬁne gate. It can be shown that in this case, the effective input gateˆit (24) is also deﬁned through a reﬁne gate mechanism, where˜it=1 −˜ftis reﬁned by it: ˆi=i·(1−(1−˜i))2+(1−i)·˜i2. Based on our experimental ﬁndings, in general we would recommend the reﬁne gate in place of the master gate. B.5. Gate ablation details For clarity, we formally deﬁne the gate ablations considered which mix and match different gate components. We remark that other combinations are possible, for example combining CI with either auxiliary gate type, which would lead to CR- or CM- gates. Alternatively, the master or reﬁne gates could be deﬁned using different activation and initial- ization strategies. We chose not to consider these methods due to lack of interpretation and theoretical soundness. O- This ablation uses the cumax activation to order the forget/input gates and has no auxiliary gates. ft=cumax(Lf(xt,ht−1)) (25) it=1 −cumax(Li(xt,ht−1)). (26) We note that one difﬁculty with this in practice is the reliance on the expensivecumax, and hypothesize that this is perhaps the ON-LSTM’s original motivation for the second set of gates combined with downsizing. UM- This variant of the ON-LSTM ablates the cumax operation on the master gates, replacing it with a sigmoid activation initialized with UGI. Equations (16), (17) are replaced with u=U(0,1) (27) bf=σ−1(u) (28) ˜ft=σ(L˜f(xt,ht−1)+bf) (29) ˜it=σ(L˜i(xt,ht−1)−bf) (30) Equations (18)-(20) are then used to deﬁne effective gates ˆft,ˆitwhich are used in the gated update (1) or (5). OR- This ablation combines ordered main gates with an auxilliary reﬁne gate. ˜ft=cumax(L˜f(xt,ht−1)+bf) (31) rt=σ(Lr(xt,ht−1)+br) (32) gt=rt·(1−(1−ft)2)+(1 −rt)·f2 t (33) it=1 −gt (34) gt,itare used as the effective forget and input gates.Improving the Gating Mechanism of Recurrent Neural Networks C. Analysis Details The gradient analysis in Figure 3 was constructed as follows. Let f,r,g be the forget, reﬁne, and effective gates g=2rf+(1−2r)f2. Letting x,ybe the pre-activations of the sigmoids onfand r, the gradient ofgcan be calculated as ∇xg=2rf(1−f)+(1 −2r)(2f)(f(1−f)) =2f(1−f)[r+(1−2r)f] ∇yg=2fr(1−r)+(−2f2)r(1−r)=2 fr(1−r)(1−f) ∥∇g∥2 =[2f(1−f)]2[ (r+f−2fr)2+r2(1−r)2] . Substituting the relation r= g−f2 2f(1−f), this reduces to the Equation 35, ∥∇g∥2 =((g−f2)(1−2f)+2f2(1−f))2 +(g−f2)2 ( 1− g−f2 2f(1−f) )2 . (35) Given the constraintf2 ≤g≤1−(1−f)2, this function can be minimized and maximized in terms of gto produce the upper and lower bounds in Figure 3b. This was performed numerically. D. Experimental Details To normalize the number of parameters used for models using master gates, i.e. the OM- and UM- gating mechanisms, we used a downsize factor on the main gates (see Sec- tion B.4). This was set toC=16 for the synthetic and image classiﬁcation tasks, and C= 32for the language modeling and program execution tasks which used larger hidden sizes. D.1. Synthetic Tasks All models consisted of single layer LSTMs with 256 hidden units, trained with the Adam optimizer (Kingma & Ba, 2014) with learning rate 1e-3. Gradients were clipped at1.0. The training data consisted of randomly generated sequences for every minibatch rather than iterating through a ﬁxed dataset. Each method ran 3 seeds, with the same training data for every method. Our version of the Copy task is a very minor variant of other versions reported in the literature, with the main difference being that the loss is considered only over the last 10 output tokens which need to be memorized. This normalizes the loss so that losses approaching0 indicate true progress. In contrast, this task is usually deﬁned with the model being required to output a dummy token at the ﬁrstN+10 steps, meaning it can be hard to evaluate performance since low average losses simply indicate that the model learns to output the dummy token. For Figure 4, the log loss curves show the median of 3 seeds, and the error bars indicate 60% conﬁdence. For Figure 5, each histogram represents the distribution of forget gate values of the hidden units (of which there are 256). The values are created by averaging units over time and samples, i.e., reducing a minibatch of forget gate activations of shape (batch size, sequence length, hidden size)over the ﬁrst two diensions, to produce the average activation value for every unit. D.2. Image Classiﬁcation All models used a single hidden layer recurrent network (LSTM or GRU). Inputsxto the model were given in batches as a sequence of shape (sequence length, num channels), (e.g. (1024,3) for CIFAR-10), by ﬂattening the input image left-to-right, top-to-bottom. The outputs of the model of shape (sequence length, hidden size) were processed independently with a single ReLU hidden layer of size 256 before the ﬁnal fully-connected layer outputting softmax logits. All training was performed with the Adam optimizer, batch size 50, and gradients clipped at 1.0. MNIST trained for 150 epochs, CIFAR-10 used 100 epochs over the training set. Table 5 All models (LSTM and GRU) used hidden state size 512. Learning rate swept in {2e−4,5e−4,1e−3,2e−3}with three seeds each. Table 5 reports the highest validation score found. The GRU model swept over learning rates{2e−4,5e−4}; all methods were unstable at higher learning rates. Figure 6 shows the median validation accuracy with quartiles (25/75% conﬁdence intervals) over the seeds, for the best-performing stable learning rate (i.e. the one with highest average validation score on the ﬁnal epoch). This was generally 5e−4 or 1e−3, with reﬁne gate variants tending to allow higher learning rates. Table 2 The UR-LSTM and UR-GRU used 1024 hidden units for the sequential and permuted MNIST task, and 2048 hidden units for the sequential CIFAR task. The vanilla LSTM baseline used 512 hidden units for MNIST and 1024 for CIFAR. Larger hidden sizes were found to be unstable. Zoneout parameters were ﬁxed to reasonable default settings based on Krueger et al. (2016), which arezc=0.5,zh=0.05 for LSTM and z= 0.1 for GRU. When zoneout was used, standard Dropout (Srivastava et al., 2014) with probabilityImproving the Gating Mechanism of Recurrent Neural Networks Table 5.Gate ablations on pixel-by-pixel image classiﬁcation. Validation accuracies on pixel image classiﬁcation. Asterisks denote divergent runs at the learning rate the best validation score was found at. Gating Method - C- O- U- R- OM- OR- UM- UR- pMNIST 94.77∗∗ 94.69 96 .17 96 .05 95 .84∗ 95.98 96 .40 95 .50 96 .43 sCIFAR 63.24∗∗ 65.60 67 .78 67 .63 71 .85∗ 67.73∗ 70.41 67 .29∗ 71.05 sCIFAR (GRU) 71.30∗ 64.61 69 .81∗∗ 70.10 70 .74∗ 70.20∗ 71.40∗∗ 69.17∗ 71.04 0.5 was also applied to the output classiﬁcation hidden layer. D.3. Language Modeling Hyperparameters are taken from Rae et al. (2018) tuned for the vanilla LSTM, which consist of (chosen parameter bolded out of sweep): {1, 2}LSTM layer, {0.0,0.1,0.2,0.3}embedding dropout, {yes,no}layer norm, and {shared,not shared}input/output embedding parameters. Our only divergence is using a hidden size of 3072 instead of 2048, which we found improved the performance of the vanilla LSTM. Training was performed with Adam at learning rate 1e-3, gradients clipped to 0.1, sequence length 128, and batch size128 on TPU. The LSTM state was reset between article boundaries. Figure 11 shows smoothed validation perplexity curves show- ing the 95% conﬁdence intervals over the last 1% of data. 0 1e10 2e10 3e10 4e10 Episode Steps 0 2.5 5 7.5 10Reward Core C-LSTM LSTM U-LSTM UR-LSTM (a) Passive Match without Distractor Rewards 0 1e10 2e10 3e10 4e10 Episode Steps 3 3.5 4 4.5 5 5.5Reward Core C-LSTM LSTM U-LSTM UR-LSTM (b) Active Match without Distractor Rewards Figure 9.Performance on Reinforcement Learning Tasks that Require Memory. We evaluated the image matching tasks from Hung et al. (2018), which test memorization and credit assign- ment, using an A3C agent (Mnih et al., 2016) with an LSTM policy core. We observe that general trends from the synthetic tasks (Sec- tion (5.1)) transfer to this reinforcement learning setting. Reinforcement Learning The Active Match and Passive Match tasks were borrowed from Hung et al. (2018) with the same settings. For Figures 9 and 13, the discount factor in the environment was set toγ=.96. For Figure 10, the discount factor was γ=.998. Figure 13 corresponds to the full Active 0 1e10 2e10 3e10 4e10 Episode Steps 4 6 8Reward Core C-LSTM LSTM U-LSTM UR-LSTM (a) Active Match with Distractor Rewards - LSTM 0 0.25e10 0.50e10 0.75e10 1e10 1.25e10 Episode Steps 4 6 8 10Reward Core C-RMA RMA U-RMA UR-RMA (b) Active Match with Distractor Rewards - RMA Figure 10.The addition of distractor rewards changes the task and relative performance of different gating mechanisms. For both LSTM and RMA recurrent cores, the UR- gates still perform best. Match task in Hung et al. (2018), while Figure 10 is their version with small distractor rewards where the apples in the distractor phase give1 instead of 5 reward. Figure 8 used 5 seeds per method. D.4. Program Evaluation Protocol was taken from Santoro et al. (2018) with minor changes to the hyperparameter search. All models were trained with the Adam optimizer, theMix curriculum strategy from Zaremba & Sutskever (2014), and batch size128. RMC: The RMC models used a ﬁxed memory slot size of 512 and swept over {2,4}memories and {2,4}attention heads for a total memory size of1024 or 2048. They were trained for 2e5 iterations. LSTM: Instead of two-layer LSTMs with sweeps over skip connections and output concatenation, single-layer LSTMs of size 1024 or 2048 were used. Learning rate was swept in {5e-4, 1e-3}, and models were trained for 5e5 iterations. Note that training was still faster than the RMC models despite the greater number of iterations.Improving the Gating Mechanism of Recurrent Neural Networks D.5. Additional Details Implementation Details The inverse sigmoid func- tion (12) can be unstable if the input is too close to {0,1}. Uniform gate initialization was instead implemented by sampling from the distribution U[1/d,1 −1/d] instead of U[0,1], where dis the hidden size, to avoid any potential numerical edge cases. This choice is justiﬁed by the fact that with perfect uniform sampling, the expected smallest and largest samples would be1/(d+1) and 1−1/(d+1). For distributional initialization strategies, a trainable bias vector was sampled independently from the chosen distribution (i.e. equation(14) or (12)) and added/subtracted to the forget and input gate ((2)-(3)) before the non-linearity. Additionally, each linear model such asWxfxt+Whfht−1 had its own trainable bias vector, effectively doubling the learning rate on the pre-activation bias terms on the forget and input gates. This was an artifact of implementation and not intended to affect performance. The reﬁne gate update equation (10) can instead be implemented as gt=rt·(1−(1−ft)2)+(1 −rt)·f2 t =2rt·ft+(1−2rt)·f2 t Permuted image classiﬁcation In an effort to standardize the permutation used in the Permuted MNIST benchmark, we use a particular deterministic permutation rather than a random one. After ﬂattening the input image into a one- dimensional sequence, we apply thebit reversalpermutation. This permutation sends the index i to the index j such that j’s binary representation is the reverse of i’s binary representation. The intuition is that if two indices i,i′are close, they must differ in their lower-order bits. Then the bit- reversed indices will be far apart. Therefore the bit-reversal permutation destroys spatial and temporal locality, which is desirable for these sequence classiﬁcation tasks meant to test long-range dependencies rather than local structure. def bitreversal_po2(n): m = int(math.log(n) / math.log(2)) perm = np.arange(n).reshape(n, 1) for i in range(m): n1 = perm.shape[0] // 2 perm = np.hstack((perm[:n1], perm[n1:])) return perm.squeeze(0) def bitreversal_permutation(n): m = int(math.ceil(math.log(n) / math.log(2))) N = 1 << m perm = bitreversal_po2(N) return np.extract(perm < n, perm) Listing 3: Bit-reversal permutation for permuted MNIST. E. Additional Experiments E.1. Synthetic Forgetting Figure 5 on the Copy task demonstrates that extremal gate activations are necessary to solve the task, and initializing the activations near1.0 is helpful. This raises the question: what happens if the initialization distribution does not match the task at hand; could the gates learn back to a more moderate regime? We point out that such a phenomenon could occur non-pathologically on more complex setups, such as a scenario where a model trains to remember on a Copy-like task and then needs to “unlearn” as part of a meta-learning or continual learning setup. Here, we consider such a synthetic scenario and experimen- tally show that the addition of a reﬁne gate helps models train much faster while in a saturated regime with extremal activa- tions. We also point to the poor performance of C- outside of synthetic memory tasks when using our high hyperparameter- free initialization as more evidence that it is very difﬁcult for standard gates to unlearn undesired saturated behavior. For this experiment, we initialize the biases of the gates extremely high (effective forget activation≈σ(6). We then consider the Adding task (Section 5.1) of length 500, hidden size 64, learning rate 1e-4. The R-LSTM is able to solve the task, while the LSTM is stuck after 1e4 iterations. 0 100000 200000 300000 400000 500000 Iteration 3.52 3.54 3.56 3.58 3.60Log Perplexity Method C-LSTM C11-LSTM C8-LSTM LSTM OM-LSTM U-LSTM UR-LSTM Figure 11.Validation learning curves, illustrating training speed and generalization (i.e. overﬁtting) behavior. E.2. Reinforcement Learning Figures 9 and 10 evaluated our gating methods with the LSTM and RMA models on the Passive Match and Active Match tasks, with and without distractors. We additionally ran the agents on an even harder version of the Active Match task with larger distractor rewards (the full Active Match from Hung et al. (2018)). Learning curves are shown in Figure 13. Similarly to the other results, the UR- gated core is noticeably better than the others. For the DNC model, it is the only one that performs better than random chance.Improving the Gating Mechanism of Recurrent Neural Networks 0.90 0.92 0.94 0.96 0.98 1.00 0 2 4 6 8 10 12 (a) R-LSTM 0.955 0.960 0.965 0.970 0.975 0.980 0.985 0.990 0.995 1.000 0 5 10 15 20 (b) LSTM Figure 12.Distribution of forget gate activations after extremal ini- tialization, and training on the Adding task. The UR-LSTM is able to learn much faster in this saturated gate regime while the LSTM does not solve the task. The smallest forget unit for the UR-LSTM after training has characteristic timescale over an order of magnitude smaller than that of the LSTM. 0 1e10 2e10 3e10 4e10 Episode Steps 3 3.5 4 4.5 5 Reward Core C-LSTM LSTM U-LSTM UR-LSTM 0 1e10 2e10 3e10 4e10 Episode Steps 3.3 3.6 3.9Reward Core C-LSTM+Mem LSTM+Mem U-LSTM+Mem URU-LSTM+Mem Figure 13.The full Active Match task with large distractor rewards, using agents with LSTM or DNC recurrent cores. E.3. Program Execution The Learning to Execute (Zaremba & Sutskever, 2014) dataset consists of algorithmic snippets from a programming language of pseudo-code. An input is a program from this language presented one character at a time, and the target output is a numeric sequence of characters representing the execution output of the program. There are three categories of tasks: Addition, Control, and Program, with distinctive types of input programs. We use the most difﬁcult setting from Zaremba & Sutskever (2014), which uses the param- eters nesting=4, length=9, referring to the nesting depth of control structure and base length of numeric literals, respectively. Examples of input programs are shown in previ- ous works (Zaremba & Sutskever, 2014; Santoro et al., 2018). We are interested in this task for several reasons. First, we are interested in comparing against the C- and OM- gate methods, because • The maximum sequence length is fairly long (several hundred tokens), meaning our Tmax heuristic for C- gates is within the right order of magnitude of dependency lengths. • The task has highly variable sequence lengths, wherein the standard training procedure randomly samples inputs of varying lengths (called the ”Mix” curriculum in Zaremba & Sutskever (2014)). Additionally, the Control and Program tasks contain complex control ﬂow and nested structure. They are thus a measure of a sequence model’s ability to model dependencies of differing lengths, as well as hierarchical information. Thus we are interested in comparing the effects of UGI methods, as well as the full OM- gates which are designed for hierarchical structures (Shen et al., 2018). Finally, this task has prior work using a different type of recurrent core, the Relational Memory Core (RMC), that we also use as a baseline to evaluate our gates on different models (Santoro et al., 2018). Both the LSTM and RMC were found to outperform other recurrent baselines such as the Differential Neural Computer (DNC) and EntNet. Training curves are shown in Figure 14, which plots the median accuracy with conﬁdence intervals. We point out a few observations. First, despite having a Tmax value on the right order of magnitude, the C- gated methods have very poor performance across the board, reafﬁrming the chrono initialization’s high sensitivity to this hyperparameter. Second, the U-LSTM and U-RMC are the best methods on the Addition task. Additionally, the UR-RMC vs. RMC on Addition is one of the very few tasks we have found where a generic substitution of the UR- gate does not improve on the basic gate. We have not investigated what property of this task caused these phenomena. Aside from the U-LSTM on addition, the UR-LSTM outperforms all other LSTM cores. The UR-RMC is also the best core on both Control and Program, the tasks involving hierarchical inputs and longer dependencies. For the most part, the improved mechanisms of the UR- gates seem to transfer to this recurrent core as well. We highlight that this is not true of similar gating mechanisms. In particular, the OM- LSTM, which is supposed to model hierarchies, has good performance on Control and Program as expected (although not better than the UR-LSTM). However, the OM- gates’ performance plummets when transferred to the RMC core. Interestingly, the -LSTM cores are consistently better than the -RMC versions, contrary to previous ﬁndings on easier versions of this task using similar protocol and hyperparam- eters (Santoro et al., 2018). We did not explore different hyperparameter regimes on this more difﬁcult setting.Improving the Gating Mechanism of Recurrent Neural Networks 0 2.5e5 5.0e5 7.5e5 1.0e6 0.3 0.4 0.5Accuracy Addition Method -LSTM C-LSTM OM-LSTM U-LSTM UR-LSTM 0 2.5e5 5.0e5 7.5e5 1.0e6 0.25 0.50 0.75 1 Control 0 2.5e5 5.0e5 7.5e5 1.0e6 Iteration 0.2 0.3 0.4 0.5 Program (a) LSTM - Learning to Execute (nesting=4, length=9) 0 1.0e5 2.0e5 3.0e5 4.0e5 5.0e5 0.3 0.4 0.5 0.6Accuracy Addition Method -RMC C-RMC OM-RMC U-RMC UR-RMC 0 1.0e5 2.0e5 3.0e5 4.0e5 5.0e5 0.2 0.4 0.6 Control 0 1.0e5 2.0e5 3.0e5 4.0e5 5.0e5 Iteration 0.2 0.3 0.4 Program (b) RMC - Learning to Execute (nesting=4, length=9) Figure 14.Program Execution evaluation accuracies.",
      "meta_data": {
        "arxiv_id": "1910.09890v2",
        "authors": [
          "Albert Gu",
          "Caglar Gulcehre",
          "Tom Le Paine",
          "Matt Hoffman",
          "Razvan Pascanu"
        ],
        "published_date": "2019-10-22T11:03:00Z",
        "pdf_url": "https://arxiv.org/pdf/1910.09890v2.pdf"
      },
      "llm_extracted_info": {
        "main_contributions": "Introduces two simple, hyper-parameter–free improvements to the standard gating of recurrent neural networks: (1) the “refine gate” – an auxiliary sigmoid gate that additively adjusts a main gate so that effective gate values can reach near-0 or near-1 without vanishing gradients; (2) “uniform gate initialization” – sampling forget-gate biases so that initial activations are uniformly distributed in (0,1), giving a wide spread of temporal scales. Used together (UR gating) these changes are drop-in for any gated RNN (e.g., LSTM, GRU, RMC), add no parameters, and consistently outperform standard gates, chrono initialization, and Ordered-Neuron gates on tasks requiring long-term memory.",
        "methodology": "Mathematically derive an additive modulation g = f + f(1−f)(2r−1) where f is the original gate and r is the refine gate, ensuring bounded outputs and larger gradients in saturated regions. Tie input gate to 1−g to keep parameter count unchanged. For initialization, draw forget-gate biases from σ⁻¹(U[ϵ,1−ϵ]) so initial decay periods follow a Pareto(α=2) distribution. Provide theoretical analysis of gradient magnitude and relation to chrono and ON-LSTM mechanisms. Implement these gates in LSTM, GRU, and memory-augmented cores; perform extensive ablations (standard, chrono, cumax, master vs refine) to isolate effects.",
        "experimental_setup": "Benchmarks: (1) Synthetic memory – Copy (length 500) and Adding (length 2000) tasks with single-layer 256-unit RNNs trained by Adam. (2) Pixel-by-pixel image classification – sequential MNIST, permuted MNIST (bit-reversal permutation), sequential CIFAR-10; single-layer 512/1024-unit RNNs, LR sweeps, Zoneout variants. (3) Language modeling – WikiText-103 using 2-layer 3072-unit LSTM with Rae et al. (2018) hyper-parameters, TPU training. (4) Reinforcement learning – Passive Match and Active Match 3-D navigation tasks (with and without distractor rewards) using A3C agents whose policy core is LSTM, RMA, or DNC. (5) Program execution – Learning-to-Execute dataset (nesting 4, length 9) with LSTM and Relational Memory Core. Metrics: cross-entropy or MSE losses for synthetic tasks, classification accuracy, perplexity for LM, episodic return for RL, execution accuracy; results reported over multiple random seeds with confidence intervals.",
        "limitations": "Analysis and experiments focus on unidirectional RNNs; bidirectional or transformer-style architectures not tested. Benefits decline when extremely task-specific gate distributions are required (needs manual chrono tuning). Cumax ordering sometimes faster but refine gate still limited by sigmoid non-linearity. RL and program tasks use relatively small environments; scalability to very large-scale or real-time systems remains unverified. No formal proof of convergence or optimality; relies on empirical tuning of learning rates and gradient clipping.",
        "future_research_directions": "1) Apply refine/UGI principles to other gated modules (e.g., attention, highway, transformer gating). 2) Explore adaptive or learned initialization distributions instead of fixed uniform. 3) Combine with orthogonal/identity recurrent weight schemes for additional stability. 4) Investigate bidirectional and encoder-decoder settings, especially in speech and translation. 5) Hardware-aware implementations to exploit the minimal-overhead gates for low-latency inference on edge devices."
      }
    },
    {
      "title": "Active Test-Time Adaptation: Theoretical Analyses and An Algorithm",
      "abstract": "Test-time adaptation (TTA) addresses distribution shifts for streaming test\ndata in unsupervised settings. Currently, most TTA methods can only deal with\nminor shifts and rely heavily on heuristic and empirical studies.\n  To advance TTA under domain shifts, we propose the novel problem setting of\nactive test-time adaptation (ATTA) that integrates active learning within the\nfully TTA setting.\n  We provide a learning theory analysis, demonstrating that incorporating\nlimited labeled test instances enhances overall performances across test\ndomains with a theoretical guarantee. We also present a sample entropy\nbalancing for implementing ATTA while avoiding catastrophic forgetting (CF). We\nintroduce a simple yet effective ATTA algorithm, known as SimATTA, using\nreal-time sample selection techniques. Extensive experimental results confirm\nconsistency with our theoretical analyses and show that the proposed ATTA\nmethod yields substantial performance improvements over TTA methods while\nmaintaining efficiency and shares similar effectiveness to the more demanding\nactive domain adaptation (ADA) methods. Our code is available at\nhttps://github.com/divelab/ATTA",
      "full_text": "Published as a conference paper at ICLR 2024 ACTIVE TEST-TIME ADAPTATION : T HEORETICAL ANALYSES AND AN ALGORITHM Shurui Gui∗ Texas A&M University College Station, TX 77843 shurui.gui@tamu.edu Xiner Li* Texas A&M University College Station, TX 77843 lxe@tamu.edu Shuiwang Ji Texas A&M University College Station, TX 77843 sji@tamu.edu ABSTRACT Test-time adaptation (TTA) addresses distribution shifts for streaming test data in unsupervised settings. Currently, most TTA methods can only deal with minor shifts and rely heavily on heuristic and empirical studies. To advance TTA under domain shifts, we propose the novel problem setting of active test-time adaptation (ATTA) that integrates active learning within the fully TTA setting. We provide a learning theory analysis, demonstrating that incorporating limited labeled test instances enhances overall performances across test domains with a theoretical guarantee. We also present a sample entropy balancing for implementing ATTA while avoiding catastrophic forgetting (CF). We introduce a simple yet effective ATTA algorithm, known as SimATTA, using real-time sample selection techniques. Extensive experimental results confirm consistency with our theoretical analyses and show that the proposed ATTA method yields substantial performance improvements over TTA methods while maintaining efficiency and shares similar effectiveness to the more demanding active domain adaptation (ADA) methods. Our code is available at https://github.com/divelab/ATTA. 1 I NTRODUCTION Deep learning has achieved remarkable success across various fields, attaining high accuracy in numerous applications (Krizhevsky et al., 2017; Simonyan and Zisserman, 2014). Nonetheless, When training and test data follow distinct distributions, models often experience significant performance degradation during test. This phenomenon, known as the distribution shift or out-of-distribution (OOD) problem, is extensively studied within the context of both domain generalization (DG) (Gulra- jani and Lopez-Paz, 2020; Koh et al., 2021; Gui et al., 2022) and domain adaptation (DA) (Ganin et al., 2016; Sun and Saenko, 2016). While these studies involve intensive training of models with considerable generalization abilities towards target domains, they overlook an important application property; namely, continuous adaptivity to real-time streaming data under privacy, resource, and efficiency constraints. This gap leads to the emergence of test-time adaptation (TTA) tasks, targeting on-the-fly adaptation to continuous new domains during the test phase or application deployment. The study of TTA encompasses two main categories; namely test-time training (TTT) methods (Sun et al., 2020; Liu et al., 2021c) and fully test-time adaptation (FTTA) (Niu et al., 2023; Wang et al., 2021). The TTT pipeline incorporates retraining on the source data, whereas FTTA methods adapt arbitrary pre-trained models to the given test mini-batch by conducting entropy minimization, without access to the source data. Nevertheless, most TTA methods can only handle corrupted distribution shifts (Hendrycks and Dietterich, 2019b) (e.g., Gaussian noise,) and rely heavily on human intuition or empirical studies. To bridge this gap, our paper focuses on tackling significant domain distribution shifts in real time with theoretical insights. We investigate FTTA, which is more general and adaptable than TTT, particularly under data ac- cessibility, privacy, and efficiency constraints. Traditional FTTA aims at adapting a pre-trained model to streaming test-time data from diverse domains under unsupervised settings. However, recent works (Lin et al., 2022; Pearl, 2009) prove that it is theoretically infeasible to achieve OOD generalization without extra information such as environment partitions. Since utilizing environment partitions requires heavy pretraining, contradicting the nature of TTA, we are motivated to incorporate extra information in a different way,i.e., integrating a limited number of labeled test-time samples to alleviate distribution shifts, following the active learning (AL) paradigm (Settles, 2009). To this end, we propose the novel problem setting of active test-time adaptation (ATTA) by incorporating ∗Equal contributions 1 arXiv:2404.05094v1  [cs.LG]  7 Apr 2024Published as a conference paper at ICLR 2024 AL within FTTA. ATTA faces two major challenges; namely, catastrophic forgetting (CF) (Kemker et al., 2018; Li and Hoiem, 2017) and real-time active sample selection. CF problem arises when a model continually trained on a sequence of domains experiences a significant performance drop on previously learned domains, due to the inaccessibility of the source data and previous test data. Real-time active sample selection requires AL algorithms to select informative samples from a small buffer of streaming test data for annotation, without a complete view of the test distribution. In this paper, we first formally define the ATTA setting. We then provide its foundational analysis under the learning theory’s paradigm to guarantee the mitigation of distribution shifts and avoid CF. Aligned with our empirical validations, while the widely used entropy minimization (Wang et al., 2021; Grandvalet and Bengio, 2004) can cause CF, it can conversely become the key to preventing CF problems with our sample selection and balancing techniques. Building on the analyses, we then introduce a simple yet effective ATTA algorithm, SimATTA, incorporating balanced sample selections and incremental clustering. Finally, we conducted a comprehensive experimental study to evaluate the proposed ATTA settings with three different settings in the order of low to high requirement restrictiveness, i.e., TTA, Enhanced TTA, and Active Domain Adaptation (ADA). Intensive experiments indicate that ATTA jointly equips with the efficiency of TTA and the effectiveness of ADA, rendering an uncompromising real-time distribution adaptation direction. Comparison to related studies. Compared to TTA methods, ATTA requires extra active labels, but the failure of TTA methods (Sec. 5.1) and the theoretical proof of Lin et al. (2022); Pearl (2009) justify its necessity and rationality. Compared to active online learning, ATTA focuses on lightweight real-time fine-tuning without round-wise re-trainings as Saran et al. (2023) and emphasizes the importance of CF avoidance instead of resetting models and losing learned distributions. In fact, active online learning is partially similar to our enhanced TTA setting (Sec. 5.2. Compared to ADA methods (Prabhu et al., 2021; Ning et al., 2021), ATTA does not presuppose access to source data, model parameters, or pre-collected target samples. Furthermore, without this information, ATTA can still perform on par with ADA methods (Sec. 5.3). The recent source-free active domain adaptation (SFADA) method SALAD (Kothandaraman et al., 2023) still requires access to model parameter gradients, pre-collected target data, and training of additional networks. Our ATTA, in contrast, with non-regrettable active sample selection on streaming data, is a much lighter and more realistic approach distinct from ADA and SFADA. More related-work discussions are provided in Appx. C. 2 T HE ACTIVE TEST-TIME ADAPTATION FORMULATION TTA methods aim to solve distribution shifts by dynamically optimizing a pre-trained model based on streaming test data. We introduce the novel problem setting of Active Test-Time Adaptation (ATTA), which incorporates active learning during the test phase. In ATTA, the model continuously selects the most informative instances from the test batch to be labeled by an explicit or implicit oracle (e.g., human annotations, self-supervised signals) and subsequently learned by the model, aiming to improve future adaptations. Considering the labeling costs in real-world applications, a “budget” is established for labeled test instances. The model must effectively manage this budget distribution and ensure that the total number of label requests throughout the test phase does not surpass the budget. We now present a formal definition of the ATTA problem. Consider a pre-trained modelf(x; ϕ) with parameters ϕ trained on the source dataset DS = (x, y)|DS|, with each data sample x ∈ Xand a label y ∈ Y. We aim to adapt model parameters θ, initialized as ϕ, to an unlabeled test-time data stream. The streaming test data exhibit distribution shifts from the source data and varies continuously with time, forming multiple domains to which we must continuously adapt. The test phase commences at time step t = 1 and the streaming test data is formulated in batches. The samples are then actively selected, labeled (by the oracle) and collected as Dte(t) = ActAlg(Ute(t)), where ActAlg(·) denotes an active selection/labeling algorithm. The labeled samples Dte(t) are subsequently incorporated into the ATTA training setDtr(t). Finally, we conclude time step t by performing ATTA training, updating model parameters θ(t) using Dtr(t), with θ(t) initialized as the previous final state θ(t − 1). Definition 1 (The ATTA problem). Given a model f(x; θ), with parameters θ, initialized with parameters θ(0) = ϕ obtained by pre-training on source domain data, and streaming test data batches Ute(t) continually changing over time, the ATTA task aims to optimize the model at any time stept (with test phase commencing at t = 1) as θ(t)∗ := argmin θ(t) (E(x,y,t)∈Dtr(t)[ℓCE (f(x; θ(t)), y)] + E(x,t)∈Ute(t)[ℓU (f(x; θ(t)))]), (1) 2Published as a conference paper at ICLR 2024 where Dtr(t) = ( ∅, t = 0 Dtr(t − 1) ∪ Dte(t), t ≥ 1, s.t. |Dtr(t)| ≤ B, (2) Dte(t) = ActAlg(Ute(t)) is actively selected and labeled, ℓCE is the cross entropy loss, ℓU is an unsupervised learning loss, and B is the budget. 3 T HEORETICAL STUDIES In this section, we conduct an in-depth theoretical analysis of TTA based on learning theories. We mainly explore two questions: How can significant distribution shifts be effectively addressed under the TTA setting? How can we simultaneously combat the issue of CF? Sec. 3.1 provides a solution with theoretical guarantees to the first question, namely, active TTA (ATTA), along with the conditions under which distribution shifts can be well addressed. Sec. 3.2 answers the second question with an underexplored technique, i.e., selective entropy minimization, building upon the learning bounds established in Sec. 3.1. We further validate these theoretical findings through experimental analysis. Collectively, we present a theoretically supported ATTA solution that effectively tackles both distribution shift and CF. 3.1 A LLEVIATING DISTRIBUTION SHIFTS THROUGH ACTIVE TEST-TIME ADAPTATION Traditional TTA is performed in unsupervised or self-supervised context. In contrast, ATTA introduces supervision into the adaptation setting. In this subsection, we delve into learning bounds and establish generalization bounds to gauge the efficacy of ATTA in solving distribution shifts. We scrutinize the influence of active learning and evidence that the inclusion of labeled test instances markedly enhances overall performances across incremental test domains. Following Kifer et al. (2004), we examine statistical guarantees for binary classification. A hypothesis is a function h : X → {0, 1}, which can serve as the prediction function within this context. In the ATTA setting, the mapping ofh varies with time as h(x, t). We use H∆H-distance following Ben- David et al. (2010), which essentially provides a measure to quantify the distribution shift between two distributions D1 and D2, and can also be applied between datasets. The probability that an estimated hypothesis h disagrees with the true labeling function g : X → {0, 1} according to distribution D is defined as ϵ(h(t), g) = E(x)∼D[|h(x, t) − g(x)|], which we also refer to as the error or risk ϵ(h(t)). While the source data is inaccessible under ATTA settings, we consider the existence of source dataset DS for accurate theoretical analysis. Thus, we initialize Dtr as Dtr(0) = DS. For every time step t, the test and training data can be expressed asUte(t) and Dtr(t) = DS ∪Dte(1) ∪Dte(2) ∪···∪ Dte(t). Building upon two lemmas (provided in Appx. D), we establish bounds on domain errors under the ATTA setting when minimizing the empirical weighted error using the hypothesish at time t. Theorem 1. Let H be a hypothesis class of VC-dimension d. At time step t, for ATTA data domains DS, Ute(1), ··· , Ute(t), ··· , Si are unlabeled samples of sizem sampled from each of thet+1 domains respectively. The total number of samples in Dtr(t) is N and the ratio of sample numbers in each component is λ = (λ0, ··· , λt). If ˆh(t) ∈ Hminimizes the empirical weighted error ˆϵw(h(t)) with the weight vector w = (w0, ··· , wt) on Dtr(t), and h∗ j (t) = arg minh∈H ϵj(h(t)) is the optimal hypothesis on the jth domain, then for any δ ∈ (0, 1), with probability of at least 1 − δ, we have ϵj(ˆh(t)) ≤ ϵj(h∗ j (t)) + 2 tX i=0,i̸=j wi  1 2 ˆdH∆H(Si, Sj) + 2 s 2d log(2m) + log 2 δ m + γi   + 2C, where C = r\u0010Pt i=0 w2 i λi \u0011\u0010 d log(2N)−log(δ) 2N \u0011 and γi = minh∈H{ϵi(h(t)) + ϵj(h(t))}. For future test domains j = t + k (k >0), assuming k′ = argmink′∈{0,1,...t} dH∆H(D(k′), Ute(t + k)) and min dH∆H (D(k′), Ute(t + k)) ≤ δD, where 0 ≤ δD ≪ +∞, then ∀δ, with probability of at least 1 − δ, we have ϵt+k(ˆh(t)) ≤ ϵt+k(h∗ t+k(t)) + tX i=0 wi  ˆdH∆H(Si, Sk′ ) + 4 s 2d log(2m) + log 2 δ m + δD + 2γi   + 2C. The adaptation performance on a test domain is majorly bounded by the composition of (labeled) training data, estimated distribution shift, and ideal joint hypothesis performance, which correspond to C, ˆdH∆H(Si, Sj), and γi, respectively. The ideal joint hypothesis error γi gauges the inherent adaptability between domains. Further theoretical analysis are in Appx. D. 3Published as a conference paper at ICLR 2024 Figure 1: (a) Empirical validation of Thm. 1. We train a series of models on N = 2000 samples from the PACS (Li et al., 2017) dataset given differentλ0 and w0 and display the test domain loss of each model. Red points are the test loss minimums given a fixed λ0. The orange line is the reference where w0 = λ0. We observe that w0 with loss minimums are located closed to the orange line but slightly smaller than λ0, which validates our findings in Eq. (4). (b) Empirical analysis with an uncertainty balancing. Given source pre-trained models, we fine-tune the models on 500 samples with different λ0 and w0, and display the combined error surface of test and source error. Although a small λ0 is good for test domain error, it can lead to non-trivial source error exacerbation. Therefore, we can observe that the global loss minimum (green X) locates in a relatively high-λ0 region. If we consider the multiple test data distributions as a single test domain,i.e., St i=1 Ute(i), Thm. 1 can be reduced into bounds for the source domain error ϵS and test domain error ϵT . Given the optimal test/source hypothesis h∗ T (t) = arg minh∈H ϵT (h(t)) and h∗ S(t) = arg minh∈H ϵS(h(t)), we have |ϵT (ˆh(t)) − ϵT (h∗ T (t))| ≤w0A + s w2 0 λ0 + (1 − w0)2 1 − λ0 B, (3a) |ϵS(ˆh(t)) − ϵS(h∗ S(t))| ≤(1 − w0)A + s w2 0 λ0 + (1 − w0)2 1 − λ0 B, (3b) where the distribution divergence termA = ˆdH∆H(S0, ST )+4 q 2d log(2m)+log 2 δ m +2γ, the empirical gap term B = 2 q d log(2N)−log(δ) 2N , ST is sampled from St i=1 Ute(i), and γ = minh∈H{ϵ0(h(t)) + ϵT (h(t))}. Our learning bounds demonstrates the trade-off between the small amount of budgeted test-time data and the large amount of less relevant source data. Next, we provide an approximation of the condition necessary to achieve optimal adaptation performance, which is calculable from finite samples and can be readily applied in practical ATTA scenarios. Following Eq. (3.a), with approximatelyB = c1 p d/N, the optimal value w∗ 0 to tighten the test error bound is a function of λ0 and A: w∗ 0 = λ0 − s A2N c2 1d − A2Nλ0(1 − λ0), for λ 0 ≥ 1 − d A2N , (4) where c1 is a constant. Note that λ0 ≥ 1 − d A2N should be the satisfied condition in practical ATTA settings, where the budget is not sufficiently big while the source data amount is relatively large. The following theorem offers a direct theoretical guarantee that ATTA reduces the error bound on test domains in comparison to TTA without the integration of active learning. Theorem 2. Let H be a hypothesis class of VC-dimension d. For ATTA data domains DS, Ute(1), Ute(2), ··· , Ute(t), considering the test-time data as a single test domain St i=1 Ute(i), if ˆh(t) ∈ H minimizes the empirical weighted error ˆϵw(h(t)) with the weight vector w on Dtr(t), let the test error be upper-bounded with |ϵT (ˆh(t)) − ϵT (h∗ T (t))| ≤EBT (w, λ, N, t). Let w′ and λ′ be the weight and sample ratio vectors when no active learning is included, i.e., w′ and λ′ s.t. w′ 0 = λ′ 0 = 1 and w′ i = λ′ i = 0 for i ≥ 1, then for any λ ̸= λ′, there exists w s.t. EBT (w, λ, N, t) < EBT (w′, λ′, N, t). (5) Therefore, the incorporation of labeled test instances in ATTA theoretically enhances the overall performance across test domains, substantiating the significance of the ATTA setting in addressing distribution shifts. All proofs are provided in Appx. E. Finally, we support the theoretical findings with experimental analysis and show the numerical results of applying the principles on real-world datasets, as shown in Fig. 1. For rigorous analysis, note that our theoretical results rest on the underlying condition that N should at least be of the same scale as d, according to the principles of VC-dimension theory. The empirical alignment of our experiments with the theoretical framework can be attributed to the assumption that fine-tuning a model is roughly equivalent to learning a model with a relatively small d. Experiment details and other validations can be found in Appx. H. 4Published as a conference paper at ICLR 2024 3.2 M ITIGATING CATASTROPHIC FORGETTING WITH BALANCED ENTROPY MINIMIZATION Catastrophic forgetting (CF), within the realm of Test-Time Adaptation (TTA), principally manifests as significant declines in overall performance, most notably in the source domain. Despite the lack of well-developed learning theories for analyzing training with series data, empirical studies have convincingly illustrated the crucial role of data sequential arrangement in model learning, thereby accounting for the phenomenon of CF. Traditionally, the mitigation of CF in adaptation tasks involves intricate utilization of source domain data. However, under FTTA settings, access to the source dataset is unavailable, leaving the problem of CF largely unexplored in the data-centric view. Table 1: Correlation analysis of high/low en- tropy samples and domains. We use a source pre-trained model to select samples with low- est/highest entropy, and 1.retrain the model on 2000 samples; 2.fine-tune the model on 300 sam- ples. We report losses on source/test domains for each setting, showing that low-entropy samples form distributions close to the source domain. Sample type Retrain Fine-tune ϵS ϵT ϵS ϵT Low entropy 0.5641 0.8022 0.0619 1.8838 High entropy 2.5117 0.3414 0.8539 0.7725 To overcome this challenge of source dataset ab- sence, we explore the acquisition of “source-like” data. In TTA scenarios, it is generally assumed that the amount of source data is considerably large. We also maintain this assumption in ATTA, practically assuming the volume of source data greatly surpasses the test-time budget. As a re- sult, we can safely assume that the pre-trained model is well-trained on abundant source do- main data DS. Given this adequately trained source model, we can treat it as a “true” source data labeling function f(x; ϕ). The model es- sentially describes a distribution, Dϕ,S(X, Y) = {(x, ˆy) ∈ (X, Y) | ˆy = f(x; ϕ), x∈ DS}. The entropy of the model prediction is defined as H(ˆy) = −P c p(ˆyc) logp(ˆyc), ˆy = f(x; ϕ), where c denotes the class. Lower entropy indicates that the model assigns high probability to one of the classes, suggesting a high level of certainty or confidence in its prediction, which can be interpreted as the sample being well-aligned or fitting closely with the model’s learned distribution. In other words, the model recognizes the sample as being similar to those it was trained on. Thus entropy can be used as an indicator of how closely a sample x aligns with the model distribution Dϕ,S. Since the model distribution is approximately the source distribution, selecting (and labeling) low-entropy samples using f(x; ϕ) essentially provides an estimate of sampling from the source dataset. Therefore, in place of the inaccessible DS, we can feasibly include the source-like dataset into the ATTA training data at each time stept: Dϕ,S(t) = {(x, f(x; ϕ))|x ∈ Ute(t), H(f(x; ϕ)) < el}, (6) where el is the entropy threshold. The assumption that Dϕ,S(t) is an approximation of DS can be empirically validated, as shown by the numerical results on PACS in Tab. 1. In contrast, high-entropy test samples typically deviate more from the source data, from which we select Dte(t) for active labeling. Following the notations in Thm. 1, we are practically minimizing the empirical weighted error of hypothesis h(t) as ˆϵ′ w(h(t)) = tX j=0 wjˆϵj(h(t)) = w0 λ0N X x∈Dϕ,S(t) |h(x, t) − f(x; ϕ)| + tX j=1 wj λjN X x,y∈Dte(j) |h(x, t) − y|. (7) By substituting DS with Dϕ,S(t) in Thm. 1, the bounds of Thm. 1 continue to hold for the test domains. In the corollary below, we bound the source error for practical ATTA at each time stept. Corollary 3. At time step t, for ATTA data domains Dϕ,S(t), Ute(1), Ute(2), ··· , Ute(t), Si are unla- beled samples of size m sampled from each of the t + 1 domains respectively, and SS is unlabeled samples of size m sampled from DS. If ˆh(t) ∈ Hminimizes ˆϵ′ w(h(t)) while other conditions remain identical to Thm. 1, then ϵS(ˆh(t)) ≤ ϵS(h∗ S(t)) + tX i=0 wi  ˆdH∆H(Si, SS) + 4 s 2d log(2m) + log 2 δ m + 2γi   + 2C, with probability at least 1 − δ, where C follows Thm. 1 and γi = minh∈H{ϵi(h(t)) + ϵS(h(t))}. Further analysis and proofs are in Appx. D and E. The following corollary provides direct theoretical support that our strategy conditionally reduces the error bound on the source domain. Corollary 4. At time step t, for ATTA data domains Dϕ,S(t), Ute(1), Ute(2), ··· , Ute(t), suppose that ˆh(t) ∈ Hminimizes ˆϵw′(h(t)) under identical conditions to Thm. 2. Let’s denote the source error upper bound with |ϵS(ˆh(t)) − ϵS(h∗ S(t))| ≤EBS(w, λ, N, t). Let w′ and λ′ be the weight 5Published as a conference paper at ICLR 2024 <latexit sha1_base64=\"NxhXSyFABPQk4q8627/odirDspg=\">AAAB9XicbVDLSgMxFM34rPVVdekmWARXZab4WhbcuKzYF7S1ZNI7bWgmMyR3lDL0P9y4UMSt/+LOvzHTdqGtBwKHc87l3hw/lsKg6347K6tr6xubua389s7u3n7h4LBhokRzqPNIRrrlMwNSKKijQAmtWAMLfQlNf3ST+c1H0EZEqobjGLohGygRCM7QSg/3mIWFGtAaGOwVim7JnYIuE29OimSOaq/w1elHPAlBIZfMmLbnxthNmUbBJUzyncRAzPiIDaBtqWIhmG46vXpCT63Sp0Gk7VNIp+rviZSFxoxD3yZDhkOz6GXif147weC6mwoVJwiKzxYFiaQY0awC2hcaOMqxJYxrYW+lfMg042iLytsSvMUvL5NGueRdli7uysXK+byOHDkmJ+SMeOSKVMgtqZI64USTZ/JK3pwn58V5dz5m0RVnPnNE/sD5/AFnsJJq</latexit> Streaming Test <latexit sha1_base64=\"a41BOKrutEYSWO9+8CjkPZKHvb8=\">AAAB73icbVBNS8NAEJ3Ur1q/qh69BIvgqSTiR48FLx4r2A9oQ9lsN+3SzSbuToQQ+ie8eFDEq3/Hm//GTZuDtj4YeLw3w8w8PxZco+N8W6W19Y3NrfJ2ZWd3b/+genjU0VGiKGvTSESq5xPNBJesjRwF68WKkdAXrOtPb3O/+8SU5pF8wDRmXkjGkgecEjRSbzAhmKWzyrBac+rOHPYqcQtSgwKtYfVrMIpoEjKJVBCt+64To5cRhZwKNqsMEs1iQqdkzPqGShIy7WXze2f2mVFGdhApUxLtufp7IiOh1mnom86Q4EQve7n4n9dPMGh4GZdxgkzSxaIgETZGdv68PeKKURSpIYQqbm616YQoQtFElIfgLr+8SjoXdfe6fnV/WWs2ijjKcAKncA4u3EAT7qAFbaAg4Ble4c16tF6sd+tj0Vqyiplj+APr8wfpIY/e</latexit> ˆy <latexit sha1_base64=\"SJEOE2ZYxLL1SU/QahOlMH6fop4=\">AAAB8HicbVBNSwMxEM3Wr1q/qh69BItQL2VX/Oix4MVjBbettEvJptk2NMkuyaxQlv4KLx4U8erP8ea/MW33oK0PBh7vzTAzL0wEN+C6305hbX1jc6u4XdrZ3ds/KB8etUycasp8GotYd0JimOCK+cBBsE6iGZGhYO1wfDvz209MGx6rB5gkLJBkqHjEKQErPfr9DNi0Cuf9csWtuXPgVeLlpIJyNPvlr94gpqlkCqggxnQ9N4EgIxo4FWxa6qWGJYSOyZB1LVVEMhNk84On+MwqAxzF2pYCPFd/T2REGjORoe2UBEZm2ZuJ/3ndFKJ6kHGVpMAUXSyKUoEhxrPv8YBrRkFMLCFUc3srpiOiCQWbUcmG4C2/vEpaFzXvunZ1f1lp1PM4iugEnaIq8tANaqA71EQ+okiiZ/SK3hztvDjvzseiteDkM8foD5zPH2KnkB4=</latexit> U te ( t ) <latexit sha1_base64=\"7rdY0fXtveVAqOkqa7z+i6K3Rp0=\">AAAB+XicbVDLSsNAFJ34rPUVdelmsAh1UxLxUXBTcOOygn1AE8pkMmmHTiZh5qZQQv/EjQtF3Pon7vwbp20W2nrgwuGce7n3niAVXIPjfFtr6xubW9ulnfLu3v7BoX103NZJpihr0UQkqhsQzQSXrAUcBOumipE4EKwTjO5nfmfMlOaJfIJJyvyYDCSPOCVgpL5tR1WPhgncYQ+GDMhF3644NWcOvErcglRQgWbf/vLChGYxk0AF0brnOin4OVHAqWDTspdplhI6IgPWM1SSmGk/n18+xedGCXGUKFMS8Fz9PZGTWOtJHJjOmMBQL3sz8T+vl0FU93Mu0wyYpItFUSYwJHgWAw65YhTExBBCFTe3YjokilAwYZVNCO7yy6ukfVlzb2rXj1eVRr2Io4RO0RmqIhfdogZ6QE3UQhSN0TN6RW9Wbr1Y79bHonXNKmZO0B9Ynz9h0pLV</latexit> f ( · ; ✓ ) <latexit sha1_base64=\"ud3dFXm+F2nsLD2/MdusutzkLvU=\">AAAB9HicbVDLSgNBEJyNrxhfUY9eBoPgKeyKr2PAixchgnlAsoTZ2d5kyMzOOjMbDEu+w4sHRbz6Md78GyfJHjSxoKGo6qa7K0g408Z1v53Cyura+kZxs7S1vbO7V94/aGqZKgoNKrlU7YBo4CyGhmGGQztRQETAoRUMb6Z+awRKMxk/mHECviD9mEWMEmMlvysC+ZTdyRD4pNQrV9yqOwNeJl5OKihHvVf+6oaSpgJiQznRuuO5ifEzogyjHCalbqohIXRI+tCxNCYCtJ/Njp7gE6uEOJLKVmzwTP09kRGh9VgEtlMQM9CL3lT8z+ukJrr2MxYnqYGYzhdFKcdG4mkCOGQKqOFjSwhVzN6K6YAoQo3NaRqCt/jyMmmeVb3L6sX9eaV2nsdRREfoGJ0iD12hGrpFddRAFD2iZ/SK3pyR8+K8Ox/z1oKTzxyiP3A+fwCmlpH9</latexit> Model SimATTA <latexit sha1_base64=\"bhVea6W/pzUPuDRNfs2xbDF7qAk=\">AAAB73icbVC7SgNBFL3rM8ZX1NJmMAhWYTf4KgM2FhYRzAOSJcxOZpMhs7PrzF0hhPyEjYUitv6OnX/jbLKFJh4YOJxzD3PvCRIpDLrut7Oyura+sVnYKm7v7O7tlw4OmyZONeMNFstYtwNquBSKN1Cg5O1EcxoFkreC0U3mt564NiJWDzhOuB/RgRKhYBSt1L6jQRYd9Eplt+LOQJaJl5My5Kj3Sl/dfszSiCtkkhrT8dwE/QnVKJjk02I3NTyhbEQHvGOpohE3/mS275ScWqVPwljbp5DM1N+JCY2MGUeBnYwoDs2il4n/eZ0Uw2t/IlSSIlds/lGYSoIxyY4nfaE5Qzm2hDIt7K6EDammDG1FRVuCt3jyMmlWK95l5eK+Wq6d53UU4BhO4Aw8uIIa3EIdGsBAwjO8wpvz6Lw4787HfHTFyTNH8AfO5w/1SI/i</latexit> Labeling <latexit sha1_base64=\"7rdY0fXtveVAqOkqa7z+i6K3Rp0=\">AAAB+XicbVDLSsNAFJ34rPUVdelmsAh1UxLxUXBTcOOygn1AE8pkMmmHTiZh5qZQQv/EjQtF3Pon7vwbp20W2nrgwuGce7n3niAVXIPjfFtr6xubW9ulnfLu3v7BoX103NZJpihr0UQkqhsQzQSXrAUcBOumipE4EKwTjO5nfmfMlOaJfIJJyvyYDCSPOCVgpL5tR1WPhgncYQ+GDMhF3644NWcOvErcglRQgWbf/vLChGYxk0AF0brnOin4OVHAqWDTspdplhI6IgPWM1SSmGk/n18+xedGCXGUKFMS8Fz9PZGTWOtJHJjOmMBQL3sz8T+vl0FU93Mu0wyYpItFUSYwJHgWAw65YhTExBBCFTe3YjokilAwYZVNCO7yy6ukfVlzb2rXj1eVRr2Io4RO0RmqIhfdogZ6QE3UQhSN0TN6RW9Wbr1Y79bHonXNKmZO0B9Ynz9h0pLV</latexit> f ( · ; ✓ ) <latexit sha1_base64=\"DPrA95GNP27SFW5vSoLC/hYa644=\">AAAB9XicbVDLSsNAFJ3UV62vqks3g0Wom5KIj4KbghuXFewDmlgmk0k7dJIJMzdKCf0PNy4Uceu/uPNvnLZZaOuBC4dz7uXee/xEcA22/W0VVlbX1jeKm6Wt7Z3dvfL+QVvLVFHWolJI1fWJZoLHrAUcBOsmipHIF6zjj26mfueRKc1lfA/jhHkRGcQ85JSAkR7CqksDCdfYTYb8tF+u2DV7BrxMnJxUUI5mv/zlBpKmEYuBCqJ1z7ET8DKigFPBJiU31SwhdEQGrGdoTCKmvWx29QSfGCXAoVSmYsAz9fdERiKtx5FvOiMCQ73oTcX/vF4KYd3LeJykwGI6XxSmAoPE0whwwBWjIMaGEKq4uRXTIVGEggmqZEJwFl9eJu2zmnNZu7g7rzTqeRxFdISOURU56Ao10C1qohaiSKFn9IrerCfrxXq3PuatBSufOUR/YH3+AFKlkbs=</latexit> f ( · ; \u0000 ) <latexit sha1_base64=\"DPrA95GNP27SFW5vSoLC/hYa644=\">AAAB9XicbVDLSsNAFJ3UV62vqks3g0Wom5KIj4KbghuXFewDmlgmk0k7dJIJMzdKCf0PNy4Uceu/uPNvnLZZaOuBC4dz7uXee/xEcA22/W0VVlbX1jeKm6Wt7Z3dvfL+QVvLVFHWolJI1fWJZoLHrAUcBOsmipHIF6zjj26mfueRKc1lfA/jhHkRGcQ85JSAkR7CqksDCdfYTYb8tF+u2DV7BrxMnJxUUI5mv/zlBpKmEYuBCqJ1z7ET8DKigFPBJiU31SwhdEQGrGdoTCKmvWx29QSfGCXAoVSmYsAz9fdERiKtx5FvOiMCQ73oTcX/vF4KYd3LeJykwGI6XxSmAoPE0whwwBWjIMaGEKq4uRXTIVGEggmqZEJwFl9eJu2zmnNZu7g7rzTqeRxFdISOURU56Ao10C1qohaiSKFn9IrerCfrxXq3PuatBSufOUR/YH3+AFKlkbs=</latexit> f ( · ; \u0000 ) <latexit sha1_base64=\"ipQ+JKlINPDcPjrbUYUkqyyzp40=\">AAAB+nicbVC7TsMwFHXKq5RXCiOLRYXEQpVUvMZKLIxF0IfURpXj3LRWHSeyHVBV+iksDCDEypew8Te4aQZoOZKlo3Puy8dPOFPacb6twsrq2vpGcbO0tb2zu2eX91sqTiWFJo15LDs+UcCZgKZmmkMnkUAin0PbH13P/PYDSMVica/HCXgRGQgWMkq0kfp2+S6bdNqQoCUxQ4K+XXGqTga8TNycVFCORt/+6gUxTSMQmnKiVNd1Eu1NiNSMcpiWeqmChNARGUDXUEEiUN4kO32Kj40S4DCW5gmNM/V3x4RESo0j31RGRA/VojcT//O6qQ6vvAkTSapB0PmiMOVYx3iWAw6YBKr52BBCJTO3YjokklBt0iqZENzFLy+TVq3qXlTPb2uV+lkeRxEdoiN0glx0ieroBjVQE1H0iJ7RK3qznqwX6936mJcWrLznAP2B9fkDSAyT+w==</latexit> Source-Pretrained <latexit sha1_base64=\"ud3dFXm+F2nsLD2/MdusutzkLvU=\">AAAB9HicbVDLSgNBEJyNrxhfUY9eBoPgKeyKr2PAixchgnlAsoTZ2d5kyMzOOjMbDEu+w4sHRbz6Md78GyfJHjSxoKGo6qa7K0g408Z1v53Cyura+kZxs7S1vbO7V94/aGqZKgoNKrlU7YBo4CyGhmGGQztRQETAoRUMb6Z+awRKMxk/mHECviD9mEWMEmMlvysC+ZTdyRD4pNQrV9yqOwNeJl5OKihHvVf+6oaSpgJiQznRuuO5ifEzogyjHCalbqohIXRI+tCxNCYCtJ/Njp7gE6uEOJLKVmzwTP09kRGh9VgEtlMQM9CL3lT8z+ukJrr2MxYnqYGYzhdFKcdG4mkCOGQKqOFjSwhVzN6K6YAoQo3NaRqCt/jyMmmeVb3L6sX9eaV2nsdRREfoGJ0iD12hGrpFddRAFD2iZ/SK3pyR8+K8Ox/z1oKTzxyiP3A+fwCmlpH9</latexit> Model <latexit sha1_base64=\"5LNAmmVR/AN9Lc2T+FRV/is2yz8=\">AAAB8nicbVDLSgNBEJyNrxhfUY9eBoPgKewGX8eACB48RDAP2CxhdjKbDJmdWWZ6lbDkM7x4UMSrX+PNv3GS7EETCxqKqm66u8JEcAOu++0UVlbX1jeKm6Wt7Z3dvfL+QcuoVFPWpEoo3QmJYYJL1gQOgnUSzUgcCtYOR9dTv/3ItOFKPsA4YUFMBpJHnBKwkn+nnvCNBK2Sca9ccavuDHiZeDmpoByNXvmr21c0jZkEKogxvucmEGREA6eCTUrd1LCE0BEZMN9SSWJmgmx28gSfWKWPI6VtScAz9fdERmJjxnFoO2MCQ7PoTcX/PD+F6CrIuExSYJLOF0WpwKDw9H/c55pREGNLCNXc3orpkGhCwaZUsiF4iy8vk1at6l1Uz+9rlfpZHkcRHaFjdIo8dInq6BY1UBNRpNAzekVvDjgvzrvzMW8tOPnMIfoD5/MHKbiRJQ==</latexit> Low Entropy <latexit sha1_base64=\"vLgKkEyV9E/djVdgAkvKuOUQOTU=\">AAAB7nicbVDLSgMxFL1TX7W+qi7dBIvgqswUX8uCG5cV7QPaoWTSTBuaZEKSEcrQj3DjQhG3fo87/8a0nYW2HrhwOOde7r0nUpwZ6/vfXmFtfWNzq7hd2tnd2z8oHx61TJJqQpsk4YnuRNhQziRtWmY57ShNsYg4bUfj25nffqLasEQ+2omiocBDyWJGsHVS+wELxanplyt+1Z8DrZIgJxXI0eiXv3qDhKSCSks4NqYb+MqGGdaWEU6npV5qqMJkjIe066jEgpowm587RWdOGaA40a6kRXP190SGhTETEblOge3ILHsz8T+vm9r4JsyYVKmlkiwWxSlHNkGz39GAaUosnziCiWbuVkRGWGNiXUIlF0Kw/PIqadWqwVX18r5WqV/kcRThBE7hHAK4hjrcQQOaQGAMz/AKb57yXrx372PRWvDymWP4A+/zB19wj48=</latexit> Samples <latexit sha1_base64=\"wuZucU3JbeEJSquG2WgqGdYMCR8=\">AAAB83icbVDLSgMxFL3js9ZX1aWbYBFclZnia1kQocsK9gHtUDJppg3NJCHJCGXob7hxoYhbf8adf2PazkJbD1w4nHMv994TKc6M9f1vb219Y3Nru7BT3N3bPzgsHR23jEw1oU0iudSdCBvKmaBNyyynHaUpTiJO29H4bua3n6g2TIpHO1E0TPBQsJgRbJ3Uq7PhCN0Lq6Wa9Etlv+LPgVZJkJMy5Gj0S1+9gSRpQoUlHBvTDXxlwwxrywin02IvNVRhMsZD2nVU4ISaMJvfPEXnThmgWGpXwqK5+nsiw4kxkyRynQm2I7PszcT/vG5q49swY0KllgqyWBSnHFmJZgGgAdOUWD5xBBPN3K2IjLDGxLqYii6EYPnlVdKqVoLrytVDtVy7zOMowCmcwQUEcAM1qEMDmkBAwTO8wpuXei/eu/exaF3z8pkT+APv8wfIYpF9</latexit> High Entropy <latexit sha1_base64=\"vLgKkEyV9E/djVdgAkvKuOUQOTU=\">AAAB7nicbVDLSgMxFL1TX7W+qi7dBIvgqswUX8uCG5cV7QPaoWTSTBuaZEKSEcrQj3DjQhG3fo87/8a0nYW2HrhwOOde7r0nUpwZ6/vfXmFtfWNzq7hd2tnd2z8oHx61TJJqQpsk4YnuRNhQziRtWmY57ShNsYg4bUfj25nffqLasEQ+2omiocBDyWJGsHVS+wELxanplyt+1Z8DrZIgJxXI0eiXv3qDhKSCSks4NqYb+MqGGdaWEU6npV5qqMJkjIe066jEgpowm587RWdOGaA40a6kRXP190SGhTETEblOge3ILHsz8T+vm9r4JsyYVKmlkiwWxSlHNkGz39GAaUosnziCiWbuVkRGWGNiXUIlF0Kw/PIqadWqwVX18r5WqV/kcRThBE7hHAK4hjrcQQOaQGAMz/AKb57yXrx372PRWvDymWP4A+/zB19wj48=</latexit> Samples <latexit sha1_base64=\"1BO6D/gzkeZNQ7HNIaph5NqELCI=\">AAAB8nicbVDLSgMxFM3UV62vqks3wSK4KjPF17LgRncV7AOmQ8mkd9rQTDIkGaEM/Qw3LhRx69e482/MtLPQ1gOBwzn3kHtPmHCmjet+O6W19Y3NrfJ2ZWd3b/+genjU0TJVFNpUcql6IdHAmYC2YYZDL1FA4pBDN5zc5n73CZRmUjyaaQJBTEaCRYwSYyX/XlAFMQhD+KBac+vuHHiVeAWpoQKtQfWrP5Q0zdOUE619z01MkBFlGOUwq/RTDQmhEzIC31JBYtBBNl95hs+sMsSRVPYJg+fq70RGYq2ncWgnY2LGetnLxf88PzXRTZAxkaQGBF18FKUcG4nz+/GQKaCGTy0hVDG7K6Zjogg1tqWKLcFbPnmVdBp176p++dCoNS+KOsroBJ2ic+Sha9REd6iF2ogiiZ7RK3pzjPPivDsfi9GSU2SO0R84nz9y2ZFU</latexit> Incremental <latexit sha1_base64=\"Jmobmj50NeE6y3ftB4xt5xZD5Eg=\">AAAB8XicbVDLSgNBEOyNrxhfUY9eBoPgKewGX8dALh4jmAcmS5id9CZDZmeXmVkhLP6FFw+KePVvvPk3TpI9aGJBQ1HVTXdXkAiujet+O4W19Y3NreJ2aWd3b/+gfHjU1nGqGLZYLGLVDahGwSW2DDcCu4lCGgUCO8GkMfM7j6g0j+W9mSboR3QkecgZNVZ6aIhUG1Rcjgblilt15yCrxMtJBXI0B+Wv/jBmaYTSMEG17nluYvyMKsOZwKdSP9WYUDahI+xZKmmE2s/mFz+RM6sMSRgrW9KQufp7IqOR1tMosJ0RNWO97M3E/7xeasIbP+MySQ1KtlgUpoKYmMzeJ0OukBkxtYQyxe2thI2posymoEs2BG/55VXSrlW9q+rlXa1Sv8jjKMIJnMI5eHANdbiFJrSAgYRneIU3RzsvzrvzsWgtOPnMMfyB8/kDzgaQ+A==</latexit> Clustering <latexit sha1_base64=\"c4xrXg0yZYBSSDLHCxlf45OWNzg=\">AAAB7nicbVDLSgNBEOz1GeMr6tHLYBA8hd2Aj2PAi8eI5gHJEmYnnWTIzOwyMyuEJR/hxYMiXv0eb/6Nk2QPmljQUFR1090VJYIb6/vf3tr6xubWdmGnuLu3f3BYOjpumjjVDBssFrFuR9Sg4AoblluB7UQjlZHAVjS+nfmtJ9SGx+rRThIMJR0qPuCMWie1HqhMBJpeqexX/DnIKglyUoYc9V7pq9uPWSpRWSaoMZ3AT2yYUW05EzgtdlODCWVjOsSOo4pKNGE2P3dKzp3SJ4NYu1KWzNXfExmVxkxk5DoltSOz7M3E/7xOagc3YcZVklpUbLFokApiYzL7nfS5RmbFxBHKNHe3EjaimjLrEiq6EILll1dJs1oJriqX99VyrZrHUYBTOIMLCOAaanAHdWgAgzE8wyu8eYn34r17H4vWNS+fOYE/8D5/AF7Wj40=</latexit> Samples <latexit sha1_base64=\"eimCpRgfVxBfxhwCehIJdcsMsvY=\">AAAB8XicbVA9SwNBEJ2LXzF+RS1tFoNgFe5SRMtAGssI5gOTI+xt5pIle3vH7p4QjvwLGwtFbP03dv4bN8kVmvhg4PHeDDPzgkRwbVz32ylsbe/s7hX3SweHR8cn5dOzjo5TxbDNYhGrXkA1Ci6xbbgR2EsU0igQ2A2mzYXffUKleSwfzCxBP6JjyUPOqLHSY1Ok2qDicjwsV9yquwTZJF5OKpCjNSx/DUYxSyOUhgmqdd9zE+NnVBnOBM5Lg1RjQtmUjrFvqaQRaj9bXjwnV1YZkTBWtqQhS/X3REYjrWdRYDsjaiZ63VuI/3n91IS3fsZlkhqUbLUoTAUxMVm8T0ZcITNiZgllittbCZtQRZlNQZdsCN76y5ukU6t69Wr9vlZpuHkcRbiAS7gGD26gAXfQgjYwkPAMr/DmaOfFeXc+Vq0FJ585hz9wPn8AzSSQ9Q==</latexit> Clustering <latexit sha1_base64=\"JgGHFC5oztwX6+XjDtZWQo9C1hA=\">AAAB7nicbVA9TwJBEJ3DL8Qv1NJmIzGxIncUaImxscREwAQuZG8ZYMPe7mV3z4Rc+BE2Fhpj6++x89+4wBUKvmSSl/dmMjMvSgQ31ve/vcLG5tb2TnG3tLd/cHhUPj5pG5Vqhi2mhNKPETUouMSW5VbgY6KRxpHATjS5nfudJ9SGK/lgpwmGMR1JPuSMWid1biQbK2365Ypf9Rcg6yTISQVyNPvlr95AsTRGaZmgxnQDP7FhRrXlTOCs1EsNJpRN6Ai7jkoaowmzxbkzcuGUARkq7UpaslB/T2Q0NmYaR64zpnZsVr25+J/XTe3wOsy4TFKLki0XDVNBrCLz38mAa2RWTB2hTHN3K2FjqimzLqGSCyFYfXmdtGvVoF6t39cqDT+PowhncA6XEMAVNOAOmtACBhN4hld48xLvxXv3PpatBS+fOYU/8D5/AFOaj4U=</latexit> Anchors <latexit sha1_base64=\"eimCpRgfVxBfxhwCehIJdcsMsvY=\">AAAB8XicbVA9SwNBEJ2LXzF+RS1tFoNgFe5SRMtAGssI5gOTI+xt5pIle3vH7p4QjvwLGwtFbP03dv4bN8kVmvhg4PHeDDPzgkRwbVz32ylsbe/s7hX3SweHR8cn5dOzjo5TxbDNYhGrXkA1Ci6xbbgR2EsU0igQ2A2mzYXffUKleSwfzCxBP6JjyUPOqLHSY1Ok2qDicjwsV9yquwTZJF5OKpCjNSx/DUYxSyOUhgmqdd9zE+NnVBnOBM5Lg1RjQtmUjrFvqaQRaj9bXjwnV1YZkTBWtqQhS/X3REYjrWdRYDsjaiZ63VuI/3n91IS3fsZlkhqUbLUoTAUxMVm8T0ZcITNiZgllittbCZtQRZlNQZdsCN76y5ukU6t69Wr9vlZpuHkcRbiAS7gGD26gAXfQgjYwkPAMr/DmaOfFeXc+Vq0FJ585hz9wPn8AzSSQ9Q==</latexit> Clustering <latexit sha1_base64=\"JgGHFC5oztwX6+XjDtZWQo9C1hA=\">AAAB7nicbVA9TwJBEJ3DL8Qv1NJmIzGxIncUaImxscREwAQuZG8ZYMPe7mV3z4Rc+BE2Fhpj6++x89+4wBUKvmSSl/dmMjMvSgQ31ve/vcLG5tb2TnG3tLd/cHhUPj5pG5Vqhi2mhNKPETUouMSW5VbgY6KRxpHATjS5nfudJ9SGK/lgpwmGMR1JPuSMWid1biQbK2365Ypf9Rcg6yTISQVyNPvlr95AsTRGaZmgxnQDP7FhRrXlTOCs1EsNJpRN6Ai7jkoaowmzxbkzcuGUARkq7UpaslB/T2Q0NmYaR64zpnZsVr25+J/XTe3wOsy4TFKLki0XDVNBrCLz38mAa2RWTB2hTHN3K2FjqimzLqGSCyFYfXmdtGvVoF6t39cqDT+PowhncA6XEMAVNOAOmtACBhN4hld48xLvxXv3PpatBS+fOYU/8D5/AFOaj4U=</latexit> Anchors <latexit sha1_base64=\"KzBZ8R84UC9mpPFQBWeRHFxcqjw=\">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKVI8FLx4rmLbQhrLZbNq1m92wuxFK6H/w4kERr/4fb/4bt20O2vpg4PHeDDPzwpQzbVz32yltbG5t75R3K3v7B4dH1eOTjpaZItQnkkvVC7GmnAnqG2Y47aWK4iTktBtObud+94kqzaR4MNOUBgkeCRYzgo2VOn4aYUOH1ZpbdxdA68QrSA0KtIfVr0EkSZZQYQjHWvc9NzVBjpVhhNNZZZBpmmIywSPat1TghOogX1w7QxdWiVAslS1h0EL9PZHjROtpEtrOBJuxXvXm4n9ePzPxTZAzkWaGCrJcFGccGYnmr6OIKUoMn1qCiWL2VkTGWGFibEAVG4K3+vI66TTqXrPevG/UWldFHGU4g3O4BA+uoQV30AYfCDzCM7zCmyOdF+fd+Vi2lpxi5hT+wPn8AYuwjxQ=</latexit> Update <latexit sha1_base64=\"y2NH6tDs2GygUDqZYglGwvR4SpA=\">AAAB+nicbVBNSwMxEJ2tX7V+bfXoJVgEQSi7PVSPFS8eK9oPaEvJptk2NMkuSVYpa3+KFw+KePWXePPfmLZ70NYHA4/3ZpiZF8ScaeN5305ubX1jcyu/XdjZ3ds/cIuHTR0litAGiXik2gHWlDNJG4YZTtuxolgEnLaC8fXMbz1QpVkk780kpj2Bh5KFjGBjpb5bvMMi5lSjc3QlyShSuu+WvLI3B1olfkZKkKHed7+6g4gkgkpDONa643ux6aVYGUY4nRa6iaYxJmM8pB1LJRZU99L56VN0apUBCiNlSxo0V39PpFhoPRGB7RTYjPSyNxP/8zqJCS97KZNxYqgki0VhwpGJ0CwHNGCKEsMnlmCimL0VkRFWmBibVsGG4C+/vEqalbJfLVdvK6Wal8WRh2M4gTPw4QJqcAN1aACBR3iGV3hznpwX5935WLTmnGzmCP7A+fwBUnKTWg==</latexit> Samples + Anchors <latexit sha1_base64=\"u0BDOcH87PXd3DsT+o414+7cHnI=\">AAAB7XicbZC7SgNBFIbPxluMt6ilIINBsAq7FjGdARvLBMwFkhBmZ2eTMbMzy8ysEJaU9jYWitj6Cql8CDufwZdwcik0+sPAx/+fw5xz/JgzbVz308msrK6tb2Q3c1vbO7t7+f2DhpaJIrROJJeq5WNNORO0bpjhtBUriiOf06Y/vJrmzTuqNJPixoxi2o1wX7CQEWys1eiQQBrdyxfcojsT+gveAgqX75Pa1/3xpNrLf3QCSZKICkM41rrtubHpplgZRjgd5zqJpjEmQ9ynbYsCR1R309m0Y3RqnQCFUtknDJq5PztSHGk9inxbGWEz0MvZ1PwvaycmLHdTJuLEUEHmH4UJR0ai6eooYIoSw0cWMFHMzorIACtMjD1Qzh7BW175LzTOi16pWKq5hUoZ5srCEZzAGXhwARW4hirUgcAtPMATPDvSeXRenNd5acZZ9BzCLzlv33Yvk3g=</latexit> ··· <latexit sha1_base64=\"+7L/8ObZcl+JIZaSFhVO3t+lUUE=\">AAAB7XicbVDLSgNBEOyNrxhf8XHzMhiEeAm7ItFjQA8eI5gHJCHMTmaT0dnZZaZXCEv+wYsHRbz6P978GyebHDSxoKGo6qa7y4+lMOi6305uZXVtfSO/Wdja3tndK+4fNE2UaMYbLJKRbvvUcCkUb6BAydux5jT0JW/5j9dTv/XEtRGRusdxzHshHSoRCEbRSs2bvizjWb9YcituBrJMvDkp1Y6CDPV+8as7iFgScoVMUmM6nhtjL6UaBZN8UugmhseUPdIh71iqaMhNL82unZBTqwxIEGlbCkmm/p5IaWjMOPRtZ0hxZBa9qfif10kwuOqlQsUJcsVmi4JEEozI9HUyEJozlGNLKNPC3krYiGrK0AZUsCF4iy8vk+Z5xatWqnc2jQuYIQ/HcAJl8OASanALdWgAgwd4hld4cyLnxXl3PmatOWc+cwh/4Hz+AFjYkTs=</latexit> D l ( t ) <latexit sha1_base64=\"9C0bB8PYImk9DX0HLfGvGd44PFA=\">AAAB7XicbVDLSgNBEOyNrxhf8XHzMhiEeAm7ItFjQA8eI5gHJCHMTmaT0dnZZaZXCEv+wYsHRbz6P978GyebHDSxoKGo6qa7y4+lMOi6305uZXVtfSO/Wdja3tndK+4fNE2UaMYbLJKRbvvUcCkUb6BAydux5jT0JW/5j9dTv/XEtRGRusdxzHshHSoRCEbRSs2b/qiMZ/1iya24Gcgy8eakVDsKMtT7xa/uIGJJyBUySY3peG6MvZRqFEzySaGbGB5T9kiHvGOpoiE3vTS7dkJOrTIgQaRtKSSZ+nsipaEx49C3nSHFkVn0puJ/XifB4KqXChUnyBWbLQoSSTAi09fJQGjOUI4toUwLeythI6opQxtQwYbgLb68TJrnFa9aqd7ZNC5ghjwcwwmUwYNLqMEt1KEBDB7gGV7hzYmcF+fd+Zi15pz5zCH8gfP5A1K8kTc=</latexit> D h ( t ) <latexit sha1_base64=\"eNrtnhPGeU8n4BRDMStm5cjQ4ts=\">AAAB73icbVBNS8NAEJ34WetX1aOXxSJ4KkmR6rHQi8cK9gPaUDbbTbt0s4m7E6GE/gkvHhTx6t/x5r9x2+agrQ8GHu/NMDMvSKQw6Lrfzsbm1vbObmGvuH9weHRcOjltmzjVjLdYLGPdDajhUijeQoGSdxPNaRRI3gkmjbnfeeLaiFg94DThfkRHSoSCUbRS1zNIGlTKQansVtwFyDrxclKGHM1B6as/jFkacYVMUmN6npugn1GNgkk+K/ZTwxPKJnTEe5YqGnHjZ4t7Z+TSKkMSxtqWQrJQf09kNDJmGgW2M6I4NqveXPzP66UY3vqZUEmKXLHlojCVBGMyf54MheYM5dQSyrSwtxI2ppoytBEVbQje6svrpF2teLVK7b5arl/ncRTgHC7gCjy4gTrcQRNawEDCM7zCm/PovDjvzseydcPJZ87gD5zPH1Naj3k=</latexit> 1st Call <latexit sha1_base64=\"mxsL+XuWb2hqFND+pzTctrB1rcY=\">AAAB73icbVBNS8NAEJ34WetX1aOXxSJ4KkmR6rHQi8cK9gPaUDababt0s4m7G6GE/gkvHhTx6t/x5r9x2+agrQ8GHu/NMDMvSATXxnW/nY3Nre2d3cJecf/g8Oi4dHLa1nGqGLZYLGLVDahGwSW2DDcCu4lCGgUCO8GkMfc7T6g0j+WDmSboR3Qk+ZAzaqzUrcqQNKgQg1LZrbgLkHXi5aQMOZqD0lc/jFkaoTRMUK17npsYP6PKcCZwVuynGhPKJnSEPUsljVD72eLeGbm0SkiGsbIlDVmovycyGmk9jQLbGVEz1qveXPzP66VmeOtnXCapQcmWi4apICYm8+dJyBUyI6aWUKa4vZWwMVWUGRtR0Ybgrb68TtrViler1O6r5fp1HkcBzuECrsCDG6jDHTShBQwEPMMrvDmPzovz7nwsWzecfOYM/sD5/AE0o49l</latexit> 2nd Call <latexit sha1_base64=\"oSA1OFmXXL9y3PJtqoVxTIG9mto=\">AAAB8HicbVA9TwJBEJ3DL8Qv1NJmIzGxIncUaElCY2UwkQ8DF7K3zMGGvb3L7p6REH6FjYXG2Ppz7Pw3LnCFgi+Z5OW9mczMCxLBtXHdbye3sbm1vZPfLeztHxweFY9PWjpOFcMmi0WsOgHVKLjEpuFGYCdRSKNAYDsY1+d++xGV5rG8N5ME/YgOJQ85o8ZKD7f4ZEidCtEvltyyuwBZJ15GSpCh0S9+9QYxSyOUhgmqdddzE+NPqTKcCZwVeqnGhLIxHWLXUkkj1P50cfCMXFhlQMJY2ZKGLNTfE1MaaT2JAtsZUTPSq95c/M/rpia89qdcJqlByZaLwlQQE5P592TAFTIjJpZQpri9lbARVZQZm1HBhuCtvrxOWpWyVy1X7yqlWiWLIw9ncA6X4MEV1OAGGtAEBhE8wyu8Ocp5cd6dj2VrzslmTuEPnM8fSFeQCA==</latexit> Next Call Figure 2: Overview of the SimATTA framework. and sample ratio vectors when Dϕ,S(t) is not included, i.e., w′ and λ′ s.t. w′ 0 = λ′ 0 = 0 . If ˆdH∆H(DS, Dϕ,S(t)) < ˆdH∆H(DS, St i=1 Ute(i)), then for any λ ̸= λ′, there exists w s.t. EBS(w, λ, N, t) < EBS(w′, λ′, N, t). (8) Corollary 4 validates that the selected low-entropy samples can mitigate the CF problem under the assumption that these samples are source-like, which is also empirically validated in Fig. 1. Note that our strategy employs entropy minimization in a selective manner, aiming to solve CF rather than the main adaptation issue. While many FTTA works use entropy minimization to adapt across domains without guarantees, our use is more theoretically-sound. 4 A N ATTA ALGORITHM Building on our theoretical findings, we introduce a simple yet effective ATTA method, known as SimATTA, that innovatively integrates incremental clustering and selective entropy minimization techniques, as illustrated in Fig. 2. We start with an overview of our methodology, including the learning framework and the comprehensive sample selection strategies. We then proceed to discuss the details of the incremental clustering technique designed for real-time sample selections. 4.1 A LGORITHM OVERVIEW Let (x, y) be a labeled sample and f(·; θ) be our neural network, where ˆy = f(x; θ) and θ represents the parameters. We have a model pre-trained on source domains with the pre-trained parameters ϕ. We initialize model parameters as θ(0) = ϕ and aim to adapt the model f(·; θ) in real-time. During the test phase, the model continuously predicts labels for streaming-in test data and concurrently gets fine-tuned. We perform sample selection to enable active learning. As discussed in Sec. 3.2, we empirically consider informative high-entropy samples for addressing distribution shifts and source-like low-entropy samples to mitigate CF. As shown in Alg. 1, at each time step t, we first partition unlabeled test samples Ute(t) into high entropy and low entropy datasets, Uh(t) and Ul(t), using an entropy threshold. The source-pretrained model f(·; ϕ) is frozen to predict pseudo labels for low entropy data. We obtain labeled low-entropy data Dl(t) by labeling Ul(t) with f(·; ϕ) and combining it with Dl(t − 1). In contrast, the selection of high-entropy samples for active labeling is less straightforward. Since the complete test dataset is inaccessible for analyzing the target domain distribution, real-time sample selection is required. We design an incremental clustering sample selection technique to reduce sample redundancy and increase distribution coverage, detailed in Sec. 4.2. The incremental clustering algorithm outputs the labeled test samples Dh(t), also referred to as anchors, given Dh(t −1) and Uh(t). After sample selection, the model undergoes test-time training using the labeled test anchors Dh(t) and pseudo-labeled source-like anchors Dl(t). Following the analyses in Sec. 3.1, the training weights and sample numbers should satisfy w(t) ≈ λ(t) for Dh(t) and Dl(t) for optimal results. The analyses and results in Sec. 3.2 further indicate that balancing the source and target ratio is the key to mitigating CF. However, when source-like samples significantly outnumber test samples, the optimal w(t) for test domains can deviate from λ(t) according to Eq. (4). 4.2 I NCREMENTAL CLUSTERING We propose incremental clustering, a novel continual clustering technique designed to select informa- tive samples in unsupervised settings under the ATTA framework. The primary goal of this strategy is to store representative samples for distributions seen so far. Intuitively, we apply clusters to cover all seen distributions while adding new clusters to cover newly seen distributions. During this process with new clusters added, old clusters may be merged due to the limit of the cluster budget. Since 6Published as a conference paper at ICLR 2024 Algorithm 1 SIMATTA: A SIMPLE ATTA ALGORITHM Require: A fixed source pre-trained model f(·; ϕ) and a real-time adapting model f(·; θ(t)) with θ(0) = ϕ. Streaming test data Ute(t) at time step t. Entropy of predictions H(ˆy) = −P c p(ˆyc) logp(ˆyc). Low entropy and high entropy thresholds el and eh. The number of cluster centroid budget NC (t) at time step t. Centroid increase number k. Learning step size η. 1: for t = 1, . . . , Tdo 2: Model inference on Ute(t) using f(·; θ(t − 1)). 3: Dl(t) ← Dl(t − 1) ∪ {(x, f(x; ϕ))|x ∈ Ute(t), H(f(x; ϕ)) < el} 4: Uh(t) ← {x|x ∈ Ute(t), H(f(x; θ)) > eh} 5: Dh(t) ← Dh(t − 1) ∪ {(x, y)|∀x ∈ IC(Dh(t − 1), Uh(t), NC(t)), y= Oracle(x)} 6: λ(t) ← |Dl(t)|/(|Dl(t)| + |Dh(t)|), |Dh(t)|/(|Dl(t)| + |Dh(t)|) 7: w(t) ← GetW(λ(t)) ▷ Generally, GetW(λ(t)) = λ(t) is a fair choice. 8: θ(t) ← θ(t − 1) 9: for (xl, yl) in Dl and (xh, yh) in Dh do 10: θ(t) ← θ(t) − ηw0∇ℓCE (f(xl; θ(t)), yl) − η(1 − w0)∇ℓCE (f(xh; θ(t)), yh) 11: end for 12: NC (t + 1) ← UpdateCentroidNum(NC (t)) ▷ Naive choice: NC (t + 1) ← NC (t) + k. 13: end for clusters cannot be stored efficiently, we store the representative samples of clusters, named anchors, instead. In this work, we adopt weighted K-means (Krishna and Murty, 1999) as our base clustering method due to its popularity and suitability for new setting explorations. When we apply clustering with new samples, a previously selected anchor should not weigh the same as new samples since the anchor is a representation of a cluster,i.e., a representation of many samples. Instead, the anchor should be considered as a barycenter with a weight of the sum of its cluster’s sample weights. For a newly added cluster, its new anchor has the weight of the whole cluster. For clusters containing multiple old anchors, i.e., old clusters, the increased weights are distributed equally among these anchors. These increased weights are contributed by new samples that are close to these old anchors. Intuitively, this process of clustering is analogous to the process of planet formation. Where there are no planets, new planets (anchors) will be formed by the aggregation of the surrounding material (samples). Where there are planets, the matter is absorbed by the surrounding planets. This example is only for better understanding without specific technical meanings. Specifically, we provide the detailed Alg. 2 for incremental clustering. In each iteration, we apply weighted K-Means for previously selected anchors Danc and the new streaming-in unlabeled data Unew. We first extract all sample features using the model from the previous step f(·; θ(t − 1)), and then cluster these weighted features. The initial weights of the new unlabeled samples are 1, while anchors inherit weights from previous iterations. After clustering, clusters including old anchors are old clusters, while clusters only containing new samples are newly formed ones. For each new cluster, we select the centroid-closest sample as the new anchor to store. As shown in line 10 of Alg. 2, for both old and new clusters, we distribute the sample weights in this cluster as its anchors’ weights. With incremental clustering, although we can control the number of clusters in each iteration, we cannot control the number of new clusters/new anchors. This indirect control makes the increase of new anchors adaptive to the change of distributions, but it also leads to indirect budget control. Therefore, in experimental studies, we set the budget limit, but the actual anchor budget will not reach this limit. The overall extra storage requirement is O(B) since the number of saved unlabeled samples is proportional to the number of saved labeled samples (anchors). 5 E XPERIMENTAL STUDIES In this study, we aim to validate the effectiveness of our proposed method, as well as explore the various facets of the ATTA setting. Specifically, we design experiments around the following research questions: RQ1: Can TTA methods address domain distribution shifts? RQ2: Is ATTA as efficient as TTA? RQ3: How do the components of SimATTA perform? RQ4: Can ATTA perform on par with stronger Active Domain Adaptation (ADA) methods? We compare ATTA with three settings, TTA (Tab. 2), enhanced TTA (Tab. 3 and 5), and ADA (Tab. 4). Datasets. To assess the OOD performance of the TTA methods, we benchmark them using datasets from DomainBed (Gulrajani and Lopez-Paz, 2020) and Hendrycks and Dietterich (2019a). We employ PACS (Li et al., 2017), VLCS (Fang et al., 2013), Office-Home (Venkateswara et al., 2017), and Tiny-ImageNet-C datasets for our evaluations. For each dataset, we designate one domain as 7Published as a conference paper at ICLR 2024 Table 2: TTA comparisons on PACS and VLCS.This table includes the two data stream mentioned in the dataset setup and reports performances in accuracy. Results that outperform all TTA baselines are highlighted in bold font. N/A denotes the adaptations are not applied on the source domain. PACS Domain-wise data stream Post-adaptation Random data stream Post-adaptation P →A→ →C→ →S P A C S →1→ →2→ →3→ →4 P A C S BN w/o adapt 99.70 59.38 28.03 42.91 99.70 59.38 28.03 42.91 43.44 43.44 43.44 43.44 99.70 59.38 28.03 42.91BN w/ adapt 98.74 68.07 64.85 54.57 98.74 68.07 64.85 54.57 62.50 62.50 62.50 62.50 98.74 68.07 64.85 54.57 Tent (steps=1) N/A 67.29 64.59 44.67 97.60 66.85 64.08 42.58 56.35 54.09 51.83 48.58 97.19 63.53 60.75 41.56Tent (steps=10) N/A 67.38 57.85 20.23 62.63 34.52 40.57 13.59 47.36 31.01 22.84 20.33 50.78 23.68 20.95 19.62EATA N/A 67.04 64.72 50.27 98.62 66.50 62.46 48.18 57.31 56.06 58.17 59.78 98.62 69.63 65.70 54.26CoTTA N/A 65.48 62.12 53.17 98.62 65.48 63.10 53.78 56.06 54.33 57.16 57.42 98.62 65.97 62.97 54.62SAR (steps=1) N/A 66.75 63.82 49.58 98.32 66.94 62.93 45.74 56.78 56.35 56.68 56.70 98.44 68.16 64.38 52.53SAR (steps=10) N/A 69.38 68.26 49.02 96.47 62.16 56.19 54.62 53.51 51.15 51.78 45.60 94.13 56.64 56.02 36.37 SimATTA (B ≤300) N/A 76.86 70.90 75.39 98.80 84.47 82.25 81.52 69.47 76.49 82.45 82.22 98.98 84.91 83.92 86.00SimATTA (B ≤500) N/A 77.93 76.02 76.30 98.62 88.33 83.49 83.74 68.46 78.22 80.91 85.49 99.16 86.67 84.77 87.71 VLCS Domain-wise data stream Post-adaptation Random data stream Post-adaptation C →L→ →S→ →V C L S V →1→ →2→ →3→ →4 C L S V BN w/o adapt 100.00 33.55 41.10 49.05 100.00 33.55 41.10 49.05 41.23 41.23 41.23 41.23 100.00 33.55 41.10 49.05BN w/ adapt 85.16 37.31 33.27 52.16 85.16 37.31 33.27 52.16 40.91 40.91 40.91 40.91 85.16 37.31 33.27 52.16 Tent (steps=1) N/A 38.55 34.40 53.88 84.73 43.86 33.61 53.11 44.85 44.29 47.38 44.98 85.30 43.49 37.81 53.35Tent (steps=10) N/A 45.41 31.44 32.32 42.54 37.65 27.79 33.12 46.13 42.31 43.51 39.48 52.01 40.32 33.64 40.37EATA N/A 37.24 33.15 52.58 84.10 37.69 32.39 52.49 43.77 42.48 43.34 41.55 83.32 36.67 31.47 52.55CoTTA N/A 37.39 32.54 52.25 82.12 37.65 33.12 52.90 43.69 42.14 43.21 42.32 81.98 37.99 33.52 53.23SAR (steps=1) N/A 36.18 34.43 52.46 83.96 39.72 36.53 52.37 43.64 43.04 44.20 41.93 85.09 40.70 36.44 53.02SAR (steps=10) N/A 35.32 34.10 51.66 82.12 41.49 33.94 53.08 43.56 42.05 42.53 41.16 85.09 37.58 33.12 52.01 SimATTA (B ≤300) N/A 62.61 65.08 74.38 99.93 69.50 66.67 77.34 62.33 69.33 73.20 71.93 99.93 69.43 72.46 80.39SimATTA (B ≤500) N/A 63.52 68.01 76.13 99.51 70.56 73.10 78.35 62.29 70.45 73.50 72.02 99.43 70.29 72.55 80.18 the source domain and arrange the samples from the other domains to form the test data stream. For DomainBed datasets, we adopt two stream order strategies. The first order uses a domain-wise data stream, i.e., we finish streaming samples from one domain before starting streaming another domain. The second order is random, where we shuffle samples from all target domains and partition them into four splits 1, 2, 3, and 4, as shown in Tab. 2. More dataset details are provided in Appx. G.1. Baselines. For baseline models, we start with the common source-only models, which either utilize pre-calculated batch statistics (BN w/o adapt) or test batch statistics (BN w/ adapt). For comparison with other TTA methods, we consider four state-of-the-art TTA methods: Tent (Wang et al., 2021), EATA (Niu et al., 2022), CoTTA (Wang et al., 2022a), and SAR (Niu et al., 2023). The three of them except Tent provide extra design to avoid CF. To compare with ADA methods, we select algorithms that are partially comparable with our method, i.e., they should be efficient (e.g., uncertainty-based) without the requirements of additional networks. Therefore, we adopt random, entropy (Wang and Shang, 2014), k-means (Krishna and Murty, 1999), and CLUE (Prabhu et al., 2021) for comparisons. Settings. For TTA, we compare with general TTA baselines in streaming adaptation using the two aforementioned data streaming orders, domain-wise and random. We choose P in PACS and C in VLCS as source domains. For domain-wise data stream, we use order A → C → S for PACS and L → S → V for VLCS. We report the real-time adaptation accuracy results for each split of the data stream, as well as the accuracy on each domain after all adaptations through the data stream (under “post-adaptation” columns). Enhanced TTA is built on TTA with access to extra random sample labels. TTA baselines are further fine-tuned with these random samples. To further improve enhanced TTA, we use long-term label storage and larger unlabeled sample pools. To its extreme where the model can access the whole test set samples, the setting becomes similar to ADA, thus we also use ADA methods for comparisons. ADA baselines have access to all samples in the pre-collected target datasets but not source domain data, whereas our method can only access the streaming test data. 5.1 T HE FAILURE OF TEST-TIME ADAPTATION The failure of TTA methods on domain distribution shifts is one of the main motivations of the ATTA setting. As shown in Tab. 2, TTA methods cannot consistently outperform eventhe simplest baseline \"BN w/ adapt\" which uses test time batch statistics to make predictions, evidencing that current TTA methods cannot solve domain distribution shifts (RQ1). Additionally, Tent (step=10) exhibits significant CF issues, where \"step=10\" indicates 10 test-time training updates, i.e., 10 gradient backpropagation iterations. This failure of TTA methods necessitates the position of ATTA. In contrast, SimATTA, with a budget B less than 300, outperforms all TTA methods on both source and target domains by substantial margins. Moreover, compared to the source-only baselines, our method improves the target domain performances significantly with negligible source performance loss, showing that ATTA is a more practically effective setting for real-world distribution shifts. 5.2 E FFICIENCY & ENHANCED TTA SETTING COMPARISONS To validate the efficiency of ATTA and broaden the dataset choice, we conduct this study on Tiny- ImageNet-C which, though does not focus on domain shifts, is much larger than PACS and VLCS. we 8Published as a conference paper at ICLR 2024 Table 3: Comparisons with Enhanced TTA on Tiny-ImageNet-C (severity level 5). Tiny-ImageNet-C Time (sec)Noise Blur Weather Digital Gauss. Shot Impul. Defoc. Glass Motion Zoom Snow Frost Fog Contr. Elastic Pixel JPEG Avg. Tent (step=1) 68.83 9.32 11.97 8.86 10.43 7.00 12.20 14.34 13.58 15.46 13.55 3.99 13.31 17.79 18.61 12.17Tent (step=10) 426.90 0.86 0.63 0.52 0.52 0.55 0.54 0.50 0.50 0.50 0.50 0.50 0.50 0.50 0.50 0.54EATA 93.14 3.98 3.33 2.18 4.80 2.37 11.02 11.41 14.06 15.26 9.65 1.36 9.88 14.24 12.12 8.26CoTTA 538.78 5.63 7.12 6.31 8.05 5.74 9.68 10.55 11.75 12.00 11.15 4.17 5.35 7.82 8.90 8.16SAR (step=1) 113.76 8.90 3.11 1.67 1.55 1.47 1.35 1.19 1.03 1.04 0.93 0.83 1.00 0.74 0.77 1.83SAR (step=10) 774.11 2.67 3.26 2.38 1.64 1.85 2.49 3.16 3.81 2.72 3.12 0.81 3.47 4.04 1.76 2.66 SimATTA (step=10) 736.289.68 19.40 12.14 30.28 17.03 42.36 43.10 31.96 40.08 29.243.21 34.56 45.24 45.74 28.86 enhance the TTA setting by fine-tuning baselines on randomly selected labeled samples. Specifically, the classifier of ResNet18-BN is pre-adapted to the brightness corruption (source domain) before test-time adapting. SimATTA’s label budget is around 4,000, while all other TTA methods have budget 4,500 for randomly selected labeled samples. The data stream order is shown in Tab. 3. Time is measured across all corrupted images in the Noise and Blur noise types, and the values represent the average time cost for adapting 10,000 images. The results clearly evidence the efficiency of ATTA (RQ2), while substantially outperforming all enhanced TTA baselines. Simply accessing labeled samples cannot benefit TTA methods to match ATTA. With 10 training updates (step=10) for each batch, FTTA methods would suffer from severe CF problem. In contrast, ATTA covers a statistically significant distribution, achieving stronger performances with 10 training updates or even more steps till approximate convergences. In fact, longer training on Tent (step=10) leads to worse results (compared to step=1), which further motivates the design of the ATTA setting. The reason for higher absolute time cost in Tab. 3 is due to differences in training steps. In this experiment, SimATTA has a training step of 10, and similar time cost as SAR per step. Note that if the enhanced TTA setting is further improved to maintain distributions with a balanced CF mitigation strategy and an incremental clustering design, the design approaches ATTA. Specifically, we compare SimATTA with its variants as the ablation study (RQ3) in Appx. I.2. 5.3 C OMPARISONS TO A STRONGER SETTING : ACTIVE DOMAIN ADAPTATION Table 4: Comparisons to ADA baselines. Source domains are denoted as \"(S)\". Results are average accuracies (with standard deviations). PACS P (S) A C S Random (B= 300) 96.21 (0.80) 81.19 (0.48) 80.75 (1.27) 84.34 (0.18)Entropy (B= 300) 96.31 (0.64)88.00 (1.46)82.48 (1.71) 80.55 (1.01)Kmeans (B= 300) 93.71 (1.50) 79.31 (4.01) 79.64 (1.44) 83.92 (0.65)CLUE (B= 300) 96.69 (0.17)83.97 (0.57)84.77 (0.88) 86.91 (0.26) SimATTA (B ≤300) 98.89 (0.09)84.69 (0.22)83.09 (0.83)83.76 (2.24) VLCS C (S) L S V Random (B= 300) 96.21 (1.65) 66.67 (1.70) 70.72 (0.30) 72.14 (1.71)Entropy (B= 300) 97.74 (1.56) 69.29 (2.26)69.25 (4.77) 75.26 (3.07)Kmeans (B= 300) 98.61 (0.27)67.57 (1.64)70.77 (0.01)74.49 (0.97)CLUE (B= 300) 85.70 (10.09) 65.29 (1.49) 69.42 (2.64) 69.09 (6.05) SimATTA (B ≤300) 99.93 (0.00) 69.47 (0.03)69.57 (2.90)78.87 (1.53) In addtion to the above comparisons with (en- hanced) TTA, which necessitate the requirement of extra information in the ATTA setting, we com- pare ATTA with a stronger setting Active Domain Adaptation (ADA) to demonstrate another supe- riority of ATTA, i.e., weaker requirements for comparable performances (RQ4). ADA baselines are able to choose the global best active samples, while ATTA has to choose samples from a small sample buffer (e.g., a size of 100) and discard the rest. Tab. 4 presents the post-adaptation model per- formance results. All ADA results are averaged from 3 random runs, while ATTA results are the post-adaptation performances averaged from the two data stream orders. As can be observed, despite the lack of a pre-collected target dataset, SimATTA produces better or competitive results against ADA methods. Moreover, without source data access, SimATTA’s design for CF allows it to maintain superior source domain performances over ADA methods. Further experimental studies including the Office-Home dataset are provided in Appx. I. In conclusion, the significant improvement compared to weaker settings (TTA, enhanced TTA) and the comparable performance with the stronger setting, ADA, rendering ATTA a setting that is as efficient as TTA and as effective as ADA. This implies its potential is worthy of future explorations. 6 C ONCLUSION AND DISCUSSION There’s no denying that OOD generalization can be extremely challenging without certain information, often relying on various assumptions easily compromised by different circumstances. Thus, it’s prudent to seek methods to achieve significant improvements with minimal cost, e.g., DG methods leveraging environment partitions and ATTA methods using budgeted annotations. As justified in our theoretical and experimental studies, ATTA stands as a robust approach to achieve real-time OOD generalization. Although SimATTA sets a strong baseline for ATTA, there’s considerable scope for further investigation within the ATTA setting. One potential direction involves developing alternatives to prevent CF in ATTA scenarios. While selective entropy minimization on low-entropy samples has prove to be empirically effective, it relies on the quality of the pre-trained model and training on incorrectly predicted low-entropy samples may reinforce the errors. It might not be cost-effective to expend annotation budgets on low-entropy samples, but correcting them could be a viable alternative solution. We anticipate that our work will spur numerous further explorations in this field. 9Published as a conference paper at ICLR 2024 ACKNOWLEDGMENTS This work was supported in part by National Science Foundation grant IIS-2006861 and National Institutes of Health grant U01AG070112. REFERENCES Hana Ajakan, Pascal Germain, Hugo Larochelle, François Laviolette, and Mario Marchand. Domain- adversarial neural networks. arXiv preprint arXiv:1412.4446, 2014. Lucas Baier, Tim Schlör, Jakob Schöffer, and Niklas Kühl. Detecting concept drift with neural network model uncertainty. In Hawaii International Conference on System Sciences, 2021. URL https://api.semanticscholar.org/CorpusID:235731947. Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman Vaughan. A theory of learning from different domains. Machine learning, 79:151–175, 2010. Davide Cacciarelli and Murat Kulahci. A survey on online active learning, 2023. Cheng Chen, Quande Liu, Yueming Jin, Qi Dou, and Pheng-Ann Heng. Source-free domain adaptive fundus image segmentation with denoised pseudo-labeling. In Medical Image Computing and Computer Assisted Intervention–MICCAI 2021: 24th International Conference, Strasbourg, France, September 27–October 1, 2021, Proceedings, Part V 24, pages 225–235. Springer, 2021. Li Chen, Tutian Tang, Zhitian Cai, Yang Li, Penghao Wu, Hongyang Li, Jianping Shi, Junchi Yan, and Yu Qiao. Level 2 autonomous driving on a single device: Diving into the devils of openpilot. arXiv preprint arXiv:2206.08176, 2022a. Weijie Chen, Luojun Lin, Shicai Yang, Di Xie, Shiliang Pu, and Yueting Zhuang. Self-supervised noisy label learning for source-free unsupervised domain adaptation. In 2022 IEEE/RSJ In- ternational Conference on Intelligent Robots and Systems (IROS) , pages 10185–10192. IEEE, 2022b. Yining Chen, Colin Wei, Ananya Kumar, and Tengyu Ma. Self-training avoids using spurious features under domain shift. Advances in Neural Information Processing Systems, 33:21061–21071, 2020. David A Cohn, Zoubin Ghahramani, and Michael I Jordan. Active learning with statistical models. Journal of artificial intelligence research, 4:129–145, 1996. Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Aleš Leonardis, Gregory Slabaugh, and Tinne Tuytelaars. A continual learning survey: Defying forgetting in classification tasks. IEEE transactions on pattern analysis and machine intelligence, 44(7):3366–3385, 2021. Yuhe Ding, Lijun Sheng, Jian Liang, Aihua Zheng, and Ran He. Proxymix: Proxy-based mixup training with label refinery for source-free domain adaptation. arXiv preprint arXiv:2205.14566, 2022. Cian Eastwood, Ian Mason, Christopher KI Williams, and Bernhard Schölkopf. Source-free adaptation to measurement shift via bottom-up feature restoration. arXiv preprint arXiv:2107.05446, 2021. Jiahao Fan, Hangyu Zhu, Xinyu Jiang, Long Meng, Chen Chen, Cong Fu, Huan Yu, Chenyun Dai, and Wei Chen. Unsupervised domain adaptation by statistics alignment for deep sleep staging networks. IEEE Transactions on Neural Systems and Rehabilitation Engineering, 30:205–216, 2022. Chen Fang, Ye Xu, and Daniel N Rockmore. Unbiased metric learning: On the utilization of multiple datasets and web images for softening bias. In Proceedings of the IEEE International Conference on Computer Vision, pages 1657–1664, 2013. Yuqi Fang, Pew-Thian Yap, Weili Lin, Hongtu Zhu, and Mingxia Liu. Source-free unsupervised domain adaptation: A survey. arXiv preprint arXiv:2301.00265, 2022. Francois Fleuret et al. Uncertainty reduction for model adaptation in semantic segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 9613–9623, 2021. 10Published as a conference paper at ICLR 2024 Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In International conference on machine learning, pages 1180–1189. PMLR, 2015. Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, François Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural networks. The journal of machine learning research, 17(1):2096–2030, 2016. Jakob Gawlikowski, Cedrique Rovile Njieutcheu Tassi, Mohsin Ali, Jongseok Lee, Matthias Humt, Jianxiang Feng, Anna Kruspe, Rudolph Triebel, Peter Jung, Ribana Roscher, et al. A survey of uncertainty in deep neural networks. arXiv preprint arXiv:2107.03342, 2021. Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. Advances in neural information processing systems, 17, 2004. Shurui Gui, Chaoyue Wang, Qihua Chen, and Dacheng Tao. Featureflow: Robust video interpolation via structure-to-texture generation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 14004–14013, 2020. Shurui Gui, Xiner Li, Limei Wang, and Shuiwang Ji. GOOD: A graph out-of-distribution benchmark. In Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track, 2022. URL https://openreview.net/forum?id=8hHg-zs_p-h. Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. arXiv preprint arXiv:2007.01434, 2020. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770–778, 2016. Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. March 2019a. doi: 10.48550/ARXIV .1903.12261. Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. arXiv preprint arXiv:1903.12261, 2019b. Steven CH Hoi, Rong Jin, Jianke Zhu, and Michael R Lyu. Semisupervised svm batch mode active learning with applications to image retrieval. ACM Transactions on Information Systems (TOIS), 27(3):1–29, 2009. Yihan Hu, Jiazhi Yang, Li Chen, Keyu Li, Chonghao Sima, Xizhou Zhu, Siqi Chai, Senyao Du, Tianwei Lin, Wenhai Wang, et al. Planning-oriented autonomous driving. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 17853–17862, 2023. Jiaxing Huang, Dayan Guan, Aoran Xiao, and Shijian Lu. Model adaptation: Historical contrastive learning for unsupervised domain adaptation without source data. Advances in Neural Information Processing Systems, 34:3635–3649, 2021. Masato Ishii and Masashi Sugiyama. Source-free domain adaptation via distributional alignment by matching batch normalization statistics. arXiv preprint arXiv:2101.10842, 2021. Yusuke Iwasawa and Yutaka Matsuo. Test-time classifier adjustment module for model-agnostic domain generalization. Advances in Neural Information Processing Systems, 34:2427–2440, 2021. Suyog Dutt Jain and Kristen Grauman. Active image segmentation propagation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2864–2873, 2016. Guoliang Kang, Lu Jiang, Yi Yang, and Alexander G Hauptmann. Contrastive adaptation network for unsupervised domain adaptation. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 4893–4902, 2019. Ashish Kapoor, Kristen Grauman, Raquel Urtasun, and Trevor Darrell. Active learning with gaussian processes for object categorization. In 2007 IEEE 11th international conference on computer vision, pages 1–8. IEEE, 2007. Neerav Karani, Ertunc Erdil, Krishna Chaitanya, and Ender Konukoglu. Test-time adaptable neural networks for robust medical image segmentation. Medical Image Analysis, 68:101907, 2021. 11Published as a conference paper at ICLR 2024 Ronald Kemker, Marc McClure, Angelina Abitino, Tyler Hayes, and Christopher Kanan. Measuring catastrophic forgetting in neural networks. In Proceedings of the AAAI conference on artificial intelligence, volume 32, 2018. Daniel Kifer, Shai Ben-David, and Johannes Gehrke. Detecting change in data streams. In VLDB, volume 4, pages 180–191. Toronto, Canada, 2004. James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. Overcoming catastrophic forgetting in neural networks. Proceedings of the national academy of sciences, 114 (13):3521–3526, 2017. Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Bal- subramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, et al. Wilds: A benchmark of in-the-wild distribution shifts. In International Conference on Machine Learning, pages 5637–5664. PMLR, 2021. Divya Kothandaraman, Sumit Shekhar, Abhilasha Sancheti, Manoj Ghuhan, Tripti Shukla, and Dinesh Manocha. Salad: Source-free active label-agnostic domain adaptation for classification, segmentation and detection. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 382–391, 2023. K Krishna and M Narasimha Murty. Genetic k-means algorithm. IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics), 29(3):433–439, 1999. Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolu- tional neural networks. Communications of the ACM, 60(6):84–90, 2017. David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai Zhang, Remi Le Priol, and Aaron Courville. Out-of-distribution generalization via risk extrap- olation (REx). In International Conference on Machine Learning , pages 5815–5826. PMLR, 2021. Vinod K Kurmi, Venkatesh K Subramanian, and Vinay P Namboodiri. Domain impression: A source data free domain adaptation method. In Proceedings of the IEEE/CVF winter conference on applications of computer vision, pages 615–625, 2021. David D Lewis and Jason Catlett. Heterogeneous uncertainty sampling for supervised learning. In Machine learning proceedings 1994, pages 148–156. Elsevier, 1994. Aodong Li, Alex Boyd, Padhraic Smyth, and Stephan Mandt. Detecting and adapting to irregular distribution shifts in bayesian online learning. Advances in neural information processing systems, 34:6816–6828, 2021a. Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M Hospedales. Deeper, broader and artier domain generalization. In Proceedings of the IEEE international conference on computer vision, pages 5542–5550, 2017. Rui Li, Qianfen Jiao, Wenming Cao, Hau-San Wong, and Si Wu. Model adaptation: Unsupervised domain adaptation without source data. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 9641–9650, 2020. Xianfeng Li, Weijie Chen, Di Xie, Shicai Yang, Peng Yuan, Shiliang Pu, and Yueting Zhuang. A free lunch for unsupervised domain adaptive object detection without source data. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 8474–8481, 2021b. Zhizhong Li and Derek Hoiem. Learning without forgetting. IEEE transactions on pattern analysis and machine intelligence, 40(12):2935–2947, 2017. Jian Liang, Dapeng Hu, Ran He, and Jiashi Feng. Distill and fine-tune: Effective adaptation from a black-box source model. arXiv preprint arXiv:2104.01539, 1(3), 2021. Jian Liang, Dapeng Hu, Jiashi Feng, and Ran He. Dine: Domain adaptation from single and multiple black-box predictors. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8003–8013, 2022. 12Published as a conference paper at ICLR 2024 Yong Lin, Shengyu Zhu, Lu Tan, and Peng Cui. Zin: When and how to learn invariance without environment partition? Advances in Neural Information Processing Systems, 35:24529–24542, 2022. Xiaofeng Liu, Fangxu Xing, Chao Yang, Georges El Fakhri, and Jonghye Woo. Adapting off-the- shelf source segmenter for target medical image segmentation. In Medical Image Computing and Computer Assisted Intervention–MICCAI 2021: 24th International Conference, Strasbourg, France, September 27–October 1, 2021, Proceedings, Part II 24, pages 549–559. Springer, 2021a. Xinyu Liu and Yixuan Yuan. A source-free domain adaptive polyp detection framework with style diversification flow. IEEE Transactions on Medical Imaging, 41(7):1897–1908, 2022. Yuang Liu, Wei Zhang, Jun Wang, and Jianyong Wang. Data-free knowledge transfer: A survey. arXiv preprint arXiv:2112.15278, 2021b. Yuejiang Liu, Parth Kothari, Bastien Van Delft, Baptiste Bellot-Gurlet, Taylor Mordan, and Alexandre Alahi. Ttt++: When does self-supervised test-time training fail or thrive? Advances in Neural Information Processing Systems, 34:21808–21820, 2021c. Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan. Learning transferable features with deep adaptation networks. In International conference on machine learning, pages 97–105. PMLR, 2015. David Lopez-Paz and Marc’Aurelio Ranzato. Gradient episodic memory for continual learning. Advances in neural information processing systems, 30, 2017. Chaochao Lu, Yuhuai Wu, José Miguel Hernández-Lobato, and Bernhard Schölkopf. Invariant causal representation learning for out-of-distribution generalization. In International Conference on Learning Representations, 2021. Xinhong Ma, Junyu Gao, and Changsheng Xu. Active universal domain adaptation. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 8968–8977, 2021. Haitao Mao, Lun Du, Yujia Zheng, Qiang Fu, Zelin Li, Xu Chen, Shi Han, and Dongmei Zhang. Source free unsupervised graph domain adaptation. arXiv preprint arXiv:2112.00955, 2021. Christoforos Mavrogiannis, Francesca Baldini, Allan Wang, Dapeng Zhao, Pete Trautman, Aaron Steinfeld, and Jean Oh. Core challenges of social robot navigation: A survey. ACM Transactions on Human-Robot Interaction, 12(3):1–39, 2023. Zachary Nado, Shreyas Padhy, D Sculley, Alexander D’Amour, Balaji Lakshminarayanan, and Jasper Snoek. Evaluating prediction-time batch normalization for robustness under covariate shift. arXiv preprint arXiv:2006.10963, 2020. Munan Ning, Donghuan Lu, Dong Wei, Cheng Bian, Chenglang Yuan, Shuang Yu, Kai Ma, and Yefeng Zheng. Multi-anchor active domain adaptation for semantic segmentation. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 9112–9122, 2021. Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan. Efficient test-time model adaptation without forgetting. In International conference on machine learning, pages 16888–16905. PMLR, 2022. Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Zhiquan Wen, Yaofo Chen, Peilin Zhao, and Mingkui Tan. Towards stable test-time adaptation in dynamic wild world. InThe Eleventh International Con- ference on Learning Representations, 2023. URL https://openreview.net/forum?id=g2YraF75Tj. Sinno Jialin Pan, Ivor W Tsang, James T Kwok, and Qiang Yang. Domain adaptation via transfer component analysis. IEEE transactions on neural networks, 22(2):199–210, 2010. Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. Advances in neural information processing systems, 32, 2019. 13Published as a conference paper at ICLR 2024 Vishal M Patel, Raghuraman Gopalan, Ruonan Li, and Rama Chellappa. Visual domain adaptation: A survey of recent advances. IEEE signal processing magazine, 32(3):53–69, 2015. Judea Pearl. Causality. Cambridge university press, 2009. Fabian Pedregosa, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et al. Scikit-learn: Machine learning in python. the Journal of machine Learning research, 12:2825–2830, 2011. Jonas Peters, Peter Bühlmann, and Nicolai Meinshausen. Causal inference by using invariant prediction: identification and confidence intervals. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 78(5):947–1012, 2016. Jonas Peters, Dominik Janzing, and Bernhard Schölkopf. Elements of causal inference: foundations and learning algorithms. The MIT Press, 2017. Viraj Prabhu, Arjun Chandrasekaran, Kate Saenko, and Judy Hoffman. Active domain adaptation via clustering uncertainty-weighted embeddings. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 8505–8514, 2021. Elan Rosenfeld, Pradeep Ravikumar, and Andrej Risteski. The risks of invariant risk minimization. arXiv preprint arXiv:2010.05761, 2020. Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization. arXiv preprint arXiv:1911.08731, 2019. Shibani Santurkar, Dimitris Tsipras, Andrew Ilyas, and Aleksander Madry. How does batch normal- ization help optimization? Advances in neural information processing systems, 31, 2018. Akanksha Saran, Safoora Yousefi, Akshay Krishnamurthy, John Langford, and Jordan T. Ash. Streaming active learning with deep neural networks. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors, Proceedings of the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pages 30005–30021. PMLR, 23–29 Jul 2023. URL https://proceedings.mlr. press/v202/saran23a.html. Harald Schafer, Eder Santana, Andrew Haden, and Riccardo Biasini. A commute in data: The comma2k19 dataset, 2018. Tobias Scheffer, Christian Decomain, and Stefan Wrobel. Active hidden markov models for informa- tion extraction. In Advances in Intelligent Data Analysis: 4th International Conference, IDA 2001 Cascais, Portugal, September 13–15, 2001 Proceedings 4, pages 309–318. Springer, 2001. Steffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bringmann, Wieland Brendel, and Matthias Bethge. Improving robustness against common corruptions by covariate shift adaptation. Advances in Neural Information Processing Systems, 33:11539–11551, 2020. Burr Settles. Active learning literature survey. 2009. Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014. Jong-Chyi Su, Yi-Hsuan Tsai, Kihyuk Sohn, Buyu Liu, Subhransu Maji, and Manmohan Chandraker. Active adversarial domain adaptation. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 739–748, 2020. Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation. In European conference on computer vision, pages 443–450. Springer, 2016. Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt. Test-time training with self-supervision for generalization under distribution shifts. In International conference on machine learning, pages 9229–9248. PMLR, 2020. 14Published as a conference paper at ICLR 2024 Yi-Hsuan Tsai, Wei-Chih Hung, Samuel Schulter, Kihyuk Sohn, Ming-Hsuan Yang, and Manmohan Chandraker. Learning to adapt structured output space for semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 7472–7481, 2018. Eric Tzeng, Judy Hoffman, Trevor Darrell, and Kate Saenko. Simultaneous deep transfer across domains and tasks. In Proceedings of the IEEE international conference on computer vision, pages 4068–4076, 2015. Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell. Adversarial discriminative domain adaptation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 7167–7176, 2017. Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman Panchanathan. Deep hashing network for unsupervised domain adaptation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 5018–5027, 2017. Sudheendra Vijayanarasimhan and Ashish Kapoor. Visual recognition and detection under bounded computational resources. In 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pages 1006–1013. IEEE, 2010. Dan Wang and Yi Shang. A new active labeling method for deep learning. In 2014 International joint conference on neural networks (IJCNN), pages 112–119. IEEE, 2014. Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, and Trevor Darrell. Tent: Fully test- time adaptation by entropy minimization. InInternational Conference on Learning Representations, 2021. URL https://openreview.net/forum?id=uXl3bZLkr3c. Mei Wang and Weihong Deng. Deep visual domain adaptation: A survey. Neurocomputing, 312: 135–153, 2018. Qin Wang, Olga Fink, Luc Van Gool, and Dengxin Dai. Continual test-time domain adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7201–7211, 2022a. Rui Wang, Zuxuan Wu, Zejia Weng, Jingjing Chen, Guo-Jun Qi, and Yu-Gang Jiang. Cross-domain contrastive learning for unsupervised domain adaptation. IEEE Transactions on Multimedia , 2022b. Garrett Wilson and Diane J Cook. A survey of unsupervised deep domain adaptation. ACM Transactions on Intelligent Systems and Technology (TIST), 11(5):1–46, 2020. Binhui Xie, Longhui Yuan, Shuang Li, Chi Harold Liu, Xinjing Cheng, and Guoren Wang. Active learning for domain adaptation: An energy-based approach. InProceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 8708–8716, 2022. Zhao Xu, Kai Yu, V olker Tresp, Xiaowei Xu, and Jizhi Wang. Representative sampling for text classification using support vector machines. In Advances in Information Retrieval: 25th European Conference on IR Research, ECIR 2003, Pisa, Italy, April 14–16, 2003. Proceedings 25, pages 393–407. Springer, 2003. Baoyao Yang, Hao-Wei Yeh, Tatsuya Harada, and Pong C Yuen. Model-induced generalization error bound for information-theoretic representation learning in source-data-free unsupervised domain adaptation. IEEE Transactions on Image Processing, 31:419–432, 2021a. Guanglei Yang, Hao Tang, Zhun Zhong, Mingli Ding, Ling Shao, Nicu Sebe, and Elisa Ricci. Transformer-based source-free domain adaptation. arXiv preprint arXiv:2105.14138, 2021b. Jianfei Yang, Xiangyu Peng, Kai Wang, Zheng Zhu, Jiashi Feng, Lihua Xie, and Yang You. Divide to adapt: Mitigating confirmation bias for domain adaptation of black-box predictors. arXiv preprint arXiv:2205.14467, 2022. H Yao, Yuhong Guo, and Chunsheng Yang. Source-free unsupervised domain adaptation with surrogate data generation. In Proceedings of NeurIPS 2021 Workshop on Distribution Shifts: Connecting Methods and Applications, 2021. 15Published as a conference paper at ICLR 2024 Hao-Wei Yeh, Baoyao Yang, Pong C Yuen, and Tatsuya Harada. Sofa: Source-data-free feature alignment for unsupervised domain adaptation. InProceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 474–483, 2021. Fuming You, Jingjing Li, and Zhou Zhao. Test-time batch statistics calibration for covariate shift. arXiv preprint arXiv:2110.04065, 2021. Hu Yu, Jie Huang, Yajing Liu, Qi Zhu, Man Zhou, and Feng Zhao. Source-free domain adaptation for real-world image dehazing. In Proceedings of the 30th ACM International Conference on Multimedia, pages 6645–6654, 2022. Haojian Zhang, Yabin Zhang, Kui Jia, and Lei Zhang. Unsupervised domain adaptation of black-box source models. arXiv preprint arXiv:2101.02839, 2021. Marvin Zhang, Sergey Levine, and Chelsea Finn. Memo: Test time robustness via adaptation and augmentation. Advances in Neural Information Processing Systems, 35:38629–38642, 2022a. Yifan Zhang, Xue Wang, Kexin Jin, Kun Yuan, Zhang Zhang, Liang Wang, Rong Jin, and Tieniu Tan. Adanpc: Exploring non-parametric classifier for test-time adaptation. In International Conference on Machine Learning, pages 41647–41676. PMLR, 2023. Yizhe Zhang, Shubhankar Borse, Hong Cai, and Fatih Porikli. Auxadapt: Stable and efficient test-time adaptation for temporally consistent video semantic segmentation. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 2339–2348, 2022b. Bowen Zhao, Chen Chen, and Shu-Tao Xia. Delta: degradation-free fully test-time adaptation. arXiv preprint arXiv:2301.13018, 2023a. Hao Zhao, Yuejiang Liu, Alexandre Alahi, and Tao Lin. On pitfalls of test-time adaptation. In International Conference on Machine Learning (ICML), 2023b. Chunting Zhou, Xuezhe Ma, Paul Michel, and Graham Neubig. Examining and combating spurious features under distribution shift. In International Conference on Machine Learning, pages 12857– 12867. PMLR, 2021. 16Published as a conference paper at ICLR 2024 Active Test-Time Adaptation: Foundational Analyses and An Algorithm Supplementary Material A B ROADER IMPACTS The field of domain generalization primarily concentrates on enhancing a model’s generalization abilities by preparing it thoroughly before deployment. However, it is equally important for deep learning applications to have the capacity for real-time adaptation, as no amount of preparation can account for all possible scenarios. Consequently, domain generalization and test-time adaptation are complementary strategies: the former is more weighty and extensive, while the latter is more agile, lightweight and privacy-friendly. This work delves into the development of a real-time model adaptation strategy that can be applied to any pre-trained models, including large language models, to enhance their adaptive capabilities. Our research does not involve any human subjects or dataset releases, nor does it raise any ethical concerns. Since this work does not directly tie to specific applications, we do not foresee any immediate negative societal impacts. Nonetheless, we acknowledge that any technological advancement may carry potential risks, and we encourage the continued assessment of the broader impacts of real-time adaptation methodologies in various contexts. B FAQ & D ISCUSSIONS To facilitate the reviewing process, we summarize the answers to the questions that arose during the discussion of an earlier version of this paper. The major updates of this version are reorganized theoretical studies, incremental clustering details, experimental reorganization, and additional datasets and settings . We include more related field comparisons to distinguish different settings. We also cover the position of this paper in literature and the main claims of this paper. Finally, we will frankly acknowledge the limitations of this paper, explain and justify the scope of coverage, and provide possible future directions. Q1: What is the relationship between the proposed ATTA protocol and stream based active learning (Saran et al., 2023)? A: We would like to discuss the difference between our work and the referenced work. 1. Real-time Training Distinction: Saran et al. (2023) doesn’t operate in real-time capacity. This is evident from their experiments, where their model is trained only after completing a round. In contrast, our work involves training the model post each batch. This positions Saran et al. (2023)’s work as an intrinsic active learning technique, while our approach leans towards TTA methods. 2. Continual Training Nuance: Following the point above, Saran et al. (2023) stands out of the scope of continual training. As they mentioned ‘each time new data are acquired, the ResNet is reset to the ImageNet pre-trained weights before being updated‘, Saran et al. (2023) starts afresh with each iteration and is out of scope for CF discussions. Contrarily, our model is continuously trained on varying distributions, compelling us to address the CF issue while preserving advantages derived from various stored distributions. 3. Comparative Complexity: Given the aforementioned distinctions, it’s evident that our task presents a greater challenge compared to theirs. In addition, we have included comparisons with stronger active learning settings in Sec. 5.3. Q2: What are the insights from the theoretically foundational analysis? A: 1. It sets a well-defined formulation and grounded theoretical framework for the ATTA setting. 2. While entropy minimizations can cause CF, balancing the learning rate and number of high/low entropy samples is conversely the key solution to both distribution shifts and 17Published as a conference paper at ICLR 2024 CF by corresponding benefits. Though adding low-entropy data is intuitive, it is crucial in that this simple operation can make methods either too conservative or too aggressive without the correct balancing conditions. 3. The studies in Sec. 3.1 directly present a feasible and guaranteed solution for imple- menting ATTA to tackle shifts while avoiding CF. The aligned empirical validations of Sec. 3.2 also instruct the implementation of SimATTA. Q3: In test-time adaptation, one important issue is that the number of testing samples in a batch may be small, which means the sample size m will also be very small. May it affect the theorem and make them become very loose? A: We consider this issue jointly from theoretical and empirical validations. 1. It is true that the theoretical bounds can be loose given a small size of m unlabeled test samples. This situation of the error bound is mathematically ascribed to the quotient between the VC-dimension d of the hypothesis class and m. Under the VC-dimension theory, the ResNet18 model we adopt should have d ≫ m. However, practically we perform fine-tuning on pre-trained models instead of training from scratch, which significantly reduces the scale of parameter update. In this case, an assumption can be established that fine-tuning a model is roughly equivalent to learning a model with a relatively small d (Appx. H). This assumption is potentially underpinned by the empirical alignment of our validation experiments with the theoretical framework (Fig. 1). To this end, experiments indicate thatd and m are practically of similar scale for our settings. This prevents our theoretical bounds from being very loose and meaningless in reality. 2. Regarding cases that our assumption does not apply, this issue would appear inevitable, since it is rigorously inherent in the estimation error of our streaming and varying test distributions. The distribution of a test stream can be hardly monitored when only a limited batch is allowed, which we consider as a limitation of TTA settings. Moreover, this issue directly implies the necessity of using a buffer for unlabeled samples. A good practice is to maintain a relatively comparable sample buffer scale. Q4: What distribution shifts can ATTA solve? A: We would like to follow (but not limited to) the work (Zhao et al., 2023b) to discuss the distribution shifts ATTA can solve. 1. As elucidated in Sec. 3.1 and Sec. 5, ATTA can solve domain generalization shifts. Domain generalization shifts include complex shifts on the joint data distribution P(X, Y), given X as the covariates and Y as the label variable. Since P(X, Y) = P(X)P(Y |X), ATTA can handle covariate shift (P(X)), label shift (P(Y )), and conditional shift (P(Y |X)). The shifts on both covariate and conditional distributions can cover the shift on labels, but they (covariate + conditional shifts) are more complicated than pure label shifts, where only the marginal label distribution changes while the conditional distribution remains. Note that the conditional shifts are generally caused by spurious correlations, where the independent causal mechanism assumption (Pearl, 2009) holds or no concept drifts exist. 2. In our framework, the distribution support of X at different time steps can be different, but we don’t cover the situation where the support of Y changes, i.e., class-incremental problems. Q5: It is unclear how many samples are selected in each minibatch of testing samples. How the total budget is distributed across the whole testing data stream? A: The number of selected samples for each minibatch is decided jointly by the incremental clustering and the cluster centroid number NC (t). Intuitively, this sample selection is a dynamic process, with NC (t) restricting the budget and incremental clustering performing sample selection. For each batch, we increase applicable clustering centroids as a maximum limit, while the exact number of the selected samples is given by the incremental clustering by how many clusters are located in the scope of new distributions. e.g., if the incoming batch does not introduce new data distributions, then we select zero samples even with increased NC (t). In contrast, if the incoming batch contains data located in multiple new distributions, the incremental clustering tends to select more samples than the NC (t) limit, thus forcing to merging of multiple previous clusters into one new cluster. 18Published as a conference paper at ICLR 2024 The incremental clustering is detailed in Sec. 4.2, and NC (t) is naively increased by a constant hyper-parameter k. Therefore, the budget is adaptively distributed according to the data streaming distribution with budgets controlled by k, which is also the reason why we compare methods under a budget limit. Q6: Could compared methods have access to a few ground-truth labels as well? Making other algorithms be able to use the same amount of ground-truth labels randomly will produce fairer comparisons. A: 1. The enhanced TTA setting is exactly the setup we provide to produce fairer comparisons. See Tab. 3 and Tab. 5 for comparison results. 2. ATTA also compares to a stronger setting ADA which can access the whole test datasets multiple times. Table 5: The table demonstrates the comparisons on PACS where all enhanced TTA baselines have 300 budgets to randomly select labeled samples. The training steps of these labeled samples are the same as the original TTA method training steps. For accumulated sample selection, please refer to our ablation studies. Method Domain-wise data stream A VG Random data stream A VG P→ →A→ →C→ →S P A C S 1 2 3 4 P A C S Source onlyBN w/o adapt 99.70 59.38 28.03 42.91 99.70 59.38 28.03 42.91 43.44 43.44 43.44 43.44 99.70 59.38 28.03 42.91BN w/ adapt 98.74 68.07 64.85 54.57 98.74 68.07 64.85 54.57 62.50 62.50 62.50 62.50 98.74 68.07 64.85 54.57 TTA Tent (steps=1) N/A 70.07 68.43 64.42 97.72 74.17 72.61 68.92 61.20 62.36 66.59 67.32 98.14 74.37 70.26 66.07Tent (steps=10) N/A 76.27 63.78 49.35 59.46 38.62 48.46 55.03 56.20 53.22 52.55 55.55 58.32 47.56 60.75 58.00EATA N/A 69.53 66.94 61.42 98.56 69.38 66.60 64.83 60.34 59.81 64.38 65.02 98.68 73.78 68.30 59.74CoTTA N/A 66.55 63.14 59.91 90.12 61.67 66.68 67.68 57.26 57.36 63.46 65.64 92.22 71.53 70.44 62.41SAR (steps=1) N/A 66.60 63.78 50.34 98.38 67.87 64.04 49.48 57.21 56.06 56.78 57.14 98.38 68.80 64.59 53.02SAR (steps=10) N/A 69.09 66.55 49.07 96.23 62.50 59.34 46.53 49.76 52.74 48.51 49.06 95.39 57.13 54.61 38.76 Ours (B ≤300) N/A 76.86 70.90 75.39 98.80 84.47 82.25 81.52 69.47 76.49 82.45 82.22 98.98 84.91 83.92 86.00 Q7: What is the position of ATTA? A: Comparisons with different settings are challenging. In this work, the design of our experiments (Sec. 5) is to overcome this challenge by comparing both weaker settings and stronger settings. While the significant performance over weaker settings renders the necessity of extra information, the comparable performance with stronger settings provides the potential to relax restricted requirements. Intuitively, ATTA is the most cost-effective option in the consideration of both efficiency and effectiveness. We further provide the following ATTA summary: ATTA, which incorporates active learning in FTTA, is the light, real-time, source-free, widely applicable setting to achieve high generalization performances for test-time adaptation. 1. Necessity: From the causality perspective, new information is necessary (Lin et al., 2022; Pearl, 2009; Peters et al., 2017) to attain generalizable over distribution shifts which are insurmountable within the current TTA framework. 2. Effectiveness: Compared to FTTA methods, ATTA produces substantially better perfor- mances, on-par with the costly active domain adaptation (ADA) methods as shown in Table 3 in the paper. 3. Efficiency: Relative to ADA methods, ATTA possesses superior efficiency, similar to general FTTA methods, as shown in Tab. 3. 4. Applicability: ATTA is a model-agnostic setting. (1) Compared to domain generalization methods, ATTA do not require re-training and has the potential to apply to any pre-trained models. One interesting future direction is designing ATTA methods for large language models (LLMs), where re-trainings are extremely expensive and source data may be in- accessible. (2) Compared to FTTA methods, ATTA can protect model parameters from corrupting while learning new distributions by fine-tuning pre-trained models, rendering it more feasible and practical. In comparison with existing works, ATTA is motivated to mitigate the limitations of previous settings: 1. FTTA: Limited generalization performance. 19Published as a conference paper at ICLR 2024 2. TTT: Not source-free; limited generalization performance. 3. ADA & domain adaptation/generalization: Expensive re-trainings; limited applicability to pre-trained models. 4. Online active learning: It does not maintain and protect adaptation performances for multiple distributions in one model and does not consider the CF problem. Q8: What is the potential practical utility of ATTA? A: 1. Empirically, our method can generally finish a round of sample selection/training of 100 frames in 5s, i.e., 20 frames per sec, which is more than enough to handle multiple practical situations. Experiments on time complexity are provided in Tab. 3, where SimATTA has comparable time efficiency. 2. As a case analysis, the autopilot system (Hu et al., 2023; Chen et al., 2022a) presents an application scenario requiring high-speed low-latency adaptations, while these adaptations are largely underexplored. When entering an unknown environment, e.g., a construction section, a system of ATTA setting can require the driver to take over the wheel. During the period of manual operation when the driver is handling the wheel, steering signals are generated, and the in-car system quickly adaptations. The system doesn’t need to record 60 frames per second, since only the key steering operations and the corresponding dash cam frames are necessary, which can be handled by ATTA algorithms processing at 20 frames per sec. In this case, the human annotations are necessary and indirect. ATTA makes use of this information and adapts in the short term instead of collecting videos and having a long-round fine-tuning (Schafer et al., 2018). 3. In addition, many scenarios applicable for ATTA are less speed-demanding than the case above. One example is a personalized chatbot that subtly prompts and gathers user labels during user interaction. In a home decoration setting, applications can request that users scan a few crucial areas to ensure effective adaptation. Social robots (Mavrogiannis et al., 2023), e.g., vacuum robots, often require users to label critical obstacles they’ve encountered. 4. Compared with ADA, ATTA stands out as the tailored solution for the above scenarios. It does not require intensive retraining or server-dependent fine-tuning, offering both speed and computational efficiency. Meanwhile, akin to other TTA methods, ATTA also ensures user privacy. While it might marginally exceed the cost of standard TTA methods, the superior generalization ability makes it a compelling choice and justifies the additional expense. Q9: What can be covered by this paper? A: This paper endeavors to establish the foundational framework for a novel setting referred to as ATTA. We target (1) positioning the ATTA setting, (2) solving the two major and basic challenges of ATTA,i.e., the mitigation of distribution shifts and the avoidance of catastrophic forgetting (CF). We achieve the first goal by building the problem formulation and analyses, and further providing extensive qualitative and well-organized experimental comparisons with TTA, enhanced TTA, and ADA settings. These efforts position ATTA as the most cost-effective option between TTA and ADA, where ATTA inherits the efficiency of TTA and the effectiveness of ADA. With our theoretical analyses and the consistent algorithm design, we validate the success of our second goal through significant empirical performances. Q10: What are not covered by this paper? A: Constructing a new setting involves multifaceted complexities. Although there are various potential applications discussed above including scaling this setting up for large models and datasets, we cannot cover them in this single piece of work. There are three main reasons. First, the topics covered by a single paper are limited. Formally establishing ATTA setting and addressing its major challenges of ATTA takes precedence over exploring practical applications. Secondly, given the interrelations between ATTA and other settings, our experimental investigations are predominantly comparative, utilizing the most representative datasets from TTA and domain adaptation to showcase persuasive results. Thirdly, many practical applications necessitate task-specific configurations, rendering them unsuitable for establishing a universal learning setting. While the current focus is on laying down the foundational aspects of ATTA, the exploration of more specialized applications remains a prospective avenue for future work in the ATTA domain. 20Published as a conference paper at ICLR 2024 C R ELATED WORKS The development of deep learning witnesses various applications (He et al., 2016; Gui et al., 2020). To tackle OOD problem, various domain generalization works emerge (Krueger et al., 2021; Sagawa et al., 2019). C.1 U NSUPERVISED DOMAIN ADAPTATION Unsupervised Domain Adaptation (UDA) (Pan et al., 2010; Patel et al., 2015; Wilson and Cook, 2020; Wang and Deng, 2018) aims at mitigating distribution shifts between a source domain and a target domain, given labeled source domain samples and unlabeled target samples. UDA methods generally rely on feature alignment techniques to eliminate distribution shifts by aligning feature distributions between source and target domains. Typical feature alignment techniques include discrepancy minimization (Long et al., 2015; Sun and Saenko, 2016; Kang et al., 2019) and adversarial training (Ganin and Lempitsky, 2015; Tsai et al., 2018; Ajakan et al., 2014; Ganin et al., 2016; Tzeng et al., 2015; 2017). Nevertheless, alignments are normally not guaranteed to be correct, leading to the alignment distortion problem as noted by Ning et al. (2021). Source-free Unsupervised Domain Adaptation (SFUDA) (Fang et al., 2022; Liu et al., 2021b) algorithms aim to adapt a pre-trained model to unlabeled target domain samples without access to source samples. Based on whether the algorithm can access model parameters, these algorithms are categorized into white-box and black-box methods. White-box SFUDA typically considers data recovery (generation) and fine-tuning methods. The former focuses on recovering source- like data (Ding et al., 2022; Yao et al., 2021), e.g., training a Generative Adversarial Network (GAN) (Kurmi et al., 2021; Li et al., 2020), while the latter employs various techniques (Mao et al., 2021), such as knowledge distillation (Chen et al., 2022b; Liu and Yuan, 2022; Yang et al., 2021b; Yu et al., 2022), statistics-based domain alignment (Ishii and Sugiyama, 2021; Liu et al., 2021a; Fan et al., 2022; Eastwood et al., 2021), contrastive learning (Huang et al., 2021; Wang et al., 2022b), and uncertainty-based adaptation (Gawlikowski et al., 2021; Fleuret et al., 2021; Chen et al., 2021; Li et al., 2021b). Black-box SFUDA cannot access model parameters and often relies on self-supervised knowledge distillation (Liang et al., 2022; 2021), pseudo-label denoising (Zhang et al., 2021; Yang et al., 2022), or generative distribution alignment (Yeh et al., 2021; Yang et al., 2021a). C.2 T EST-TIME ADAPTATION Test-time Adaptation (TTA), especially Fully Test-time Adaptation (FTTA) algorithms (Wang et al., 2021; Iwasawa and Matsuo, 2021; Karani et al., 2021; Nado et al., 2020; Schneider et al., 2020; Wang et al., 2022a; Zhao et al., 2023a; Niu et al., 2022; Zhang et al., 2022a; Niu et al., 2023; You et al., 2021; Zhang et al., 2022b), can be considered as realistic and lightweight methods for domain adaptation. Built upon black-box SFUDA, FTTA algorithms eliminate the requirement of a pre-collected target dataset and the corresponding training phase. Instead, they can only access an unlabeled data stream and apply real-time adaptation and training. In addition to FTTA, Test-time Training (TTT) (Sun et al., 2020; Liu et al., 2021c) often relies on appending the original network with a self-supervised task. TTT methods require retraining on the source dataset to transfer information through the self-supervised task. Although they do not access the source dataset during the test-time adaptation phase, TTT algorithms are not off-the-shelf source-free methods. TTA is a promising and critical direction for real-world applications, but current entropy minimization-based methods can be primarily considered as feature calibrations that require high-quality pseudo-labels. This requirement, however, can be easily violated under larger distribution shifts. Current TTA algorithms, inheriting UDA drawbacks, cannot promise good feature calibration results, which can be detrimental in real-world deployments. For instance, entropy minimization on wrongly predicted target domain samples with relatively low entropy can only exacerbate spurious correla- tions (Chen et al., 2020). Without extra information, this problem may be analogous to applying causal inference without intervened distributions, which is intrinsically unsolvable (Peters et al., 2016; Pearl, 2009). This paper aims to mitigate this issue with minimal labeled target domain samples. To minimize the cost, we tailor active learning techniques for TTA settings. It is worth noting that a recent work AdaNPC (Zhang et al., 2023) is essentially a domain gener- alization method with a TTA phase attached, while our ATTA is built based on the FTTA setting. Specifically, Current FTTA methods and our work cannot access the source domain. In contrast, 21Published as a conference paper at ICLR 2024 AdaNPC accesses source data to build its memory bank, circumventing the catastrophic forgetting problem. Furthermore, AdaNPC requires multiple source domains and training before performing TTA. Thus AdaNPC uses additional information on domain labels and retraining resources for its memory bank, undermining the merits of FTTA. Regarding theoretical bounds, their target domain is bounded by source domain error and model estimations (in big-O expression), while we consider active sample learning and time variables for varying test distributions. C.3 C ONTINUAL DOMAIN ADAPTATION Many domain adaptation methods focus on improving target domain performance, neglecting the performance on the source domain, which leads to the CF problem (Kemker et al., 2018; Kirkpatrick et al., 2017; Li and Hoiem, 2017; Lopez-Paz and Ranzato, 2017; De Lange et al., 2021; Wang et al., 2022a; Niu et al., 2022). This issue arises when a neural network, after being trained on a sequence of domains, experiences a significant degradation in its performance on previously learned domains as it continues to learn new domains. Continual learning, also known as lifelong learning, addresses this problem. Recent continual domain adaptation methods have made significant progress by employing gradient regularization, random parameter restoration, buffer sample mixture, and more. Although the CF problem is proposed in the continual learning field, it can occur in any source-free OOD settings since the degradation caused by CF is attributed to the network’s parameters being updated to optimize performance on new domains, which may interfere with the representations learned for previous domains. C.4 A CTIVE DOMAIN ADAPTATION Active Domain Adaptation (ADA) (Prabhu et al., 2021; Ning et al., 2021; Su et al., 2020; Ma et al., 2021; Xie et al., 2022) extends semi-supervised domain adaptation with active learning strate- gies (Cohn et al., 1996; Settles, 2009), aiming to maximize target domain performance with a limited annotation budget. Therefore, the key challenge of active learning algorithms is selecting the most informative unlabeled data in target domains (Kapoor et al., 2007). Sample selection strategies are of- ten based on uncertainty (Lewis and Catlett, 1994; Scheffer et al., 2001), diversity (Jain and Grauman, 2016; Hoi et al., 2009), representativeness (Xu et al., 2003), expected error minimization (Vijaya- narasimhan and Kapoor, 2010), etc. Among these methods, uncertainty and diversity-based methods are simple and computationally efficient, making them the most suitable choices to tailor for TTA settings. Adapting these strategies is non-trivial because, compared to typical active domain adaptation, our proposed Active Test-time Adaptation (ATTA) setting does not provide access to source data, model parameters, or pre-collected target samples. This requirement demands that our active sample selection algorithm select samples for annotation during data streaming. Consequently, this active sampling selection process is non-regrettable, i.e., we can only meet every sample once in a short period. To avoid possible confusion, compared to the recent Source-free Active Domain Adaptation (SFADA) method SALAD (Kothandaraman et al., 2023), we do not require access to model parameter gradients, training additional neural networks, or pre-collected target datasets. Therefore, our ATTA setting is quite different, much lighter, and more realistic than ADA and SFADA. C.5 A CTIVE ONLINE LEARNING The most related branch of active online learning (AOL) (Cacciarelli and Kulahci, 2023) is active online learning on drifting data stream (Zhou et al., 2021; Baier et al., 2021; Li et al., 2021a). Generally, these methods include two components, namely, detection and adaptation. Compared with ATTA, there are several distinctions. First, this line of studies largely focuses on the distribution shift detection problem, while ATTA focuses on multi-domain adaptations. Second, AOL on drifting data stream aims to detect and adapt to one current distribution in the stream, without considering preserving the adaptation abilities of multiple past distributions by maintaining and fine-tuning the original pre-trained models. In contrast, ATTA’s goal is to achieve the OOD generalization optimums adaptable across multiple source and target distributions, leading to the consideration of CF problems. Third, while AOL requires one-by-one data input and discard, ATTA maintains a buffer for incoming data before selection decisions. This is because ATTA targets maintaining the original model without corrupting and replacing it, such that making statistically meaningful and high-quality decisions is 22Published as a conference paper at ICLR 2024 critical for ATTA. In contrast, AOL allows resetting and retraining new models, whose target is more lean to cost saving and one-by-one manner. D F URTHER THEORETICAL STUDIES In this section, we refine the theoretical studies with supplement analysis and further results. We use the H-divergence and H∆H-distance definitions following (Ben-David et al., 2010). Definition 2 (H-divergence). For a function class H and two distributions D1 and D2 over a domain X, the H-divergence between D1 and D2 is defined as dH(D1, D2) = sup h∈H |Px∼D1 [h(x) = 1] − Px∼D2 [h(x) = 1]|. The H∆H-distance is defined base on H-divergence. We use the H∆H-distance definition follow- ing (Ben-David et al., 2010). Definition 3 (H∆H-distance). For two distributions D1 and D2 over a domain X and a hypothesis class H, the H∆H-distance between D1 and D2 w.r.t. H is defined as dH∆H(D1, D2) = sup h,h′∈H Px∼D1 [h(x) ̸= h′(x)] + Px∼D2 [h(x) ̸= h′(x)]. (9) The H∆H-distance essentially provides a measure to quantify the distribution shift between two distributions. It measures the maximum difference of the disagreement between two hypotheses in H for two distributions, providing a metrics to quantify the distribution shift between D1 and D2. H-divergence and H∆H-distance have the advantage that they can be applied between datasets, i.e., estimated from finite samples. Specifically, let S1, S2 be unlabeled samples of size m sampled from D1 and D2; then we have estimated H∆H-distance ˆdH(S1, S2). This estimation can be bounded based on Theorem 3.4 of Kifer et al. (2004), which we state here for completeness. Theorem 5. Let A be a collection of subsets of some domain measure space, and assume that the VC-dimension is some finite d. Let P1 and P2 be probability distributions over that domain and S1, S2 finite samples of sizes m1, m2 drawn i.i.d. according P1, P2 respectively. Then Pm1+m2 [|ϕA(S1, S2) − ϕA(P1, P2)| > ϵ] ≤ (2m)de−m1ϵ2/16 + (2m)de−m2ϵ2/16, (10) where Pm1+m2 is the m1 + m2’th power of P - the probability that P induces over the choice of samples. Theorem 5 bounds the probability for relativized discrepancy, and its applications in below lemmas and Theorem 1 help us bound the quantified distribution shifts between domains. The probability, according to a distribution D, that an estimated hypothesis h disagrees with the true labeling function g : X → {0, 1} is defined as ϵ(h(t), g) = E(x)∼D[|h(x, t) − g(x)|], which we also refer to as the error or risk ϵ(h(t)). While the source domain dataset is inaccessible under ATTA settings, we consider the existence of the source dataset DS for the purpose of accurate theoretical analysis. Thus, we initialize Dtr(0) as DS, i.e., Dtr(0) = DS. For every time step t, the test and training data can be expressed as Ute(t) and Dtr(t) = DS ∪ Dte(1) ∪ Dte(2) ∪ ··· ∪Dte(t). (11) We use N to denote the total number of samples in Dtr(t) and λ = (λ0, λ1, ··· , λt) to represent the ratio of sample numbers in each component subset. In particular, we have |DS| |Dtr(t)| = λ0, |Dte(1)| |Dtr(t)| = λ1, ··· , |Dte(t)| |Dtr(t)| = λt, (12) where Pt i=0 λi = 1. Therefore, at time step t, the model has been trained on labeled data Dtr(t), which contains t + 1 components consisting of a combination of data from the source domain and multiple test-time domains. For each domain the model encounters, DS, Ute(1), Ute(2), ··· , Ute(t), let ϵj(h(t)) denote the error of hypothesis h at time t on the jth domain. Specifically, ϵ0(h(t)) = ϵS(h(t)) represents the error of h(t) on the source data DS, and ϵj(h(t)) for j ≥ 1 denotes the error of h(t) on test data Ute(j). Our optimization minimizes a convex combination of training error over the labeled samples from all domains. Formally, given the vector w = (w0, w1, ··· , wt) of domain error 23Published as a conference paper at ICLR 2024 weights with Pt j=0 wj = 1 and the sample number from each component Nj = λjN, we minimize the empirical weighted error of h(t) as ˆϵw(h(t)) = tX j=0 wjˆϵj(h(t)) = tX j=0 wj Nj X Nj |h(x, t) − g(x)|. (13) Note that w, λ and N are also functions of t, which we omit for simplicity. We now establish two lemmas as the preliminary for Theorem 1. In the following lemma, we bound the difference between the weighted error ϵw(h(t)) and the domain error ϵj(h(t)). Lemma 6. Let H be a hypothesis space of VC-dimension d. At time step t, let the ATTA data domains be DS, Ute(1), Ute(2), ··· , Ute(t), and Si be unlabeled samples of size m sampled from each of the t + 1 domains respectively. Then for any δ ∈ (0, 1), for every h ∈ Hminimizing ϵw(h(t)) on Dtr(t), we have |ϵw(h(t)) − ϵj(h(t))| ≤ tX i=0,i̸=j wi  1 2 ˆdH∆H(Si, Sj) + 2 s 2d log(2m) + log 2 δ m + γi  , with probability of at least 1 − δ, where γi = minh∈H{ϵi(h(t)) + ϵj(h(t))}. In the following lemma, we provide an upper bound on the difference between the true and empirical weighted errors ϵw(h(t)) and ˆϵw(h(t)). Lemma 7. Let H be a hypothesis class. For Dtr(t) = DS ∪ Dte(1) ∪ ··· ∪Dte(t) at time t, if the total number of samples in Dtr(t) is N, and the ratio of sample numbers in each component is λj, then for any δ ∈ (0, 1) and h ∈ H, with probability of at least 1 − δ, we have P[|ϵw(h(t)) − ˆϵw(h(t))| ≥ϵ] ≤ 2 exp   −2Nϵ2/( tX j=0 w2 j λj ) ! . Thus, as wj deviates from λj, the feasible approximation ˆϵw(h(t)) with a finite number of labeled samples becomes less reliable. The proofs for both lemmas are provided in Appx. E. Building upon the two preceding lemmas, we proceed to derive bounds on the domain errors under the ATTA setting when minimizing the empirical weighted error using the hypothesis h at time t. Lemma 6 bounds the difference between the weighted error ϵw(h(t)) and the domain error ϵj(h(t)), which is majorly influenced by the estimatedH∆H-distance and the quality of discrepancy estimation. During the ATTA process, the streaming test data can form multiple domains and distributions. However, if we consider all data during the test phase as a single test domain,i.e., St i=1 Ute(i), we can simplify Lemma 6 to obtain an upper bound for the test error ϵT as |ϵw(h(t)) − ϵT (h(t))| ≤w0  1 2 ˆdH∆H(S0, ST ) + 2 s 2d log(2m) + log 2 δ m + γ  , (14) where γ = min h∈H{ϵ0(h(t)) + ϵT (h(t))}, and ST is sampled from St i=1 Ute(i). To understand Lamma 7, we need to understand Hoeffding’s Inequality, which we state below as a Proposition for completeness. Proposition 8 (Hoeffding’s Inequality). Let X be a set, D1, . . . , Dt be probability distributions on X, and f1, . . . , ft be real-valued functions on X such that fi : X → [ai, bi] for i = 1, . . . , t. Then for any ϵ >0, P  \f\f\f\f\f 1 t tX i=1 fi(x) − 1 t tX i=1 Ex∼Di[fi(x)] \f\f\f\f\f ≥ ϵ ! ≤ 2 exp   − 2t2ϵ2 Pt i=1(bi − ai)2 ! (15) where E[fi(x)] is the expected value of fi(x). Lamma 7 provides an upper bound on the difference between the true and empirical weighted errors ϵw(h(t)) and ˆϵw(h(t)). Thus, as wj deviates from λj, the feasible approximation ˆϵw(h(t)) with a finite number of labeled samples becomes less reliable. Building upon the two preceding lemmas, we proceed to derive bounds on the domain errors under the ATTA setting when minimizing the empirical weighted error using the hypothesis h at time t. Theorem 1 essentially bounds the performance of ATTA on the source and each test domains. The adaptation performance on a test domain is majorly 24Published as a conference paper at ICLR 2024 bounded by the composition of (labeled) training data, estimated distribution shift, and ideal joint hypothesis performance, which correspond to C, ˆdH∆H(Si, Sj), and γi, respectively. The ideal joint hypothesis error γi gauges the inherent adaptability between domains. If we consider the multiple data distributions during the test phase as a single test domain, i.e., St i=1 Ute(i), Theorem 1 can be reduced into bounds for the source domain error ϵS and test domain error ϵT . With the optimal test/source hypothesis h∗ T (t) = arg min h∈H ϵT (h(t)) and h∗ S(t) = arg minh∈H ϵS(h(t)), |ϵT (ˆh(t)) − ϵT (h∗ T (t))| ≤w0A + s w2 0 λ0 + (1 − w0)2 1 − λ0 B, (16a) |ϵS(ˆh(t)) − ϵS(h∗ S(t))| ≤(1 − w0)A + s w2 0 λ0 + (1 − w0)2 1 − λ0 B, (16b) where the distribution divergence termA = ˆdH∆H(S0, ST )+4 q 2d log(2m)+log 2 δ m +2γ, the empirical gap term B = 2 q d log(2N)−log(δ) 2N , ST is sampled from St i=1 Ute(i), and γ = minh∈H{ϵ0(h(t)) + ϵT (h(t))}. Our learning bounds demonstrates the trade-off between the small amount of budgeted test-time data and the large amount of less relevant source data. Next, we provide an approximation of the condition necessary to achieve optimal adaptation performance, which is calculable from finite samples and can be readily applied in practical ATTA scenarios. Following Eq. (16.a), with approximately B = c1 p d/N, the optimal value w∗ 0 to tighten the test error bound is a function of λ0 and A: w∗ 0 = λ0 − s A2N c2 1d − A2Nλ0(1 − λ0), for λ 0 ≥ 1 − d A2N , (17) where c1 is a constant. Note that λ0 ≥ 1 − d A2N should be the satisfied condition in practical ATTA settings, where the budget is not sufficiently big while the source data amount is relatively large. When the budget is sufficiently large or the source data amount is not sufficiently large compared to the distribution shift A, the optimal w∗ 0 for the test error bound is w∗ 0 = 0, i.e., using no source data since possible error reduction from the data addition is always less than the error increase caused by large divergence between the source data and the test data. Theorem 2 offers a direct theoretical guarantee that ATTA reduces the error bound on test domains in comparison to TTA without the integration of active learning. Following Theorem 1, when no active learning is included during TTA,i.e., w0 = λ0 = 1, the upper boundw0A+ q w2 0 λ0 + (1−w0)2 1−λ0 B ≥ A+B; when enabling ATTA, withw0 = λ0 ̸= 1, we can easily achieve an upper bound w0A + B < A+ B. Therefore, the incorporation of labeled test instances in ATTA theoretically enhances the overall performance across test domains, substantiating the significance of the ATTA setting in addressing distribution shifts. Entropy quantifies the amount of information contained in a probability distribution. In the context of a classification model, lower entropy indicates that the model assigns high probability to one of the classes, suggesting a high level of certainty or confidence in its prediction. When a model assigns low entropy to a sample, this high confidence can be interpreted as the sample being well-aligned or fitting closely with the model’s learned distribution. In other words, the model “recognizes” the sample as being similar to those it was trained on, hence the high confidence in its prediction. While entropy is not a direct measure of distributional distance, it can be used as an indicator of how closely a sample aligns with the model’s learned distribution. This interpretation is more about model confidence and the implied proximity rather than a strict mathematical measure of distributional distance. The pre-trained model is well-trained on abundant source domain data, and thus the model distribution is approximately the source distribution. Selecting low-entropy samples using essentially provides an estimate of sampling from the source dataset. Thus, Dϕ,S(t), based on well-aligned with the model’s learned distribution is an approximation of DS. When we consider the CF problem and feasibly include the source-like dataset Dϕ,S(t) into the ATTA training data in place of the inaccessible DS in Eq. (11), we can also derive bounds on the domain errors under this practical ATTA setting when minimizing the empirical weighted errorϵ′ w(h(t)) using the hypothesis h at time t, similar to Theorem 1. Let H be a hypothesis class of VC-dimension d. At time step t, for ATTA data domainsDϕ,S(t), Ute(1), Ute(2), ··· , Ute(t), Si are unlabeled samples of size m sampled from each of the t + 1 domains respectively. The total number of samples in Dtr(t) is 25Published as a conference paper at ICLR 2024 N and the ratio of sample numbers in each component is λi. If ˆh(t) ∈ Hminimizes the empirical weighted error ˆϵ′ w(h(t)) with the weight vector w on Dtr(t), and h∗ j (t) = arg minh∈H ϵj(h(t)) is the optimal hypothesis on the jth domain, then for any δ ∈ (0, 1), we have ϵj(ˆh(t)) ≤ ϵj(h∗ j (t)) + 2 tX i=0,i̸=j wi  1 2 ˆdH∆H(Si, Sj) + 2 s 2d log(2m) + log 2 δ m + γi   + 2C with probability of at least 1 − δ, where C = r\u0010Pt i=0 w2 i λi \u0011\u0010 d log(2N)−log(δ) 2N \u0011 and γi = minh∈H{ϵi(h(t)) + ϵj(h(t))}. Other derived results following Theorem 1 also apply for this practical ATTA setting. Further empirical validations for our theoretical results are provided in Appx. H. E P ROOFS This section presents comprehensive proofs for all the lemmas, theorems, and corollaries mentioned in this paper, along with the derivation of key intermediate results. Lemma 6. Let H be a hypothesis space of VC-dimension d. At time step t, let the ATTA data domains be DS, Ute(1), Ute(2), ··· , Ute(t), and Si be unlabeled samples of size m sampled from each of the t + 1 domains respectively. Then for any δ ∈ (0, 1), for every h ∈ Hminimizing ϵw(h(t)) on Dtr(t), we have |ϵw(h(t)) − ϵj(h(t))| ≤ tX i=0,i̸=j wi  1 2 ˆdH∆H(Si, Sj) + 2 s 2d log(2m) + log 2 δ m + γi  , with probability of at least 1 − δ, where γi = minh∈H{ϵi(h(t)) + ϵj(h(t))}. Proof. First we prove that given unlabeled samples of size m S1, S2 sampled from two distributions D1 and D2, we have dH∆H(D1, D2) ≤ ˆdH∆H(S1, S2) + 4 s 2d log(2m) + log 2 δ m . (18) We start with Theorem 3.4 of Kifer et al. (2004): Pm1+m2 [|ϕA(S1, S2) − ϕA(P1, P2)| > ϵ] ≤ (2m)de−m1ϵ2/16 + (2m)de−m2ϵ2/16. (19) In Eq. 19, ’d’ is the VC-dimension of a collection of subsets of some domain measure space A, while in our case, d is the VC-dimension of hypothesis space H. Following (Ben-David et al., 2010), the H∆H space is the set of disagreements between every two hypotheses inH, which can be represented as a linear threshold network of depth 2 with 2 hidden units. Therefore, the VC-dimension of H∆H is at most twice the VC-dimension of H, and the VC-dimension of our domain measure space is 2d for Eq. 19 to hold. Given δ ∈ (0, 1), we set the upper bound of the inequality to δ, and solve for ϵ: δ = (2m)2de−m1ϵ2/16 + (2m)2de−m2ϵ2/16. We rewrite the inequality as δ (2m)2d = e−m1ϵ2/16 + e−m2ϵ2/16; taking the logarithm of both sides, we get log δ (2m)2d = −m1 ϵ2 16 + log(1 +e−(m1−m2) ϵ2 16 ). 26Published as a conference paper at ICLR 2024 Assuming m1 = m2 = m and defining a = ϵ2 16 , we have log δ (2m)2d = −ma + log 2; rearranging the equation, we then get ma + log(δ/2) = 2d log(2m). Now, we can solve for a: a = 2d log(2m) + log 2 δ m . Recall that a = ϵ2 16 , so we get: ϵ = 4√a ϵ = 4 s 2d log(2m) + log 2 δ m . With probability of at least 1 − δ, we have |ϕA(S1, S2) − ϕA(P1, P2)| ≤4 s 2d log(2m) + log 2 δ m ; therefore, dH∆H(D1, D2) ≤ ˆdH∆H(S1, S2) + 4 s 2d log(2m) + log 2 δ m . (20) Now we prove Lemma 6. We use the triangle inequality for classification error in the derivation. For the domain error of hypothesis h at time t on the jth domain ϵj(h(t)), given the definition of ϵw(h(t)), |ϵw(h(t)) − ϵj(h(t))| = | tX i=0 wiϵi(h(t)) − ϵj(h(t))| ≤ tX i=0 wi|ϵi(h(t)) − ϵj(h(t))| ≤ tX i=0 wi(|ϵi(h(t)) − ϵi(h(t), h∗ i (t))| + |ϵi(h(t), h∗ i (t)) − ϵj(h(t), h∗ i (t))| + |ϵj(h(t), h∗ i (t)) − ϵj(h(t))|) ≤ tX i=0 wi(ϵi(h∗ i (t)) + |ϵi(h(t), h∗ i (t)) − ϵj(h(t), h∗ i (t))| + ϵj(h∗ i (t))) ≤ tX i=0 wi(γi + |ϵi(h(t), h∗ i (t)) − ϵj(h(t), h∗ i (t))|), where γi = minh∈H{ϵi(h(t)) + ϵj(h(t))}. By the definition of H∆H-distance and our proved Eq. 20, |ϵi(h(t), h∗ i (t)) − ϵj(h(t), h∗ i (t))| ≤sup h,h′∈H |ϵi(h(t), h′(t)) − ϵj(h(t), h′(t))| = sup h,h′∈H Px∼Di[h(x) ̸= h′(x)] + Px∼Dj [h(x) ̸= h′(x)] = 1 2dH∆H(Di, Dj) ≤ 1 2 ˆdH∆H(Si, Sj) + 2 s 2d log(2m) + log 2 δ m , 27Published as a conference paper at ICLR 2024 where Di, Dj denote the ith and jth domain. Therefore, |ϵw(h(t)) − ϵj(h(t))| ≤ tX i=0 wi(γi + |ϵi(h(t), h∗ i (t)) − ϵj(h(t), h∗ i (t))|) ≤ tX i=0 wi(γi + 1 2dH∆H(Di, Dj)) ≤ tX i=0 wi(γi + 1 2 ˆdH∆H(Si, Sj) + 2 s 2d log(2m) + log 2 δ m ). Since ϵi(h(t)) − ϵj(h(t)) = 0 when i = j, we derive |ϵw(h(t)) − ϵj(h(t))| ≤ tX i=0,i̸=j wi  1 2 ˆdH∆H(Si, Sj) + 2 s 2d log(2m) + log 2 δ m + γi  , with probability of at least 1 − δ, where γi = minh∈H{ϵi(h(t)) + ϵj(h(t))}. This completes the proof. Lemma 7. Let H be a hypothesis class. For Dtr(t) = DS ∪ Dte(1) ∪ ··· ∪Dte(t) at time t, if the total number of samples in Dtr(t) is N, and the ratio of sample numbers in each component is λj, then for any δ ∈ (0, 1) and h ∈ H, with probability of at least 1 − δ, we have P[|ϵw(h(t)) − ˆϵw(h(t))| ≥ϵ] ≤ 2 exp   −2Nϵ2/( tX j=0 w2 j λj ) ! . Proof. We apply Hoeffding’s Inequality in our proof: P  \f\f\f\f\f 1 t tX i=1 fi(x) − 1 t tX i=1 Ex∼Di[fi(x)] \f\f\f\f\f ≥ ϵ ! ≤ 2 exp   − 2t2ϵ2 Pt i=1(bi − ai)2 ! . (21) In the jth domain, there are λjN samples. With the true labeling function g(x), for each of the λjN samples x, let there be a real-valued function fi(x) fi(x) = wj λj |h(x, t) − g(x)|, where fi(x) ∈ [0, wj λj ]. Incorporating all the domains, we get ˆϵw(h(t)) = tX j=0 wjˆϵj(h(t)) = tX j=0 wj λjN X λjN |h(x, t) − g(x)| = 1 N tX j=0 λjNX i=1 fi(x), which corresponds to the 1 t Pt i=1 fi(x) part in Hoeffding’s Inequality. Due to the linearity of expectations, we can calculate the sum of expectations as 1 N tX j=0 λjNX i=1 E[fi(x)] = 1 N ( tX j=0 λjN wj λj ϵj(h(t))) = tX j=0 wjϵj(h(t)) = ϵw(h(t)), which corresponds to the 1 t Pt i=1 Ex∼Di[fi(x)] part in Hoeffding’s Inequality. Therefore, we can apply Hoeffding’s Inequality as P[|ϵw(h(t)) − ˆϵw(h(t))| ≥ϵ] ≤ 2 exp   −2N2ϵ2/( NX i=0 range2(fi(x))) ! = 2 exp   −2N2ϵ2/( tX j=0 λjN(wj λj )2) ! = 2 exp   −2Nϵ2/( tX j=0 w2 j λj ) ! . This completes the proof. 28Published as a conference paper at ICLR 2024 Theorem 1. Let H be a hypothesis class of VC-dimension d. At time step t, for ATTA data domains DS, Ute(1), Ute(2), ··· , Ute(t), Si are unlabeled samples of size m sampled from each of the t + 1 domains respectively. The total number of samples in Dtr(t) is N and the ratio of sample numbers in each component is λi. If ˆh(t) ∈ Hminimizes the empirical weighted error ˆϵw(h(t)) with the weight vector w on Dtr(t), and h∗ j (t) = arg minh∈H ϵj(h(t)) is the optimal hypothesis on the jth domain, then for any δ ∈ (0, 1), with probability of at least 1 − δ, we have ϵj(ˆh(t)) ≤ ϵj(h∗ j (t)) + 2 tX i=0,i̸=j wi  1 2 ˆdH∆H(Si, Sj) + 2 s 2d log(2m) + log 2 δ m + γi   + 2C, where C = r\u0010Pt i=0 w2 i λi \u0011\u0010 d log(2N)−log(δ) 2N \u0011 and γi = minh∈H{ϵi(h(t)) + ϵj(h(t))}. For future test domains j = t + k (k >0), assuming k′ = argmink′∈{0,1,...t} dH∆H(D(k′), Ute(t + k)) and min dH∆H (D(k′), Ute(t + k)) ≤ δD, where 0 ≤ δD ≪ +∞, then ∀δ, with probability of at least 1 − δ, we have ϵt+k(ˆh(t)) ≤ ϵt+k(h∗ t+k(t)) + tX i=0 wi  ˆdH∆H(Si, Sk′ ) + 4 s 2d log(2m) + log 2 δ m + δD + 2γi   + 2C. Proof. First we prove that for any δ ∈ (0, 1) and h ∈ H, with probability of at least 1 − δ, we have |ϵw(h(t)) − ˆϵw(h(t))| ≤ vuut  tX i=0 w2 i λi !\u0012d log(2N) − log(δ) 2N \u0013 . (22) We apply Theorem 3.2 of Kifer et al. (2004) and Lemma 7, P[|ϵw(h(t)) − ˆϵw(h(t))| ≥ϵ] ≤ (2N)d exp   −2Nϵ2/( tX j=0 w2 j λj ) ! . Given δ ∈ (0, 1), we set the upper bound of the inequality to δ, and solve for ϵ: δ = (2N)d exp   −2Nϵ2/( tX j=0 w2 j λj ) ! . We rewrite the inequality as δ (2N)d = e −2Nϵ2/(Pt j=0 w2 j λj ) , taking the logarithm of both sides, we get log δ (2N)d = −2Nϵ2/( tX j=0 w2 j λj ). Rearranging the equation, we then get ϵ2 = ( tX j=0 w2 j λj )d log(2N) − log(δ) 2N . Therefore, with probability of at least 1 − δ, we have |ϵw(h(t)) − ˆϵw(h(t))| ≤ vuut  tX i=0 w2 i λi !\u0012d log(2N) − log(δ) 2N \u0013 . (23) 29Published as a conference paper at ICLR 2024 Based on Eq. 23, we now prove Theorem 1. For the empirical domain error of hypothesis h at time t on the jth domain ϵj(ˆh(t)), applying Lemma 6, Eq. 23, and the definition of h∗ j (t), we get ϵj(ˆh(t)) ≤ ϵw(ˆh(t)) + tX i=0,i̸=j wi  1 2 ˆdH∆H(Si, Sj) + 2 s 2d log(2m) + log 2 δ m + γi   ≤ ˆϵw(ˆh(t)) + vuut  tX i=0 w2 i λi !\u0012d log(2N) − log(δ) 2N \u0013 + tX i=0,i̸=j wi  1 2 ˆdH∆H(Si, Sj) + 2 s 2d log(2m) + log 2 δ m + γi   ≤ ˆϵw(h∗ j (t)) + vuut  tX i=0 w2 i λi !\u0012d log(2N) − log(δ) 2N \u0013 + tX i=0,i̸=j wi  1 2 ˆdH∆H(Si, Sj) + 2 s 2d log(2m) + log 2 δ m + γi   ≤ ϵw(h∗ j (t)) + 2 vuut  tX i=0 w2 i λi !\u0012d log(2N) − log(δ) 2N \u0013 + tX i=0,i̸=j wi  1 2 ˆdH∆H(Si, Sj) + 2 s 2d log(2m) + log 2 δ m + γi   ≤ ϵj(h∗ j (t)) + 2 vuut  tX i=0 w2 i λi !\u0012d log(2N) − log(δ) 2N \u0013 + 2 tX i=0,i̸=j wi  1 2 ˆdH∆H(Si, Sj) + 2 s 2d log(2m) + log 2 δ m + γi   = ϵj(h∗ j (t)) + 2 tX i=0,i̸=j wi  1 2 ˆdH∆H(Si, Sj) + 2 s 2d log(2m) + log 2 δ m + γi   + 2C with probability of at least 1 − δ, where C = r\u0010Pt i=0 w2 i λi \u0011\u0010 d log(2N)−log(δ) 2N \u0011 and γi = minh∈H{ϵi(h(t)) + ϵj(h(t))}. For future test domains j = t + k where k > 0, we have the assumption that k′ = argmink′∈{0,1,...t} dH∆H(D(k′), Ute(t + k)) and min dH∆H(D(k′), Ute(t + k)) ≤ δD. Here, we slightly abuse the notation D(k′) to represent Ds if k′ = 0 and Ute(k′) if k′ > 0. Then we get ϵt+k(ˆh(t)) ≤ ϵw(ˆh(t)) + tX i=0 wi  1 2 ˆdH∆H(Si, St+k) + 2 s 2d log(2m) + log 2 δ m + γi   ≤ ϵw(ˆh(t)) + tX i=0 wi  1 2( ˆdH∆H(Si, Sk′ ) + ˆdH∆H(Sk′ , St+k)) + 2 s 2d log(2m) + log 2 δ m + γi   ≤ ϵw(ˆh(t)) + tX i=0 wi  1 2 ˆdH∆H(Si, Sk′ ) + 1 2δD + 2 s 2d log(2m) + log 2 δ m + γi   ≤ ˆϵw(ˆh(t)) + vuut  tX i=0 w2 i λi !\u0012d log(2N) − log(δ) 2N \u0013 + tX i=0 wi  1 2 ˆdH∆H(Si, Sk′ ) + 1 2δD + 2 s 2d log(2m) + log 2 δ m + γi   30Published as a conference paper at ICLR 2024 ≤ ˆϵw(h∗ t+k(t)) + vuut  tX i=0 w2 i λi !\u0012d log(2N) − log(δ) 2N \u0013 + tX i=0 wi  1 2 ˆdH∆H(Si, Sk′ ) + 1 2δD + 2 s 2d log(2m) + log 2 δ m + γi   ≤ ϵw(h∗ t+k(t)) + 2 vuut  tX i=0 w2 i λi !\u0012d log(2N) − log(δ) 2N \u0013 + tX i=0 wi  1 2 ˆdH∆H(Si, Sk′ ) + 1 2δD + 2 s 2d log(2m) + log 2 δ m + γi   ≤ ϵt+k(h∗ t+k(t)) + 2 vuut  tX i=0 w2 i λi !\u0012d log(2N) − log(δ) 2N \u0013 + 2 tX i=0 wi  1 2 ˆdH∆H(Si, Sk′ ) + 1 2δD + 2 s 2d log(2m) + log 2 δ m + γi   = ϵt+k(h∗ t+k(t)) + tX i=0 wi  ˆdH∆H(Si, Sk′ ) + 4 s 2d log(2m) + log 2 δ m + δD + 2γi   + 2C. with probability of at least 1−δ, where C = r\u0010Pt i=0 w2 i λi \u0011\u0010 d log(2N)−log(δ) 2N \u0011 , γi = minh∈H{ϵi(h(t))+ ϵt+k(h(t))}, and 0 ≤ δD ≪ +∞. This completes the proof. Theorem 2. Let H be a hypothesis class of VC-dimension d. For ATTA data domains DS, Ute(1), Ute(2), ··· , Ute(t), considering the test-time data as a single test domain St i=1 Ute(i), if ˆh(t) ∈ H minimizes the empirical weighted error ˆϵw(h(t)) with the weight vector w on Dtr(t), let the test error be upper-bounded with |ϵT (ˆh(t)) − ϵT (h∗ T (t))| ≤EBT (w, λ, N, t). Let w′ and λ′ be the weight and sample ratio vectors when no active learning is included, i.e., w′ and λ′ s.t. w′ 0 = λ′ 0 = 1 and w′ i = λ′ i = 0 for i ≥ 1, then for any λ ̸= λ′, there exists w s.t. EBT (w, λ, N, t) < EBT (w′, λ′, N, t). (24) Proof. From Theorem 1, we can derive the bound for the test error where the test-time data are considered as a single test domain: |ϵT (ˆh(t)) − ϵT (h∗ T (t))| ≤EBT (w, λ, N, t) = w0( ˆdH∆H(S0, ST ) + 4 s 2d log(2m) + log 2 δ m + 2γ) + 2 s w2 0 λ0 + (1 − w0)2 1 − λ0 r d log(2N) − log(δ) 2N ; and we simplify the above equation as |ϵT (ˆh(t)) − ϵT (h∗ T (t))| ≤w0A + s w2 0 λ0 + (1 − w0)2 1 − λ0 B, (25) where the distribution divergence termA = ˆdH∆H(S0, ST )+4 q 2d log(2m)+log 2 δ m +2γ, the empirical gap term B = 2 q d log(2N)−log(δ) 2N , ST is sampled from St i=1 Ute(i), and γ = minh∈H{ϵ0(h(t)) + ϵT (h(t))}. Since we have s w2 0 λ0 + (1 − w0)2 1 − λ0 = s (w0 − λ0)2 λ0(1 − λ0) + 1 ≥ 1, (26) 31Published as a conference paper at ICLR 2024 where Formula 26 obtains the minimum value if and only if w0 = λ0; when enabling ATTA with any λ0 ̸= 1, we can get EBT (w, λ, N, t) = w0A + s w2 0 λ0 + (1 − w0)2 1 − λ0 B ≥ w0A + B, (27) where the minimum value EBT (w, λ, N, t)min = w0A + B can be obtained with condition w0 = λ0 ̸= 1. When no active learning is included, i.e., for weight and sample ratio vectors w′ and λ′, w′ 0 = λ′ 0 = 1 and w′ i = λ′ i = 0 for i ≥ 1, we have EBT (w′, λ′, N, t) = w′ 0A + s w′2 0 λ′ 0 + (1 − w′ 0)2 1 − λ′ 0 B = A + B. (28) Since for EBT (w, λ, N, t)min = w0A + B, w0 < 1 and A, B >0 hold, we derive EBT (w, λ, N, t)min = w0A + B < A+ B = EBT (w′, λ′, N, t). (29) This completes the proof. Corollary 3. At time step t, for ATTA data domains Dϕ,S(t), Ute(1), Ute(2), ··· , Ute(t), Si are unla- beled samples of size m sampled from each of the t + 1 domains respectively, and SS is unlabeled samples of size m sampled from DS. If ˆh(t) ∈ Hminimizes ˆϵ′ w(h(t)) while other conditions remain identical to Theorem 1, then ϵS(ˆh(t)) ≤ ϵS(h∗ S(t)) + tX i=0 wi  ˆdH∆H(Si, SS) + 4 s 2d log(2m) + log 2 δ m + 2γi   + 2C, with probability at least 1 − δ, where C follows Theorem 1 and γi = minh∈H{ϵi(h(t)) + ϵS(h(t))}. Proof. For the empirical source error on DS of hypothesis h at time t, similar to Theorem 1, we apply Lemma 6, Eq. 23 to get ϵS(ˆh(t)) ≤ ϵw(ˆh(t)) + tX i=0 wi  1 2 ˆdH∆H(Si, SS) + 2 s 2d log(2m) + log 2 δ m + γi   ≤ ˆϵw(ˆh(t)) + vuut  tX i=0 w2 i λi !\u0012d log(2N) − log(δ) 2N \u0013 + tX i=0 wi  1 2 ˆdH∆H(Si, SS) + 2 s 2d log(2m) + log 2 δ m + γi   ≤ ˆϵw(h∗ S(t)) + vuut  tX i=0 w2 i λi !\u0012d log(2N) − log(δ) 2N \u0013 + tX i=0 wi  1 2 ˆdH∆H(Si, SS) + 2 s 2d log(2m) + log 2 δ m + γi   ≤ ϵw(h∗ S(t)) + 2 vuut  tX i=0 w2 i λi !\u0012d log(2N) − log(δ) 2N \u0013 + tX i=0 wi  1 2 ˆdH∆H(Si, SS) + 2 s 2d log(2m) + log 2 δ m + γi   ≤ ϵS(h∗ S(t)) + 2 vuut  tX i=0 w2 i λi !\u0012d log(2N) − log(δ) 2N \u0013 + 2 tX i=0 wi  1 2 ˆdH∆H(Si, SS) + 2 s 2d log(2m) + log 2 δ m + γi   32Published as a conference paper at ICLR 2024 = ϵS(h∗ S(t)) + tX i=0 wi  ˆdH∆H(Si, SS) + 4 s 2d log(2m) + log 2 δ m + 2γi   + 2C with probability of at least 1 − δ, where C = r\u0010Pt i=0 w2 i λi \u0011\u0010 d log(2N)−log(δ) 2N \u0011 and γi = minh∈H{ϵi(h(t)) + ϵS(h(t))}. This completes the proof. Corollary 4. At time step t, for ATTA data domains Dϕ,S(t), Ute(1), Ute(2), ··· , Ute(t), suppose that ˆh(t) ∈ Hminimizes ˆϵw′(h(t)) under identical conditions to Theorem 2. Let’s denote the source error upper bound with |ϵS(ˆh(t)) − ϵS(h∗ S(t))| ≤EBS(w, λ, N, t). Let w′ and λ′ be the weight and sample ratio vectors when Dϕ,S(t) is not included, i.e., w′ and λ′ s.t. w′ 0 = λ′ 0 = 0 . If ˆdH∆H(DS, Dϕ,S(t)) < ˆdH∆H(DS, St i=1 Ute(i)), then for any λ ̸= λ′, there exists w s.t. EBS(w, λ, N, t) < EBS(w′, λ′, N, t). (30) Proof. From Theorem 1, considering the test-time data as a single test domain, we can derive the bound for the source error on DS: |ϵS(ˆh(t)) − ϵS(h∗ S(t))| ≤EBS(w, λ, N, t) = w0( ˆdH∆H(S0, SS) + 4 s 2d log(2m) + log 2 δ m + 2γ) + (1 − w0)( ˆdH∆H(SS, ST ) + 4 s 2d log(2m) + log 2 δ m + 2γ′) + 2 s w2 0 λ0 + (1 − w0)2 1 − λ0 r d log(2N) − log(δ) 2N , where ST is sampled fromSt i=1 Ute(i), γ = minh∈H{ϵ0(h(t))+ϵS(h(t))}, and γ′ = minh∈H{ϵT (h(t))+ ϵS(h(t))}. We have s w2 0 λ0 + (1 − w0)2 1 − λ0 = s (w0 − λ0)2 λ0(1 − λ0) + 1 ≥ 1, (31) where the equality and the minimum value are obtained if and only if w0 = λ0. When Dϕ,S(t) is not included,i.e., with the weight and sample ratio vectorsw′ and λ′ s.t. w′ 0 = λ′ 0 = 0, using the empirical gap term B = 2 q d log(2N)−log(δ) 2N , we have EBS(w′, λ′, N, t) = ˆdH∆H(SS, ST ) + 4 s 2d log(2m) + log 2 δ m + 2γ′ + s w2 0 λ0 + (1 − w0)2 1 − λ0 B = ˆdH∆H(SS, ST ) + 4 s 2d log(2m) + log 2 δ m + 2γ′ + B. When Dϕ,S(t) is included with λ0 ̸= 0, EBS(w, λ, N, t) = w0( ˆdH∆H(S0, SS) + 4 s 2d log(2m) + log 2 δ m + 2γ) + (1 − w0)( ˆdH∆H(SS, ST ) + 4 s 2d log(2m) + log 2 δ m + 2γ′) + s w2 0 λ0 + (1 − w0)2 1 − λ0 B ≤ w0( ˆdH∆H(S0, SS) + 4 s 2d log(2m) + log 2 δ m + 2γ) + (1 − w0)( ˆdH∆H(SS, ST ) + 4 s 2d log(2m) + log 2 δ m + 2γ′) + B, 33Published as a conference paper at ICLR 2024 Algorithm 2 INCREMENTAL CLUSTERING (IC) Require: Given previously selected anchors, new unlabeled samples, and the cluster budget as Danc, Unew, and NC . Global anchor weights wanc = (wanc 1 , . . . , wanc |Danc|)⊤. 1: For simplicity, we consider anchor weights wanc as a global vector. 2: function IC(Danc, Unew, NC ) 3: wsp ← Concat(wanc, 1⊤ |Unew|) ▷ Assign all new samples with weight 1. 4: Φ ← Extract the features from the penultimate layer of model f on x ∈ Danc ∪ Unew in order. 5: clusters ← Weighted-K-Means(Φ, wsp, NC) 6: new_clusters ← {clusteri | ∀clusteri ∈ clusters, ∀x ∈ Danc, x /∈ clustersi} 7: Xnew_anchors ← {the closest sample x to the centroid of clusteri | ∀clusteri ∈ new_clusters} 8: Xanchors ← {x ∈ Danc} ∪Xnew_anchors 9: wanc ← Concat(wanc, 0⊤ |Xnew_anchors|) ▷ Initialize new anchor weights. 10: for wanc i ∈ wanc, wanc i ← wanc i + # sample of clusterj # anchor in clusterj , wanc i ∈ clusterj ▷ Weight accumulation. 11: Return Xanchors 12: end function where the minimum value can be obtained with condition w0 = λ0 ̸= 0. In practical learning scenarios, we generally assume adaptation tasks are solvable; therefore, there should be a prediction function that performs well on two distinct domains. In this case, γ and γ′ should be relatively small, so we can assume γ ≈ γ′. If ˆdH∆H(S0, SS) < ˆdH∆H(SS, ST ), then we have EBS(w, λ, N, t)min = w0( ˆdH∆H(S0, SS) + 4 s 2d log(2m) + log 2 δ m + 2γ) + (1 − w0)( ˆdH∆H(SS, ST ) + 4 s 2d log(2m) + log 2 δ m + 2γ′) + B < ˆdH∆H(SS, ST ) + 4 s 2d log(2m) + log 2 δ m + 2γ′ + B = EBS(w′, λ′, N, t). Therefore, we derive EBS(w, λ, N, t)min < EBS(w′, λ′, N, t). (32) This completes the proof. F I NCREMENTAL CLUSTERING F.1 A LGORITHM DETAILS We provide the detailed algorithm for incremental clustering as Alg. 2. F.2 V ISUALIZATION To better illustrate the incremental clustering algorithm, we provide visualization results on PACS to demonstrate the process. As shown in Fig. 3, the initial step of IC is a normal K-Means clustering step, and ten anchors denoted as \"X\" are selected. The weights of all samples in a clusters is aggregated into the corresponding anchor’s weight. Therefore, these ten samples (anchors) are given larger sizes visually (i.e., larger weights) than that of other new test samples in the first IC step (Fig. 4). During the first IC step, several distributions are far away from the existed anchors and form clusters 1,7,9 and 10, which leads to 4 new selected anchors. While the number of cluster centroid is only increased by 1, 4 of the existing anchors are clustered into the same cluster 8 (purple). Thus IC produces 4 new anchors instead of 1. Similarly, in the second IC step (Fig. 5), the new streaming-in test samples introduce a new distribution; IC produces 3 new clusters (4, 8, and 11) and the corresponding number of anchors to cover them. The number of centroid is only increased by 1, which implies that there are two original-cluster-merging events. More IC step visualization results are provided in Fig. 6 and 7. 34Published as a conference paper at ICLR 2024 Figure 3: Initial IC step: normal clustering. Left: Clustering results. Right: Selecting new anchors. Figure 4: The first IC step. Left: Weighted clustering results. Right: Selecting new anchors. Figure 5: The second IC step. Left: Weighted clustering results. Right: Selecting new anchors. 35Published as a conference paper at ICLR 2024 Figure 6: The third IC step. Left: Weighted clustering results. Right: Selecting new anchors. Figure 7: The fourth IC step. Left: Weighted clustering results. Right: Selecting new anchors. 36Published as a conference paper at ICLR 2024 G E XPERIMENT DETAILS In this section, we provide more experimental details including the details of the datasets and training settings. G.1 D ETAILS ABOUT THE DATASETS We adopt datasets PACS, VLCS, and Office-Home from DomainBed (Gulrajani and Lopez-Paz, 2020) with the same domain splits. All available licenses are mentioned below. • PACS (Li et al., 2017) includes four domains: art, cartoons, photos, and sketches. PACS is a 7-class classification dataset with 9,991 images of dimension (3, 224, 224). • VLCS (Fang et al., 2013) contains photographic domains: Caltech101, LabelMe, SUN09, and VOC2007. This dataset includes 10,729 images of dimension (3, 224, 224) with 5 classes. • Office-Home (Venkateswara et al., 2017) is a 65-class dataset, including domains: art, clipart, product, and real. VLCS includes 10,729 images of dimension (3, 224, 244). (License) • Tiny-ImageNet-C is a 200-class dataset, including 15 corrupt types. Tiny-ImageNet-C includes 150,000 images of dimension (3, 224, 244). Since the class number 200 is less than ImageNet (1000), the model’s last layer classifier needs to be adapted. In this work, we use the brightness corruption domain to adapt. In the source pretraining phase, we adopt the most ImageNet-like domain as our source domain. For PACS and Office-Home, we use domains \"photos\" and \"real\" as the source domains, respectively, while for VLCS, Caltech101 is assigned to apply the source pretraining. We freeze the random seeds to generate the sample indices order for the two test data streams, namely, the domain-wise data stream and the random data stream. For PACS, the domain-wise data stream inputs samples from domain art, cartoons, to sketches, while we shuffle all samples from these three domains in the random data stream. For VLCS, we stream the domains in the order: LabelMe, SUN09, and VOC2007, as the domain-wise data stream. For Office-Home, the domain-wise data stream order becomes art, clipart, and product. G.2 T RAINING AND OPTIMIZATION SETTINGS In this section, we extensively discuss the model architectures, optimization settings, and method settings. G.2.1 A RCHITECTURES PACS & VLCS. We adopt ResNet-18 as our model encoder followed by a linear classifier. The initial parameters of ResNet-18 are ImageNet pre-trained weights. In our experiment, we remove the Dropout layer since we empirically found that using the Dropout layer might degrade the optimization process when the sample number is small. The specific implementation of the network is closely aligned with the implementation in DomainBed (Gulrajani and Lopez-Paz, 2020). Office-Home. We employ ResNet-50 as our model encoder for Office-Home. Except for the architecture, the other model settings are aligned with the ResNet-18. Tiny-ImageNet-C ResNet-18 is adapted from ImageNet to Tiny-ImageNet-C by training the last linear layer. G.2.2 T RAINING & OPTIMIZATION In this section, we describe the training configurations for both the source domain pre-training and test-time adaptation procedures. Source domain pre-training. For the PACS and VLCS datasets, models are fine-tuned on the selected source domains for 3,000 iterations. The Adam optimizer is utilized with a learning rate 37Published as a conference paper at ICLR 2024 of 10−4. In contrast, for the Office-Home dataset, the model is fine-tuned for a longer duration of 10,000 iterations with a slightly adjusted learning rate of 5 × 10−5. Test-time adaptation. For test-time adaptation across PACS and VLCS, the pre-trained source model is further fine-tuned using the SGD optimizer with a learning rate of 10−3. While on Office-Home and Tiny-ImageNet-C, a learning rate of 10−4 is adopted. For all TTA baselines, barring specific exceptions, we faithfully adhere to the original implementation settings. A noteworthy exception is the EATA method, which requires a cosine similarity threshold. The default threshold of the original EATA implementation was not suitable for the three datasets used in our study, necessitating an adjustment. We empirically set this threshold to 0.5 for training. Unlike Tent and SAR, which only require the optimization of batch normalization layers (Santurkar et al., 2018), SimATTA allows the training of all parameters in the networks. In experiments, we use a tolerance count (tol) to control the training process. SimATTA will stop updating once the loss does not descrease for more than 5 steps. However, for Tiny-ImageNet-C, SimATTA uses ‘steps=10‘ for time comparisons since other methods apply at most 10 steps. G.2.3 M ETHOD SETTINGS Tent. In our experiments, we apply the official implementation of Tent1. Specifically, we evaluate Tent with 1 test-time training step and 10 steps, respectively. EATA.Our EATA implementation follows its official code2. In our experiments, EATA has 2000 fisher training samples, E0 = 0.4 × log(# class), ϵ <0.5. CoTTA. For CoTTA, we strictly follow all the code and settings from its official implementation3. SAR. With SAR’s official implementation4, we set E0 = 0 .4 × log(# class) and e0 = 0 .1 in our experiments. ADA baselines. For ADA baselines, we follow the architecture of the official implementation of CLUE (Prabhu et al., 2021)5. SimATTA Implementation. Our implementation largely involves straightforward hyperparameter settings. The higher entropy bound eh = 10−2 should exceed the lower entropy bound el, but equal values are acceptable. Empirically, the lower entropy bound el can be set to 10−3 for VLCS and Office-Home, or 10−4 for PACS. The choice of el is largely dependent on the number of source-like samples obtained. A lower el may yield higher-accuracy low-entropy samples, but this could lead to unstable training due to sample scarcity. Though experimentation with different hyperparameters is encouraged, our findings suggest that maintaining a non-trivial number of low-entropy samples and setting an appropriateλ0 are of primary importance. If λ0 < 0.5, CF may ensue, which may negate any potential improvement. Regarding the management of budgets, numerous strategies can be adopted. In our experiments, we utilized a simple hyperparameter k, varying from 1 to 3, to regulate the increasing rate of budget consumption. This strategy is fairly elementary and can be substituted by any adaptive techniques. G.3 S OFTWARE AND HARDWARE We conduct our experiments with PyTorch (Paszke et al., 2019) and scikit-learn (Pedregosa et al., 2011) on Ubuntu 20.04. The Ubuntu server includes 112 Intel(R) Xeon(R) Gold 6258R CPU @2.70GHz, 1.47TB memory, and NVIDIA A100 80GB PCIe graphics cards. The training process costs graphics memory less than 10GB, and it requires CPU computational resources for scikit-learn K-Means clustering calculations. Our implementation also includes a GPU-based PyTorch K-Means method for transferring calculation loads from CPUs to GPUs. However, for consistency, the results of our experiments are obtained with the original scikit-learn K-Means implementation. 1https://github.com/DequanWang/tent 2https://github.com/mr-eggplant/EATA 3https://github.com/qinenergy/cotta 4https://github.com/mr-eggplant/SAR 5https://github.com/virajprabhu/CLUE 38Published as a conference paper at ICLR 2024 Figure 8: Target loss surface on 2000 samples without source pre-training. The red points denote the loss minimum for a fixed λ0. The orange line denote the place where w0 = λ0. Figure 9: Target loss surface on 2000 samples with source pre-training. H E MPIRICAL VALIDATIONS FOR THEORETICAL ANALYSIS In this section, we undertake empirical validation of our learning theory, which encompasses multiple facets awaiting verification. In contemporary computer vision fields, pre-trained models play a pivotal role, and performance would significantly decline without the use of pre-trained features. The learning theory suggests that given the vast VC-dimension of complete ResNets, without substantial data samples, the training error cannot be theoretically tight-bounded. However, we show empirically in the following experiments that fine-tuning pre-trained models is behaviorally akin to training a model with a low VC-dimension. Training on 2000 Samples Without Source Domain Pre-training. For an ImageNet pre-trained ResNet-18 model, we trained it using 2000 samples from the PACS dataset. To ascertain the optimal value w∗ 0 in Equation 4, we trained multiple models for different w0 and λ0 pairings. For each pair, we derived the target domain loss (from art, cartoons, and sketches) post-training and plotted this loss on the z-axis. With w0 and λ0 serving as the xy-axes, we drafted the target domain loss ϵT surface in Figure 8. As the results show, given a λ0, the optimal w∗ 0 typically aligns with the line λ0 = w0, with a slight downward shift, which aligns with Equation 4. 39Published as a conference paper at ICLR 2024 Figure 10: Target loss surface on 500 samples with source pre-training. Figure 11: Source loss surface on 500 samples with source pre-training. 40Published as a conference paper at ICLR 2024 Figure 12: Target and source loss surface on 500 samples with source pre-training. Table 6: TTA comparisons on Office-Home. This table includes the two data stream settings mentioned in the dataset setup and reports performances in accuracy. Results that outperform all TTA baselines are highlighted in bold font. N/A denotes the adaptations are not applied on the source domain. Office-Home Domain-wise data stream Post-adaptation Random data stream Post-adaptation R →A→ →C→ →P R A C P 1 2 3 4 R A C P BN w/o adapt 93.78 42.93 37.62 59.90 93.78 42.93 37.62 59.90 46.82 46.82 46.82 46.82 93.78 42.93 37.62 59.90BN w/ adapt 92.38 49.69 39.43 63.53 92.38 49.69 39.43 63.53 50.88 50.88 50.88 50.88 92.38 49.69 39.43 63.53 Tent (steps=1) N/A 49.61 39.31 63.87 92.47 49.57 39.89 63.89 49.95 50.27 50.23 52.06 92.40 49.24 39.68 63.98Tent (steps=10) N/A 49.61 39.04 61.41 87.08 44.79 38.37 60.49 50.05 49.31 48.74 47.79 85.31 42.85 37.89 58.71EATA N/A 49.65 39.04 63.53 91.60 49.61 38.65 63.48 49.73 50.27 49.45 51.07 91.05 49.11 38.26 62.99CoTTA N/A 49.61 38.76 61.84 87.81 44.95 35.92 59.04 49.84 49.84 48.95 50.43 86.99 43.68 34.73 57.56SAR (steps=1) N/A 49.65 39.24 63.53 92.45 49.73 39.36 63.69 49.84 50.05 49.91 51.67 92.38 49.57 39.50 63.87SAR (steps=10) N/A 49.53 38.81 61.50 88.94 46.15 37.04 59.41 50.09 50.30 49.77 49.22 89.14 46.23 36.31 59.45 SimATTA (B ≤300) N/A 56.20 48.38 71.66 95.75 60.07 52.62 74.70 58.57 60.88 62.91 63.67 95.89 62.01 54.98 74.70SimATTA (B ≤500) N/A 58.71 51.11 74.36 96.03 62.05 57.41 76.98 58.85 62.63 63.41 64.31 95.91 63.78 57.87 77.09 Training on 2000 Samples with Source Domain Pre-training. To further assess the effects of source pre-training, we repeated the same experiment on a source pre-trained ResNet-18. The results are depicted in Figure 9. This experiment provides empirical guidance on selecting w0 in source domain pre-trained situations. The findings suggest that the optimal w∗ 0 non-trivially shifts away from the line λ0 = w0 towards lower-value regions. Considering the source pre-training process as using a greater quantity of source domain samples, it implies that when the number of source samples greatly exceeds target samples, a lower w0 can enhance target domain results. Training on 500 Samples with Source Domain Pre-training. We proceed to fine-tune the source domain pre-trained ResNet-18 using only 500 samples, thereby simulating active TTA settings. We train models with various w0 and λ0 pairings, then graph the target domain losses, source domain losses, and the combined losses. As shown in Figure 10, the target losses still comply with our theoretical deductions where the local minima are close to the line λ0 = w0 and marginally shift towards lower values. Considering the challenge of CF, the source domain results in Figure 11 suggest a reverse trend compared to the target domain, where lower λ0 and w0 values yield superior target domain results but inferior source domain results. Thus, to curb CF, the primary strategy is to maintain a relatively higher λ0. When considering both target and source domains, a balance emerges as depicted in Figure 12. The global minimum is located in the middle region, demonstrating the trade-off between the target domain and source domain performance. I A DDITIONAL EXPERIMENT RESULTS In this section, we provide additional experiment results. The Office-Home results and ablation studies will be presented in a similar way as the main paper. In the full results Sec. I.3, we will post more detailed experimental results with specific budget numbers and intermediate performance during the test-time adaptation. 41Published as a conference paper at ICLR 2024 Table 7: Comparisons to ADA baselines on Office-Home. The source domain is denoted as \"(S)\" in the table. Results are average accuracies with standard deviations). Office-Home R (S) A C P Random (B = 300) 95.04 (0.20) 57.54 (1.16) 53.43 (1.17) 73.46 (0.97) Entropy (B = 300) 94.39 (0.49) 61.21 (0.71) 56.53 (0.71) 72.31 (0.28) Kmeans (B = 300) 95.09 (0.14) 57.37 (0.90) 51.74 (1.34) 71.81 (0.39) CLUE (B = 300) 95.20 (0.23) 60.18 (0.98) 58.05 (0.43) 73.72 (0.70) Ours (B ≤300) 95.82 (0.07) 61.04 (0.97) 53.80 (1.18) 74.70 (0.00) I.1 R ESULTS ON OFFICE -HOME We conduct experiments on Office-Home and get the test-time performances and post-adaptation performances for two data streams. As shown in Tab. 6, SimATTA can outperform all TTA baselines with huge margins. Compared to ADA baselines under the source-free settings, as shown in Tab. 7, SimATTA obtains comparable results. I.2 A BLATION STUDIES Figure 13: Ablation study on PACS and VLCS.\"IC=0\" denotes removing incremental clustering (IC) selection. \"LE=0\" denotes removing the low-entropy (LE) sample training. Domain-wise stream and random stream are applied on first and second rows, respectively. The accuracy values are averaged across all splits/domains. In this section, we explore three variations of our method to examine the individual impacts of its components. The first variant replaces the incremental clustering selection with entropy selection, 42Published as a conference paper at ICLR 2024 where only the samples with the highest entropy are chosen. The second variant eliminates low- entropy sample training. The third variation combines the first and second variants. We perform this ablation study on the PACS and VLCS as outlined in Fig. 13. We denote the use of incremental clustering (IC) and low-entropy training (LE) respectively as IC=1 and LE=1. The experiments essentially reveals the effectiveness of incremental clustering and low-entropy- sample training. As we have detailed in Sec. 3.2, these techniques are designed to to select informative samples, increase distribution coverage, and mitigate catastrophic forgetting. These designs appositely serve the ATTA setting where the oracle has costs and the budget is limited. Therefore, their effectiveness is prominent particularly when the budget is small. As the results show, when the budget B ≤100 or B ≤300, removing the components observably impairs performances. When B gets large, more active samples cover a larger distribution; thus the performance gap from random selection and informative selection gets smaller. In the extreme case where B → ∞, all samples are selected and thus the superiority of our meticulously-designed techniques are not manifested. Specifically, our analysis yields several insights. First, SimATTA (LE=1, IC=1) comprehensively outperforms other variants on both datasets, different streams, and different budgets. Second, variants without low-entropy training (LE=0, IC=0/1) easily fail to produce stable results (e.g., domain-wise stream in VLCS). Third, SimATTA’s performance surpasses this variant on PACS’s domain-wise stream clearly especially when the budgets are low. This indicates these variants fail to retrieve the most informative style shift (PACS’s shifts) samples, which implies the advantage of incremental clustering when the budget is tight. In addition, these results show that IC has its unique advantage on domain-wise streams where distributions change abruptly instead of random streams. Therefore, compared to PACS’s domain- wise stream results, the reason for the smaller performance improvement of SimATTA over the variant (LE=1, IC=0) on VLCS’s domain-wise stream is that images in VLCS are all photos that do not include those severe style shifts in PACS (i.e., art, cartoons, and sketches). That is, when the shift is not severe, we don’t need IC to cover very different distributions, and selecting samples using entropy can produce good results. In brief, IC is extraordinary for severe distribution shifts and quick adaptation. It is worth mentioning that low budget comparison is essential to show the informative sample retrieval ability, since as the budget increases, all AL techniques will tend to perform closely. I.3 C OMPLETE EXPERIMENT RESULTS We provide complete experimental results in this section. As shown in Tab. 8, we present the full results for two data streams. The test-time adaptation accuracies are shown in the \"Current domain\" row, while the \"Budgets\" row denotes the used budget by the end of the domain. The rest four rows denote the four domain test results by the end of the real-time adaptation of the current domain, where the first column results are the test accuracy before the test-time adaptation phase. N/A represents \"do not apply\". Table 8: Tent (steps=1) on PACS. Tent (steps=1) Domain-wise data stream Random data stream P →A→ → C→ → S 1 → → 2→ → 3→ → 4→ Current domain N/A 67.29 64.59 44.67 56.35 54.09 51.83 48.58 Budgets N/A N/A N/A N/A N/A N/A N/A N/A P 99.70 98.68 98.38 97.60 98.56 98.08 97.72 97.19 A 59.38 69.09 68.95 66.85 68.07 67.33 65.58 63.53 C 28.03 64.04 65.19 64.08 64.85 65.19 62.97 60.75 S 42.91 53.65 47.39 42.58 54.57 49.83 44.13 41.56 J C HALLENGES AND PERSPECTIVES Despite advancements, test-time adaptation continues to pose considerable challenges. As previously discussed, without supplementary information and assumptions, the ability to guarantee model generalization capabilities is limited. However, this is not unexpected given that recent progress 43Published as a conference paper at ICLR 2024 Table 9: Tent (steps=10) on PACS. Tent (steps=10) Domain-wise data stream Random data stream P →A→ → C→ → S 1 → → 2→ → 3→ → 4→ Current domain N/A 67.38 57.85 20.23 47.36 31.01 22.84 20.33 Budgets N/A N/A N/A N/A N/A N/A N/A N/A P 99.70 95.45 87.43 62.63 93.83 81.32 65.39 50.78 A 59.38 64.94 55.03 34.52 55.32 40.28 28.27 23.68 C 28.03 55.89 56.70 40.57 54.52 39.68 27.22 20.95 S 42.91 36.96 26.27 13.59 32.25 23.16 20.95 19.62 Table 10: EATA on PACS. EATA Domain-wise data stream Random data stream P →A→ → C→ → S 1 → → 2→ → 3→ → 4→ Current domain N/A 67.04 64.72 50.27 57.31 56.06 58.17 59.78 Budgets N/A N/A N/A N/A N/A N/A N/A N/A P 99.70 98.62 98.50 98.62 98.68 98.62 98.50 98.62 A 59.38 68.90 68.16 66.50 68.65 68.95 69.34 69.63 C 28.03 63.74 65.36 62.46 65.19 66.00 65.57 65.70 S 42.91 54.01 52.89 48.18 55.71 55.64 54.09 54.26 Table 11: CoTTA on PACS. CoTTA Domain-wise data stream Random data stream P →A→ → C→ → S 1 → → 2→ → 3→ → 4→ Current domain N/A 65.48 62.12 53.17 56.06 54.33 57.16 57.42 Budgets N/A N/A N/A N/A N/A N/A N/A N/A P 99.70 98.68 98.62 98.62 98.62 98.62 98.56 98.62 A 59.38 65.82 65.87 65.48 66.02 65.87 66.31 65.97 C 28.03 62.63 63.05 63.10 63.01 62.88 63.01 62.97 S 42.91 53.88 54.03 53.78 54.67 55.31 55.10 54.62 Table 12: SAR (steps=1) on PACS. SAR (steps=1) Domain-wise data stream Random data stream P →A→ → C→ → S 1 → → 2→ → 3→ → 4→ Current domain N/A 66.75 63.82 49.58 56.78 56.35 56.68 56.70 Budgets N/A N/A N/A N/A N/A N/A N/A N/A P 99.70 98.68 98.50 98.32 98.74 98.56 98.50 98.44 A 59.38 68.02 68.07 66.94 67.87 68.65 68.55 68.16 C 28.03 62.84 64.97 62.93 63.82 64.89 64.46 64.38 S 42.91 53.47 52.07 45.74 54.92 55.46 53.68 52.53 Table 13: SAR (steps=10) on PACS. SAR (steps=10) Domain-wise data stream Random data stream P →A→ → C→ → S 1 → → 2→ → 3→ → 4→ Current domain N/A 69.38 68.26 49.02 53.51 51.15 51.78 45.60 Budgets N/A N/A N/A N/A N/A N/A N/A N/A P 99.70 98.20 95.39 96.47 97.13 97.78 97.72 94.13 A 59.38 72.36 66.60 62.16 62.74 64.94 66.11 56.64 C 28.03 63.44 68.30 56.19 59.77 61.73 62.03 56.02 S 42.91 53.37 44.59 54.62 41.00 49.66 48.79 36.37 44Published as a conference paper at ICLR 2024 Table 14: SimATTA (B ≤300) on PACS. SimATTA (B ≤300) Domain-wise data stream Random data stream P →A→ → C→ → S 1 → → 2→ → 3→ → 4→ Current domain N/A 76.86 70.90 75.39 69.47 76.49 82.45 82.22 Budgets N/A 75 145 223 66 142 203 267 P 99.70 98.44 98.86 98.80 97.96 98.68 99.04 98.98 A 59.38 80.71 82.32 84.47 73.97 80.52 81.10 84.91 C 28.03 48.12 82.00 82.25 72.35 81.06 83.36 83.92 S 42.91 32.78 56.25 81.52 79.49 83.10 84.78 86.00 Table 15: SimATTA (B ≤500) on PACS. SimATTA (B ≤500) Domain-wise data stream Random data stream P →A→ → C→ → S 1 → → 2→ → 3→ → 4→ Current domain N/A 77.93 76.02 76.30 68.46 78.22 80.91 85.49 Budgets N/A 121 230 358 102 221 343 425 P 99.70 98.92 98.86 98.62 98.20 99.46 99.10 99.16 A 59.38 87.01 87.60 88.33 73.39 79.20 84.91 86.67 C 28.03 54.78 83.96 83.49 68.43 74.40 84.22 84.77 S 42.91 46.37 63.53 83.74 81.34 81.04 86.66 87.71 Table 16: Tent (steps=1) on VLCS. Tent (steps=1) Domain-wise data stream Random data stream C →L→ → S→ → V 1 → → 2→ → 3→ → 4→ Current domain N/A 38.55 34.40 53.88 44.85 44.29 47.38 44.98 Budgets N/A N/A N/A N/A N/A N/A N/A N/A C 100.00 84.81 85.44 84.73 84.95 85.16 85.80 85.30 L 33.55 40.02 43.11 43.86 39.68 41.98 43.11 43.49 S 41.10 33.39 35.41 33.61 36.29 37.90 38.27 37.81 V 49.08 53.20 54.06 53.11 53.76 54.18 53.76 53.35 Table 17: Tent (steps=10) on VLCS. Tent (steps=10) Domain-wise data stream Random data stream C →L→ → S→ → V 1 → → 2→ → 3→ → 4→ Current domain N/A 45.41 31.44 32.32 46.13 42.31 43.51 39.48 Budgets N/A N/A N/A N/A N/A N/A N/A N/A C 100.00 73.07 48.34 42.54 74.13 62.19 56.54 52.01 L 33.55 46.61 38.44 37.65 44.88 45.93 43.41 40.32 S 41.10 31.75 28.82 27.79 35.37 36.14 35.28 33.64 V 49.08 48.05 40.14 33.12 50.50 44.49 42.48 40.37 Table 18: EATA on VLCS. EATA Domain-wise data stream Random data stream C →L→ → S→ → V 1 → → 2→ → 3→ → 4→ Current domain N/A 37.24 33.15 52.58 43.77 42.48 43.34 41.55 Budgets N/A N/A N/A N/A N/A N/A N/A N/A C 100.00 85.16 85.02 84.10 84.73 84.52 84.10 83.32 L 33.55 37.16 37.24 37.69 37.09 36.78 36.90 36.67 S 41.10 33.39 33.49 32.39 33.33 32.54 31.84 31.47 V 49.08 51.87 52.16 52.49 52.07 52.43 52.64 52.55 45Published as a conference paper at ICLR 2024 Table 19: CoTTA on VLCS. CoTTA Domain-wise data stream Random data stream C →L→ → S→ → V 1 → → 2→ → 3→ → 4→ Current domain N/A 37.39 32.54 52.25 43.69 42.14 43.21 42.32 Budgets N/A N/A N/A N/A N/A N/A N/A N/A C 100.00 81.55 81.98 82.12 82.61 82.47 82.12 81.98 L 33.55 37.20 37.91 37.65 38.48 38.22 38.40 37.99 S 41.10 30.71 32.78 33.12 34.00 33.70 33.97 33.52 V 49.08 52.01 52.64 52.90 53.64 53.14 53.08 53.23 Table 20: SAR (steps=1) on VLCS. SAR (steps=1) Domain-wise data stream Random data stream C →L→ → S→ → V 1 → → 2→ → 3→ → 4→ Current domain N/A 36.18 34.43 52.46 43.64 43.04 44.20 41.93 Budgets N/A N/A N/A N/A N/A N/A N/A N/A C 100.00 84.31 84.17 83.96 85.09 85.23 85.23 85.09 L 33.55 35.62 38.29 39.72 38.55 39.34 40.21 40.70 S 41.10 33.24 36.41 36.53 34.37 35.62 36.29 36.44 V 49.08 51.75 52.61 52.37 52.90 52.75 53.05 53.02 Table 21: SAR (steps=10) on VLCS. SAR (steps=10) Domain-wise data stream Random data stream C →L→ → S→ → V 1 → → 2→ → 3→ → 4→ Current domain N/A 35.32 34.10 51.66 43.56 42.05 42.53 41.16 Budgets N/A N/A N/A N/A N/A N/A N/A N/A C 100.00 83.96 83.04 82.12 84.03 84.24 85.23 85.09 L 33.55 34.07 35.92 41.49 39.53 38.37 37.65 37.58 S 41.10 31.93 34.89 33.94 35.19 32.94 33.88 33.12 V 49.08 51.33 51.51 53.08 52.78 52.34 51.78 52.01 Table 22: SimATTA (B ≤300) on VLCS. SimATTA (B ≤300) Domain-wise data stream Random data stream C →L→ → S→ → V 1 → → 2→ → 3→ → 4→ Current domain N/A 62.61 65.08 74.38 62.33 69.33 73.20 71.93 Budgets N/A 79 175 272 71 135 208 262 C 100.00 99.51 98.52 99.93 99.86 99.79 100.00 99.93 L 33.55 68.11 69.92 69.50 62.61 66.64 68.45 69.43 S 41.10 55.24 68.89 66.67 65.54 69.29 71.79 72.46 V 49.08 66.08 70.94 77.34 73.79 76.87 78.82 80.39 Table 23: SimATTA (B ≤500) on VLCS. SimATTA (B ≤500) Domain-wise data stream Random data stream C →L→ → S→ → V 1 → → 2→ → 3→ → 4→ Current domain N/A 63.52 68.01 76.13 62.29 70.45 73.50 72.02 Budgets N/A 113 266 446 107 203 283 356 C 100.00 99.29 98.59 99.51 99.93 99.86 99.86 99.43 L 33.55 62.95 70.63 70.56 66.57 67.09 67.24 70.29 S 41.10 51.31 73.83 73.10 65.33 71.79 72.91 72.55 V 49.08 59.36 71.65 78.35 73.58 77.84 80.01 80.18 46Published as a conference paper at ICLR 2024 Table 24: Tent (steps=1) on Office-Home. Tent (steps=1) Domain-wise data stream Random data stream R →A→ → C→ → P 1 → → 2→ → 3→ → 4→ Current domain N/A 49.61 39.31 63.87 49.95 50.27 50.23 52.06 Budgets N/A N/A N/A N/A N/A N/A N/A N/A R 96.44 92.33 92.36 92.47 92.38 92.45 92.45 92.40 A 57.07 49.73 49.73 49.57 49.69 49.73 49.57 49.24 C 44.97 39.27 39.54 39.89 39.45 39.68 39.73 39.68 P 73.15 63.60 63.66 63.89 63.60 63.82 63.93 63.98 Table 25: Tent (steps=10) on Office-Home. Tent (steps=10) Domain-wise data stream Random data stream R →A→ → C→ → P 1 → → 2→ → 3→ → 4→ Current domain N/A 49.61 39.04 61.41 50.05 49.31 48.74 47.79 Budgets N/A N/A N/A N/A N/A N/A N/A N/A R 96.44 91.99 89.14 87.08 92.08 90.80 88.59 85.31 A 57.07 49.94 46.77 44.79 49.44 48.21 45.69 42.85 C 44.97 38.58 39.11 38.37 40.18 40.02 38.63 37.89 P 73.15 63.28 61.03 60.49 64.36 63.64 61.12 58.71 Table 26: EATA on Office-Home. EATA Domain-wise data stream Random data stream R →A→ → C→ → P 1 → → 2→ → 3→ → 4→ Current domain N/A 49.65 39.04 63.53 49.73 50.27 49.45 51.07 Budgets N/A N/A N/A N/A N/A N/A N/A N/A R 96.44 92.36 92.17 91.60 92.38 92.22 91.71 91.05 A 57.07 49.57 49.53 49.61 49.69 49.40 49.36 49.11 C 44.97 39.08 39.01 38.65 39.27 39.01 38.42 38.26 P 73.15 63.42 63.42 63.48 63.51 63.37 63.33 62.99 Table 27: CoTTA on Office-Home. CoTTA Domain-wise data stream Random data stream R →A→ → C→ → P 1 → → 2→ → 3→ → 4→ Current domain N/A 49.61 38.76 61.84 49.84 49.84 48.95 50.43 Budgets N/A N/A N/A N/A N/A N/A N/A N/A R 96.44 90.38 88.02 87.81 90.48 89.37 88.00 86.99 A 57.07 48.58 45.53 44.95 47.34 46.35 44.62 43.68 C 44.97 36.66 35.58 35.92 37.55 36.40 35.44 34.73 P 73.15 60.40 57.74 59.04 61.12 59.63 58.35 57.56 Table 28: SAR (steps=1) on Office-Home. SAR (steps=1) Domain-wise data stream Random data stream R →A→ → C→ → P 1 → → 2→ → 3→ → 4→ Current domain N/A 49.65 39.24 63.53 49.84 50.05 49.91 51.67 Budgets N/A N/A N/A N/A N/A N/A N/A N/A R 96.44 92.38 92.31 92.45 92.40 92.36 92.36 92.38 A 57.07 49.65 49.57 49.73 49.69 49.61 49.57 49.57 C 44.97 39.34 39.22 39.36 39.34 39.56 39.47 39.50 P 73.15 63.51 63.51 63.69 63.60 63.71 63.71 63.87 47Published as a conference paper at ICLR 2024 Table 29: SAR (steps=10) on Office-Home. SAR (steps=10) Domain-wise data stream Random data stream R →A→ → C→ → P 1 → → 2→ → 3→ → 4→ Current domain N/A 49.53 38.81 61.50 50.09 50.30 49.77 49.22 Budgets N/A N/A N/A N/A N/A N/A N/A N/A R 96.44 92.20 92.06 88.94 92.40 92.47 91.53 89.14 A 57.07 49.40 49.77 46.15 49.81 50.02 48.91 46.23 C 44.97 39.20 38.63 37.04 39.50 39.29 38.65 36.31 P 73.15 63.53 62.69 59.41 64.18 64.18 62.83 59.45 Table 30: SimATTA (B ≤300) on Office-Home. SimATTA (B ≤300) Domain-wise data stream Random data stream R →A→ → C→ → P 1 → → 2→ → 3→ → 4→ Current domain N/A 56.20 48.38 71.66 58.57 60.88 62.91 63.67 Budgets N/A 75 187 277 79 147 216 278 R 96.44 95.43 95.43 95.75 95.91 95.96 96.01 95.89 A 57.07 57.56 59.50 60.07 58.34 59.91 61.15 62.01 C 44.97 42.25 52.46 52.62 51.66 52.30 54.75 54.98 P 73.15 68.84 70.13 74.70 72.45 73.10 74.50 74.70 Table 31: SimATTA (B ≤500) on Office-Home. SimATTA (B ≤500) Domain-wise data stream Random data stream R →A→ → C→ → P 1 → → 2→ → 3→ → 4→ Current domain N/A 58.71 51.11 74.36 58.85 62.63 63.41 64.31 Budgets N/A 107 284 440 126 248 361 467 R 96.44 95.69 95.71 96.03 96.26 96.19 95.87 95.91 A 57.07 61.43 61.43 62.05 58.18 61.15 61.52 63.78 C 44.97 46.41 57.73 57.41 53.17 55.14 56.79 57.87 P 73.15 70.74 71.98 76.98 73.51 74.18 75.78 77.09 48Published as a conference paper at ICLR 2024 in deep learning heavily relies on large-scale data. Consequently, two promising paths emerge: establishing credible assumptions and leveraging additional information. Firstly, developing credible assumptions can lead to comprehensive comparisons across various stud- ies. Given that theoretical guarantees highlight the inherent differences between methods primarily based on the application limits of their assumptions, comparing these assumptions becomes critical. Without such comparative studies, empirical evaluations may lack precise guidance and explanation. Secondly, while we acknowledge the value of real-world data (observations), discussions surrounding the use of extra information remain pertinent. Considerations include the strategies to acquire this supplementary information and the nature of the additional data needed. Despite the myriad of works on domain generalization, domain adaptation, and test-time adaptation, a comprehensive survey or benchmark encapsulating the aforementioned comparisons remains an unmet need. Moreover, potential future directions for out-of-distribution generalization extend beyond domain generalization and test-time adaptation. One promising avenue is bridging the gap between causal inference and deep learning, for instance, through causal representation learning. In conclusion, our hope is that this work not only offers a novel practical setting and algorithm but also illuminates meaningful future directions and research methodologies that can benefit the broader scientific community. 49",
      "meta_data": {
        "arxiv_id": "2404.05094v1",
        "authors": [
          "Shurui Gui",
          "Xiner Li",
          "Shuiwang Ji"
        ],
        "published_date": "2024-04-07T22:31:34Z",
        "pdf_url": "https://arxiv.org/pdf/2404.05094v1.pdf",
        "github_url": "https://github.com/divelab/ATTA"
      },
      "llm_extracted_info": {
        "main_contributions": "Introduces Active Test-Time Adaptation (ATTA), a new setting that augments fully test-time adaptation with limited active labeling; provides VC-theory-based generalization and forgetting bounds proving benefit of few labeled test samples; proposes Sample-Entropy Balancing to avoid catastrophic forgetting; delivers a lightweight algorithm, SimATTA, that integrates balanced selective entropy minimization and incremental clustering for real-time sample selection; shows SimATTA outperforms state-of-the-art TTA and matches heavier ADA methods on PACS, VLCS, Office-Home and Tiny-ImageNet-C.",
        "methodology": "1) Theoretical analysis: derives error bounds using H∆H distance for multi-domain streaming setting; optimizes weight w0 ≈ λ0 to trade source vs test data, proves ATTA tighter than TTA. 2) Catastrophic forgetting mitigation: treat low-entropy test samples as source-like, include them with balanced weights (Sample-Entropy Balancing). 3) SimATTA algorithm: • split each test batch into high-entropy (candidate informative) and low-entropy (source-like) sets; • incremental weighted k-means clustering on high-entropy buffer to pick diverse anchors within a budget; • query oracle for anchors, add pseudo-labels for low-entropy samples; • fine-tune all model params online with weighted cross-entropy. Implementation uses ResNet backbones, SGD/Adam, small buffer, budget growth k.",
        "experimental_setup": "Datasets: PACS, VLCS, Office-Home (DomainBed splits) for domain shift; Tiny-ImageNet-C (15 corruption types) for covariate noise; source domain pre-training on one domain, streaming test data in domain-wise and random orders. Baselines: Source-only BN, Tent, EATA, CoTTA, SAR (TTA); enhanced TTA with random labels; Active Domain Adaptation methods (Random, Entropy, K-means, CLUE). Metrics: online accuracy per split and post-adaptation accuracy; time cost. Budgets tested ≤100, ≤300, ≤500 anchors; training steps 1 or 10 for baselines, adaptive for SimATTA.",
        "limitations": "Assumes oracle labeling available and fixed small budget; relies on entropy as proxy for source-likeness which may fail if pre-trained model is poor; incremental clustering uses simple k-means and a manual budget-increase hyper-parameter; theoretical bounds depend on VC-dimension simplifications and assume fine-tuning reduces effective model capacity; experiments limited to image classification, moderate backbone sizes; no analysis on class-incremental or label-space shifts.",
        "future_research_directions": "1) Design adaptive or learned budgeting and centroid-growth strategies removing manual k; 2) Explore alternative source-like identification beyond entropy, including causal or self-supervised criteria; 3) Extend ATTA to other modalities (NLP, graphs) and larger backbones/LLMs; 4) Handle class-incremental and open-set shifts within ATTA; 5) Develop stronger theoretical bounds capturing continual optimization dynamics; 6) Integrate uncertainty-aware or memory-efficient clustering to further cut computation.",
        "experimental_code": "# =======================  SimATTA main algorithm  =======================\n# File: ATTA/kernel/algorithms/SimATTA.py\n\nimport copy\nimport time\nfrom typing import Union, Literal\n\nimport numpy as np\nfrom sklearn.metrics import pairwise_distances_argmin_min\nfrom torch import nn\nimport torch\nfrom munch import Munch\nfrom tqdm import tqdm\n\nfrom ATTA import register\nfrom ATTA.utils.config_reader import Conf\nfrom ATTA.data.loaders.fast_data_loader import InfiniteDataLoader, FastDataLoader\nfrom torch.utils.data import TensorDataset\nfrom .Base import AlgBase\n\n\n@register.alg_register\nclass SimATTA(AlgBase):\n    \"\"\"Implementation of SimATTA (Sample-entropy-balanced Incremental Multidomain Active TTA).\n    Main idea:\n        1. Split each arriving batch into High-Entropy (HE, informative) and Low-Entropy (LE, source-like) parts\n           using thresholds eh/el.\n        2. Maintain two anchor buffers (target & source) updated via incremental weighted k-means clustering.\n        3. Query oracle on HE anchors, add pseudo-labels for LE samples (Sample-Entropy Balancing).\n        4. Fine-tune network online with weighted cross-entropy; teacher model updated with EMA.\n    \"\"\"\n\n    def __init__(self, config: Conf):\n        super(SimATTA, self).__init__(config)\n\n        # student / teacher\n        self.teacher = copy.deepcopy(self.model.to('cpu'))\n        self.model.to(config.device)\n        self.teacher.to(config.device)\n        self.update_teacher(0)  # copy at t=0\n\n        # buffers & parameters -------------------------------------------------\n        self.budgets = 0                        # total oracle budget used\n        self.anchors = None                     # target-entropy anchors\n        self.source_anchors = None              # LE (source-like) anchors\n        self.buffer = []\n\n        # clustering settings\n        self.n_clusters = 10                    # initial clusters for HE\n        self.nc_increase = config.atta.SimATTA.nc_increase\n        self.source_n_clusters = 100            # clusters for LE\n\n        # thresholds & balancing ------------------------------------------------\n        self.cold_start = config.atta.SimATTA.cold_start\n        self.beta = config.atta.SimATTA.beta    # trade-off HE / LE when weighting loss\n        self.alpha = 0.2                        # min alpha for HE in cold start\n        self.target_cluster = bool(config.atta.SimATTA.target_cluster)\n        self.LE = bool(config.atta.SimATTA.LE)  # whether to treat LE as source-like\n\n        # internal logging\n        self.vis_round = 0\n\n    # -------------------------------------------------------------------------\n    #  TEACHER UPDATE (EMA)\n    # -------------------------------------------------------------------------\n    def update_teacher(self, alpha_teacher: float):\n        for t_param, s_param in zip(self.teacher.parameters(), self.model.parameters()):\n            t_param.data[:] = alpha_teacher * t_param.data + (1 - alpha_teacher) * s_param.data\n        if not self.config.model.freeze_bn:\n            for tm, m in zip(self.teacher.modules(), self.model.modules()):\n                if isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d)):\n                    tm.running_mean = alpha_teacher * tm.running_mean + (1 - alpha_teacher) * m.running_mean\n                    tm.running_var  = alpha_teacher * tm.running_var  + (1 - alpha_teacher) * m.running_var\n\n    # -------------------------------------------------------------------------\n    #  CORE ONLINE ADAPTATION LOOP\n    # -------------------------------------------------------------------------\n    @torch.no_grad()\n    def adapt_on_env(self, loader, env_id):\n        acc = 0\n        for data, target in tqdm(loader[env_id]):\n            data, target = data.to(self.config.device), target.to(self.config.device)\n\n            # 1) Select informative samples via entropy & clustering --------------\n            outputs, closest, self.anchors = self.sample_select(\n                self.model, data, target, self.anchors,\n                n_clusters=int(self.n_clusters), ent_beta=1,\n                ent_bound=self.config.atta.SimATTA.eh,\n                incremental_cluster=self.target_cluster)\n\n            # 2) (Optional) treat low-entropy samples as source-like --------------\n            if self.LE:\n                _, _, self.source_anchors = self.sample_select(\n                    self.teacher, data, target, self.source_anchors,\n                    n_clusters=self.source_n_clusters, ent_beta=0,\n                    use_pseudo_label=True,\n                    ent_bound=self.config.atta.SimATTA.el,\n                    incremental_cluster=False)\n            else:\n                self.source_anchors = self.update_anchors(None, torch.tensor([]), None, None, None)\n\n            # 3) Update budgets / cluster numbers --------------------------------\n            self.budgets     += len(closest)\n            self.n_clusters  += self.nc_increase\n            self.source_n_clusters += 1\n\n            # 4) Online fine-tuning with balanced weights ------------------------\n            if self.source_anchors.num_elem() > 0:\n                self.cluster_train(self.anchors, self.source_anchors)\n            else:\n                self.cluster_train(self.anchors, self.anchors)\n\n            # 5) Refresh anchor features for next round --------------------------\n            self.anchors = self.update_anchors_feats(self.anchors)\n\n            # real-time accuracy --------------------------------------------------\n            acc += self.config.metric.score_func(target, outputs).item() * data.shape[0]\n        acc /= len(loader[env_id].sampler)\n        print(f\"#IN#Env {env_id} real-time Acc.: {acc:.4f}\")\n        return acc\n\n    # -------------------------------------------------------------------------\n    #  ANCHOR SELECTION & CLUSTERING\n    # -------------------------------------------------------------------------\n    @torch.no_grad()\n    def sample_select(self,\n                      model, data, target, anchors,\n                      n_clusters: int,\n                      ent_beta: int,\n                      use_pseudo_label: bool = False,\n                      ent_bound: float = 1e-2,\n                      incremental_cluster: bool = False):\n        \"\"\"Split batch using entropy, optionally cluster and return new anchors.\"\"\"\n        model.eval()\n        feats   = model[0](data)\n        outputs = model[1](feats)\n        pseudo_label = outputs.argmax(1).cpu()\n        data   = data.cpu(); feats = feats.cpu(); target = target.cpu()\n        entropy = self.softmax_entropy(outputs).cpu()\n\n        # ---------- selection masks ----------\n        if not incremental_cluster:\n            entropy_np = entropy.numpy()\n            if ent_beta == 0:  # low entropy set\n                idx = np.argsort(entropy_np)[:n_clusters]\n                idx = idx[entropy_np[idx] < ent_bound]\n            else:             # high entropy set\n                idx = np.argsort(entropy_np)[-n_clusters:]\n                idx = idx[entropy_np[idx] >= ent_bound]\n            weights = torch.zeros(len(idx), dtype=torch.float)\n        else:\n            if ent_beta == 0:\n                mask = entropy < ent_bound\n            else:\n                mask = entropy >= ent_bound\n            data, target, feats, pseudo_label = data[mask], target[mask], feats[mask], pseudo_label[mask]\n            # incremental weighted k-means ----------------------------------\n            # (Uses CPU sklearn KMeans, GPU version available via utils)\n            from joblib import parallel_backend\n            from sklearn.cluster import KMeans\n            if anchors:\n                feats4cluster = torch.cat([anchors.feats, feats])\n                sample_weight = torch.cat([anchors.weight,\n                                           torch.ones(len(feats))])\n            else:\n                feats4cluster = feats\n                sample_weight = torch.ones(len(feats))\n            with parallel_backend('threading', n_jobs=8):\n                kmeans = KMeans(n_clusters=n_clusters, n_init=10, algorithm='elkan').fit(\n                    feats4cluster, sample_weight=sample_weight)\n                raw_closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, feats4cluster)\n            kmeans_labels = kmeans.labels_\n            if anchors:\n                num_anchors = anchors.num_elem()\n                prev_cluster = torch.tensor(kmeans_labels[:num_anchors])\n                anchored_mask = torch.zeros(len(raw_closest), dtype=torch.bool)\n                anchored_mask[prev_cluster.unique()] = True\n                new_cluster_mask = ~anchored_mask\n                closest = raw_closest[new_cluster_mask] - num_anchors\n                weights = torch.tensor(np.bincount(kmeans_labels)[new_cluster_mask])\n            else:\n                closest = raw_closest\n                weights = torch.tensor(np.bincount(kmeans_labels))\n        # ---------- update anchor buffers ----------\n        if use_pseudo_label:\n            anchors = self.update_anchors(anchors, data[closest], pseudo_label[closest], feats[closest], weights)\n        else:\n            anchors = self.update_anchors(anchors, data[closest], target[closest], feats[closest], weights)\n        return outputs, closest, anchors\n\n    # -------------------------------------------------------------------------\n    #  BUFFER & TRAIN-UTILITY FUNCTIONS\n    # -------------------------------------------------------------------------\n    def update_anchors(self, anchors, data, target, feats, weight):\n        if anchors is None:\n            anchors = Munch()\n            anchors.data   = data\n            anchors.target = target\n            anchors.feats  = feats\n            anchors.weight = weight\n            anchors.num_elem = lambda : len(anchors.data)\n        else:\n            anchors.data   = torch.cat([anchors.data,   data])\n            anchors.target = torch.cat([anchors.target, target])\n            anchors.feats  = torch.cat([anchors.feats,  feats])\n            anchors.weight = torch.cat([anchors.weight, weight])\n        return anchors\n\n    def update_anchors_feats(self, anchors):\n        loader = FastDataLoader(TensorDataset(anchors.data), weights=None,\n                                batch_size=32, num_workers=self.config.num_workers, sequential=True)\n        anchors.feats = None\n        self.model.eval()\n        for (data,) in loader:\n            data = data.to(self.config.device)\n            feat = self.model[0](data).cpu()\n            anchors.feats = feat if anchors.feats is None else torch.cat([anchors.feats, feat])\n        return anchors\n\n    # -------------------------------------------------------------------------\n    #  TRAINING WITH SELECTED ANCHORS (HE vs LE, Sample-Entropy Balancing)\n    # -------------------------------------------------------------------------\n    @torch.enable_grad()\n    def cluster_train(self, target_anchors, source_anchors):\n        self.model.train()\n        # loaders --------------------------------------------------------------\n        source_loader = InfiniteDataLoader(TensorDataset(source_anchors.data, source_anchors.target), None,\n                                           batch_size=self.config.train.train_bs, num_workers=self.config.num_workers)\n        target_loader = InfiniteDataLoader(TensorDataset(target_anchors.data, target_anchors.target), None,\n                                           batch_size=self.config.train.train_bs, num_workers=self.config.num_workers)\n        alpha = target_anchors.num_elem() / (target_anchors.num_elem() + source_anchors.num_elem())\n        if source_anchors.num_elem() < self.cold_start:\n            alpha = min(0.2, alpha)  # cold-start: rely more on source\n\n        optimizer = torch.optim.SGD(self.model.parameters(), lr=self.config.atta.SimATTA.lr, momentum=0.9)\n        ST_loader = zip(source_loader, target_loader)\n        loss_window, lowest_loss, tol = [], float('inf'), 0\n        for i, ((S_data, S_y), (T_data, T_y)) in enumerate(ST_loader):\n            S_data, S_y = S_data.to(self.config.device), S_y.to(self.config.device)\n            T_data, T_y = T_data.to(self.config.device), T_y.to(self.config.device)\n            # weighted CE ----------------------------------------------------------------\n            loss_s = self.config.metric.loss_func(self.model(S_data), S_y)\n            loss_t = self.config.metric.loss_func(self.model(T_data), T_y)\n            loss = (1 - alpha) * loss_s + alpha * loss_t\n            optimizer.zero_grad(); loss.backward(); optimizer.step()\n\n            # early-stop based on moving window --------------------------------\n            if len(loss_window) < self.config.atta.SimATTA.stop_tol:\n                loss_window.append(loss_t.item())\n            else:\n                mean_loss = np.mean(loss_window); tol += 1\n                if mean_loss < lowest_loss: lowest_loss, tol = mean_loss, 0\n                if tol > 5: break\n                loss_window = []\n            if i > self.config.atta.SimATTA.steps: break\n\n    # -------------------------------------------------------------------------\n    #  UTILITIES --------------------------------------------------------------\n    # -------------------------------------------------------------------------\n    def softmax_entropy(self, x: torch.Tensor, y: torch.Tensor = None) -> torch.Tensor:\n        if y is None:\n            if x.shape[1] == 1:\n                x = torch.cat([x, -x], dim=1)\n            return -(x.softmax(1) * x.log_softmax(1)).sum(1)\n        else:\n            return -0.5 * (x.softmax(1) * y.log_softmax(1)).sum(1) - 0.5 * (y.softmax(1) * x.log_softmax(1)).sum(1)\n\n    def enable_bn(self, model):\n        if not self.config.model.freeze_bn:\n            for m in model.modules():\n                if isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d)):\n                    m.momentum = 0.1\n\n\n# =======================  Associated argument schema  ======================\n# File: ATTA/utils/args.py\n\nclass SimATTAArgs(TreeTap):\n    steps: int = None          # fine-tuning iterations per batch\n    lr: float = None           # learning rate for adaptation\n    eh: float = None           # high-entropy threshold\n    el: float = None           # low-entropy threshold\n    cold_start: int = None     # number of source anchors before relying more on target\n    beta: float = None         # trade-off coefficient (HE vs LE loss)\n    nc_increase: float = None  # cluster budget increase per batch\n    stop_tol: int = None       # window size for early-stop in cluster_train\n    target_cluster: int = None # whether to perform incremental clustering on HE\n    LE: int = None             # whether to use Low-Entropy samples in training\n\nclass ATTAArgs(TreeTap):\n    name: str = None\n    budgets: int = None\n    episodic: bool = None\n    batch_size: int = None\n    al_rate: float = None\n    gpu_clustering: bool = None\n    SimATTA: SimATTAArgs = None\n",
        "experimental_info": "SimATTA default / tunable hyper-parameters (taken from SimATTAArgs and code):\n\nGeneral ATTA settings\n    atta.name                 = 'SimATTA'          # select this algorithm\n    atta.budgets              : int                # total oracle queries allowed\n    atta.batch_size           : int                # data loader batch size\n    atta.al_rate              : float (optional)   # active-learning rate for ground-truth querying\n    atta.gpu_clustering       : bool               # use GPU K-means implementation\n\nSimATTA-specific (config path: atta.SimATTA.*)\n    steps          (int)   : # SGD steps over anchor loaders for each online update (default ≈ 200)\n    lr             (float) : learning-rate for cluster_train (e.g. 1e-3 or 0.001)\n    eh             (float) : entropy threshold that defines High-Entropy (HE) informative samples (e.g. 1e-3)\n    el             (float) : entropy threshold that defines Low-Entropy (LE) source-like samples (e.g. 1e-4)\n    cold_start     (int)   : minimum number of source anchors before α can exceed 0.2 (e.g. 100)\n    beta           (float) : loss weight for entropy-balanced training (code default 0.2)\n    nc_increase    (float) : how many new clusters to add after every batch (e.g. 0.5, 1, 2)\n    stop_tol       (int)   : window size used for early-stopping in cluster training (e.g. 20)\n    target_cluster (0/1)   : 1 ⇒ incremental clustering on HE buffer; 0 ⇒ fixed sampling\n    LE             (0/1)   : 1 ⇒ treat Low-Entropy samples as source-like and include with pseudo-labels\n\nderived internal variables (updated online)\n    n_clusters          : current #clusters for HE buffer (starts at 10, += nc_increase each step)\n    source_n_clusters   : #clusters used for LE buffer (starts at 100, +1 each step)\n    budgets             : cumulative oracle cost (increments by |closest| each batch)\n\nBackbone / optimisation (inherit from global config)\n    model               : ResNet-18/50 or other encoder from networks module\n    optimiser           : SGD(momentum=0.9) over all model params in cluster_train\n    teacher EMA         : α_teacher provided via update_teacher (default 0 — full copy, can be changed)\n\nData protocol\n    • Source training set: initially trained offline on first environment.\n    • Streaming test batches arrive sequentially in env_id order.\n    • For each batch SimATTA performs steps described above.\n    • Evaluation: accuracy per environment and averaged across frames.\n\nHardware / runtime\n    • GPU clustering option uses fast_pytorch_kmeans; CPU fallback uses sklearn KMeans with n_jobs=8.\n    • num_workers for DataLoader taken from config.num_workers (e.g. 4).\n\nThese settings reproduce the Sample-Entropy-balanced incremental multi-domain streaming experiments presented in the paper; change them in YAML or CLI (e.g. --atta.SimATTA.eh 1e-3) to match ablations reported by authors.\n"
      }
    },
    {
      "title": "An Adaptive Algorithm for Learning with Unknown Distribution Drift",
      "abstract": "We develop and analyze a general technique for learning with an unknown\ndistribution drift. Given a sequence of independent observations from the last\n$T$ steps of a drifting distribution, our algorithm agnostically learns a\nfamily of functions with respect to the current distribution at time $T$.\nUnlike previous work, our technique does not require prior knowledge about the\nmagnitude of the drift. Instead, the algorithm adapts to the sample data.\nWithout explicitly estimating the drift, the algorithm learns a family of\nfunctions with almost the same error as a learning algorithm that knows the\nmagnitude of the drift in advance. Furthermore, since our algorithm adapts to\nthe data, it can guarantee a better learning error than an algorithm that\nrelies on loose bounds on the drift. We demonstrate the application of our\ntechnique in two fundamental learning scenarios: binary classification and\nlinear regression.",
      "full_text": "arXiv:2305.02252v3  [cs.LG]  27 Oct 2023 An Adaptive Algorithm for Learning with Unknown Distribution Drift Alessio Mazzetto Brown University Eli Upfal Brown University Abstract W e develop and analyze a general technique for learning with an unknown distri- bution drift. Given a sequence of independent observations from the last T steps of a drifting distribution, our algorithm agnostically lea rns a family of functions with respect to the current distribution at time T . Unlike previous work, our tech- nique does not require prior knowledge about the magnitude o f the drift. Instead, the algorithm adapts to the sample data. Without explicitly estimating the drift, the algorithm learns a family of functions with almost the sa me error as a learning algorithm that knows the magnitude of the drift in advance. F urthermore, since our algorithm adapts to the data, it can guarantee a better le arning error than an algorithm that relies on loose bounds on the drift. W e demons trate the application of our technique in two fundamental learning scenarios: bin ary classiﬁcation and linear regression. 1 Introduction Standard statistical learning models (such as P AC learning ) assume independent and identically distributed training set, and evaluate the performance of t heir algorithms with respect to the same distribution as the training set [V apnik, 1998, van de Geer, 2000, Shalev-Shwartz and Ben-David, 2014, W ainwright, 2019]. However, in many practical applic ations, such as weather forecast, ﬁ- nance prediction or consumer preference analysis, the trai ning data is drawn from a non-stationary distribution that drifts in time. In this work, we consider a more general setting where the samples are still independent, but their distribution can change ov er time. T o obtain accurate results, the learning algorithm needs to adjust to the distribution drif t occurring in the input. This framework has been extensively studied in the literatu re [Helmbold and Long, 1991, Bartlett, 1992, Helmbold and Long, 1994, Barve and Long, 1996, 1997]. T his line of research culminated in showing that as long as the total variation distance of two co nsecutive distributions is bounded by ∆ , there exists an algorithm that agnostically learns a family of binary classiﬁers with VC dimension ν with expected error O((ν∆) 1/ 3) [Long, 1998], which can be shown to be tight. These results we re generalized in the work of Mohri and Mu ˜ noz Medina [2012] to a ddress any family of functions with bounded Rademacher complexity and to use a ﬁner problem-dep endent distance between distribu- tions called discrepancy, originally introduced in the con text of domain adaptation [Mansour et al., 2009]. The core idea of the aforementioned work is to learn by using a number of previous samples that minimizes the trade-off between the error due to the varianc e of the estimation ( statistical error ), and the error due to the drifting of the samples with respect t o the current distribution ( drift error ). If the algorithm trains using only a few recent observations , the statistical error will be large. If the algorithm uses a larger training set, including not very recent observations, the drift error will be large. For example, if the algorithm uses the most recent r training point, the hypothesis class has VC-dimension ν, and the distribution drift in each step is bounded by ∆ , then the statistical error is O( √ ν/r) and the drift error is O(r∆) . The trade-off with respect to r is optimized for r = Θ((∆ 2/ν)−1/ 3) giving O((ν∆) 1/ 3) error, as mentioned before. This, as well as similar ap- proaches in the literature, requires an upper bound to the ma gnitude of the drift and resolves thetrade-off between the statistical and drift errors based on this knowledge. As noted in previous work [Hanneke and Y ang, 2019], it is an open problem to develop an a lgorithm that adapts to the training set and does not rely on prior knowledge about the drift, whos e solution would lead to the practical applicability of those ideas. Our work resolves this open problem. Our algorithm does not r equire any prior knowledge of the magnitude of the drift, and it adapts based on the input data. Without explicitly estimating the drift (which is often impossible), the algorithm agnostically le arns a family of functions with the same error guarantee as an algorithm that knows the exact magnitu de of the drift in advance. Our approach has two advantages: it eliminates the, often unrealistic, r equirement of having a bound on the drift, and it gives better results when the drift bounds are not tigh t. W e showcase our algorithm in two important learning settings: binary classiﬁcation and lin ear regression. 2 Preliminary Let (Z, A) be a measurable space. Let Z1, . . . , Z T be a sequence of mutually independent random variables on Zdistributed according to P1, . . . , P T respectively, i.e. Zt ∼Pt for t ≤T . For r ≤T , we denote by P r T the average distribution of the most recent r distributions PT −r+1, . . . , P T : P r T (A) .= 1 r T∑ t=T −r+1 Pt(A) ∀A ∈A . W e set Pr T to be the corresponding empirical distribution over the ran dom variables ZT −r+1, . . . , Z T : Pr T (A) .= |{Zt ∈A : T −r + 1 ≤t ≤T }| r ∀A ∈A . Let Fbe a class of measurable functions from Zto R. For f ∈F, and any distributions P, Q on (Z, A), we let P (f) .= E Z∼P f(Z) = ∫ fdP, ∥P −Q∥F .= sup f∈F |P (f) −Q(f)| . The norm ∥·∥F is a notion of discrepancy introduced by the work of Mohri and Mu ˜ noz Medina [2012] to quantify the error due to the distribution shift wi th respect to a family of functions F, and it is based on previous work on domain adaptation [Mansour et al., 2009]. The goal is to estimate PT (f) for all f ∈F using the random variables Z1, . . . , Z T . Let 1 ≤r ≤T , and suppose that we do this estimate by considering the empir ical values induced by the most recent r random variables. Then, by using triangle inequality, we ha ve the following decomposition E∥PT −Pr T ∥F ≤E ∥P r T −Pr T ∥F   statistical error + ∥PT −P r T ∥F   drift error . (1) The ﬁrst term of the upper bound is the expected statistical error of the estimation, and quantiﬁes how accurately the empirical values {Pr T (f) : f ∈F} approximate the expectation of each function f according to P r T . The second term ∥PT −P r T ∥F of the upper bound represents the drift error . Intuitively, the statistical error decreases by consideri ng more samples, whereas the drift error can potentially increase since we are considering distributio ns that are further away from our current distribution. W e are looking for the value of r that balances this trade-off between statistical error and drift error. 2.1 Statistical Error Since our results revolve around learning a class of functio ns F, we ﬁrst need to assume that Fis “learnable”, i.e. the statistical error can be bounded as a f unction of r. For concreteness, we use the following standard assumption that the family of Fsatisﬁes the standard machine learning uniform convergence requirement with rate O(1/√ r). Assumption 1. (Uniform Convergence). There exists non-negative constan ts CF, 1 and CF, 2 such that for any ﬁxed r ≤T and δ ∈(0, 1), it holds E∥P r T −Pr T ∥F ≤CF, 1 √r , 2and with probability at least 1 −δ, we have ∥P r T −Pr T ∥F ≤CF, 1 √r + CF, 2 √ ln(1/δ) r . The learnability of a family of functions Fis an extensively studied topic in the statistical learning literature (e.g., [Bousquet et al., 2003, W ainwright, 2019 ]). For a family of binary functions, the above assumption is equivalent to Fhaving a ﬁnite VC-dimension, in which case CF, 1 = O(ν) and CF, 2 = O(1). For a general family of functions F, a sufﬁcient requirement is that the Rademacher complexity of the ﬁrst r samples is O(r−1/ 2) and the range of any function in Fis uniformly bounded. There is nothing special about the rate O(r−1/ 2). It is possible to adapt our analysis to any rate O(r−α ) with α ∈(0, 1) by modifying the constants of our algorithm. 2.2 Quantifying the Drift Error While for many classes F, it is possible to provide an upper bound to the statistical e rror by using standard statistical learning theory tools, the drift erro r is unknown and challenging to estimate. The literature used different approaches to quantify the drift error. By using triangle inequality, it is possible to show that for any r ≤T , we have the following upper bounds to the drift error: ∥PT −P r T ∥F ≤1 r r∑ t=1 ∥PT −PT −t∥F ≤max t<r ∥PT −PT −t∥F ≤ r−1∑ t=1 ∥PT −t −PT −t+1∥F . (2) In a long line of research (e.g., [Bartlett, 1992, Long, 1998 , Mohri and Mu ˜ noz Medina, 2012, Hanneke and Y ang, 2019]), it is assumed that an upper bound to the drift error is known apriori. One of the most used assumption is that there exists a known upper bound ∆ to the discrepancy between any two consecutive distributions, in which case we can uppe r bound ∑ r−1 t=1 ∥PT −t −PT −t+1∥F with r∆ . In this case, for a binary family Fwith VC-dimension ν, we obtain that: E∥PT −P r T ∥F ≲ √ ν r + r∆ , and we can choose the value of r that minimizes this upper bound. Since these algorithms rel y on an unrealistic assumption that an upper bound to the drift is known a priori, they are not usable in practice. It is an open problem to provide a competitive algo rithm that can choose r adaptively and it is oblivious to the magnitude of the drift. Another sequence of work [Mohri and Mu ˜ noz Medina, 2012, A wa sthi et al., 2023] relaxes the prob- lem setting assuming that the algorithm can observe multipl e samples from each distribution P1, . . . , P T . In this case, they can provably estimate the discrepancies between different distri- butions, and compute a weighting of the samples that minimiz es a trade-off between the statistical error and the estimated discrepancies. This strategy does n ot apply to our more general setting, as we can have access to at most one sample from each distributio n. Surprisingly, we show that we can adaptively choose the valu e of r to minimize the trade-off between statistical error and drift error without explicitly estim ating the discrepancy. Noticeably, our method does not require any additional assumption on the drift. The only requirement for our algorithm is that we can compute the norm ∥·∥F from a set of samples. This is formalized as follows. Assumption 2. (Computability). There exists a procedure that computes ∥Pr T −P2r T ∥F for any r ≤T/2. In general, the hardness of computing the norm ∥·∥F depends on the family F. This challenge is also common in previous work that uses this norm to quantify t he distribution drift [Mansour et al., 2009, A wasthi et al., 2023]. In this paper, we provide two exa mples of important learning settings where this assumption is satisﬁed: binary classiﬁcation wi th zero-one loss and linear regression with squared loss. 3 Main Result Under those assumption, we prove the following theorem, whi ch is our main result. 3Theorem 1. Let δ ∈(0, 1). Let Assumptions 1 and 2 hold. Given Z1, . . . , Z T , Algorithm 1 outputs a value ˆr ≤T such that with probability at least 1 −δ, it holds that ∥PT −Pˆr T ∥F = O ( min r≤T [ CF, 1 √r + max t<r ∥PT −PT −t∥F + CF, 2 √ log(log(r + 1)/δ) r ]) In order to appreciate this theorem, we can observe the follo wing. If we learn using the most recent r samples, similarly to (1) we have the following error decomp osition ∥PT −Pr T ∥F ≤∥P r T −Pr T ∥F + ∥PT −P r T ∥F By using Assumption 1 and (2), we have that with probability a t least 1 −δ it holds that ∥PT −Pr T ∥F ≤CF, 1 √r + CF, 2 √ log(1/δ) r + max t<r ∥PT −PT −t∥F . (3) Theorem 1 guarantees a learning error that is essentially wi thin a multiplicative constant factor as good as the upper bound obtained by selecting the optimal cho ice of r in (3). This result provides an afﬁrmative answer to the open problem posed by Hanneke and Y ang [2019], that asked if it was possible to adaptively choose the value of r that minimizes (3) 1 . The upper bound of the theorem contains a negligible additional factor log(r+1) within the logarithm due to the union bound required to consider multiple candidate values of r. As further evidence of the efﬁciency of our algorithm, assume that there is no drift, and we are in the usu al i.i.d. setting where P1 = . . . = PT . In this setting, the following corollary immediately follo ws from Theorem 1 by setting the drift error equal to 0. Corollary 2. Consider the setting of Theorem 1, and also assume that P1 = . . . = PT . W ith probability at least 1 −δ, the window size ˆr computed by Algorithm 1 satisﬁes ∥PT −Pˆr T ∥F = O ( CF, 1 √ T + CF, 2 √ log(log(T + 1)/δ) T ) Observe that in the i.i.d. case, Assumption 1 implies that wi th probability at least 1 −δ, it holds ∥PT −PT T ∥F ≤CF, 1/ √ T + CF, 2 √ log(1/δ)/T . Corollary 2 shows that with our algorithm we obtain a result that is competitive except for a negligible e xtra factor O(log T ) within the logarithm. W e want to emphasize that our algorithm does not know in advan ce whether the data is i.i.d. or drifting, and this factor is the small cost of our algorithm t o adapt between those two cases. 4 Algorithm W e describe an algorithm that attains the results of Theorem 1. Throughout the remaining of this section, we let Assumptions 1 hold. In particular, the algor ithm has access to constants CF, 1 and CF, 2 that satisfy this assumption. The main challenge is the fact that the drift error ∥PT −Pr T ∥F is unknown for any r > 1, and it is challenging to quantify since we have only a single sample ZT ∼PT . W e ﬁrst provide an informal description of the algorithm. Ou r algorithm revolves around the fol- lowing strategy. W e do not try to estimate the drift. Instead , we try to assess whether increasing the sample size can yield a better upper bound on the error. Recal l that given the most recent r samples, we have the following upper bound on the error, E∥PT −Pr T ∥F ≤CF, 1 √r + ∥PT −P r T ∥F . (4) The algorithm cannot evaluate (4) since the drift component , ∥PT −P r T ∥F , is unknown. Our key idea is to compare the difference in the upper bound on the err or when using the latest 2r or r samples:(CF, 1√ 2r −CF, 1√r ) + ( ∥PT −P 2r T ∥F −∥PT −P r T ∥F ) ≤ (CF, 1√ 2r −CF, 1√r ) + ∥P r T −P 2r T ∥F (5) 1 W e prove a stronger result. The original formulation of the q uestion uses the looser upper bound∑ r− 1 t=1 ∥PT − t − PT − t+1∥F to the drift error in (3), which can be signiﬁcantly worse as s hown in an exam- ple of Section 5 4The last step follows from the triangle inequality: ∥PT −P 2r T ∥F ≤∥PT −P r T ∥F + ∥P r T −P 2r T ∥F . By considering the latest 2r samples rather than r samples, we can see from (5) that the statistical error decreases, and the difference in drift error can be upp er bounded by ∥P 2r T −P r T ∥F . W e can estimate ∥P r T −P 2r T ∥F using ∥Pr T −P2r T ∥F within expected error O(CF, 1/√ r) as it depends on ≥r samples. This suggests the following algorithm. Let r be the current sample size considered by the algorithm. The algorithm starts from r equal to 1, and doubles the sample size as long as ∥Pr T −P2r T ∥F is small. If ∥Pr T −P2r T ∥F is big enough, a substantial drift must have occurred in the distributions PT −2r+1, . . . , P T , and we can show that this implies that maxt<2r−1∥PT −PT −t∥F is also large. When this happens, we can stop our algorithm and r eturn the current sample size. For a formal description of the algorithm, let δ ∈(0, 1) denote the probability of failure of our algorithm, and let ri = 2 i, for i ≥0, be the size of the training set used by the algorithm at itera tion i + 1. For ease of notation, we set CF,δ .= CF, 1 + CF, 2 √ 2 ln(π2/(6δ)), and S(r, δ) .= CF,δ√r + CF, 2 √ 2 ln(log2(r) + 10) r . (6) The proofs of the following propositions appear in the Appen dix A. Proposition 3. W ith probability at least 1 −δ, the following event holds: ∥P ri T −Pri T ∥F ≤S(ri, δ) ∀i ≥0 W e assume that the event of Proposition 3 holds, otherwise ou r algorithm fails (with probability ≤δ). Our algorithm considers the following inﬂated upper bound U(r, δ) to ∥Pr T −PT ∥F deﬁned as follows U(r, δ) .= 21 ·S(r, δ) + ∥PT −P r T ∥F . (7) Proposition 3 implies that with probability at least 1 −δ for any i ≥0, we have U(ri, δ) = 21 ·S(ri, δ) + ∥PT −P ri T ∥F ≥∥Pri T −P ri T ∥F + ∥PT −P ri T ∥F ≥∥PT −Pri T ∥F W e use this value as an upper bound that our algorithm guarant ees if we choose a sample size ri. W e observe that with respect to (4), the upper bound of the alg orithm also contains an additional term that is proportional to √ log(1/δ) for the high-probability guarantee, and a term proportiona l to √log log ri that is necessary for the union bound across all possible win dow sizes ri for i ≥0. This union bound is required as we need to have a correct estim ation for all possible sample sizes ri in order to assure that the algorithm takes a correct decisio n at each step. The constant factor in front of the upper bound on the statistical error S(ri, δ) is a technical detail that allows taking into account the error of the estimation of the difference in drif t error. W e want to compare the upper bound U(ri, δ) with the upper bound U(ri+1, δ) obtained by doubling the current sample size ri. As we previously discussed, it is possible to show that if ∥Pri T −Pri+1 T ∥F is sufﬁciently small, then U(ri+1, δ) ≤U(ri, δ), and this intuition is formalized in the following proposition. Proposition 4. Assume that the event of Proposition 3 holds and let i ≥0. If ∥Pri T −Pri+1 T ∥F ≤4S(ri, δ) then U(ri+1, δ) ≤U(ri, δ). The algorithm works as follows. Starting from i = 0 , we iteratively increase i by one while ∥Pri T − Pri+1 T ∥F ≤4S(ri, δ). There are two cases. In the ﬁrst case, we reach ri = ⌊log2 T ⌋, and this implies that ri+1 > T . In this case, the algorithm returns ri, and Proposition 4 guarantees that the sample size returned by the algorithm is as good as any previo usly considered sample size. In the second case, we reach a value of i such that ∥Pri T −Pri+1 T ∥F > 4S(ri, δ). In this case, we return ri, and we can still prove that this is a good choice. In fact, as s hown in the next proposition, this terminating condition implies a lower bound maxt<ri+1 ∥PT −PT −i∥F , thus any estimation with a number of recent samples greater or equal to ri+1 could have a non-negligible drift error. 5Algorithm 1: Adaptive Learning Algorithm under Drift i ←0 ; while ri ≤T/2 do if ∥Pri T −Pri+1 T ∥F ≤4S(ri, δ) then i ←i + 1 ; end else return ri ; end end return ri Proposition 5. Assume that the event of Proposition 3 holds, and assume that there exists i ≥0 such that ∥Pri T −Pri+1 T ∥F > 4S(ri, δ), then maxt<ri+1 ∥PT −PT −t∥F > S (ri, δ). The pseudo-code of the algorithm is reported in Algorithm 1. The algorithm receives in input δ, the samples Z1, . . . , Z T , and returns an integer ˆr ∈{1, . . . , T }that satisﬁes Theorem 1. Proof of Theorem 1. W e assume that the event of Proposition 3 holds. If it doesn’t , we say that our algorithm fails, and this happens with probability ≤δ. Let ˆr = rj = 2 j for j ≥0 be the value returned by the algorithm when it terminates. W e remind that our algorithm guarantees an upper bound U(rj , δ) ≥∥PT −Prj T ∥F to the learning error by using rj samples. Let r∗ be the value of r that minimizes this expression r∗ = argmin r≤T ( 21 ·S(r, δ) + max t<r ∥PT −PT −t∥F ) , and let B∗ be the minimum value of this expression, i.e. B∗ = 21 ·S(r∗, δ) + max t<r∗ ∥PT −PT −t∥F be any ﬁxed optimal sample size, where we remind the deﬁnitio n of U from (7). The ﬁrst observation is that the right-hand side of the inequality in Theorem 1 is O(B∗). Therefore, in order to prove the theorem, it is sufﬁcient to show that U(rj , δ)/B∗ = O(1). W e distinguish two cases: (a) r∗ < 2rj , and (b) r∗ ≥2rj. W e ﬁrst consider case (a). W e let k ≥0 be the largest integer such that rk ≤r∗. Since r∗ < 2rj , it holds that k ≤j. Since our algorithm returned rj , Proposition 4 applies for i = 0 , . . . , j −1, thus U(rj , δ) ≤U(rk, δ). W e have that: U(rj , δ) B∗ ≤U(rk, δ) B∗ (8) W e observe that U(rk, δ) B∗ = 21S(rk, δ) + ∥PT −P rk T ∥F 21S(r∗, δ) + max t<r∗ ∥PT −PT −t∥F ≤21S(rk, δ) + max t<rk ∥PT −PT −t∥F 21S(r∗, δ) + max t<r∗ ∥PT −PT −t∥F ≤S(rk, δ) S(r∗, δ) + maxt<rk ∥PT −PT −t∥F maxt<r∗ ∥PT −PT −t∥F ≤ √ r∗ rk + 1 ≤3 , where the ﬁrst inequality is due to (2), and the last inequali ty is due to the fact that rk ≤r∗ < 2rk by deﬁnition of rk. By using the above inequality in (8), we obtain that U(rj , δ)/B∗ ≤3. W e consider case (b). Since T ≥r∗ ≥2rj = rj+1, the algorithm returned rj because ∥Prj T − Prj+1 T ∥F > 4S(rj , δ). Using Proposition 5, we have max t<r∗ ∥PT −PT −t∥F ≥ max t<rj+1 ∥PT −PT −t∥F > S (rj , δ) . Therefore, we have that U(rj , δ) B∗ = 21S(rj , δ) + ∥PT −P rj T ∥F 21S(r∗, δ) + max t<r∗ ∥PT −PT −t∥F ≤ 21S(rj, δ) maxt<r∗ ∥PT −PT −t∥F + maxt<rj ∥PT −PT −t∥F maxt<r∗ ∥PT −PT −t∥F ≤21S(rj, δ) S(rj , δ) + 1 = 21 This concludes the proof. 65 Binary Classiﬁcation with Distribution Drift In this section, we show an application of Theorem 1 for the fu ndamental statistical learning problem of agnostic learning a family of binary classiﬁers. Let Z= X×Y , where Xis the feature space, and Y= {0, 1}is the label space, i.e. Zt = ( Xt, Yt). A hypothesis class His a class of functions h : X↦→Y that classify the feature space X. Given a point (x, y) ∈X×Y and a function h ∈H, the risk of h on (x, y) is deﬁned through the following function Lh(x, y) = 1{y̸=h(x)}. W e work with the class of functions F= {Lh : h ∈H}. Let h∗ = argmin h∈H PT (Lh) be a function with minimum expected risk with respect to the c urrent distribution PT . W e want to use Theorem 1 to ﬁnd a function h ∈H such that PT (Lh) is close to PT (Lh∗ ). Let ν be the VC dimension of H. The VC dimension describes the complexity of the family H, and it is used to quantify the statistical error. In particu lar, using standard learning tools, it is possible to show that the family Fsatisﬁes Assumption 1 on the sample complexity with constants CF, 1 = O(√ ν) and CF, 2 = O(1) (e.g., [Mohri et al., 2018]). Finally, to satisfy Assumption 2, we need to exhibit a proced ure that for r ≤T/2, outputs the quantity ∥Pr T −P2r T ∥F . This quantity is also referred to as Y-discrepancy between the empirical distributions Pr T and P2r T in previous work on transfer learning [Mohri and Mu ˜ noz Medi na, 2012]. W e can adapt a strategy from Ben-David et al. [2010] to our set ting and show that it is possible to compute it by solving an empirical risk minimization proble m. W e say that a hypothesis class His computationally tractable if given a ﬁnite set of points from X×Y , there exists an algorithm that returns a hypothesis h that achieves the minimum risk over this set of points. Lemma 6. Assume that His symmetric, i.e. h ∈H ⇐⇒1 −h ∈H. F or r ≤T/2, it holds ∥Pr T −P2r T ∥F = 1 2 −1 2 inf h∈H [ 1 r T∑ t=T −r+1 Lh(Xt, 1 −Yt) + 1 r T −r∑ t=T −2r+1 Lh(Xt, Yt) ] Given r, the minimum in Lemma 6 can be computed by solving an empirica l risk minimization over the most recent 2r points, where we ﬂip the label of half of those points, i.e. we use the points (XT −2r+1, YT −2r+1), . . . , (XT −r, YT −r), (XT −r+1, 1−YT −r+1), . . . , (XT , 1−YT ). Thus, if His computationally tractable and symmetric, Assumption 2 hol ds. This is indeed true for many hypoth- esis class, e.g., hyperplanes, axis-aligned rectangles, o r threshold functions. However, the empirical risk minimization problem could be expensive to solve exact ly, but as we discuss in Section 8, it is possible to modify the algorithm to allow for an approximati on of ∥Pr T −P2r T ∥F . Our main result for binary classiﬁcation is given in the foll owing theorem: Theorem 7. Let Hbe a computationally tractable and symmetric binary class w ith VC dimension ν. Let F = {Lh : h ∈H}. Let ˆr ≤T be output of Algorithm 1 with input Z1, . . . , Z T using the family F. Let ˆh = argmin h∈H Pˆr T (Lh) be an empirical risk minimizer over the most recent ˆr samples. W ith probability at least 1 −δ, the following holds: PT (Lˆh) −PT (Lh∗ ) = O ( min r≤T [ √ ν r + max t<r ∥PT −PT −t∥F + √ log(log(r + 1)/δ) r ]) The symmetry assumption is not necessary, and in the appendi x we show how to remove it at the cost of a more expensive computation of the discrepancy. It is ins tructive to compare this upper bound with the results of previous work. An often used assumption i n the literature, originally introduced in Bartlett [1992], is that there is a known value ∆ > 0, such that drift in each step is bounded by ∆ , i.e. for all t < T , ∥Pt+1 −Pt∥F ≤∆ . Assume that T is sufﬁciently large, i.e. T = Ω(( ν/∆ 2)1/ 3). By using this assumption on the drift, previous work showed t hat with high-probability, they can ﬁnd a classiﬁer ˆh such that PT (Lˆh) −PT (Lh∗ ) = O ( 3√ ∆ ν ) , and it can be shown that this upper bound is tight up to constants within those assumptions [Bar ve and Long, 1996]. These previous works assumed they had access a priori to the value of ∆ , since those algorithms compute ˆh by solving a empirical risk minimization over a number of previ ous samples Θ(( ν/∆ 2)1/ 3) that is decided before observing the data. On the other hand, this as sumption on the drift together with (2) implies that maxt<r∥PT −PT −t∥F ≤(r −1)∆ . Our algorithm (Theorem 7) guarantees an error that depends on a minimum choice over r ≤ T , hence it is always smaller than the one 7obtained with a speciﬁc choice of r. If we choose r = ( ν/∆ 2)1/ 3 in the upper bound of Theorem 7, we can show that with high-probability, our algorithm retur ns a classiﬁer ˆ h such that PT (Lˆh) − PT (Lh∗ ) = O ( 3√ ∆ ν + 6 √ ∆ 2/ν √ log log(ν/∆ 2) ) . Our algorithm achieves this guarantee while being adaptive with respect to the upper bound ∆ , and it can indeed guarantee a better result when this upper bound is loose. For example, assume an extreme case in which the algorithm is given a ∆ > 0 bound on the drift in each step, but the training set has actually no drift, it wa s all drawn from the distribution PT . Previous methods are oblivious to the actual data, and they g uarantee an upper bound O ( 3√ ∆ ν ) with high-probability, since they decide the sample size Θ(( ν/∆ 2)1/ 3) a priory without observing the input. In contrast, our algorithm adapts to this scenari o, and Theorem 7 guarantees that we ob- tain an O (√ ν/T + √ (log log T )/T ) error, with high-probability, essentially retrieving the error guarantee for learning with independent and identically di stributed samples. Observe that our upper bound depends on T , and it goes to 0 when T →∞. It is possible to show that our algorithm can obtain asymptot ically better guarantee even if ∥Pt − Pt−1∥F = ∆ ≪1 for all t < T , i.e. there is an exact drift of ∆ at each step. This is because our algorithm provides a guarantee as a function of maxt<r∥PT −PT −t∥F rather than the looser quantity ∑ r−1 t=1 ∥PT −t −PT −t+1∥F , as shown in the following example. Let X= [0 , 1], and let H be a class of threshold functions over [0, 1] i.e. for any c ∈[0, 1], there exists classiﬁers hc, h′ c ∈H such that hc(x) = 1 if and only if x ≥c and h′ c(x) = 1 if and only if x < c . The class Hhas VC-dimension equal to 2. W e construct a sequence of distributions P1, . . . , P T as follows. The marginal distribution over Xis uniform for each distribution Pt with t = 1 , . . . , T . At time t ≤T , the classiﬁcation of x ∈[0, 1] is given by a function ℓt : [0 , 1] ↦→{0, 1}. Assume that there exists two disjoint intervals I0 = [ p0, p0 + ∆ /2) and I1 = [ p1, p1 + ∆ /2) such that ℓT (x) = 0 for all x ∈I0 and ℓT (x) = 1 for all x ∈I1. W e let ℓT −t(x) =    1 −ℓT (x) if (x ∈I0) ∧(t is odd ) 1 −ℓT (x) if (x ∈I1) ∧(t is even ) ℓT (x) otherwise , ∀x ∈X, t < T . In particular, ℓT −t(x) differs from ℓT (x) for x ∈I0 if t is odd, and for x ∈I1 if t is even. By construction, ∥Pt −Pt−1∥F = ∆ for all t < T , i.e. there is an exact drift of ∆ at each step (to be precise, in the last step ∥PT −PT −1∥F = ∆ /2). As discussed before, with the assumption of a bounded drift ∆ at each step, previous methods guarantee an upper bound O( 3√ ∆) with high- probability. However, we also have that for any 1 ≤r ≤T , it holds by construction that max t<r ∥PT −PT −t∥F ≤∆ . Hence, our algorithm (Theorem 7) guarantees with high-prob ability an upper bound O ( ∆ + √ ν/T + √ (log log T )/T ) . Since our algorithm is adaptive with respect to the drift, it can correctly use more samples. In contrast, previous non-adaptive algorithms that rely on th e assumption of bounded drift ∆ at each step choose a sample size of Θ(∆ −2/ 3) based on this assumption, thus they can only guarantee a looser bound of O(∆ 1/ 3), even when this assumption is satisﬁed with equality. It is possible to use the recent lower bound strategy of Mazze tto and Upfal [2023] in order to show that the upper bound of Theorem 7 is essentially tight in a min imax sense. Theorem 8. Let Hbe a binary class with VC dimension ν, and consider an arbitrary non- decreasing sequence ∆ 1 = 0 , ∆ 2, . . . , ∆ T of non-negative real numbers. Let F= {Lh : h ∈H}. Let Abe any algorithm that observes Z1, . . . , Z T , and it outputs a classiﬁer hA ∈H. If Φ ∗ = min r≤T (√ ν r + ∆ r ) < 1/3 , then, for any algorithm A, there exists a sequence of distributions P1, . . . , P T such that maxt<r∥PT −PT −t∥F ≤∆ r for any r ≤T , and with probability at least 1/8 it holds that: PT (LhA ) −PT (Lh∗ ) = Ω(Φ ∗) = Ω ( min r≤T (√ ν r + max t<r ∥PT −PT −t∥F )) 86 Linear Regression with Squared Loss In the previous section, we showed an application of Theorem 1 for the problem of binary classiﬁca- tion with zero-one loss. In this section, we show that our mai n result can also be applied to a linear regression problem. Similarly to the previous section, we l et Z= X×Y , where Xis the feature space and Y= [ −1, 1] is the label space, i.e. Zt = ( Xt, Yt). In this section, we constrain the feature space X= {x ∈Rd : ∥x∥2 ≤1}to be the unit ball centered at the origin in Rd. W e consider the ℓ2 regularized linear prediction class H= {x ↦→⟨x, w⟩: w ∈Rd ∧ ∥w∥2 ≤ 1}. W e denote each predictor hw ∈H with its weight w. T o evaluate the quality of a prediction y = hw(x), we use the squared loss L : R ×R ↦→R deﬁned as L(y, y′) = ( y −y′)2. For each hw ∈H, we let Lw(x, y) = L(hw(x), y) be the function that evaluates the loss incurred by hw for any z = ( x, y) ∈Z. W e work with the family of functions F= {Lw : hw ∈H}. By a standard uniform convergence argument based on the Rademacher compl exity of F(e.g., see [Kakade et al., 2008, Shamir, 2015, A wasthi et al., 2020]), we have that for a ny 1 ≤r ≤T , it holds: ∥P r T −Pr T ∥F = O ( 1 √r + √ ln(1/δ) r ) , thus we satisfy Assumption 1 with CF, 1 = O(1) and CF, 2 = O(1). The computation of the discrepancy is more challenging. Let 1 ≤r ≤T/2. Using the deﬁnition of F, we have that: ∥Pr T −P2r T ∥F = 1 2r sup w:∥w∥≤1 ⏐ ⏐ ⏐ ⏐ ⏐ T∑ t=T −r+1 ( Yt −⟨Xt, w⟩ )2 − T −r∑ t=T −2r+1 ( Yt −⟨Xt, w⟩ )2 ⏐ ⏐ ⏐ ⏐ ⏐ . (9) Let cr ∈R, br ∈Rd, and Ar ∈Rd×d be deﬁned as follows: ar = T∑ t=T −r+1 Y 2 t − T −r∑ t=T −2r+1 Y 2 t , b r = T −r∑ t=T −2r+1 YtXt − T∑ t=T −r+1 YtXt , Ar = T∑ t=T −r+1 XT t Xt − T −r∑ t=T −2r+1 XT t Xt , and observe that the matrix Ar is symmetric. Using those deﬁnition, we can manipulate the r ight- hand side of (9) to show that it is equivalent to: max ( −ar + inf w:∥w∥≤1 [ wT (−Ar)w −2bT r w ] , ar + inf w:∥w∥≤1 [ wT (Ar)w −2(−bT r )w ] ) (10) In order to compute (10), it is sufﬁcient to be able to solve th e minimization problem inf w:∥w∥≤1 ( wT Aw −2bT w ) (11) where A ∈Rd×d is a symmetric matrix, and b ∈Rd. This minimization problem has been exten- sively studied for the trust-region method [Conn et al., 200 0], and Hager [2001, Section 2] provides a way to compute the solution of (11) in terms of a diagonaliza tion of A. Thus, we also satisfy As- sumption 2, and we can obtain the following result as an immed iate corollary of Theorem 1. Theorem 9. Let δ ∈(0, 1). Let 1 ≤ˆr ≤T be the output of Algorithm 1 with input Z1, . . . , Z T and using the family Fdescribed in this section. Let ˆw = argmin w:∥w∥≤1 Pˆr T (Lw) be the linear classiﬁer with minimum loss over the most recent ˆr samples. Then, with probability at least 1 −δ: PT (L ˆw) −PT (Lw∗ ) = O ( min r≤T [ 1 √r + max t<r ∥PT −PT −t∥F + √ log(log(r + 1)/δ) r ]) where w∗ = argmin w:∥w∥≤1 PT (Lw) is the linear predictor with minimum loss with respect to the current distribution PT . 97 Related W ork Additional variants of learning with distribution drift ha ve been studied in the literature. Freund and Mansour [1997] provide a reﬁned learning algorit hm in the special case of rapid dis- tribution shift with a constant direction of change. In the w ork of Bartlett et al. [2000], they show specialized bounds in the case of infrequent changes and oth er different restrictions on the distri- bution drift. The work of Crammer et al. [2010] provides regr et bound for online learning with an adversarial bounded drift. Y ang [2011] studies the problem of active learning in a distribution drift setting. Hanneke et al. [2015] provide an efﬁcient polynomi al time algorithm to learn a class of lin- ear separators with a drifting target concept under the unif orm distribution in the realizable setting. Interestingly, they also show how to adapt their algorithm w ith respect to an unknown drift, al- though their technique relies on the realizability of the le arning problem. In the more recent work of Hanneke and Y ang [2019], they relax the independence assump tion and provide learning guarantees for a sequence of random variables that is both drifting and m ixing. 8 Conclusion, Limitations and Future Directions W e present a general learning algorithm that adapts to an unk nown distribution drift in the training set. Unlike previous work, our technique does not require pr ior knowledge about the magnitude of the drift. For the problem of binary classiﬁcation, we show t hat without explicitly estimating the drift, there exists an algorithm that learns a binary classi ﬁer with the same or better error bounds compared to the state-of-the-art results that rely on prior information about the magnitude of the drift. This is a major step toward practical solutions to the problem since prior knowledge about the distribution drift in the training set is often hard to obtai n. W e presented concrete results for binary classiﬁcation and linear regression, but our technique can be applied for learning any family of functions Fas long as it is possible to compute the distance ∥Pr T −P2r T ∥F between the empirical distributions with r and 2r samples according to the ∥·∥F norm (Assumption 2). This is often a challenging problem, an d it is related to the computation of the discrepancy between distributions, which was studie d in previous work on transfer learn- ing [Mansour et al., 2009, Ben-David et al., 2010]. For binar y classiﬁcation, we assume that the empirical risk minimization problem is tractable. However , an exact solution to this problem is computationally hard for many hypothesis classes of intere st, and this is a limitation of our algo- rithm and previous work on transfer learning. In those cases , we can modify our analysis to use the best-known approximation for the distance ∥Pr T −P2r T ∥F as long as there is an approximation guarantee with respect to its exact value. As an illustrativ e example, if we have a procedure that returns an approximation Er such that 1 ≤∥Pr T −P2r T ∥F /Er ≤α for any r ≥1, then it is possible to change the algorithm to obtain a guarantee that is at the mo st a factor O(α2) worse than the one achieved by Algorithm 1 with the exact computation of the dis tance (we refer to Appendix B for additional details). The method presented here uses a distribution-independent upper bound for the statistical error. While this upper bound can be tight in the worst-case, as show n in our lower bound for binary classiﬁcation (Theorem 8), it can be loose for some other seq uence of distributions. As a future direction, it is an interesting problem to provide an adapti ve algorithm with respect to the drift that uses distribution-dependent upper bounds, for exampl e, based on the Rademacher complexity, which can be possibly computed from the input data. Our algor ithm does not naturally extend to this setting, as it requires knowing the rate at which the upper bo und on the statistical error is decreasing (see proof of Proposition 4). Acknowledgements. This material is based on research sponsored by Defense Adva nced Research Projects Agency (DARP A) and Air Force Research Laboratory ( AFRL) under agreement number F A8750-19-2-1006 and by the National Science Foundation (N SF) under award IIS-1813444. The U.S. Government is authorized to reproduce and distribute r eprints for Governmental purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessa rily representing the ofﬁcial poli- cies or endorsements, either expressed or implied, of Defen se Advanced Research Projects Agency (DARP A) and Air Force Research Laboratory (AFRL) or the U.S. Government. 10References Pranjal A wasthi, Natalie Frank, and Mehryar Mohri. On the ra demacher complexity of linear hy- pothesis sets. arXiv preprint arXiv:2007.11045 , 2020. Pranjal A wasthi, Corinna Cortes, and Christopher Mohri. Th eory and algorithm for batch distri- bution drift problems. In International Conference on Artiﬁcial Intelligence and St atistics (AIS- TATS), 2023. Peter L Bartlett. Learning with a slowly changing distribut ion. In Proceedings of the ﬁfth annual workshop on Computational Learning Theory (COLT) , 1992. Peter L Bartlett, Shai Ben-David, and Sanjeev R Kulkarni. Le arning changing concepts by exploiting the structure of change. Machine Learning , 41(2):153–174, 2000. Rakesh D Barve and Philip M Long. On the complexity of learnin g from drifting distributions. In Conference on Computational Learning Theory (COLT) , 1996. Rakesh D Barve and Philip M Long. On the complexity of learnin g from drifting distributions. Information and Computation , 138(2):170–193, 1997. Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, F ernando Pereira, and Jennifer W ort- man V aughan. A theory of learning from different domains. Machine learning , 79(1):151–175, 2010. Olivier Bousquet, St´ ephane Boucheron, and G ´ abor Lugosi. Introduction to statistical learning the- ory. In Summer School on Machine Learning . Springer, 2003. Andrew R Conn, Nicholas IM Gould, and Philippe L T oint. T rust region methods . SIAM, 2000. Koby Crammer, Eyal Even-Dar, Y ishay Mansour, and Jennifer W ortman V aughan. Regret mini- mization with concept drift. Conference on Learning Theory (COLT) , 2010. Y oav Freund and Y ishay Mansour. Learning under persistent d rift. In European Conference on Computational Learning Theory , pages 109–118, 1997. William W Hager. Minimizing a quadratic over a sphere. SIAM Journal on Optimization , 12(1): 188–208, 2001. Steve Hanneke and Liu Y ang. Statistical learning under nons tationary mixing processes. In Inter- national Conference on Artiﬁcial Intelligence and Statist ics (AISTATS) , 2019. Steve Hanneke, V arun Kanade, and Liu Y ang. Learning with a dr ifting target concept. In Conference on Algorithmic Learning Theory (ALT) , 2015. David P Helmbold and Philip M Long. Tracking drifting concep ts using random examples. In Proceedings of the fourth annual workshop on Computational Learning Theory (COLT) , 1991. David P Helmbold and Philip M Long. Tracking drifting concep ts by minimizing disagreements. Machine learning , 14(1):27–45, 1994. Sham M Kakade, Karthik Sridharan, and Ambuj T ewari. On the co mplexity of linear prediction: Risk bounds, margin bounds, and regularization. Advances in Neural Information Processing Systems (NeurIPS) , 2008. Philip M Long. The complexity of learning according to two mo dels of a drifting environment. In Conference on Computational Learning Theory (COLT) , 1998. Y ishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh. Do main adaptation: Learning bounds and algorithms. arXiv preprint arXiv:0902.3430 , 2009. Alessio Mazzetto and Eli Upfal. Nonparametric density esti mation under distribution drift. Interna- tional Conference on Machine Learning (ICML) , 2023. Mehryar Mohri and Andres Mu ˜ noz Medina. New analysis and alg orithm for learning with drifting distributions. In International Conference on Algorithmic Learning Theory ( ALT), 2012. 11Mehryar Mohri, Afshin Rostamizadeh, and Ameet T alwalkar. F oundations of machine learning . MIT press, 2018. Shai Shalev-Shwartz and Shai Ben-David. Understanding machine learning: From theory to algo- rithms. Cambridge university press, 2014. Ohad Shamir. The sample complexity of learning linear predi ctors with the squared loss. Journal of Machine Learning Research , 16:3475–3486, 2015. Alexander B Tsybakov. Introduction to nonparametric estim ation. In Springer Series in Statistics , 2008. Sara van de Geer. Empirical Processes in M-estimation , volume 6. Cambridge University Press, 2000. Vladimir N. V apnik. Statistical Learning Theory . John Wiley & Sons, Inc., 1998. Martin J W ainwright. High-dimensional statistics: A non-asymptotic viewpoint , volume 48. Cam- bridge University Press, 2019. Liu Y ang. Active learning with a drifting distribution. Advances in Neural Information Processing Systems (NeurIPS) , 2011. Bin Y u. Assouad, fano, and le cam. F estschrift for Lucien Le Cam: research papers in probabili ty and statistics , 1997. 12A Deferred Proofs Proof of Proposition 3. For any i ≥0, let δi = 6 δ/[π2(i + 10)2]. By using Assumption 1, we have that with probability at least 1 −δi it holds that ∥P ri T −Pri T ∥F ≤CF, 1 + CF, 2 √ ln(π2/6) + ln(1 /δ) + 2 ln( i + 10)√ri ≤CF, 1 + √ 2CF, 2 √ ln(π2/(6δ)) + ln( i + 10)√ri ≤CF,δ √ri + CF, 2 √ 2 ln(i + 10) ri where in the second inequality we used the deﬁnition of CF,δ and the fact that √x + y ≤√x + √y. Additionaly, the following equality holds ∞∑ i=0 δi ≤δ (6 π2 ) ∞∑ i=1 1/i2 = δ , where in the last equality, we used the known fact that ∑ ∞ i=1 1/i2 = π2/6. Thus, if we take an union bound over all i ≥0, we have with probability at least 1 −δ it holds that ∥P ri T −Pri T ∥F ≤CF,δ √ri + CF, 2 √ 2 ln(i + 10) ri ∀i ≥0 . The statement follows by observing that the right-hand side of the above inequality is equal to S(ri, δ) for any i ≥0. Proof of Proposition 4. . W e have U(ri+1, δ) −U(ri, δ) = 21[ S(ri+1, δ) −S(ri, δ)] + ∥PT −P ri+1 T ∥F −∥PT −P ri T ∥F . By using the triangle inequality, we obtain ∥PT −P ri+1 T ∥F ≤∥PT −P ri T ∥F + ∥P ri T −P ri+1 T ∥F , thus we have U(ri+1, δ) −U(ri, δ) ≤21[S(ri+1, δ) −S(ri, δ)] + ∥P ri T −P ri+1 T ∥F . (12) W e use the triangle inequality and Proposition 3 to show that ∥P ri T −P ri+1 T ∥F ≤∥P ri T −Pri T ∥F + ∥P ri+1 T −Pri+1 T ∥F + ∥Pri T −Pri+1 T ∥F ≤∥Pri T −Pri+1 T ∥F + S(ri, δ) + S(ri+1, δ) . If we plug the above inequality in (12) and use the assumption that ∥Pri T −Pri+1 T ∥F ≤4S(ri, δ), we obtain U(ri+1, δ) −U(ri, δ) ≤21[S(ri+1, δ) −S(ri, δ)] + S(ri+1, δ) + 5 S(ri, δ) = 22 S(ri+1, δ) −16S(ri, δ) If we expand the above upper bound by using the deﬁnition of th e function S, we have 22S(ri+1, δ) −16S(ri, δ) = CF,δ √ri+1 [22 −16 √ 2] + CF, 2 √ 2 ln(i + 11) ri+1 [ 22 −16 √ 2 √ ln(i + 10) ln(i + 11) ] ≤0 , where the last inequality follows since 22−16 √ 2 ≤0, and 22−16 √ 2 √ ln(i + 10)/ ln(i + 11) ≤0. Thus, it holds that U(ri+1, δ) −U(ri, δ) ≤22S(ri+1, δ) −16S(ri, δ) ≤0 , and we can conclude that U(ri+1, δ) ≤U(ri, δ). 13Proof of Proposition 5. . Observe that by using the triangle inequality, it holds tha t ∥Pri T −Pri+1 T ∥F ≤∥P ri T −Pri T ∥F + ∥P ri+1 T −Pri+1 T ∥F + ∥P ri T −P ri+1 T ∥F ≤∥P ri T −P ri+1 T ∥F + S(ri, δ) + S(ri+1, δ) ≤∥P ri T −P ri+1 T ∥F + 2S(ri, δ) , where in the second inequality we used Proposition 3. By assu mption, we have that ∥Pri T − Pri+1 T ∥F ≥4S(ri+1, δ), hence ∥P ri T −P ri+1 T ∥F ≥2S(ri, δ) (13) Observe that by triangle inequality, we have that ∥P ri T −P ri+1 T ∥F ≤∥PT −P ri T ∥F + ∥PT −P ri+1 T ∥F . W e use (2) and obtain that ∥P ri T −P ri+1 T ∥F ≤max t<ri ∥PT −PT −t∥F + max t<ri+1 ∥PT −PT −t∥F ≤2 max t<ri+1 ∥PT −PT −t∥F . By combining the above inequality with (13), we ﬁnally obtai n that maxt<ri+1 ∥PT −PT −t∥F ≥ S(ri, δ). Proof of Lemma 6. W e remind that F= {Lh : h ∈H}. By using the deﬁnition of ∥·∥F , we have ∥Pr T −P2r T ∥F = sup h∈H ⏐ ⏐ ⏐ ⏐ ⏐ 1 r T∑ t=T −r+1 Lh(Xt, Yt) − 1 2r T∑ t=T −2r+1 Lh(Xt, Yt) ⏐ ⏐ ⏐ ⏐ ⏐ = 1 2 sup h∈H ⏐ ⏐ ⏐ ⏐ ⏐ 1 r T∑ t=T −r+1 Lh(Xt, Yt) −1 r T −r∑ t=T −2r+1 Lh(Xt, Yt) ⏐ ⏐ ⏐ ⏐ ⏐ . W e can remove the absolute value by re-writing this expressi on as ∥Pr T −P2r T ∥F = 1 2 max { sup h∈H ( 1 r T∑ t=T −r+1 Lh(Xt, Yt) −1 r T −r∑ t=T −2r+1 Lh(Xt, Yt) ) , sup h∈H ( 1 r T −r∑ t=T −2r+1 Lh(Xt, Yt) −1 r T∑ t=T −r+1 Lh(Xt, Yt) )} . (14) Consider the ﬁrst argument of the above maximum. W e can obser ve that for any (X, Y ) ∈X×Y , it holds that Lh(X, Y ) + Lh(X, 1 −Y ) = 1 , thus we obtain that sup h∈H ( 1 r T∑ t=T −r+1 Lh(Xt, Yt) −1 r T −r∑ t=T −2r+1 Lh(Xt, Yt) ) = sup h∈H ( 1 −1 r T∑ t=T −r+1 Lh(Xt, 1 −Yt) −1 r T −r∑ t=T −2r+1 Lh(Xt, Yt) ) =1 −inf h∈H ( 1 r T∑ t=T −r+1 Lh(Xt, 1 −Yt) + 1 r T −r∑ t=T −2r+1 Lh(Xt, Yt) ) (15) Similarly, we can demonstrate that the second term of the max imum is equal to: sup h∈H ( 1 r T −r∑ t=T −2r+1 Lh(Xt, Yt) −1 r T∑ t=T −r+1 Lh(Xt, Yt) ) =1 −inf h∈H ( 1 r T∑ t=T −r+1 Lh(Xt, Yt) + 1 r T −r∑ t=T −2r+1 Lh(Xt, 1 −Yt) ) . (16) 14Therefore, to compute the discrepancy (14), it is sufﬁcient to solve the two empirical risk minimiza- tion problems in (15) and (16). T o obtain the ﬁnal statement, we can observe that for any (X, Y ) and h ∈H, it holds that Lh(X, Y ) = L1−h(X, 1 −Y ). Thus, we can show that (16) is equivalent to: 1 −inf h∈H ( 1 r T∑ t=T −r+1 Lh(Xt, Yt) + 1 r T −r∑ t=T −2r+1 Lh(Xt, 1 −Yt) ) =1 −inf h∈H ( 1 r T∑ t=T −r+1 L1−h(Xt, 1 −Yt) + 1 r T −r∑ t=T −2r+1 L1−h(Xt, Yt) ) . Since His symmetric, i.e. 1 −h ∈H ⇐⇒ h ∈H, we can conclude that (15) and (16) have the same value. This concludes the proof. Proof of Theorem 7. Since Hhas VC-dimension ν, by a standard argument we have that the family F= {Lh : h ∈H} has VC-dimension upper bounded by 2ν, thus it satisﬁes Assumption 1 on the sample complexity for uniform convergence with CF, 1 = O(√ν) and CF, 2 = O(1). W e can observe that since His symmetric, Lemma 6 shows that we can compute ∥Pr T −P2r T ∥F for any r ≥1 by solving an empirical risk minimization problem. Since His computationally tractable, there exists a procedure that solves this problem, thus we al so satisfy Assumption 2. Remark: If the symmetry assumption does not hold, in the proof of Lemm a 6 we show that we can still compute the discrepancy ∥Pr T −P2r T ∥F by solving the two empirical risk minimization problems in (15) and (16). Hence, we can use Algorithm 1 with the family F, and let ˆr be the value returned by the algorithm. Theorem 1 guarantees that with probability at least 1 −δ, we have that ∥PT −Pˆr T ∥F = O ( min r≤T [ √ ν r + max t<r ∥PT −PT −t∥F + √ log(log(r + 1)/δ) r ]) . (17) Now , we have that PT (Lˆh) −PT (Lh∗ ) = PT (Lˆh) −PT (Lh∗ ) = PT (Lˆh) −Pˆr T (Lˆh) + Pˆr T (Lˆh) −PT (Lh∗ ) ≤PT (Lˆh) −Pˆr T (Lˆh) + Pˆr T (Lh∗ ) −PT (Lh∗ ) ≤|PT (Lˆh) −Pˆr T (Lˆh)|+ |Pˆr T (Lh∗ ) −PT (Lh∗ )| ≤2∥PT −Pˆr T ∥F , where the ﬁrst inequality is due to the deﬁnition of ˆh. Therefore, using (17), we have that with probability at least 1 −δ, it holds PT (Lˆh) −PT (Lh∗ ) = O ( min r≤T [ √ ν r + max t<r ∥PT −PT −t∥F + √ log(log(r + 1)/δ) r ]) . Proof of Theorem 9. The theorem is proven following the same structure as the pro of of Theorem 7. A.1 Lower Bound. In this section, we prove the lower bound of Theorem 8. The pro of structure is based on the work of Mazzetto and Upfal [2023]. W e provide a simpler statement of their proof in our setting, and we remove the additional regularity assumption used in that wo rk to characterize the drift error. W e introduce the following notation. W e say that a distribution Q over Zn is a product distribution if it can be written as the product o f n distributions over Z, i.e. Q = Q1 ×. . . ×Qn. For any n ≥1, we can observe that since the random 15variables Z1, . . . , Z n are independent, their distribution can be described as a pr oduct distribution over Zn. Given two strings τ, τ ′ ∈{−1, 1}n, we let hd(τ, τ ′) = 1 2 ∥τ −τ′∥1 be the Hamming distance between the two strings, i.e. the number of positio ns in which the two strings differ. Let ν be the VC dimension of the hypothesis class H. W e will construct a (later deﬁned) family of product distributions Q= {Q(τ ) = Q(τ ) 1 ×. . . ×Q(τ ) T : τ ∈{−1, 1}ν }over ZT that are indexed by a string τ ∈{−1, 1}ν . Intuitively, each distribution Q(τ ) is a possible candidate for the distribution of the random variables Z1, . . . , Z T . W e will show that for any algorithm A, there exists a product distribution Q(τ ) such that the classiﬁer hA computed by Ausing the samples Z1, . . . , Z T from Q(τ ) has large expected error. The proof is based on Assouad’s Lem ma. W e provide a statement of this lemma that is an adaptation of its classical statement t o our setting [Y u, 1997]. Lemma 10 (Assouad’s Lemma) . Let Qbe deﬁned as above. F or any function g : ZT ↦→{−1, 1}ν , there exists τ ∈{−1, 1}ν such that E Z∼Q(τ ) hd ( g(Z1, . . . , Z n), τ ) ≥ν 2 · min τ ′,τ ′′ hd(τ ′,τ ′′)=1 ∥Q(τ ′) ∧Q(τ ′′)∥1 Let ∆ 1 = 0 , ∆ 2, . . . , ∆ T be the sequence deﬁned in the statement of Theorem 8. W e let Φ : {1, . . . , T }↦→R be the function Φ( r) = (√ ν r + ∆ r ) . W e let Φ ∗ = min r Φ( r), and we remind that we assume Φ ∗ < 1/3 in the statement of the Theorem. W e build the family Qbased on the following value: ˜r = max { 1 ≤r ≤T : ∆ r < √ ν r } Proposition 11. The following holds: Φ(˜r) ≤3Φ ∗ . Proof. Let r∗ ∈{1, . . . , r }be a value such that Φ ∗ = Φ( r∗). The statement follows by exploiting the deﬁnition of ˜r. W e distinguish two cases. If ˜r ≥r∗, we have that Φ(˜r) Φ ∗ = ∆ ˜r + √ ν/˜r ∆ r∗ + √ ν/r∗ ≤2 √ ν/˜r√ ν/r∗ = 2 √ r∗/˜r ≤2 Conversely, if r∗ > ˜r, we have that Φ(˜r) Φ ∗ = ∆ ˜r + √ ν/˜r ∆ r∗ + √ ν/r∗ = ∆ ˜r + √ ν/(˜r + 1) √ (˜r + 1)/˜r ∆ r∗ + √ ν/r∗ ≤3∆ ˜r+1/∆ r∗ ≤3 In the ﬁrst inequality we used the fact that the sequence ∆ 1, . . . , ∆ T is non-decreasing, and the inequality √ ν/(˜r + 1) ≤∆ ˜r+1 due to the deﬁnition ot ˜r. W e deﬁne the family of product distributions Qas follows. Let X1, . . . , Xν be a shatter set for the hypothesis class H. W e build the following family Q= {Q(τ ) = Q[τ ] 1 ×. . . ×Q[τ ] T : τ ∈{−1, 1}ν } of product distributions over ZT = ( X×Y )T that are indexed by τ ∈{−1, 1}ν . They are deﬁned as follows: Pr (X,Y )∼Q(τ ) t (Y = 1 |X = Xi) = { 1 2 + τi 16 √ 6 (√ ν ˜r + ∆ ˜r −∆ T −t+1 ) if t > T −˜r 1 2 else Pr (X,Y )∼Q(τ ) t (X = Xi) = 1 ν ∀i ∈{1, . . . , ν } 16Those distributions are well-deﬁned. In fact, we have that f or all t > T −˜r: 1 16 √ 6 (√ ν ˜r + ∆ ˜r −∆ T −t+1 ) ≤ 1 16 √ 6 (√ ν ˜r + ∆ ˜r ) ≤ 1 16 √ 6 Φ(˜r) ≤ 3 10Φ ∗ < 1/4 , where we used Proposition 11. Given a classiﬁer h ∈H and τ ∈{−1, 1}ν , we remind that Q(τ ) T (Lh) = Pr (X,Y )∼Q(τ ) T (h(X) ̸= Y ) . W e can observe that for any classiﬁer h ∈H and t > T −˜r, it holds by construction that: ⏐ ⏐ ⏐Q(τ ) T (Lh) −Q(τ ) T −t+1(Lh) ⏐ ⏐ ⏐= 1 16 √ 6 ∆ T −t+1 ≤∆ T −t+1 , and for any t ≤T −˜r, we have that ⏐ ⏐ ⏐Q(τ ) T (Lh) −Q(τ ) T −t(Lh) ⏐ ⏐ ⏐= 1 16 √ 6 ( ∆ ˜r + √ ν ˜r ) ≤ 1 8 √ 6 √ ν ˜r = 1 8 √ 6 √ ν ˜r + 1 √ ˜r + 1 ˜r ≤ 1 8 √ 3 ∆ ˜r+1 ≤∆ T −t+1 , where the ﬁrst and the second inequality are due to the deﬁnit ion of ˜r, and the last inequality follows from the fact that the sequence ∆ 1, . . . , ∆ T is non-decreasing. Hence, if we let F= {Lh : h ∈H}, it results that for τ and for any 1 ≤r ≤T , it holds that: max t<r ∥Q(τ ) T −Q(τ ) T −t∥F ≤∆ r . (18) W e also let Lh∗ be the minimum loss that is achieved by a function h ∈H with respect to Q(τ ) T , i.e. Lτ h∗ = argmin Lh:h∈H Q(τ ) T (Lh). By using the family Qtogether with Assouad’s Lemma, we can show the following. Lemma 12. Let Qbe deﬁned as above. Let A : ZT ↦→ Hbe any algorithm that observes a sequence of elements T elements from Z, and it outputs a classiﬁer hA. F or any algorithm A, there exists τ ∈{−1, 1}ν such that if the input Z1, . . . , Z n is sampled according to Q(τ ), then: E [ Q(τ ) T (LhA ) −Q(τ ) T (Lτ h∗ ) ] ≥7 √ 6Φ ∗ 768 . Proof. Let τ ∈{−1, 1}ν . W e can deﬁne τA = ( 2hA(X1) −1, . . . , 2 ·hA(Xν ) −1 ) ∈{−1, 1}ν . W e have that: Q(τ ) T ( Lτ hA ) = [ 1 2 − 1 16 √ 6 (√ ν ˜r + ∆ ˜r )] + 1 8 √ 6ν (√ ν ˜r + ∆ ˜r ) ν∑ i=1 1{τA,i ̸=τi} = [ 1 2 − 1 16 √ 6 (√ ν ˜r + ∆ ˜r )] + Φ(˜r) 8 √ 6ν hd ( τA, τ ) By construction of Q(τ ) T , we can observe that Q(τ ) T (Lτ h∗ ) = [ 1 2 − 1 16 √ 6 (√ d ˜r + ∆ ˜r )] , hence, we have the following relation Q(τ ) T (LhA ) −Q(τ ) T (Lτ h∗ ) = Φ(˜r) 8 √ 6ν hd ( τA, τ ) (19) =⇒E [ Q(τ ) T (LhA ) −Q(τ ) T (Lτ h∗ ) ] = Φ(˜r) 8 √ 6ν E hd ( τA, τ ) 17Observe that Acan be seen as a map from ZT to {−1, 1}ν (i.e., the string τA). Hence, we can apply Lemma 10: this implies that there exists τ ∈{−1, 1}ν such that E [ Q(τ ) T (LhA ) −Q(τ ) T (Lτ h∗ ) ] ≥ Φ(˜r) 16 √ 6 min τ ′,τ ′′ hd(τ ′,τ ′′)=1 ∥Q(τ ′) ∧Q(τ ′′)∥1 . W e are left to evaluate the right-hand side of the above inequ ality. W e can use the following known relations that hold for any two distributions P and Q over ZT [Tsybakov, 2008]: ∥P ∧Q∥1 = 1 −1 2∥P −Q∥1, ∥P −Q∥1 ≤ √ 2KL(P, Q) (20) where KL is the Kullback–Leibler divergence (we refer to the classic deﬁnition of those distances as in [Tsybakov, 2008]). Let τ′ and τ′′ be two strings in {−1, 1}ν that only differ in one coordinate. Let Ber(p) be a Bernoulli distribution with parameter p ∈[0, 1]. W e have that: KL(Q(τ ′), Q(τ ′′)) = T∑ t=1 KL(Q(τ ′) t , Q(τ ′′) t ) = T∑ t=T −˜r+1 KL(Q(τ ′) t , Q(τ ′′) t ) = 1 ν ˜r∑ t=1 KL ( Ber (1 2 + 1 16 √ 6 (√ ν ˜r + ∆ t )) , Ber (1 2 − 1 16 √ 6 (√ ν ˜r + ∆ t ))) (21) where the ﬁrst equality is due to the factorization property of the KL-divergence, the second and third equality are due to the deﬁnition of the family Q. For any ǫ < 1/4, it holds that KL ( Ber (1 2 −ǫ ) , Ber (1 2 + ǫ )) ≤12ǫ2 . By plugging the above inequality in (21), and using the fact t hat (x + y)2 ≤2x2 + 2y2, we obtain that KL(Q(τ ′), Q(τ ′′)) ≤ 24 162 ·6ν [ ˜r∑ t=1 ν ˜r + ˜r∑ t=1 ∆ 2 ˜r ] ≤ 24 162 ·6ν [ ν + ˜r∆ 2 ˜r ] By using the deﬁnition of ˜r, it holds that ∆ 2 ˜r ˜r ≤ν. Thus, we we have that KL(Q(τ ′), Q(τ ′′)) ≤ 1/32. If we use this inequality with (20), we have min τ ′,τ ′′ hd(τ ′,τ ′′)=1 ∥Q(τ ′) ∧Q(τ ′′)∥1 ≥7/8 . Hence, we can conclude that there exists τ ∈{−1, 1}ν such that E [ Q(τ ) T (LhA ) −Q(τ ) T (Lτ h∗ ) ] ≥7 √ 6Φ(˜r) 768 . By using this Lemma, we can easily prove Theorem 8. Proof of Theorem 8. . By Lemma 12, there exists τ such that if Pt = Q(τ ) t for all 1 ≤t ≤T , then the algorithm Awith input Z1, . . . , Z T satisﬁes E [PT (LhA ) −PT (Lh∗ )] ≥7 √ 6Φ ∗/768 . (22) Due to (18), we observe that the distributions P1, . . . , P T satisfy the assumption on the drift. 18Let E = PT (LhA ) −PT (Lh∗ ). Observe that due to the construction of Q(τ ) and (19), we have that E ≤Φ(˜r)/(8 √ 6) ≤3Φ ∗/(8 √ 6), where the last inequality is due to Proposition 11. Let α > 0 be a later deﬁned value. W e have that: E[E] = E[E|E > α Φ ∗] Pr(E ≥αΦ ∗) + E[E|E < α Φ ∗] Pr(E ≤αΦ ∗) ≤(3Φ ∗/(8 √ 6)) Pr(E ≥αΦ ∗) + αΦ ∗(1 −P r(E ≤αΦ ∗)) = Pr( E ≥αΦ ∗) [3Φ ∗/20 −αΦ ∗] + αΦ ∗ . By using the above inequality together with (22), we ﬁnally o btain that: Pr(E ≥αΦ ∗) ≥7 √ 6Φ ∗/768 −αΦ ∗ 3Φ ∗/(8 √ 6) −αΦ ∗ = 7 √ 6/768 −α 3/(8 √ 6) −α W e set α = 1 /(112 √ 6) and we ﬁnally obtain that Pr ( E ≥ Φ ∗ 112 √ 6 ) ≥1/8 . B Relaxing Assumption 2 Given a family F, it is possible that the exact computation of ∥Pr T −P2r T ∥F is computationally hard. In this section, we show an example on how to relax Assumption 2 to allow an approximation of this quantity. Let α ≥1. W e say that an algorithm A in an α-approximation procedure if given Zt−2r+1, . . . , Z T , it computes an estimate A(ZT −2r+1, . . . , Z T ) such that 1 ≤ ∥Pr T −P2r T ∥F A(ZT −2r+1, . . . , Z T ) ≤α for any r ≤T/2. That is, the algorithm A does not compute the value of the supremum of the norm ∥·∥F exactly, but it guarantees a constant factor approximation α. In this case, we can modify the algorithm as follows. Algorithm 2: Adaptive Learning Algorithm under Drift with Approximatio n Procedure i ←0 ; while ri ≤T/2 do if A(Zt−2r+1, . . . , Z T ) ≤4 ·S(ri, δ) then i ←i + 1 ; end else return ri ; end end return ri Theorem 13. Let δ ∈ (0, 1). Let Assumptions 1 hold, and assume that there exists an α- approximation procedure for estimating ∥Pr T −P2r T ∥F for any r ≤T/2. Given Z1, . . . , Z T , there exists an algorithm that outputs a value ˆr ≤T such that with high-probability, it holds that ∥PT −Pˆr T ∥F = α ·O ( min r≤T [ αCF, 1 √r + max t<r ∥PT −PT −t∥F + αCF, 2 √ log(log(r + 1)/δ) r ]) Proof. The proof follows the same strategy as the one of the main theo rem with slight modiﬁcations, and we discuss those changes. W e replace the deﬁnition of U(r, δ) with U(r, δ) = (18 α + 9)S(r, δ) + ∥PT −P r T ∥F 19in order to take into account the additional error due to the a pproximation procedure. W e can observe that A(ZT −ri+1−1, . . . , Z T ) ≤4S(ri, δ) implies ∥Pri T −Pri+1 T ∥F ≤4αS(ri, δ) since A is an α-approximation procedure. W e can follow the steps of Propos ition 4 with those different constants to show an equivalent statement of this Proposition. On the other hand, we have that if A(Zt−2r+1, . . . , Z T ) > 4S(ri, δ) then ∥Pr T −P2r T ∥F > 4S(ri, δ) , and Proposition 5 applies. Therefore, we can use the same pro of strategy of Theorem 1 to prove Theorem 13 20",
      "meta_data": {
        "arxiv_id": "2305.02252v3",
        "authors": [
          "Alessio Mazzetto",
          "Eli Upfal"
        ],
        "published_date": "2023-05-03T16:37:32Z",
        "pdf_url": "https://arxiv.org/pdf/2305.02252v3.pdf"
      },
      "llm_extracted_info": {
        "main_contributions": "Proposes an adaptive learning algorithm that agnostically learns under unknown distribution drift without any prior bound on the drift size; achieves nearly the same error guarantees as algorithms that know the drift in advance; resolves an open problem posed by Hanneke & Yang (2019); supplies tight theoretical bounds and lower‐bound optimality; demonstrates applicability to binary classification and linear regression.",
        "methodology": "Derives a bias–variance style decomposition into statistical error (O(1/√r)) and drift error (discrepancy norm). Algorithm iteratively doubles the window size r of most-recent samples and compares the empirical discrepancy ∥P_r−P_{2r}∥_F with a threshold derived from statistical bounds. Stops when discrepancy is large, returning optimal r̂. Requires only the ability to compute (or α-approximate) the discrepancy norm; uses uniform convergence constants C_{F,1}, C_{F,2}. Provides proofs of upper bounds (Theorem 1), corollaries for i.i.d. data, and concrete instantiations for (i) VC-bounded binary classifiers using ERM to compute discrepancy, and (ii) ℓ2-regularized linear regression using trust-region optimization.",
        "experimental_setup": "Not mentioned",
        "limitations": "1. Assumption that discrepancy ∥P_r−P_{2r}∥_F can be exactly (or α-approximately) computed; this can be computationally hard for many hypothesis classes. 2. Relies on uniform convergence rate O(1/√r); constants must be known. 3. Purely theoretical; no empirical validation presented. 4. Algorithm’s bound includes an extra log log factor due to union bound. 5. Focuses on independent samples; extension to dependent or adversarial settings left open.",
        "future_research_directions": "1. Design efficient approximation schemes for computing the discrepancy for rich or intractable hypothesis classes. 2. Replace distribution-independent statistical bounds with data-dependent (e.g., Rademacher) estimates to tighten guarantees. 3. Empirical evaluation on real drifting data streams to test practical performance. 4. Extend framework to dependent observations, adversarial drifts, or concept-drift active learning. 5. Explore adaptation under other loss functions and more complex models (e.g., deep networks)."
      }
    },
    {
      "title": "Non-Stationary Learning of Neural Networks with Automatic Soft Parameter Reset",
      "abstract": "Neural networks are traditionally trained under the assumption that data come\nfrom a stationary distribution. However, settings which violate this assumption\nare becoming more popular; examples include supervised learning under\ndistributional shifts, reinforcement learning, continual learning and\nnon-stationary contextual bandits. In this work we introduce a novel learning\napproach that automatically models and adapts to non-stationarity, via an\nOrnstein-Uhlenbeck process with an adaptive drift parameter. The adaptive drift\ntends to draw the parameters towards the initialisation distribution, so the\napproach can be understood as a form of soft parameter reset. We show\nempirically that our approach performs well in non-stationary supervised and\noff-policy reinforcement learning settings.",
      "full_text": "Non-Stationary Learning of Neural Networks with Automatic Soft Parameter Reset Alexandre Galashov∗ UCL Gatsby Google DeepMind agalashov@google.com Michalis K. Titsias Google DeepMind mtitsias@google.com András György Google DeepMind agyorgy@google.com Clare Lyle Google DeepMind clarelyle@google.com Razvan Pascanu Google DeepMind razp@google.com Yee Whye Teh Google DeepMind University of Oxford ywteh@google.com Maneesh Sahani UCL Gatsby maneesh@gatsby.ucl.ac.uk Abstract Neural networks are traditionally trained under the assumption that data come from a stationary distribution. However, settings which violate this assumption are becoming more popular; examples include supervised learning under distributional shifts, reinforcement learning, continual learning and non-stationary contextual bandits. In this work we introduce a novel learning approach that automatically models and adapts to non-stationarity, via an Ornstein-Uhlenbeck process with an adaptive drift parameter. The adaptive drift tends to draw the parameters towards the initialisation distribution, so the approach can be understood as a form of soft parameter reset. We show empirically that our approach performs well in non-stationary supervised and off-policy reinforcement learning settings. 1 Introduction Neural networks (NNs) are typically trained using algorithms like stochastic gradient descent (SGD), assuming data comes from a stationary distribution. This assumption fails in scenarios such as continual learning, reinforcement learning, non-stationary contextual bandits, and supervised learning with distribution shifts [20, 53]. A phenomenon occurring in non-stationary settings is the loss of plasticity [12, 2, 13], manifesting either as a failure to generalize to new data despite reduced training loss [4, 2], or as an inability to reduce training error as the data distribution changes [13, 37, 1, 42, 34]. In [38], the authors argue for two factors that lead to the loss of plasticity: preactivation distribution shift, leading to dead or dormant neurons [47], and parameter norm growth causing training instabili- ties. To address these issues, strategies often involvehard resets based on heuristics like detecting dormant units [47], assessing neuron utility [13, 12], or simply after a fixed number of steps [ 43]. Though effective at increasing plasticity, hard resets can be inefficient as they can discard valuable knowledge captured by the parameters. We propose an algorithm that implements a mechanism of soft parameter resets, in contrast to the hard resets discussed earlier. A soft reset partially moves NN parameters towards the initialization ∗Corresponding author 38th Conference on Neural Information Processing Systems (NeurIPS 2024). arXiv:2411.04034v1  [cs.LG]  6 Nov 2024while keeping them close to their previous values. It also increases learning rate of the learning algorithm, allowing new NN parameters to adapt faster to the changing data. The amount by which the parameters move towards the initialization and the amount of learning rate increase are controlled by the drift parameters which are learned online. The exact implementation of soft reset mechanism is based on the use of a drift model in NN parameters update before observing new data. Similar ideas which modify the starting point of SGD as well as increase the learning rate of SGD depending on non-stationarity were explored (see [21, 29]) in an online convex optimization setting. Specifically, in [21], the authors assume that the optimal parameter of SGD changes according to some dynamical model out of a finite family of models. They propose an algorithm to identify this model and a way to leverage this model in a modified SGD algorithm. Compared to these works, we operate in a general non-convex setting. Proposed drift model can be thought as a dynamical Bayesian prior over Neural Network parameters, which is adapted online to new data. We make a specific choice of drift model which implements soft resets mechanism. Our contributions can be summarized as follows. First, we propose an explicit model for the drift in NN parameters and describe the procedure to estimate the parameters of this model online from the stream of data. Second, we describe how the estimated drift model is incorporated in the learning algorithm. Third, we empirically demonstrate the effectiveness of this approach in preventing the loss of plasticity as well as in an off-policy reinforcement learning setting. 2 Non-stationary learning with Online SGD In a non-stationary learning setting with changing data distributionspt(x, y), where x ∈ RL, y∈ RK, we define the loss function for parameters θ ∈ RD as Lt(θ) = E(xt,yt)∼ptLt(θ, xt, yt) (1) Our goal is to find a parameter sequence Θ = (θ1, . . . , θT ) that minimizes the dynamic regret: RT (Θ, Θ⋆) = 1 T PT t=1 (Lt(θt) − Lt(θ⋆ t )) , (2) with a reference sequence Θ⋆ = (θ⋆ 1, . . . , θ⋆ T ), satisfying θ⋆ t = arg minθ Lt(θ). A common approach to the online learning problem is online stochastic gradient descent (SGD) [23]. Starting from initial parameters θ0, the method updates these parameters sequentially for each batch of data {(xi t, yi t)}B i=1 s.t. (xi t, yi t) ∼ pt(xt, yt). The update rule is: θt+1 = θt − αt∇θLt+1(θt), where ∇θLt+1(θt) = 1 B PB i=1 ∇θLt+1(θt, xi t, yi t) and αt is learning rate. See also Appendix G for the connection of SGD to proximal optimization. Convex Setting. In the convex setting, online SGD with a fixed learning rate α can handle non- stationarity [56]. By selecting α appropriately – potentially using additional knowledge about the reference sequence—we can optimize the dynamic regret in (2). In general, algorithms that adapt to the observed level of non-stationarity can outperform standard online SGD. For example, in [29], the authors propose to adjust the learning rateαt, while in [21] and in [29], the authors suggest modifying the starting point of SGD from θt to an adjusted θ′ t proportional to the level of non-stationarity. Non-Convex Setting. Non-stationary learning with NNs is more complex, since now there is a changing set of local minima as the data distribution changes. Such changes can lead to a loss of plasticity and other pathologies. Alternative optimization methods like Adam [ 30], do not fully resolve this issue [13, 37, 1, 42, 34]. Parameter resets [13, 48, 12] partially mitigate the problem, but could be too aggressive if the data distributions are similar. 3 Online non-stationary learning with learned parameter resets Notation. We denote by N(θ; µ, σ2) a Gaussian distribution on θ with mean µ and variance σ2. We denote θi the i-the component of the vector θ = (θ1, . . . , θD). Unless explicitly mentioned, we assume distributions are defined per NN parameter and we omit the index i. We denote as Lt+1(θ) = −log p(yt+1|xt+1, θ) the negative log likelihood on (yt+1, xt+1) for parameters θ. We introduce Soft Resets, an approach that enhances learning algorithms on non-stationary data distributions and prevents plasticity loss. The main idea is to assume that the data is generated in 2Graphical model (c) Stationary case  (d) Non-stationary case  without dynamical model (e) Non-stationary case with  dynamical model (a) i.i.d. assumption (b) non i.i.d. assumption Toy Bayesian Inference example Figure 1: Left: graphical model for data generating process in the (a) stationary case and (b) non- stationary case with drift model p(θt+1|θt, γt). Right: (c) In a stationary online learning regime, the Bayesian posterior (red dashed circles) in the long run will concentrate around θ∗ (red dot). (d) In a non-stationary regime where the optimal parameters suddenly change from current value θ∗ t to new value θ∗ t+1 (blue dot) online Bayesian estimation can be less data efficient and take time to recover when the change-point occurs. (e) The use of p(θ|θt, γt) and the estimation of γt allows to increase the uncertainty, by soft resetting the posterior to make it closer to the prior (green dashed circle), so that the updated Bayesian posterior pt+1(θ) (blue dashed circle) can faster track θ∗ t+1. non-i.i.d. fashion such that a change in the data distribution is modeled by the drift in the parameters p(θt+1|θt, γt) at every time t + 1 before new data is observed. We assume a class of drift models p(θt+1|θt, γt) which encourages the parameters to move closer to the initialization. The amount of drift (and level of non-stationarity) is controlled by γt which are estimated online from the data. As can be seen below, in the context of SGD, this approach adjusts the starting point θt of the update to a point ˜θt(γt), which is closer to the initialization and increases the learning rate proportionally to the drift. In the context of Bayesian inference, this approach shrinks the mean of the estimated posterior towards the prior and increases the variance proportional to γt. This approach is inspired by prior work in online convex optimization for non-stationary environments [e.g., 25, 21, 8, 18, 29]. 3.1 Toy illustration of the advantage of drift models Consider online Bayesian inference with 2-D observations yt = θ⋆ + ϵt , where θ⋆ ∈ R2 are unknown true parameters and ϵt ∼ N(0; σ2I) is Gaussian noise with variance σ2. Starting from a Gaussian prior p0(θ) = N(θ; µ0; Σ0), the posterior distribution pt+1(θ) = p(θ|y1, . . . , yt) = N(θ; µt+1, Σt+1) is updated using Bayes’ rule pt+1(θ) ∼ p(yt+1|θ)pt(θ). (3) The posterior update (3) comes from the i.i.d. assumption on the data generation process (Figure 1a), since pt+1(θ) ∼ p0(θ) Qt+1 s=1 p(ys|θ). By the Central Limit Theorem (CLT), the posterior mean µt converges to θ⋆ and the covariance matrix Σt shrinks to zero (the radius of red circle in Figure 1c). Suppose now that the true parameters θ⋆ t (kept fixed before t) change to new parameters θ⋆ t+1 at time t + 1. The i.i.d. assumption (Figure 1a) is violated and the update (3) becomes problematic because the low uncertainty (small radius of red dashed circle in Figure 1d) in pt(θ) causes the posterior pt+1(θ) (see blue circle) to adjust slowly towards θ⋆ t+1 (blue dot) as illustrated in Figure 1d. To address this issue, we assume that before observing new data, the parameters drift according to p(θt+1|θt, γt) where the amount of drift is controlled by γt. The corresponding conditional independence structure is shown in Figure 1b. The posterior update then becomes: pt+1(θ) ∼ p(yt+1|θ) R p(θ|θ′ t, γt)pt(θ′ t)dθ′ t. (4) For a suitable choice of drift model p(θt+1|θt, γt), this modification allows pt+1(θ) (blue circle) to adjust more rapidly towards the new θ⋆ t+1 (blue dot), see Figure 1e. This is because the new priorR p(θ|θ′ t, γt)pt(θ′ t)dθ′ t has larger variance (green circle) thanpt(θ) and its mean is closer to the center of the circle. Ideally, the parameter γt should capture the underlying non-stationarity in the data distribution in order to control the impact of the prior R p(θ|θ′ t, γt)pt(θ′ t)dθ′ t. For example, if at some point the non-stationarity disappears, we want the drift model to exhibit no-drift to recover the posterior update (3). This highlights the importance of the adaptive nature of the drift model. 33.2 Ornstein-Uhlenbeck parameter drift model We motivate the specific choice of the drift model which is useful for maintaining plasticity. We assume that our Neural Network has enough capacity to learn anystationary dataset in a fixed number of iterations starting from a good initialization θ0 ∼ p0(θ) [see, e.g., 24, 16]. Informally, we call the initialization θ0 plastic and the region around θ0 a plastic region. Consider now a piecewise stationary datastream that switches between a distribution pa, with a set of local minima Ma of the negative likelihood L(θ), to a distribution pb at time t + 1, with a set of local minima Mb. If Mb is far from Ma, then hard reset might be beneficial, but if Mb is close to Ma, resetting parameters is suboptimal. Furthermore, since θ is high-dimensional, different dimensions might need to be treated differently. We want a drift model that can capture all of these scenarios. Drift model. The drift model p(θt+1|θt, γt) which exhibits the above properties is given by p(θ|θt, γt) = N(θ; γtθt + (1 − γt)µ0; (1− γ2 t )σ2 0), (5) which is separately defined for every parameter dimension θi where p0(θi 0) ∼ N(θi 0; µi 0; \u0002 σi 0 \u00032 ) is the per-parameter prior distribution and γt = (γ1 t , . . . , γD t ). The model is a discretized Ornstein- Uhlenbeck (OU) process [50] (see Appendix A for the derivation). The parameter γt ∈ [0, 1] is a drift parameter and controls the amount of non-stationarity in each parameter. For γt = 1, there is no drift and for γt = 0, the drift model reverts the parameters back to the prior. A value of γt ∈ (0, 1) interpolates between these two extremities. A remarkable property of (5) is that starting from the current parameter θt, if we simulate a long trajectory, as T → ∞, the distribution of p(θT |θt) will converge to the prior p(θ0). This is only satisfied (for γt ∈ (0, 1)) due to the variance σ2 0(1 − γ2 t ). Replacing it by an arbitrary variance σ2 would result in the variance of p(θT |θt) either going to 0 or growing to ∞, harming learning. Thus, the model (5) encourages parameters to move towards plastic region (initialization). In Appendix B, we discuss this further and other potential choices for the drift model. 3.3 Online estimation of drift model The drift model p(θt+1|θt, γt) quantifies prior belief about the change in parameters before seeing new data. A suitable choice of an objective to select γt is predictive likelihood which quantifies the probability of new data under our current parameters and drift model. From Bayesian perspective, it means selecting the prior distribution which explains the future data the best. We derive the drift estimation procedure in the context of approximate online variational infer- ence [ 7] with Bayesian Neural Networks (BNN). Let Γt = ( γ1, . . . , γt) be the history of ob- served parameters of the drift model and St = {(x1, y1), . . . ,(xt, yt)} be the history of ob- served data. The objective of approximate online variational inference is to propagate an ap- proximate posterior qt(θ|St, Γt−1) over parameters, such that it is constrained to some family Q of probability distributions. In the context of BNNs, it is typical [ 5] to assume a family Q = {q(θ) : q(θ) ∼ QD i=1 N(θi; µi, \u0002 σi\u00032 ); θ = (θ1, . . . , θD)} of Gaussian mean-field distributions over parameters θ ∈ RD (separate Gaussian per parameter). For simplicity of notation, we omit the index i. Let qt(θ) ≜ qt(θ|St, Γt−1) ∈ Qbe the Gaussian approximate posterior at time t with mean µt and variance σ2 t for every parameter. The new approximate posterior qt+1(θ) ∈ Qis found by qt+1(θ) = arg minq KL[q(θ)||p(yt+1|xt+1, θ)qt(θ|γt)] , (6) where the prior term is the approximate predictive look-ahead prior given by qt(θ|γt) = R qt(θt)p(θ|θt, γt)dθt = N(θ; ˜µt(γt), ˜σ2 t (γt)) (7) that has parameters ˜µt(γt) = γtµt + (1− γt)µ0, ˜σ2 t (γt) = γ2 t σ2 t + (1− γ2 t )σ2 0, see Appendix I.1 for derivation. The form of this prior qt(θ|γt) comes from the non i.i.d. assumption (see Figure 1b) and the form of the drift model (5). For new batch of data (xt+1, yt+1) at time t + 1, the approximate predictive log-likelihood equals to log qt(yt+1|xt+1, γt) = log R p(yt+1|xt+1, θ)qt(θ|γt)dθ. (8) The log-likelihood (8) allows us to quantify predictions on new data (xt+1, yt+1) given our current distribution qt(θ) and the drift model from (5). We want to find such γ⋆ t that γ⋆ t ≈ arg maxγt log qt(yt+1|xt+1, γt) (9) 4Using γ⋆ t in (5) modifies the prior distribution (7) to fit the most recent observations the best by putting more mass on the region where the new parameter could be found (see Figure 1,right). Gradient-based optimization for γt. The approximate predictive prior in (7) is Gaussian which allows us to use the so-called reparameterisation trick to optimize (8) via gradient descent. Starting from an initial value of drift parameter γ0 t at time t, we perform K updates with learning rate ηγ γt,k+1 = γt,k + ηγ∇γ log R p(yt+1|xt+1, ˜µt(γt,k) + ϵ˜σt(γt,k))N(ϵ; 0, I)dϵ, (10) The integral is evaluated by Monte-Carlo (MC) using M samples ϵi ∼ N(ϵ; 0, I), i = 1, . . . , M R p(yt+1|xt+1, ˜µt(γt,k) + ϵ˜σt(γt,k))N(ϵ; 0, I)dϵ ≈ 1 M PM i=1 p(yt+1|xt+1, ˜µt(γt,k) + ϵi˜σt(γt,k)) (11) Inductive bias in the drift model is captured by γ0 t , where γt,0 = 1 encourages stationarity, while γt,0 = γt−1,K promotes temporal smoothness. In practice, we found γt,0 = 1 was the most effective. Structure in the drift model. The drift model can be defined to be shared across different subsets of parameters which reduces the expressivity of the drift model but also provides regularization to (10). We consider γt to be either defined for each parameter or for each layer. See Section 5 for details as well as corresponding results in Appendix H. Interpretation of γt. By linearising log p(yt+1|xt+1, θ) around µt, we can compute (8) in a closed form and get the following loss for γt (see Appendix J for the proof) optimizing (9) F(γt) = 0.5(σ2 t (γt) ⊙ gt+1)⊤gt+1 − (γt ⊙ µt + (1 − γt) ⊙ µ0)⊤gt+1, where gt = ∇Lt+1(µt) and Lt+1(θ) = −log p(yt+1|xt+1, µt), and where ⊙ denotes element-wise product performed only over parameters for which γt is shared (see paragraph about structure in drift model). The transpose operation is also defined on a subset of parameters for which γt is shared. Adding the ℓ2 penalty 1 2 λ||γt − γ0 t ||2 encoding the starting point γ0 t , gives us the closed form for γt γt = (µt−µ0)T gt+1+λγ0 t ((σ2 0−σ2 t )·gt+1)T gt+1+λ , (12) where we also clip parameters γt to [0, 1]. The expression (12) gives us the geometric interpretation for γt. The value of γt depends on the angle between (µt − µ0) and gt+1 When these vectors are aligned, γt is high and is low otherwise. When these vectors are orthogonal or the gradient gt+1 ≈ 0, the value of γt is heavily influenced by γ0 t . Moreover, when gt+1 ≈ 0, we can interpret it as being close to a local minimum, i.e., stationary, which means that we want γt ≈ 1, therefore adding the ℓ2 penalty is important. Also, when the norm of the gradients gt+1 is high, the value of γt is encouraged to decrease, introducing the drift. This means that using γt in the parameter update (see Section 3.5) encourages the norm of the gradient to stay small. In practice, we found that update (12) was unstable suggesting that linearization of the log-likelihood might not be a good approximation for learning γt. 3.4 Approximate Bayesian update of posterior qt(θ) with BNNs The optimization problem (6) for the per-parameter Gaussianq(θ) = N(θ; µ, σ2) with Gaussian prior qt(θ) = N(θ; µt, σ2 t ), both defined for every parameter of NN, can be written (see Appendix I.1) to minimize the following loss ˜Ft(µ, σ, γt) = Eϵ∼N(0;I) [Lt+1(µ + ϵσ)] + PD i=1 λi t \u0014 (µi−˜µi t(γt))2+[σi] 2 2[˜σi t(γt)] 2 − 1 2 log \u0002 σi\u00032 \u0015 , (13) where λi t > 0 are per-parameter temperature coefficients. The use of small temperature λ > 0 parameter (shared for all NN parameters) was shown to improve empirical performance of Bayesian Neural Networks [54]. Given that in (13), the variance ˜σ2 t (γt) can be small, in order to control the strength of the regularization, we propose to use per parameter temperature λi t = λ × \u0002 σi t \u00032 , where λ >0 is a global constant. This leads to the following objective ˆFt(µ, σ, γt) = Eϵ∼N(0;I) [Lt+1(µ + ϵσ)]+λ 2 P i ri t h (µi − ˜µi t(γt))2 + [σi]2 − \u0002 ˜σi t(γt) \u00032 log[σi]2 i , (14) where the quantity ri t = [σi t]2/[σi t(γt)]2 is a relative change in the posterior variance due to the drift. The ratio ri t = 1 when γt = 1. For γt < 1 since typically σ2 t < σ2 0, the ratio is ri t < 1. Thus, as long as there is non-stationarity (γt < 1), the objective(14) favors the data termEϵ∼N(0;I) [Lt+1(µ + ϵσ)] 5Algorithm 1 Soft-Reset algoritm Input: Data-stream ST = {(xt, yt)})T t=1 Neural Network (NN) initializing distribution pinit(θ) and specific initialization θ0 ∼ pinit(θ) Learning rate αt for parameters and ηγ for drift parameters Number of gradient updates Kγ on drift parameter γt NN initial standard deviation (STD) scaling p ≤ 1 (see (23)) and ratio s = σt pσ0 . for step t = 0, 1, 2, . . . , Tdo For (xt+1, yt+1), predict ˆyt+1 = f(xt+1|θt) Compute performance metric based on (yt+1, ˆyt+1) Initialize drift parameter γt,0 = 1 for step k = 0, 1, 2, . . . , Kγ do Sample θ′ 0 ∼ pinit(θ) Stochastic update (21) on drift parameter using specific initialization (24) γt,k+1 = γt,k +ηγ∇γ h log p(yt+1|xt+1, γtθt + (1 − γt)θ0 + θ′ 0p p 1 − γ2 t + γ2 t s2) i γt=γt,k end for Get ˜θt(γt,K) with (17) and ˜αt(γt,K) with (18) Update parameters θt+1 = ˜θt(γt,K) − ˜αt(γt,K) ◦ ∇θLt+1(˜θt(γt,K)) end for allowing the optimization to respond faster to changes in the data distribution. To find new parameters, let µt+1,0 = ˜µt(γt) and σt+1,0 = ˜σt(γt), and perform updates K on (14) µt+1,k+1 = µt+1,k − αµ ˆFt(µt+1,k, σt+1,k, γt), σt+1,k+1 = σt+1,k − ασ ˆFt(µt+1,k, σt+1,k, γt), (15) where αµ and ασ are learning rates for the mean and for the standard deviation correspondingly. All derivations are provided in Appendix I.1. The full procedure is described in Algorithm 2. 3.5 Fast MAP update of posterior qt(θ) As a faster alternative to propagating the posterior (6), we do MAP updates with the prior p0(θ) = N(θ; µ0; σ2 0) and the approximate posterior qt(θ) = N(θ; θt; σ2 t = s2σ2 0), where s ≤ 1 is a hyperparameter controlling the variance σ2 t of qt(θ). Since a fixed s may not capture the true parameters variance, using a Bayesian method (see Section 3.4) is preferred but comes at a high computational cost (see Appendix E for discussion). The MAP update is given by (see Appendix I.2 for derivations) finding a minimum of the following proximal objective G(θ) = Lt+1(θ) + 1 2 PD i=1 |θi−˜θi t(γt)|2 ˜αi t(γt) (16) where the regularization target for the parameter dimension i is given by ˜θi t(γt) = γi tθi t + (1 − γi t)µi 0 (17) and the per-parameter learning rate is given as (assuming that αt the base SGD learning rate) ˜αi t(γt) = αt \u0010 (γi t)2 + 1−(γi t)2 s2 \u0011 . (18) Linearising Lt+1(θ) around ˜θt(γt) and optimizing (16) for θ leads to (see Appendix I.2) θt+1 = ˜θt(γt) − ˜αt(γt) ◦ ∇θLt+1(˜θt(γt)), (19) where ◦ is element-wise multiplication. For γt = 1, we recover the ordinary SGD update, while the values γt < 1 move the starting point of the modified SGD closer to the initialization as well as increase the learning rate. Algorithm 1 describes the full procedure. In Appendix C we describe additional practical choices made for the Soft Resets algorithm. Similarly to the Bayesian approach (15), we can do multiple updates on (16). We describe this Soft Resets Proximal algorithm in Appendix I.2 and full procedure is given in Algorithm 3. 64 Related Work Plasticity loss in Neural Networks. Our model shares similarities with reset-based approaches such as Shrink & Perturb (S&P) [2] and L2-Init [33]; however, whereas we learn drift parameters from data, these methods do not, leaving them vulnerable to mismatch between assumed non-stationarity and the actual realized non-stationarity in the data. Continual Backprop [ 13] or ReDO [47] apply resets in a data-dependent fashion, e.g. either based on utility or whether units are dead. But they use hard resets, and cannot amortize the cost of removing entire features. Interpretation (12) of γt connects to the notion of parameters utility from [14], but this quantity is used to prevent catastrophic forgetting by decreasing learning rate for high γt. Our method increases the learning rate for low γt to maximize adaptability, and is not designed to prevent catastrophic forgetting. Non-stationarity. Non-stationarity arises naturally in a variety of contexts, the most obvious being continual and reinforcement learning. The structure of non-stationarity may vary from problem to problem. At one extreme, we have a piece-wise stationary setting, for example a change in the location of a camera generating a stream of images, or a hard update to the learner’s target network in value-based deep RL algorithms. This setting has been studied extensively due to its propensity to induce catastrophic forgetting [e.g. 31, 45, 51, 10] and plasticity loss [13, 39, 38, 34]. At the other extreme, we can consider more gradual changes, for example due to improvements in the policy of an RL agent [40, 46, 42, 13] or shifts in the data generating process [ 36, 55, 20, 53]. Further, these scenarios might be combined, for example in continual reinforcement learning [31, 1, 13] where the reward function or transition dynamics could change over time. Non-stationary online convex optimization. Non-stationary prediction has a long history in online convex optimization, where several algorithms have been developed to adapt to changing data [see, e.g., 25, 8, 22, 17, 21, 18, 29]. Our approach takes an inspiration from these works by employing a drift model as, e.g., [25, 21] and by changing learning rate as [29, 52]. Further, our OU drift model bears many similarities to the implicit drift model introduced in the update rule of [ 25] (see also [8, 17]), where the predictive distribution is mixed with a uniform distribution to ensure the prediction could change quickly enough if the data changes significantly, where in our case p0 plays the same role as the uniform distribution. Bayesian approaches to non-stationary learning. A standard approach is Variational Continual Learning [41], which focuses on preventing catastrophic forgetting and is an online version of “Bayes By Backprop” [5]. This method does not incorporate dynamical parameter drift components. In [ 35], the authors applied variational inference (VI) on non-stationary data, using the OU-process and Bayesian forgetting, but unlike in our approach, their drift parameter is not learned. Further, in [49], the authors considered an OU parameter drift model similar to ours, with an adaptable drift scalar γ and analytic Kalman filter updates, but is applied over the final layer weights only, while the remaining weights of the network were estimated by online SGD. In [28], the authors propose to deal with non-stationarity by assuming that each parameter is a finite sum of random variables following different OU process. They derive VI updates on the posterior of these variables. Compared to this work, we learn drift parameters for every NN parameter rather than assuming a finite set of drift parameters. A different line of research assumes that the drift model is known and use different techniques to estimate the hidden state (the parameters) from the data: in [9], the authors use Extended Kalman Filter to estimate state and in [ 3], they propagate the MAP estimate of the hidden state distribution with K gradient updates on a proximal objective similar to (43), whereas in Bayesian Online Natural Gradient (BONG) [27], the authors use natural gradient for the variational parameters. 5 Experiments Soft reset methods. There are multiple variations of our method. We call the method implemented by Algorithm 1 with 1 gradient update on the drift parameter Soft Reset, while other versions show different parameter choices: Soft Reset (Kγ = 10) is a version with 10 updates on the drift parameter, while Soft Reset (Kγ = 10, Kθ = 10) is the method of Algorithm 3 in Appendix I.2 with 10 updates on drift parameter, followed by 10 updates on NN parameters. Bayesian Soft Reset (Kγ = 10 , Kθ = 10) is a method implemented by Algorithm 2 with 10 updates on drift parameter followed by 10 updates on the mean µt and the variance σ2 t (uncertainty) for each NN parameter. Bayesian method performed the best overall but required higher computational complexity (see Appendix E). Unless specified, γt is shared for all the parameters in each layer (separately for weight and biases). 70 50 100 150 200 T ask id 0.65 0.70 0.75 0.80 0.85Average T ask Accuracy Permuted MNIST 0 50 100 150 200 T ask id 0.2 0.4 0.6 0.8Average T ask Accuracy Random Label MNIST -- Data Efficient Online SGD L2 init Hard Reset Shrink and Perturb Soft Reset Bayesian Soft Reset K = 10, K = 10,  per parameter 0 50 100 150 200 T ask id 0.2 0.4 0.6 0.8 1.0Average T ask Accuracy Random Label CIFAR-10 -- Memorization Figure 2: Plasticity benchmarks. Left: performance on permuted MNIST. Center: performance on random-label MNIST (data efficient). Right: performance on random-label CIFAR-10(memoriza- tion). The x-axis is the task id and the y-axis is the per-task training accuracy (25). 0 50 100 150 200 T ask id 0.65 0.70 0.75 0.80 0.85Average T ask Accuracy Permuted MNIST 0 50 100 150 200 T ask id 0.2 0.4 0.6 0.8Average T ask Accuracy Random Label MNIST -- Data Efficient Soft Reset Soft Reset K = 10 Soft Reset Proximal K = 10, K = 10 Bayesian Soft Reset K = 10, K = 10 Bayesian Soft Reset K = 10, K = 10,  per parameter 0 50 100 150 200 T ask id 0.2 0.4 0.6 0.8 1.0Average T ask Accuracy Random Label CIFAR-10 -- Memorization Figure 3: Different variants of Soft Resets . Left: performance on permuted MNIST . Center: performance on random-label MNIST (data efficient). Right: performance on random-label CIFAR- 10 (memorization). The x-axis is the task id and the y-axis is the per-task training accuracy (25). Loss of plasticity. We analyze the performance of our method on plasticity benchmarks [34, 39, 38]. Here, we have a sequence of tasks, where each task consists of a fixed (for all tasks) subset of 10000 images images from either CIFAR-10 [32] or MNIST, where either pixels are permuted or the label for each image is randomly chosen. Several papers [34, 39, 38] study a memorization random-label setting where SGD can perfectly learn each task from scratch. To highlight the data-efficiency of our approach, we study the data-efficient setting where SGD achieves only 50% accuracy on each task when trained from scratch. Here, we expect that algorithms taking into account similarity in the data, to perform better. To study the impact of the non-stationarity of the input data, we consider permuted MNIST where pixels are randomly permuted within each task (the same task as considered by 34). As baselines, we use Online SGD and Hard Reset at task boundaries. We also consider L2 init [34], which adds L2 penalty ||θ − θ0||2 to the fixed initialization θ0 as well as Shrink&Perturb [2], which multiplies each parameter by a scalar λ ≤ 1 and adds random Gaussian noise with fixed variance σ. See Appendix D.1 for all details. As metrics, we use average per-task online accuracy (25), which is At = 1 N PN i=1 at i, where at i are the online accuracies collected on the task t via N timesteps, corresponding to the duration of the task. In Figure 5, we also use average accuracy over all T tasks, i.e. AT = 1 T PT t=1 At The results are provided in Figure 2. We observe that Soft Reset is always better than Hard Reset and most baselines despite the lack of knowledge of task boundaries. The gap is larger in the data efficient regime. Moreover, we see that L2 Init only performs well in the memorization regime, and achieves comparable performance to Hard Reset in the data efficient one. The method L2 Init could be viewed as an instantiation of our Soft Reset Proximal method optimizing (16) with γt = 0 at every step, which is sub-optimal when there is similarity in the data. Bayesian Soft Reset demonstrates significantly better performance overall, see also discussion below. In Figure 3, we compare different variants of Soft Reset. We observe that adding more compute for estimating γt (thus, estimating non-stationarity, Kγ = 10) as well as doing more updates on NN 81 2 3 4 5 MLP Layer 0.65 0.70 0.75 0.80 0.85 0.90Minimum  (a) Minimum t encountered MNIST CIFAR-10 0 20000 40000 60000 80000100000 t 0.5 0.6 0.7 0.8 0.9 1.0 (b) First layer t for Random Label MNIST 0 100000200000300000400000500000600000 t 0.5 0.6 0.7 0.8 0.9 1.0 (c) First layer t for Random Label CIFAR-10 Figure 4: Left: the minimum encountered γt for each layer on random-label MNIST and CIFAR-10. Center: the dynamics of γt on the first 20 tasks on MNIST. Right: the same on CIFAR-10. parameters (thus, more accurately adapting to non-staionarity, Kθ = 10) leads to better performance. All variants of Soft Reset γt parameters are shared for each NN layer, except for the Bayesian method. This variant is able to take advantage of a more complex per-parameter drift model, while other variants performed considerably worse, see Appendix H.4. We hypothesize this is due to the NN parameters uncertainty estimates σt which Bayesian method provide, while others do not, which leads to a more accurate drift model estimation, since uncertainty is used in this update (10). But, this approach comes at a higher computational cost, see Appendix E. In Appendix H, we provide ablations of the structure of the drift model, as well as of the impact of learning the drift parameter. Qualitative behavior of Soft Resets. For Soft Reset, we track the values of γt for the first MLP layer when trained on random-label tasks studied above (only 20 tasks), as well as the minimum encountered value of γt for each layer, which highlights the maximum amount of resets. Figure 4b,c shows γt as a function of t, and suggests that γt aggressively decreases at task boundaries (red dashed lines). The range of values of γt depends on the task and on the layer, see Figure 4a. Overall, γt changes more aggressively for long duration (memorization) random-label CIFAR-10 and less for shorter (data-efficient) random-label MNIST. See Appendix H.2 for more detailed results. To study the behavior of Soft Reset under input distribution non-stationarity, we consider a variant of Permuted MNIST where each image is partitioned into patches of a given size. The non-stationarity is controlled by permuting the patches (not pixels). Figure 5a shows the minimum encountered γt for each layer for different patch sizes. As the patch size increases and the problem becomes more stationary, the range of values for γt is less aggressive. See Appendix H.3 for more detailed results. Impact of non-stationarity. We consider a variant of random-label MNIST where for each task, an image has either a random or a true label. The label assignment is kept fixed throughout the task and is changed at task boundaries. We consider cases of 20%, 40% and 60% of random labels and we control the duration of each task (number of epochs). In total, the stream contains 200 tasks. In Figure 5b, we show performance of Online SGD, Hard Reset and in Figure 5c, the one of Soft Reset and of Bayesian Soft Reset. See Appendix D.2 for more details. The results suggest that for the shortest duration of the tasks, the performance of all the methods is similar. As we increase the duration of each of the task (moving along the x-axis), we see that both Soft Resets variants perform better than SGD and the gap widens as the duration increases. This implies that Soft Resets is more effective with infrequent data distribution changes. We also observe that Bayesian method performs better in all the cases, highlighting the importance of estimating uncertainty for NN parameters. 5.1 Reinforcement learning Reinforcement learning experiments. We conduct Reinforcement Learning (RL) experiments in the highly off-policy regime, similarly to [43], since in this setting loss of plasticity was observed. We ran SAC [19] agent with default parameters from Brax [15] on the Hopper-v5 and Humanoid-v4 GYM [6] environments (from Brax [15]). To reproduce the setting from [ 43], we control the off-policyness of the agent by setting the off-policy ratio M such that for every 128 environment steps, we do 128M gradient steps with batch size of 256 on the replay buffer. As baselines we consider ordinary SAC, hard-coded Hard Reset where we reset all the parameters K = 5 times throughout training (every 200000 steps), while keeping the replay buffer fixed (similarly to [43]). We employ our Soft Reset method as follows. After we have collected fresh data from the environment, we do one gradient update on γt (shared for all the parameters within each layer) with batch size of 128 on this new chunk of data and the previously collected one, i.e., two chunks of data in total. Then we initialize ˜θt(γt) and we employ the update rule (43) where the regularization ˜θt(γt) is kept constant for all the off-policy gradient updates on the replay buffer. See Appendix D.3 for more details. 9conv2_d_1conv2_d_2conv2_d_3conv2_d_4 linear linear_1 0.825 0.850 0.875 0.900 0.925 0.950 0.975Minimum t encountered (a) Permuted Patch MNIST Permuted patch size 1 2 4 7 14 30 100 400 Number of epochs per task 0.2 0.4 0.6 0.8 1.0Average accuracy over all tasks (b) Online SGD and Hard Reset performance Methods Online SGD Soft Resets Bayesian Soft Resets (K = 10, K = 10,  per parameter)  Hard Reset Random labels % 20 40 60 30 100 400 Number of epochs per task 0.2 0.4 0.6 0.8 1.0Average accuracy over all tasks (c) Soft Resets (Bayeisan / non-Bayesian) performance Methods Online SGD Soft Resets Bayesian Soft Resets (K = 10, K = 10,  per parameter)  Hard Reset Figure 5: (a) the x-axis denotes the layer, the y-axis denotes the minimum encountered γt for each convolutional and fully-connected layer when trained on permuted Patches MNIST, color is the patch size. The impact of non-stationarity on performance on random-label MNIST of Online SGD and Hard Reset is shown in (b) while the one of Soft Resets is shown in (c). The x-axis denotes the number of epochs each task lasts, while the marker and line styles denote the percentage of random labels within each task, circle (solid) represents 20%, rectangle(dashed) 40%, while rhombus (dashed and dot) 60%. The y-axis denotes the average performance (over 3 seeds) on the stream of 200 tasks. 0 2000 4000 6000 Humanoid. Replay Ratio -- 1.0 Humanoid. Replay Ratio -- 32.0 Humanoid. Replay Ratio -- 128.0 0.0 0.2 0.4 0.6 0.8 1.0 1e6 0 2000 4000 6000 Hopper. Replay Ratio -- 1.0 Soft Reset Baseline Hard Reset 0.0 0.2 0.4 0.6 0.8 1.0 1e6 Hopper. Replay Ratio -- 32.0 0.0 0.2 0.4 0.6 0.8 1.0 1e6 Hopper. Replay Ratio -- 128.0 Figure 6: RL results. First row is humanoid, second is hopper. Each column corresponds to different replay ratio. The x-axis is the number of total timesteps, the y-axis the average reward. The shaded area denotes the standard deviation across 3 random seeds and the solid line indicates the mean. The results are given in Figure 6. As the off-policy ratio increases, Soft Reset becomes more efficient than the baselines. This is consistent with our finding in Figure 5b,c, where we showed that the performance of Soft Reset is better when the data distribution is not changing fast. Figure 8 in Appendix D.3 shows the value of learned γt. It shows γt mostly change for the value function and not for the policy indicating that the main source of non-stationarity comes from the value function. 6 Conclusion Learning efficiently on non-stationary distributions is critical to a number of applications of deep neural networks, most prominently in reinforcement learning. In this paper, we have proposed a new method, Soft Resets, which improves the robustness of stochastic gradient descent to nonstationarities in the data-generating distribution by modeling the drift in Neural Network (NN) parameters. The proposed drift model implements soft reset mechanism where the amount of reset is controlled by the drift parameter γt. We showed that we could learn this drift parameter from the data and therefore we could learn when and how far to reset each Neural Network parameter. We incorporate the drift model in the learning algorithm which improves learning in scenarios with plasticity loss. The variant of our method which models uncertainty in the parameters achieves the best performance on plasticity benchmarks so far, highlighting the promise of the Bayesian approach. Furthermore, we found that our approach is particularly effective either on data distributions with a lot of similarity or on slowly changing distributions. Our findings open the door to a variety of exciting directions for future work, such as investigating the connection to continual learning and deepening our theoretical analysis of the proposed approach. 10References [1] Zaheer Abbas, Rosie Zhao, Joseph Modayil, Adam White, and Marlos C. Machado. Loss of plasticity in continual deep reinforcement learning, 2023. [2] Jordan T. Ash and Ryan P. Adams. On warm-starting neural network training, 2020. [3] Gianluca M. Bencomo, Jake C. Snell, and Thomas L. Griffiths. Implicit maximum a posteriori filtering via adaptive optimization, 2023. [4] Tudor Berariu, Wojciech Czarnecki, Soham De, Jorg Bornschein, Samuel Smith, Razvan Pascanu, and Claudia Clopath. A study on the plasticity of neural networks. arXiv preprint arXiv:2106.00042, 2021. [5] Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. Weight uncertainty in neural network. In Francis Bach and David Blei, editors, Proceedings of the 32nd Inter- national Conference on Machine Learning, volume 37 of Proceedings of Machine Learning Research, pages 1613–1622, Lille, France, 07–09 Jul 2015. PMLR. [6] Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and Wojciech Zaremba. Openai gym, 2016. [7] Tamara Broderick, Nicholas Boyd, Andre Wibisono, Ashia C Wilson, and Michael I Jordan. Streaming variational bayes. In C.J. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K.Q. Weinberger, editors,Advances in Neural Information Processing Systems, volume 26. Curran Associates, Inc., 2013. [8] N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University Press, Cambridge, 2006. [9] Peter G. Chang, Gerardo Durán-Martín, Alexander Y Shestopaloff, Matt Jones, and Kevin Murphy. Low-rank extended kalman filtering for online learning of neural networks from streaming data, 2023. [10] Zhiyuan Chen and Bing Liu. Lifelong machine learning. Synthesis Lectures on Artificial Intelligence and Machine Learning, 12(3):1–207, 2018. [11] Hugh Dance and Brooks Paige. Fast and scalable spike and slab variable selection in high- dimensional gaussian processes, 2022. [12] Shibhansh Dohare, J. Fernando Hernandez-Garcia, Qingfeng Lan, Parash Rahman, Ashique Ru- pam Mahmood, and Richard S. Sutton. Loss of plasticity in deep continual learning. Nature, 632:768 – 774, 2024. [13] Shibhansh Dohare, Richard S. Sutton, and A. Rupam Mahmood. Continual backprop: Stochastic gradient descent with persistent randomness, 2022. [14] Mohamed Elsayed and A. Rupam Mahmood. Addressing loss of plasticity and catastrophic forgetting in continual learning, 2024. [15] C. Daniel Freeman, Erik Frey, Anton Raichuk, Sertan Girgin, Igor Mordatch, and Olivier Bachem. Brax - a differentiable physics engine for large scale rigid body simulation, 2021. http://github.com/google/brax. [16] Xavier Glorot and Yoshua Bengio. Understanding the difficulty of training deep feedforward neural networks. In Yee Whye Teh and Mike Titterington, editors,Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, volume 9 of Proceedings of Machine Learning Research, pages 249–256, Chia Laguna Resort, Sardinia, Italy, 13–15 May 2010. PMLR. [17] A. György, T. Linder, and G. Lugosi. Efficient tracking of large classes of experts. IEEE Transactions on Information Theory, IT-58(11):6709–6725, Nov. 2012. 11[18] András György and Csaba Szepesvári. Shifting regret, mirror descent, and matrices. In Proceedings of The 33rd International Conference on Machine Learning, pages 2943–2951, 2016. [19] Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine. Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor, 2018. [20] Raia Hadsell, Dushyant Rao, Andrei A. Rusu, and Razvan Pascanu. Embracing change: Continual learning in deep neural networks. Trends in Cognitive Sciences, 24(12):1028–1040, 2020. [21] Eric Hall and Rebecca Willett. Dynamical models and tracking regret in online convex pro- gramming. In International Conference on Machine Learning, pages 579–587. PMLR, 2013. [22] E. Hazan and C. Seshadhri. Efficient learning algorithms for changing environments. In Proc. 26th Annual International Conference on Machine Learning, pages 393–400. ACM, 2009. [23] Elad Hazan. Introduction to online convex optimization, 2023. [24] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers: Surpassing human-level performance on imagenet classification, 2015. [25] M. Herbster and M. K. Warmuth. Tracking the best expert. Machine Learning, 32(2):151–178, 1998. [26] Hemant Ishwaran and J. Sunil Rao. Spike and slab variable selection: Frequentist and bayesian strategies. The Annals of Statistics, 33(2), April 2005. [27] Matt Jones, Peter Chang, and Kevin Murphy. Bayesian online natural gradient (bong), 2024. [28] Matt Jones, Tyler R. Scott, and Michael Curtis Mozer. Human-like learning in temporally structured environments. In AAAI Spring Symposia, 2024. [29] Mikhail Khodak, Maria-Florina Balcan, and Ameet Talwalkar. Adaptive gradient-based meta- learning methods, 2019. [30] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization, 2017. [31] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A. Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, and Raia Hadsell. Overcoming catas- trophic forgetting in neural networks. Proceedings of the National Academy of Sciences , 114(13):3521–3526, March 2017. [32] Alex Krizhevsky. Learning multiple layers of features from tiny images. Tech- nical report, University of Toronto, 2009. https://www.cs.toronto.edu/~kriz/ learning-features-2009-TR.pdf . [33] Aviral Kumar, Rishabh Agarwal, Dibya Ghosh, and Sergey Levine. Implicit under- parameterization inhibits data-efficient deep reinforcement learning, 2021. [34] Saurabh Kumar, Henrik Marklund, and Benjamin Van Roy. Maintaining plasticity in continual learning via regenerative regularization, 2023. [35] Richard Kurle, Botond Cseke, Alexej Klushyn, Patrick van der Smagt, and Stephan Günnemann. Continual learning with bayesian neural networks for non-stationary data. In International Conference on Learning Representations, 2020. [36] Zhiqiu Lin, Jia Shi, Deepak Pathak, and Deva Ramanan. The clear benchmark: Continual learning on real-world imagery. In Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track, 2021. [37] Clare Lyle, Mark Rowland, and Will Dabney. Understanding and preventing capacity loss in reinforcement learning, 2022. 12[38] Clare Lyle, Zeyu Zheng, Khimya Khetarpal, Hado van Hasselt, Razvan Pascanu, James Martens, and Will Dabney. Disentangling the causes of plasticity loss in neural networks, 2024. [39] Clare Lyle, Zeyu Zheng, Evgenii Nikishin, Bernardo Avila Pires, Razvan Pascanu, and Will Dabney. Understanding plasticity in neural networks, 2023. [40] V olodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, and Martin Riedmiller. Playing atari with deep reinforcement learning, 2013. [41] Cuong V . Nguyen, Yingzhen Li, Thang D. Bui, and Richard E. Turner. Variational continual learning. In International Conference on Learning Representations, 2018. [42] Evgenii Nikishin, Junhyuk Oh, Georg Ostrovski, Clare Lyle, Razvan Pascanu, Will Dabney, and André Barreto. Deep reinforcement learning with plasticity injection, 2023. [43] Evgenii Nikishin, Max Schwarzer, Pierluca D’Oro, Pierre-Luc Bacon, and Aaron Courville. The primacy bias in deep reinforcement learning, 2022. [44] Neal Parikh and Stephen Boyd. Proximal algorithms. Found. Trends Optim., 1(3):127–239, jan 2014. [45] German I. Parisi, Ronald Kemker, Jose L. Part, Christopher Kanan, and Stefan Wermter. Continual lifelong learning with neural networks: A review. Neural Networks, 113:54–71, 2019. [46] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy optimization algorithms, 2017. [47] Ghada Sokar, Rishabh Agarwal, Pablo Samuel Castro, and Utku Evci. The dormant neuron phenomenon in deep reinforcement learning. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors, Proceedings of the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pages 32145–32168. PMLR, 23–29 Jul 2023. [48] Ghada Sokar, Rishabh Agarwal, Pablo Samuel Castro, and Utku Evci. The dormant neuron phenomenon in deep reinforcement learning, 2023. [49] Michalis K. Titsias, Alexandre Galashov, Amal Rannen-Triki, Razvan Pascanu, Yee Whye Teh, and Jorg Bornschein. Kalman filter for online classification of non-stationary data, 2023. [50] G. E. Uhlenbeck and L. S. Ornstein. On the theory of the brownian motion. Phys. Rev., 36:823–841, Sep 1930. [51] Gido M van de Ven and Andreas S Tolias. Three scenarios for continual learning.arXiv preprint arXiv:1904.07734, 2019. [52] Tim van Erven, Wouter M. Koolen, and Dirk van der Hoeven. Metagrad: Adaptation using multiple learning rates in online learning. Journal of Machine Learning Research, 22(161):1–61, 2021. [53] Eli Verwimp, Rahaf Aljundi, Shai Ben-David, Matthias Bethge, Andrea Cossu, Alexander Gepperth, Tyler L. Hayes, Eyke Hüllermeier, Christopher Kanan, Dhireesha Kudithipudi, Christoph H. Lampert, Martin Mundt, Razvan Pascanu, Adrian Popescu, Andreas S. Tolias, Joost van de Weijer, Bing Liu, Vincenzo Lomonaco, Tinne Tuytelaars, and Gido M. van de Ven. Continual learning: Applications and the road forward, 2024. [54] Florian Wenzel, Kevin Roth, Bastiaan S. Veeling, Jakub ´Swi ˛ atkowski, Linh Tran, Stephan Mandt, Jasper Snoek, Tim Salimans, Rodolphe Jenatton, and Sebastian Nowozin. How good is the bayes posterior in deep neural networks really?, 2020. [55] Runtian Zhai, Stefan Schroedl, Aram Galstyan, Anoop Kumar, Greg Ver Steeg, and Pradeep Natarajan. Online continual learning for progressive distribution shift (OCL-PDS): A practi- tioner’s perspective, 2023. [56] Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In Proceedings of the Twentieth International Conference on International Conference on Machine Learning, ICML’03, page 928–935. AAAI Press, 2003. 13NeurIPS Paper Checklist 1. Claims Question: Do the main claims made in the abstract and introduction accurately reflect the paper’s contributions and scope? Answer: [Yes] Justification: We outline main contributions of the paper in the introduction and abstract. Guidelines: • The answer NA means that the abstract and introduction do not include the claims made in the paper. • The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. • The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. • It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. 2. Limitations Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We discuss limitations in the experimental section Guidelines: • The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. • The authors are encouraged to create a separate \"Limitations\" section in their paper. • The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. • The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. • The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. • The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. • If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. • While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren’t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an impor- tant role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. 3. Theory Assumptions and Proofs Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [NA] 14Justification: Guidelines: • The answer NA means that the paper does not include theoretical results. • All the theorems, formulas, and proofs in the paper should be numbered and cross- referenced. • All assumptions should be clearly stated or referenced in the statement of any theorems. • The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. • Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. • Theorems and Lemmas that the proof relies upon should be properly referenced. 4. Experimental Result Reproducibility Question: Does the paper fully disclose all the information needed to reproduce the main ex- perimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: We disclose the experimental information in Experimental and Appendix sections. Guidelines: • The answer NA means that the paper does not include experiments. • If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. • If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. • Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. • While NeurIPS does not require releasing code, the conference does require all submis- sions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. 5. Open access to data and code Question: Does the paper provide open access to the data and code, with sufficient instruc- tions to faithfully reproduce the main experimental results, as described in supplemental material? 15Answer: [No] Justification: Unfortunately, due to IP constrains, we cannot release the code for the paper. Guidelines: • The answer NA means that paper does not include experiments requiring code. • Please see the NeurIPS code and data submission guidelines ( https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details. • While we encourage the release of code and data, we understand that this might not be possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). • The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details. • The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. • The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. • At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). • Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. 6. Experimental Setting/Details Question: Does the paper specify all the training and test details (e.g., data splits, hyper- parameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: We provide experimental details in the appendix. Guidelines: • The answer NA means that the paper does not include experiments. • The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. • The full details can be provided either with the code, in appendix, or as supplemental material. 7. Experiment Statistical Significance Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: We specify that we report results with 3 random seeds with mean and standard deviation. Guidelines: • The answer NA means that the paper does not include experiments. • The authors should answer \"Yes\" if the results are accompanied by error bars, confi- dence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. • The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). • The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) • The assumptions made should be given (e.g., Normally distributed errors). 16• It should be clear whether the error bar is the standard deviation or the standard error of the mean. • It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified. • For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). • If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. 8. Experiments Compute Resources Question: For each experiment, does the paper provide sufficient information on the com- puter resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: We provide information about compute resources required in the appendix. Guidelines: • The answer NA means that the paper does not include experiments. • The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. • The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. • The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn’t make it into the paper). 9. Code Of Ethics Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: Based on our understanding, our work conforms to the every aspect of NeurIPS Code of Ethics. Guidelines: • The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. • If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. • The authors should make sure to preserve anonymity (e.g., if there is a special consid- eration due to laws or regulations in their jurisdiction). 10. Broader Impacts Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: Guidelines: • The answer NA means that there is no societal impact of the work performed. • If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. • Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. 17• The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. • The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. • If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). 11. Safeguards Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: Guidelines: • The answer NA means that the paper poses no such risks. • Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. • Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. • We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. 12. Licenses for existing assets Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: We cite the works which introduced the publicly available datasets Guidelines: • The answer NA means that the paper does not use existing assets. • The authors should cite the original paper that produced the code package or dataset. • The authors should state which version of the asset is used and, if possible, include a URL. • The name of the license (e.g., CC-BY 4.0) should be included for each asset. • For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. • If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. • For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. 18• If this information is not available online, the authors are encouraged to reach out to the asset’s creators. 13. New Assets Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: Guidelines: • The answer NA means that the paper does not release new assets. • Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. • The paper should discuss whether and how consent was obtained from people whose asset is used. • At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. 14. Crowdsourcing and Research with Human Subjects Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: Guidelines: • The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. • Including this information in the supplemental material is fine, but if the main contribu- tion of the paper involves human subjects, then as much detail as possible should be included in the main paper. • According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. 15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: Guidelines: • The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. • Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper. • We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution. • For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. 19A Ornstein-Uhlenbeck process We make use that the Ornstein-Uhlenbeck process [50] defines a SDE that can be solved explicitly and written as a time-continuous Gaussian Markov process with transition density p(xt|xs) = N(xse−(t−s), (1 − e−2(t−s))σ2 0I), for any pair of times t > s. Based on this as a drift model for the parameters θt (so θt is the state xt) we use the conditional density p(θt+1|θt) = N(θtγt, (1 − γ2 t )σ2 0I), where γt = e−δt and δt ≥ 0 corresponds to the learnable discretization time step. In other words, by learning γt online we equivalently learn the amount of a continuous “time shift” δt between two consecutive states in the OU process. This essentially models parameter drift since e.g. if γt = 1, then δt = 0 and there is no “time shift” which means that the next state/parameter remains the same as the previous one, i.e. θt+1 = θt. B Other choices of drift model In this section, we discuss alternative choices of a drift model instead of (5). Independent mean and variance of the drift. We consider the drift model where the mean and the variance are not connected, i.e., p(θt+1|θt, γt, βt) = N(θt+1; γtθt + (1 − γt)µ0; β2 t ), (20) where γt ∈ [0, 1] is the parameters controlling the mean of the distribution and βt is the learned variance. When β is fixed, this would be similar to our experiment in Figure 16 where we assumed known task boundaries and we do not estimate the drift parameters but assume it as a hyperparameter. Figure 16, left corresponds to the case when βt is a fixed parameter independent from γt whereas Figure 16, right corresponds to the case when βt = p 1 − γ2 t σ0, i.e., when we use the drift model (5). We see from the results, using drift model (5) leads to a better performance. In case when βt are learned, estimating the parameters of this model will likely overfit to the noise since there is a lot of degrees of freedom. Shrink & Perturb [2]. When we do not use the mean of the initialization, we can use the following drift model p(θt+1|θt, λt, βt) = N(θt+1; λtθt; β2 t ) Similarly to the case of (20), estimating both parameters λt and βt from the data will likely overfit to the noise. Arbitrary linear model. We can use the arbitrary linear model of the form p(θt+1|θt, At, Bt) = N(θt+1; Atθt; Bt), but estimating the parameters At and Bt has too many degrees of freedom and will certainly overfit. Gaussian Spike & Slab We consider a Gaussian [11] approximation to Spike & Slab [26] prior p(θt+1|θt, γt) = γtp(θt+1|θt) + (1− γt)p0(θt+1), which is a mixture of two distributions - a Gaussian p(θt+1|θt) = N(θt+1; θt, σ2) centered around the previous parameter θt and an initializing distribution p0(θt+1) = N(θt+1; µ0, σ2 0). This model, however, implements the mechanism of Hard reset as opposed to the soft ones. Moreover, estimating such a model and incorporating it into a learning update is more challenging since the mixture of Gaussian is not conjugate with respect to a Gaussian which will make the KL term (34) to be computed only approximately via Monte Carlo updates. C Practical implementations of the drift model estimation Stochastic approximation for drift parameters estimation In practice, we use M = 1, which leads to the stochastic approximationR p(yt+1|xt+1, µt(γk t ) + ϵσt(γk t ))N(ϵ; 0, I)dϵ ≈ p \u0000 yt+1|xt+1, µt(γk t ) + ϵσt(γk t ) \u0001 (21) 20Using NN initializing distribution. In the drift model (5), we assume that the initial distribution over parameters is given by p0(θ) = N(θ; µ0; σ2 0). In practice, we have access to the NN initializer pinit(θ) = N(θ; 0;σ2 0) where µ0 = 0 (for most of the NNs). This means that we can replace ϵ from (10) by 1 σ0 θ′ 0 where θ′ 0 ∼ pinit(θ). This means that the term in (21) can be replaced by p \u0000 yt+1|xt+1, µt(γk t ) + ϵσt(γk t ) \u0001 = p \u0010 yt+1|xt+1, µt(γk t ) + θ′ 0 q 1 − γ2 t + γ2 t σ2 t σ2 0 \u0011 , (22) where we used the fact that σ2 t (γt) = γ2 t σ2 t + (1 − γ2 t )σ2 0. Note that in (22), we only need to know the ratio σ2 σ2 0 rather than both of these. We will see that in Section 3.5, only this ratio is used for the underlying algorithm. Finally, in practice, we can tie p0(θ) to the specific initialization θ0 ∼ pinit(θ). It was observed empricially [34] that using a specific initialization in gradient updates led to better performance than using samples from the initial distribution. This would imply that p0(θ) = N(θ; θ0, ˜σ2 0), (23) with ˜σ2 0 = p2σ2 0. The parameter p ≤ 1 accounts for the fact that the distribution p0(θ) should have lower than pinit(θ) variance since it uses the specific initializaiton from the prior. This modification would imply the following modification on the drift model term (22) p \u0000 yt+1|xt+1, µt(γk t ) + ϵσt(γk t ) \u0001 = p \u0010 yt+1|xt+1, µt(γk t ) + θ′ 0p q 1 − γ2 t + γ2 t σ2 t σ2 0 \u0011 (24) D Experimental details D.1 Plasticity experiments Tasks In this section we provide experimental details. As plasticity tasks, we use a randomly selected subset of size 10000 from CIFAR-10 [32] and from MNIST. This subset is fixed for all the tasks. Within each task, we randomly permute labels for every image; we call such problems random-label classification problems. We study two regimes –data efficient, where we do 400 epochs on a task with a batch size of 128, and memorization, a regime where we do only 70 epochs with a batch size of 128. As the main backbone architecture, we use MLP with 4 hidden layers each having a hidden dimension of 256 hidden units. We use ReLU activation function and do not use any batch or layer normalization. For the incoming data, we apply random crop, for MNIST to produce images of size 24 × 24 and for CIFAR-10 to produce images of size 28 × 28. We normalize images to be within [0, 1] range by dividing by 255. On top of that, we consider permuted MNIST task with a similar training ragime as in [34] – we consider a subset of 10000 images, with batch size 16 and each task is one epoch. As a backbone, we still use MLP with ReLU activation and 4 hidden layers. Moreover, we considered permuted Patch MNIST, where we permute patches, not individual pixels. In this case, we used a simple 4 layer convolutional neural network with 2 fully connected layers at the end. Metrics We use online accuracy as first metric with results reported in Appendix H. Moreover we use per-task Average Online Accuracywhich is At = 1 N NX i=1 at i, (25) where at i are the online accuracies collected on the task t via N timesteps. Baselines First baseline is Online SGD which sequentially learns over the sequence of task, with a fixed learning rate. Hard Reset is the Online SGD which resets all the parameters at task boundaries. L2 init [34] adds a regularizer λ||θ − θ0||2 term to each Online SGD update where the regularization strength λ is a hyperparameter. Shrink & Perturb applies the transformation λθt + σϵ, ϵ∼ N(ϵ; 0, I) to each parameter before the gradient update. The hyperparameters are λ and σ. Soft Reset corresponds to one update (10) starting from 1 using 1 Monte Carlo estimate. We always use 1 Monte Carlo estimate for updating γt as we found that it worked well in practice on these tasks. The hyperparameters of the method – σ2 0 initial variance of the prior, which we set to be equal to 21p2 1 N where N is the width of the hidden layer and p is a constant (hyperparameter). It always equals to p = 0.1. On top of that the second hyperparameter is s, such that σt = sσ0, which controls the relative decrease of the constant posterior variance. This is the hyperparameter over which we sweep over. Another hyperparameter is the learning rate for learning γt. For Soft Reset Proximal, we also have a proximal coefficient regularization constant λ. Besides that, we also sweep over the learning rate for the parameter. For the Bayesian Soft Reset, we just add an additional learning rate for the variance ασ and we do 1 Monte Carlo sample for each ELBO update. Hyper parameters selection and evaluation For all the experiments, we run a sweep over the hyperparameters. We select the best hyperparameters based on the smallest cumulative error (sum of all 1 − at i throughout the training). We then report the mean and the standard deviation across 3 seeds in all the plots. Hyperparameter ranges . Learning rate α which is used to update parameters, for all the methods, is selected from{1e−4, 5e−4, 1e−3, 5e−3, 1e−2, 5e−2, 1e−1, 5e−1, 1.0}. The λinit parameter in L2 Init, is selected from{10.0, 1.0, 0.0, 1e−1, 5e−1, 1e−2, 5e−2, 1e−3, 5e−3, 1e−4, 5e−4, 1e− 5, 5e−5, 1e−6, 5e−6, 1e−7, 5e−7, 1e−8, 5e−8, 1e−9, 5e−9, 1e−10, }. For S&P, the shrink parameter λ is selected from {1.0, 0.99999, 0.9999, 0.999, 0.99, 0.9, 0.8, 0.7, 0.5, 0.3, 0.2, 0.1}, and the perturbation parameter σ is from {1e − 1, 1e − 2, 1e − 3, 1e − 4, 1e − 5, 1e − 6}. As noise distribution, we use the Neural Network initial distribution. For Soft Resets , the learning rate for γt is selected from {0.5, 0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001}, the constant s is se- lected from {1.0, 0.95, 0.9, 0.8, 0.7, 0.6, 0.5, 0.3, 0.1}, the proximal cost ˜λ in (41) is selected from {1.0, 0.1, 0.01}, the same is true for the proximal cost in the Bayesian method (38). On top of that for the Bayesian method, we always use p (see Algorithm 2) equal to p = 0.05 and s = 0.9, i.e. the posterior is always slightly smaller than the prior. Finally for the Bayesian method we had to learn the variance with learning rate from {0.01, 0.1, 1, 10} range. In practice, we found that there is one learning rate of 0.1, which was always the best in practice for most of the methods and only proximal Soft Resets on memorization CIFAR-10 required smaller learning rate 0.01. This allowed us to significantly reduce the hyperparameter sweep. D.2 Impact of non-stationarity experiments In this experiment, we consider a subset of 10000 images from MNIST (fixed throughtout all experiment) and a sequence of tasks. Each task is constructed by assigning either a true or a random label to each image from MNIST, where the probability of assignment is controlled by the experiment. The duration of each is controlled by the number of epochs with batch size of 128. As backbone we use MLP with 4 hidden layers and 256 hidden units and ReLU activation. For all the methods, the learning rate is 0.1. For Soft Resets, we use s = 0.9 and p = 1 and ηγ = 0.01. Bayesian method uses proximal cost λ = 0.01. Detailed results are given in Figure 7. D.3 Reinforcement learning experiments We conduct experiments in the RL environments. We take the canonical implementation of Soft-Actor Critic(SAC) from Brax [15] repo in github, which uses 2 layer MLPs for both policy and Q-function. It employs ReLU activation functions for both. On top of that, it uses2 MLP networks to parameterize Q-function (see Brax [15]) for more details. To employ Soft Reset, we do the following. After we have collected a chunk of data ( 128) time-steps, we do one update (10) on γt starting from 1 at every update of γt, where γt is shared for all the parameters within each layer of a Neural Network, separately for weights and biases. On top of that, since we have policy and value function networks, we have separate γt for each of these. After the update on γt, we compute θt(γt) and αt(γt), see Section 3.5. After that, we employ the proximal objective (41) with a fixed regularization target θt(γt). Concretely, we use the update rule (43) where for each update the gradient is estimate on the batch of data from the replay buffer. This is not exactly the same as what we did with plasticity benchmarks since there the update was applied to the same batch of data, multiple times. Nevertheless, we found this strategy effective and easy to implement on top of a SAC algorithm. In practice, we swept over the parameter s (similar for both, policy and the value function) which controls the relative learning rate increase in (18). Moreover, we swept over the proximal regularization constant ˜λ from eqn. (41), which was different for the policy and for the value function. In practice, we found 220 25 50 75 100 125 150 175 200 0.0 0.2 0.4 0.6 0.8 1.0 20% of random labels | 30 epochs 0 25 50 75 100 125 150 175 200 20% of random labels | 100 epochs 0 25 50 75 100 125 150 175 200 20% of random labels | 400 epochs 0 25 50 75 100 125 150 175 200 0.0 0.2 0.4 0.6 0.8 1.0 40% of random labels | 30 epochs 0 25 50 75 100 125 150 175 200 40% of random labels | 100 epochs 0 25 50 75 100 125 150 175 200 40% of random labels | 400 epochs 0 25 50 75 100 125 150 175 200 T ask id 0.0 0.2 0.4 0.6 0.8 1.0T ask accuracy 60% of random labels | 30 epochs 0 25 50 75 100 125 150 175 200 T ask id T ask accuracy 60% of random labels | 100 epochs 0 25 50 75 100 125 150 175 200 T ask id T ask accuracy 60% of random labels | 400 epochs Methods Online SGD Soft Resets Bayesian Soft Resets (K = 10, K = 10,  per parameter)  Hard Reset Methods Online SGD Soft Resets Bayesian Soft Resets (K = 10, K = 10,  per parameter)  Hard Reset Figure 7: Non-stationarity impact. The x-axis denotes task id, each column denotes the duration, whereas a row denotes the amount of label noise. Each color denotes the method studied. The y-axis denotes average over 3 seeds online accuracy. 0.0 0.2 0.4 0.6 0.8 1.0 1e6 7 8 9 1e 5+9.999e 1 Replay Ratio = 1.0,  for policy 0.0 0.2 0.4 0.6 0.8 1.0 1e6 0.2 0.4 0.6 0.8 1.0 Replay Ratio = 32.0,  for policy 0.0 0.2 0.4 0.6 0.8 1.0 1e6 0.4 0.6 0.8 1.0 Replay Ratio = 128.0,  for policy Layer # 0 : Weights Layer # 1 : Biases Layer # 1 : Weights Layer # 1 : Biases Layer # 2 : Weights 0.0 0.2 0.4 0.6 0.8 1.0 1e6 0.96 0.97 0.98 0.99 1.00 Replay Ratio = 1.0,  for Q1 0.0 0.2 0.4 0.6 0.8 1.0 1e6 0.7 0.8 0.9 1.0 Replay Ratio = 32.0,  for Q1 0.0 0.2 0.4 0.6 0.8 1.0 1e6 0.4 0.6 0.8 1.0 Replay Ratio = 128.0,  for Q1 Layer # 0 : Weights Layer # 1 : Biases Layer # 1 : Weights Layer # 1 : Biases Layer # 2 : Weights 0.0 0.2 0.4 0.6 0.8 1.0 1e6 0.96 0.97 0.98 0.99 1.00 Replay Ratio = 1.0,  for Q2 0.0 0.2 0.4 0.6 0.8 1.0 1e6 0.7 0.8 0.9 1.0 Replay Ratio = 32.0,  for Q2 0.0 0.2 0.4 0.6 0.8 1.0 1e6 0.4 0.6 0.8 1.0 Replay Ratio = 128.0,  for Q2 Layer # 0 : Weights Layer # 1 : Biases Layer # 1 : Weights Layer # 1 : Biases Layer # 2 : Weights Figure 8: Visualization of the γt dynamics for the run on Humanoid environment. Each column corresponds to the replay ratio studied. First row denotes the γt for the policy π. The second and the third rows denote the γt for the two Q-functions. that using proximal constant of 0 for the policy led to the best empirical results. The range for the proximal constants ˜λ was {0.1, 0.01, 0.001} and for s was {0.8, 0.9, 0.95, 0.97, 1.0}. We used p = 1 for all the experiments. For each experiment, we used a 3 hours of the A100 GPU with 40 Gb of memory. 23E Computational complexity We provide the study of computational cost for all the proposed methods. Notations: • P be the number of parameters in the Neural Network • L is the number of layers • O(S) is the cost of SGD backward pass. • Mγ - number of Monte Carlo samples for the drift model • Mθ - number of Monte Carlo samples for the parameter updates (Bayesian Method). • Kγ - number of updates for the drift parameter • Kθ - number of NN parameter updates. Method Comp. cost Memory SGD O(S) O(P) Soft resets γ per layer O(KγMγS + S) O(L + (Mγ + 1)P) Soft resets γ per param. O(KγMγS + S) O(P + (Mγ + 1)P) Soft resets γ per layer + proximal (Kθ iters) O(KγMγS + KθS) O(L + (Mγ + 1)P) Soft resets γ per param. + proximal (Kθ iters) O(KγMγS + KθS) O(P + (Mγ + 1)P) Bayesian Soft Reset Proximal (Kθ iters) γ per layer O(KγMγS + 2MθKθS) P(L + (Mγ + 2)P) Bayesian Soft Reset Proximal (Kθ iters) γ per param. O(KγMγS + 2MθKθS) P(P + (Mγ + 2)P) Table 1: Comparison of methods, computational cost, and memory requirements The general theoretical cost of all the proposed approaches is given in Table 1. In practice, for all the experiments, we assume that Mγ = 1 and Mθ = 1. Moreover, we used Kγ = 1 and Kθ = 1 for Soft Reset, Kγ = 10 and Kθ = 1 for Soft Reset with more computation. On top of that, for Soft Reset proximal and all Bayesian methods, we used Kγ = 10 and Kθ = 10. Table 2, quantifying the complexity of all the methods from Figure 2. Method Comp. cost Memory SGD O(S) O(P) Soft resets γ per layer O(2S) O(L + 2P) Soft resets γ per param. O(2S) O(3P) Soft resets γ per layer + proximal (Kθ = 10 iters) O(20S) O(L + 2P) Soft resets γ per param. + proximal (Kθ iters) O(20S) O(3P) Bayesian Soft Reset Proximal (Kθ iters) γ per layer O(30S) P(L + 3P) Bayesian Soft Reset Proximal (Kθ iters) γ per param. O(30S) P(4) Table 2: Comparison of methods, computational cost, and memory requirements for methods in Figure 2. The complexity O(2S) of Soft Resets comes from one update on drift parameter and one updat eon NN parameters. The memory complexity requires storing O(L) parameters gamma (one for each layer), parameters θt with O(P) and sampled parameters for drift model update which requires O(P). Note that as Figure 9 suggests, it is beneficial to spend more computational cost on optimizing gamma and on doing multiple updates on parameters. However, even the cheapest version of our method Soft Resets still leads to a good performance as indicated in Figure 2. The complexity of soft resets in reinforcement learning setting requires only one gradient update on γ after each new chunk of fresh data from the environment. In SAC, we do G gradient updates on parameters for every new chunk of data. Assuming that complexity of one gradient update in SAC is O(S), soft reset only requires doing one additional gradient update to fit γ parameter. The computation complexity of Soft Reset in Reinforcement Learning is marginally higher than SAC but leads to better empirical performance in a highly off-policy regime, see Appendix D.3. 24Soft Reset Soft Reset K = 10 Soft Reset Proximal K = 10, K = 10 Bayesian Soft Reset K = 10, K = 10 Bayesian Soft Reset K = 10, K = 10,  per parameter 0.81 0.82 0.83 0.84 0.85 0.86 0.87 Permutted MNIST Soft Reset Soft Reset K = 10 Soft Reset Proximal K = 10, K = 10 Bayesian Soft Reset K = 10, K = 10 Bayesian Soft Reset K = 10, K = 10,  per parameter 0.55 0.60 0.65 0.70 0.75 0.80 0.85 Random Label MNIST -- Data Efficient Soft Reset Soft Reset K = 10 Soft Reset Proximal K = 10, K = 10 Bayesian Soft Reset K = 10, K = 10 Bayesian Soft Reset K = 10, K = 10,  per parameter 0.80 0.85 0.90 0.95 Random Label CIFAR-10 -- memorization Figure 9: Compute-performance tradeoff. The x-axis indicates the method going from the cheapest (left) to the most expensive (right). See Table 2 for complexity analysis. The y-axis is the average performance on all the tasks across the stream. Method Comp. cost Memory SAC O(GS) O(P) Soft resets γ per layer O(S + GS) O(L + 2P) Table 3: Comparison of methods, computational cost, and memory requirements for methods in for RL. F Sensitivity analysis We study the sensitivity of Soft Resets whereγ is defined per layer when trained on random-label MNIST (data efficient). We fix the learning rate to α = 0.1. We study the sensitivity of learning rate for the drift parameter, ηγ, as well as p – initial prior standard deviation rescaling, and s – posterior standard deviation rescaling parameter. On top of that, we conduct the sensitivity analysis of L2 Init [34] and Shrink&Perturb [2] methods. The x-axis of each plot denotes one of the studied hyperparameters, whereas y-axis is the average performance across all the tasks (see Experiments section for tasks definition). The standard deviation is reported over 3 random seeds. A color indicates a second hyperparameter which is studied, if available. In the title of each plot, we write hyperparameters which are fixed. The analysis is provided in Figure 10 for Soft Resets and in Figure 11 for the baselines. The most important parameter is the learning rate of the drift model ηγ. For each method, there exists a good value of this parameter and performance is sensitive to it. This makes sense since this parameter directly impacts how we learn the drift model. The performance of Soft Resets is robust with respect to the posterior standard deviation scalings parameter as long as it is s ≥ 0.5. For s <0.5, the performance degrades. This parameter is defined from σt = sσ0 and affects relative increase in learning rate given by 1 γ2+(1−γ2)/s2) which could be ill-behaved for small s. We also study the sensitivity of the baseline methods. We find that L2 Init [34] is very sensitive to the parameter λ, which is a penalty term for λ||θ − θ0||2. In fact, Figure 11, left shows that there is only one good value of this parameter which works. Shrink&Perturb [ 2] is very sensitive to the shrink parameter λ. Similar to L2 Init, there is only one value which works, 0.9999 while values 0.999 and values 0.99999 lead to bad performance. This method however, is not very sensitive to the perturb parameter σ provided that σ ≤ 0.001. 25Compared to the baselines, our method is more robust to the hyperparameters choice. Below, we also add sensitivity analysis for other method variants. Figure 12 shows sensitivity of Soft Resets, Kγ = 10, Figure 13 shows sensitivity ofSoft Resets, Kγ = 10, Kθ = 10, Figure 14 shows sensitivity of Bayesian Soft Resets , Kγ = 10 , Kθ = 10 with γt per layer, Figure 15 shows sensitivity of Bayesian Soft Resets, Kγ = 10, Kθ = 10 with γt per parameter. 0.2 0.4 0.6 0.8 1.0 Posterior standard deviation scaling `s` 0.1 0.2 0.3 0.4 0.5 0.6Average accuracy Sensitivity Soft-Reset (MNIST). Prior standard deviation scaling p = 0.05  Learning rate 0.0001 0.0005 0.001 0.005 0.01 0.05 0.1 0.5 0.2 0.4 0.6 0.8 1.0 Posterior standard deviation scaling `s` 0.1 0.2 0.3 0.4 0.5 0.6Average accuracy Sensitivity Soft-Reset (MNIST). Drift learning rate = 0.1 Prior std scaling p 0.01 0.05 0.1 Figure 10: Soft Reset, sensitivity analysis of performance with respect to the hyperparameters on data-efficient random-label MNIST. The x-axis denotes the studied hyperparameter, whereas the y-axis denotes the average performance across the tasks. The standard deviation is computed over 3 random seeds. The color indicates additional studied hyperparameter. (Left) shows sensitivity analysis where the x-axis is the posterior standard deviation scaling s and the color indicates the drift model learning rate ηγ. (Right) shows sensitivity of Soft Reset where the x-axis is the posterior standard deviation scaling s and the color indicates initial prior standard deviation scaling p. 10 9  10 7  10 5  10 3  10 1  101 L2 term regularization cost `s` 0.0 0.2 0.4 0.6 0.8Average accuracy Sensitivity L2 Init (MNIST). Learning rate = 0.1 10 6  10 5  10 4  10 3  10 2  10 1 Perturb parameter ` ` 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45Average accuracy Sensitivity Shrink and Perturb (MNIST). Learning rate = 0.1 Shrink parameter  0.9 0.99 0.999 0.9999 0.99999 1.0 Figure 11: L2 Init and Shrink&Perturb sensitivity analysis of performance with respect to the hyperparameters on data-efficient random-label MNIST. The x-axis denotes the studied hyperparame- ter, whereas the y-axis denotes the average performance across the tasks. The standard deviation is computed over 3 random seeds. The color optionally indicates additional studied hyperparameter. (Left) shows sensitivity of L2 Init with respect to the L2 penalty regularization cost λ applied to ||θ − θ0||2 term. We do not use an additional hyperparameter, therefore there is only one color. (Right) shows sensitivity of Shrink&Perturb method where the x-axis is the perturb parameter σ while the color indicates the shrink parameter λ. G Proximal SGD Each step of online SGD can be seen in terms of a regularized minimization problem referred to as the proximal form [44]: ˆθt+1 = arg minθ Lt+1(θ) + 1 2αt ||θ − θt||2. (26) In general, we cannot solve (26) directly, so we consider a Taylor expansion of Lt+1 around θt, giving θt+1 = arg minθ ∇θLt+1(θt)⊤(θ − θt) + 1 2αt ||θt − θ||2. (27) Here we see the role of αt > 0 as both enforcing that the Taylor expansion around θt is accurate, and regularising θt+1 towards the old parameters θt (hence ensuring that the learning from past data is not forgotten). Solving (27) naturally leads to the well known SGD update: θt+1 = θt − αt∇θLt+1(θt), where αt can now also be interpreted as the learning rate. 260.2 0.4 0.6 0.8 1.0 Posterior standard deviation scaling `s` 0.1 0.2 0.3 0.4 0.5 0.6Average accuracy Sensitivity Soft-Reset, K = 10 (MNIST). Prior standard deviation scaling p = 0.05  Learning rate 0.0001 0.0005 0.001 0.005 0.01 0.05 0.1 0.5 0.2 0.4 0.6 0.8 1.0 Posterior standard deviation scaling `s` 0.1 0.2 0.3 0.4 0.5 0.6Average accuracy Sensitivity Soft-Reset K = 10 (MNIST). Drift learning rate = 0.01 Prior std scaling p 0.01 0.05 0.1 Figure 12: Soft Reset, Kγ = 10, sensitivity analysis of performance with respect to the hyperparam- eters on data-efficient random-label MNIST. The x-axis denotes the studied hyperparameter, whereas the y-axis denotes the average performance across the tasks. The standard deviation is computed over 3 random seeds. The color indicates additional studied hyperparameter. (Left) shows sensitivity analysis where the x-axis is the posterior standard deviation scaling s and the color indicates the drift model learning rate ηγ. (Right) shows sensitivity analysis where the x-axis is the posterior standard deviation scaling s and the color indicates initial prior standard deviation scaling p. 0.2 0.4 0.6 0.8 1.0 Posterior standard deviation scaling `s` 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8Average accuracy Sensitivity Soft-Reset, K = 10, K heta = 10 (MNIST). Prior standard deviation scaling p = 0.05  Learning rate 0.0001 0.0005 0.001 0.005 0.01 0.2 0.4 0.6 0.8 1.0 Posterior standard deviation scaling `s` 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8Average accuracy Sensitivity Soft-Reset, K = 10, K heta = 10 (MNIST). Drift learning rate = 0.0001 Prior std scaling p 0.01 0.05 0.1 0.5 1.0 Figure 13: Soft Reset, Kγ = 10 , Kθ = 10 , sensitivity analysis of performance with respect to the hyperparameters on data-efficient random-label MNIST. The x-axis denotes the studied hyperparameter, whereas the y-axis denotes the average performance across the tasks. The standard deviation is computed over 3 random seeds. The color indicates additional studied hyperparameter. (Left) shows sensitivity analysis where the x-axis is the posterior standard deviation scaling s and the color indicates the drift model learning rate ηγ. (Right) shows sensitivity analysis where the x-axis is the posterior standard deviation scaling s and the color indicates initial prior standard deviation scaling p. 10 3  10 2  10 1  100 Prior standard deviation scaling `p` 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8Average accuracy Sensitivity Bayesian Soft-Reset,  per layer (MNIST). KL cost = 0.01  Learning rate 0.0001 0.0005 0.001 0.005 0.01 0.1 10 3  10 2  10 1  100 KL cost,  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8Average accuracy Sensitivity Bayesian Soft-Reset,  per layer (MNIST). Initial prior rescaling p = 0.05  Learning rate 0.0001 0.0005 0.001 0.005 0.01 0.1 Figure 14: Bayesian Soft Reset, Kγ = 10, Kθ = 10 with γt per layer, sensitivity analysis of performance with respect to the hyperparameters on data-efficient random-label MNIST. The x-axis denotes the studied hyperparameter, whereas the y-axis denotes the average performance across the tasks. The standard deviation is computed over 3 random seeds. The color indicates additional studied hyperparameter. (Left) shows sensitivity analysis where the x-axis is the prior standard deviation initial scaling p and the color indicates the drift model learning rate ηγ. (Right) shows sensitivity analysis where the x-axis is the KL divergence coefficient λ while the color indicates the learning rate ηγ. 2710 3  10 2  10 1  100 Prior standard deviation scaling `p` 0.2 0.4 0.6 0.8 1.0Average accuracy Sensitivity Bayesian Soft-Reset,  per parameter (MNIST). KL cost = 0.01  Learning rate 0.0001 0.0005 0.001 0.005 0.01 10 3  10 2  10 1  100 KL cost,  0.0 0.2 0.4 0.6 0.8 1.0Average accuracy Sensitivity Bayesian Soft-Reset,  per parameter (MNIST). Initial prior rescaling p = 0.05  Learning rate 0.0001 0.0005 0.001 0.005 0.01 Figure 15: Bayesian Soft Reset, Kγ = 10, Kθ = 10 with γt per parameter, sensitivity analysis of performance with respect to the hyperparameters on data-efficient random-label MNIST. The x-axis denotes the studied hyperparameter, whereas the y-axis denotes the average performance across the tasks. The standard deviation is computed over 3 random seeds. The color indicates additional studied hyperparameter. (Left) shows sensitivity analysis where the x-axis is the prior standard deviation initial scaling p and the color indicates the drift model learning rate ηγ. (Right) shows sensitivity analysis where the x-axis is the KL divergence coefficient λ while the color indicates the learning rate ηγ. 0 50 100 150 200 T ask id 0.0 0.2 0.4 0.6 0.8Average T ask Accuracy Perfect Soft-Reset with constant l.r. 0 50 100 150 200 T ask id Average T ask Accuracy Perfect Soft-Reset with higher l.r. at switch Online SGD Hard Reset Hard Reset (only last) Soft Reset Soft Reset ( = 0.2) Soft Reset ( = 0.4) Soft Reset ( = 0.6) Soft Reset ( = 0.8) Figure 16: Perfect soft-resets on data-efficient random-label MNIST. Left, Soft Reset method does not use higher learning rate when γ <1. Right, Soft Reset increases the learning rate when γ <1, see (18). The x-axis represents task id, whereas the y-axis is the average training accuracy on the task. H Qualitative behavior of soft resets and additional results on Plasticity benchmarks H.1 Perfect Soft Resets To understand the impact of drift model (5), we study the data efficient random-label MNIST setting where task boundaries are known. We runOnline SGD, Hard Reset which resets all parameters at task boundaries, and Hard Reset (only last) which resets only the last layer. We useSoft Reset method (19) where γt = 1 all the time and becomes γt = ˆγt (with manually chosen ˆγt) at task boundaries. We consider constant learning rate αt(γt) and increasing learning rate (18) at task boundary for Soft Reset. On top of that, we run Soft Reset method unaware of task boundaries which learns γt. We report Average training task accuracy metric in Figure 16. See Appendix D.1 for details. The results suggest that with the appropriate choice of ˆγt, Soft Reset is much more efficient than Hard Reset and the effect becomes stronger if the learning rate αt(γt) increases. We also see that Soft Reset could learn an appropriate γt without the knowledge of task boundary. H.2 Qualitative Behaviour on Soft Resetson random-label tasks. We observe what values ofγt we get as we train Soft Reset method on random-label MNIST (data- efficient) and CIFAR-10 (memorization). The results are given in Figure 17 for MNIST and in Figure 18 for CIFAR-10. We report these for the first 20 tasks. 280 200000 400000 600000 Step 0.5 0.6 0.7 0.8 0.9 1.0CIFAR-10  for linear 0 200000 400000 600000 Step  for linear_1 0 200000 400000 600000 Step  for linear_2 0 200000 400000 600000 Step  for linear_3 0 200000 400000 600000 Step  for linear_4 Figure 17: Behaviour of γt for different layers on random-label MNIST (data efficient) for the first 20 tasks. 0 200000 400000 600000 Step 0.5 0.6 0.7 0.8 0.9 1.0CIFAR-10  for linear 0 200000 400000 600000 Step  for linear_1 0 200000 400000 600000 Step  for linear_2 0 200000 400000 600000 Step  for linear_3 0 200000 400000 600000 Step  for linear_4 Figure 18: Behaviour of γt for different layers on random-label CIFAR-10 (memorization) for the first 20 tasks. H.3 Qualitative Behaviour on Soft Resetson permuted patches of MNIST. We consider a version of permuted MNIST where instead of permuting all the pixels, we permute patches of pixels with a patch size varying from1 to 14. The patch size of 1 corresponds to permututed MNIST and therefore the most non-stationary case, while patch size of 14 corresponds to least non- stationary case. We use a convolutional Neural Network in this case. In Figure 19, we report the behavior of γ for different convolutional and fully connected layers on first few tasks. H.4 Bayesian method is better than non-Bayesian As discussed in Section 5, we found that in practice Soft Reset and Soft Reset Proximal where γ is learned per-parameter, did not perform well on the plasticity benchmarks. However, the Bayesian variant described in Section I.1, actually benefited from specifying γ for every parameter in Neural Network. We report these additional results in Figure 20. We see that the non Bayesian variants where γt is specified per parameter, do not perform well. The fact that the Bayesian method performs better here suggests that it is important to have a good uncertainty estimate σ2 t for the update (10) on γt. When, however, we regularize γt to be shared across all parameters within each layer, this introduces useful inductive bias which mitigates the lack of uncertainty estimation in the parameters. This is because for non-Bayesian methods, we assume that the uncertainty is fixed, given by a hyperparameter – assumption which would not always hold in practice. H.5 Qualitative behavior of soft resets In this section, we zoom-in in the data-efficient experiment on random-label MNIST. We useSoft Reset Proximal (γ per layer) method with separate γ for layer (different for each weight and for each bias) and run it for 20 tasks on random-label MNIST. In Figure 21 we show the online accuracy as we learn over this sequence of tasks. In Figure 22, we visualize the dynamics of parameters γ for each layer. First of all, we see that γt seems to accurately capture the task boundaries. Second, we see that the amount by which each γt changes depends on the parameter type – weights versus biases, and it depends on the layer. The architecture in this setting starts form linear and goes up to linear4, which represent the 4 MLP hidden layers with a last layer linear4. 0 10000 20000 30000 40000 Step 0.80 0.85 0.90 0.95 1.00  for conv2_d_1 Permuted patch size 1 2 4 7 14 0 10000 20000 30000 40000 Step 0.80 0.85 0.90 0.95 1.00  for conv2_d_2 0 10000 20000 30000 40000 Step 0.80 0.85 0.90 0.95 1.00  for conv2_d_3 0 10000 20000 30000 40000 Step 0.80 0.85 0.90 0.95 1.00  for conv2_d_4 0 10000 20000 30000 40000 Step 0.80 0.85 0.90 0.95 1.00  for linear 0 10000 20000 30000 40000 Step 0.80 0.85 0.90 0.95 1.00  for linear_1 Figure 19: Behaviour of γt for different layers on permuted MNIST 290 50 100 150 200 T ask id 0.3 0.4 0.5 0.6 0.7 0.8Average T ask Accuracy Random Label MNIST -- Data Efficient Hard Reset Soft Reset Soft Reset Proximal Soft Reset Proximal (  per parameter) Soft Reset (  per parameter) Bayesian Soft Reset Proximal Bayesian Soft Reset Proximal (  per parameter) 0 50 100 150 200 T ask id 0.4 0.6 0.8 1.0Average T ask Accuracy Random Label CIFAR-10 -- Memorization Figure 20: Performance of γ per-parameter methods 0 20000 40000 60000 80000 100000 Time-step 0.0 0.2 0.4 0.6 0.8 1.0Accuracy Figure 21: Visualization of accuracy when trained on data efficient random-label MNIST task. The dashed red lines correspond to a task boundary. 0 20000 40000 60000 80000 100000 0.00014 0.00012 0.00010 0.00008 0.00006 0.00004 0.00002 0.00000 +1  Per Layer linear b 0 20000 40000 60000 80000 100000 0.00006 0.00004 0.00002 0.00000 0.00002 0.00004 0.00006 0.00008 0.00010 +9.999e 1   Per Layer linear_1 b 0 20000 40000 60000 80000 100000 0.9992 0.9994 0.9996 0.9998 1.0000  Per Layer linear_2 b 0 20000 40000 60000 80000 100000 0.99982 0.99984 0.99986 0.99988 0.99990 0.99992 0.99994 0.99996  Per Layer linear_3 b 0 20000 40000 60000 80000 100000 4.0 4.5 5.0 5.5 6.0 1e 5+9.999e 1   Per Layer linear_4 b 0 20000 40000 60000 80000 100000 0.9970 0.9975 0.9980 0.9985 0.9990 0.9995 1.0000  Per Layer linear w 0 20000 40000 60000 80000 100000 0.9970 0.9975 0.9980 0.9985 0.9990 0.9995 1.0000  Per Layer linear_1 w 0 20000 40000 60000 80000 100000 0.9975 0.9980 0.9985 0.9990 0.9995 1.0000  Per Layer linear_2 w 0 20000 40000 60000 80000 100000 0.9965 0.9970 0.9975 0.9980 0.9985 0.9990 0.9995 1.0000  Per Layer linear_3 w 0 20000 40000 60000 80000 100000 0.9965 0.9970 0.9975 0.9980 0.9985 0.9990 0.9995 1.0000  Per Layer linear_4 w Figure 22: Visualization of γ and task boundaries on data-efficient Random-label MNIST. H.6 Impact of specific initialization In this section, we study the impact of using specific initializationθ0 ∼ pinit(θ) in p0(θ) as discussed in Appendix C. Using the specific initialization in Soft Resets leads to fixing the mean of the p0(θ) to be θ0, see (23). This, in turn, leads to the predictive distribution (24). In case when we are not using specific initialization θ0, the mean of p0(θ) is 0 and the predictive distribution is given by(22). To understand the impact of this design decision, we conduct an experiment on random label MNIST with Soft Reset, where we either use the specific initialization or not. For each of the variants, we do a hyperparameters sweep. The results are given in Figure 23. We see that both variants perform similarly. I Learning parameters with estimated drift models In this section, we provide a Bayesian Neural Network algorithm to learn the distributions of NN parameters when there is a drift in the data distribution. Moreover, we provide a MAP-like inference 300 50 100 150 200 0.3 0.4 0.5 0.6 Soft Reset -- no specific init in p0( ) Soft Reset -- with specific init in p0( ) Figure 23: Impact of specific initialization θ0 as a mean of p0(θ) in Soft Resets. The x-axis represents task id. The y-axis represents the average task accuracy with standard deviation computed over 3 random seeds. The task is random label MNIST – data efficient. algorithm which does not require to learn the distributions over parameters, but simply propagates the MAP estimate over these. I.1 Bayesian Neural Networks algorithm In this section, we describe an algorithm for parameters update based on Bayesian Neural Networks (BNN). It is based on the online variational Bayes setting described below. Let the family of distributions over parameters be Q = {q(θ) : q(θ) ∼ DY i=1 N(θi; µi, σ2 i ); θ = (θ1, . . . , θD)}, (28) which is the family of Gaussian mean-field distributions over parameters θ ∈ RD (separate Gaussian per parameter). For simplicity of notation, we omit the index i. Let Γt = ( γ1, . . . , γt) be the history of observed parameters of the drift model and St = {(x1, y1), . . . ,(xt, yt)} be the history of observed data. We denote by qt(θ) ≜ qt(θ|St, Γt−1) ∈ Qthe Gaussian approximate posterior at time t with mean µt and variance σ2 t for every parameter. The approximate predictive look-ahead prior is given by qt(θ|γt) = R qt(θt)p(θ|θt, γt)dθt = N(θ; µt(γt), σ2 t (γt)), (29) that has parameters µt(γt) = γtµt + (1 − γt)µ0, σ2 t (γt) = γ2 t σ2 t + (1 − γ2 t )σ2 0. To see this, we will use the law of total expectation and the law total variance. For two random variables X and Y defined on the same space, law of total expectation says E[Y ] = E[E[Y |X]] and the law of total variance says V[Y ] = E[V[Y |X]] + V[E[Y |X]] In our case, from the drift model (5), we have the conditional distribution θ|θt = γtθt + (1 − γt)µ0 + q (1 − γ2 t )σ2 0ϵ, ϵ∼ N(0; I) (30) From (30), we have E[θ|θt] = γtθt + (1 − γt)µ0 V[θ|θt] = (1 − γ2 t )σ2 0 From here, we have that the mean is given by E[θ] = E[E[θ|θt]] = γtµt + (1 − γt)µ0 (31) and the variance is given by V[θ] = E[V[θ|θt]] + V[E[θ|θt]] V[θ] = (1 − γ2 t )σ2 0 + γ2 t θ2 t (32) 31Now, we note that qt(θ|γt) is a Gaussian and its parameters are given by E[θ] = γtµt + (1 − γt)µ0 from (31) and by V[θ] = (1 − γ2 t )σ2 0 + γ2 t θ2 t from (32). Then, for new data (xt+1, yt+1) at time t + 1, the approximate predictive log-likelihood equals to log qt(yt+1|xt+1, γt) = log R p(yt+1|xt+1, θ)qt(θ|γt)dθ. We are looking for a new approximate posterior qt+1(θ) such that qt+1(θ) = arg min q KL[q(θ)||p(yt+1|xt+1, θ)qt(θ|γt)] (33) The optimization problem (33) can be written as minimization of the following loss Ft(θ, γt) = Eq [Lt+1(θ)] + KL[q(θ)||qt(θ|γt)] , (34) since Lt+1(θ) = −log p(yt+1|xt+1, θ). Using the fact that we are looking for a member q ∈ Q from (28), we can write the objective (34) as Ft(µ, σ, γt) = Eϵ∼N(0;I) [Lt+1(µ + ϵσ)] + KL[q(θ)||qt(θ|γt)] , where we used the reparameterisation trick for the loss term. We now expand the regularization term to get Ft(µ, σ, γt) = Eϵ∼N(0;I) [Lt+1(µ + ϵσ)] + X i \" (µi − µt,i(γt))2 + σ2 i 2σ2 t,i(γt) − 1 2 log σ2 i # (35) Since the posterior variance of NN parameters may become small, the optimization of (35) may become numerically unstable due to division by σ2 t,i(γt). It was shown [ 54] that using small temperature on the prior led to better empirical results when using Bayesian Neural Networks, a phenomenon known as cold posterior. Here, we define a temperature per-parameter, i.e., λt,i > 0 for every time-step t, such that the objective above becomes ˜Ft(µ, σ, γt; {λt,i}i) = Eϵ∼N(0;I) [Lt+1(µ + ϵσ)] + X i λt,i \" (µi − µt,i(γt))2 + σ2 i 2σ2 t,i(γt) − 1 2 log σ2 i # (36) As said above, it is common to use the same temperature λt,i = λ for all the parameters. In this work, we propose the specific choice of the temperature to be λt,i = λσ2 t,i, (37) where λ >0 is some globally chosen temperature parameter. This leads to the following objective ˆFt(µ, σ, γt; {rt, i}i) = Eϵ∼N(0;I) [Lt+1(µ + ϵσ)]+1 2 X i rt,i \u0002 (µi − µt,i(γt))2 + σ2 i − σ2 t,i(γt) logσ2 i \u0003 , (38) where the quantity rt,i is defined as rt,i = σ2 t,i σ2 t (γt) = σ2 t,i γ2 t σ2 t,i+(1−γ2 t )σ2 0 , which represents the relative change in the posterior variance due to the drift. In the exact stationary case, when γt = 1, this ratio is rt,i = 1 while for γt < 1 , since typically σ2 t < σ2 0, we have rt,i < 1. This means that in the non-stationary case, the strength of the regularization in (38) in favor of the data term Eϵ∼N(0;I) [Lt+1(µ + ϵσ)], allowing the optimization to respond faster to the change in the data distribution. In practice, this data term is approximated via Monte-Carlo, i.e. Eϵ∼N(0;I) [Lt+1(µ + ϵσ)] ∼ 1 M MX i=1 Lt+1(µ + ϵiσ) (39) To find new parameters, µt+1 and σt+1, we let µ0 t+1 = µt(γt) and σ0 t+1 = σt(γt) and perform multiple K updates on (38) µk+1 t+1 = µk t+1 − αµ ˆFt(µk t+1, σk t+1, γt, {rt, i}i), σk+1 t+1 = σk t+1 − ασ ˆFt(µk t+1, σk t+1, γt, {rt, i}i), where αµ and ασ are corresponding learning rates. The full algorithm of learning the drift parameters γt as well as learning the Bayesian Neural Network parameters using the procedure above is given in Algorithm 2. 32Algorithm 2 Bayesian Soft-Reset algorithm Input: Data-stream ST = {(xt, yt)})T t=1 Neural Network initial variance for every parameter σ2 0 coming from standard NN library NN initializer pinit(θ) Proximal cost λ ≥ 0. Initial prior variance rescaling p ∈ [0, 1]. Initial posterior variance rescaling f ∈ [0, 1]. Learning rate for the mean αµ and for the standard deviation ασ Number of gradient updates Kθ to be applied on µ and σ Number of Monte-Carlo samples Mθ for estimating µ and σ in (39) Number of gradient updates Kγ on drift parameter γt in (10) Number of Monte-Carlo samples Mγ to estimate γt in (11) Learning rate ηγ for drift parameter Initial drift parameters γ0 = 1 for every iteration. Initialization: Initialize NN parameters θ0 ∼ pinit(θ) Initialize prior distribution p0(θ) = N(θ; 0;p2σ2 0) to be used for drift model (5). Initialize posterior q0(θ) to be N(θ; θ0; σ2 init), where σ2 init = f2p2σ2 0. for step t = 0, 1, 2, . . . , Tdo Current posterior qt = N(θ; µt, σ2 t ) For (xt+1, yt+1), predict ˆyt+1 = f(xt+1|µt) with current posterior mean parameters µt Compute performance metric based on (yt+1, ˆyt+1) Estimating the drift Initialize drift parameter γ0 t = γ0. Compute µt(γt) = γtµt and σ2(γt) = γ2 t σ2 t + (1 − γ2 t )σ2 0 for k = 0, . . . , Kγ − 1 do γk+1 t = γk t ηγ∇γ log 1 Mγ PMγ i=1 p(yt+1|xt+1, µt(γk t ) + ϵiσt(γk t )) end for Updating variational posterior Let µ0 t+1 = γtµt, σ0 t+1 = p γ2 t σ2 t + (1 − γ2 t )σ2 0 Let rt,i = σ2 t,i σ2 t (γt) = σ2 t,i γ2 t σ2 t,i+(1−γ2 t )σ2 0 to be used in for k = 0, . . . , Kθ − 1 do µk+1 t+1 = µk t+1 − αµ ˆFt(µk t+1, σk t+1, γt, {rt,i}i, λ) σk+1 t+1 = σk t+1 − ασ ˆFt(µk t+1, σk t+1, γt, {rt,i}i, λ) end for end for I.2 Modified SGD with drift model Instead of propagating the posterior (6), we do MAP updates on (4) with the prior p0(θ) = N(θ; µ0; σ2 0) and the posterior qt(θ) = N(θ; θt; s2σ2 0), where s ≤ 1 is hyperparameter control- ling the variance σ2 t of the posterior qt(θ). Since fixed s may not capture the true parameters variance, using Bayesian method (see Appendix I.1) is preferred but comes at a high computational cost. Instead of Bayesian update (33), we consider maximum a-posteriori (MAP) update max θ log p(yt+1|xt+1, θ) + logqt(θ|γt), with qt(θ|γt) given by (29). Denoting Lt+1(θ) = log p(yt+1|xt+1, θ) and using the definition of qt(θ|γt), we get the following problem max θ −Lt+1(θ) − X i λt,i \" (µi − µt,i(γt))2 2σ2 t,i(γt) # , (40) where similarly to (36), we use a per-parameter temperature λt,i ≥ 0. We choose temperature to be equal to λt,i = s2σ2 0,iλ, 33Algorithm 3 Proximal Soft-Reset algoritm Input: Data-stream ST = {(xt, yt)})T t=1 Neural Network (NN) initializing distribution pinit(θ) and specific initialization θ0 ∼ pinit(θ) Learning rate αt for parameters and ηγ for drift parameters Number of gradient updates Kγ on drift parameter γt Number of gradient updates Kθ on NN parameters Proximal term cost λ ≥ 0 NN initial standard deviation (STD) scaling p ≤ 1 (see (23)) and ratio s = σt pσ0 . for step t = 0, 1, 2, . . . , Tdo For (xt+1, yt+1), predict ˆyt+1 = f(xt+1|θt) Compute performance metric based on (yt+1, ˆyt+1) Initialize drift parameter γ0 t = 1 for step k = 0, 1, 2, . . . , Kγ do Sample θ′ 0 ∼ pinit(θ) Stochastic update (21) on drift parameter using specific initialization (24) γk+1 t = γk t + ηγ∇γ h log p(yt+1|xt+1, γtθt + (1 − γt)θ0 + θ′ 0p p 1 − γ2 t + γ2 t s2) i γt=γk t end for Initialize θ0 t+1 = θt(γK t ) with (42) and use αt(γK t ) = αt \u0010 (γi t)2 + 1−(γi t)2 s2 \u0011 with (44) for step k = 0, 1, 2, . . . , Kθ do θk+1 t+1 = θk t+1 − αt(γt) ◦ ∇θGt+1(θk t+1; λ) end for end for where λ is some constant. Such choice of temperature is motivated by the same logic as in (37) – it is a constant multiplied by the posterior variance σ2 t,i = s2σ2 0,i. With such choice of temperature, maximizing (40) is equivalent to minimizing G(θ; λ) = Lt+1(θ) + λ 2 PD i=1 |θi−θi t(γt)|2 rt,i(γ) (41) where the regularization target for the dimension i is θi t(γi t) = γi tθi t + (1 − γi t)µi 0 (42) and the constant rt,i(γ) is given by rt,i(γt) = \u0010 (γi t)2 + 1−(γi t)2 s2 \u0011 We can perform K gradient updates (41) with a learning rate αt starting from θ0 t+1 = θt(γt), θk+1 t+1 = θk t+1 − αt(γt) ◦ ∇θGt+1(θk t+1; λ), (43) where the vector-valued learning rate αt(γt) is given by αt(γt) = αtrt,i(γt) = αt \u0012 (γi t)2 + 1 − (γi t)2 s2 \u0013 , (44) with αt the base learning rate. Note that doing one update is equivalent to modified SGD method(19). Doing multiple updates on (43) allows us to perform multiple computations on the same data. The corresponding algorithm is given in Algorithm 3. J Proof of linearisation Interpretation of γt. By linearising log p(yt+1|xt+1, θ) around µt, we can simplify (8) to get F(γt) = (γt ⊙ µt + (1 − γt) ⊙ µ0)T gt+1 − 0.5(σ2 t (γt) ⊙ gt+1)T gt+1 − λ PK i=1(γt,i − γ0 t,i)2, where ⊙ denotes elementwise product, gt = −∇Lt+1(µt) is the negative gradient of the loss (1) evaluated at µt and we added the ℓ2-penalty 1 2 λ(γt,i − γ0 t,i)2 to take into account the initialization. 34Proof. We assume that the following linearisation is correct log p(yt+1|xt+1, θ) ∼ log p(yt+1|xt+1, µt) + gT t+1(θ − µt), where gt+1 = −∇θ log p(yt+1|xt+1, θ= µt) = ∇θLt+1(µt) Then, we have p(yt+1|xt+1, θ) ∼ p(yt+1|xt+1, µt) expgT t+1(θ−µt) Let’s write the integral from (8) log Z p(yt+1|xt+1, θ) exp−1 2 (θ−µt(γt))T Σ−1 t (γt)(θ−µt(γt)) dθ 1p (2π)D|Σt(γt)| = log Z p(yt+1|xt+1, µt) expgT t+1(θ−µt) exp−1 2 (θ−µt(γt))T Σ−1 t (γt)(θ−µt(γt)) dθ 1p (2π)D|Σt(γt)| = log p(yt+1|xt+1, µt) + log Z expgT t+1(θ−µt) exp−1 2 (θ−µt(γt))T Σ−1 t (γt)(θ−µt(γt)) dθ 1p (2π)D|Σt(γt)| Consider only the exp term inside the integral: gT t+1(θ − µt) − 1 2(θ − µt(γt))T Σ−1 t (γt)(θ − µt(γt)) = gT t+1θ − gT t+1µt − 1 2θT Σ−1 t (γt)θ + θT Σ−1 t (γt)µt(γt) − 1 2µt(γt)T Σ−1 t (γt)µt(γt) = −1 2θT Σ−1 t θ + θT (Σ−1 t (γt)µt(γt) + gt+1) − gT t+1µt − 1 2µt(γt)T Σ−1 t (γt)µt(γt) = −1 2 \u0000 θT Σ−1 t θ − 2θT (Σ−1 t (γt)µt(γt) + gt+1) \u0001 − gT t+1µt − 1 2µt(γt)T Σ−1 t (γt)µt(γt) Let’s focus on this term −1 2 \u0000 θT Σ−1 t θ − 2θT (Σ−1 t (γt)µt(γt) + gt+1) \u0001 = −1 2 \u0000 θT Σ−1 t θ − 2θT Σ−1 t b(γt) \u0001 = −1 2 \u0000 θT Σ−1 t θ − 2θT Σ−1 t b(γt) + b(γt)T Σ−1 t b(γt) − b(γt)T Σ−1 t b(γt) \u0001 = −1 2 \u0000 θT Σ−1 t θ − 2θT Σ−1 t b(γt) + b(γt)T Σ−1 t b(γt) \u0001 + 1 2b(γt)T Σ−1 t b(γt) = −1 2(θ − b(γt))T Σ−1 t (θ − b(γt)) + 1 2b(γt)T Σ−1 t b(γt) where b(γt) = Σt(γt) \u0002 Σ−1 t (γt)µt(γt) + gt+1 \u0003 Therefore, the integral could be written as log Z expgT t+1(θ−µt) exp−1 2 (θ−µt(γt))T Σ−1 t (γt)(θ−µt(γt)) dθ 1p (2π)D|Σt(γt)| = 1 2b(γt)T Σ−1 t b(γt) + log Z exp−1 2 (θ−b(γt))T Σ−1 t (θ−b(γt)) dθ 1p (2π)D|Σt(γt)| − gT t+1µt − 1 2µt(γt)T Σ−1 t (γt)µt(γt) = 1 2b(γt)T Σ−1 t (γt)b(γt) − gT t+1µt − 1 2µt(γt)T Σ−1 t (γt)µt(γt) Now, we only keep the terms depending on γt 1 2b(γt)T Σ−1 t (γt)b(γt) − 1 2µt(γt)T Σ−1 t (γt)µt(γt) = 1 2 \u0002 Σ−1 t (γt)µt(γt) + gt+1 \u0003T Σt(γt) \u0002 Σ−1 t (γt)µt(γt) + gt+1 \u0003 − 1 2µt(γt)T Σ−1 t (γt)µt(γt) = 1 2µt(γt)T Σ−1 t (γt)µt(γt) + gT t+1µt(γt) + gT t+1 1 2Σt(γt)gt+1 − 1 2µt(γt)T Σ−1 t (γt)µt(γt) = gT t+1µt(γt) + 1 2gT t+1Σt(γt)gt+1 35Since Σt(γt) = diag(σ2 t γ2 t + (1 − γ2 t )σ2 0), we recover gT t+1(γt ⊙ µt + (1 − γt) ⊙ µ0) + 1 2gT t+1 \u0000 (σ2 t γ2 t + (1 − γ2 t )σ2 0) ⊙ gt+1 \u0001 Now, we add an l2-penalty λ 2 ||γt − γ0 t,i||2 and we get F(γt) = gT t+1(γt ⊙ µt + (1− γt) ⊙ µ0) + 1 2gT t+1 \u0000 (σ2 t γ2 t + (1 − γ2 t )σ2 0) ⊙ gt+1 \u0001 − λ 2 ||γt − γ0 t,i||2 Let’s take the gradient wrt γt, we get ∇F(γt) = gT t+1(µt − µ0) + gT t+1 \u0000 (σ2 t γt − σ2 0γt) ⊙ gt+1 \u0001 − λ(γt − γ0 t,i) = gT t+1(µt − µ0) + λγ0 t,i − γt(λ + gT t+1 \u0000 (σ2 0 − σ2 t ) ⊙ gt+1 \u0001 = 0 Then γt = gT t+1(µt − µ0) + λγ0 t,i λ + gT t+1 ((σ2 0 − σ2 t ) ⊙ gt+1) If γt is defined per parameter, this becomes γt = gt+1(µt − µ0) + λγ0 t,i λ + g2 t+1(σ2 0 − σ2 t ) K Toy illustrative example for SGD underperformance in the non-stationary regime Illustrative example of SGD on a non-stationary stream. We consider a toy problem of tracking a changing mean value. Let the observations in the stream St follow yt = µt + σϵ, where ϵ ∼ N(0, 1), σ = 0.01. Every 50 timesteps the mean µt switches from −2 to 2. We fit a 3-layer MLP with layer sizes (10, 5, 1) and ReLU activations, using SGD with two different choices for the learning rate: α = 0.05 and α = 0.15. Moreover, given that we know when a switch of the mean happens, we reset (or not reset) all the parameters at every switch as we run SGD. Only during the reset, we use different learning rate β = 0.05 or β = 0.15. Using higher learning rate during reset allows SGD to learn faster from new data. We also ran SGD with α = 0.05 and β = 0.15, where the higher learning rate is used during task switch but we do not reset the parameters. We found that it performed the same as SGD with α = 0.05, which highlights the benefit of reset. 0 50 100 150 200 250 300 Number of timesteps 2 1 0 1 2 Predicted mean   True data SGD ( = 0.05) SGD ( = 0.05) + reset ( = 0.05) SGD ( = 0.15) SGD ( = 0.05) + reset ( = 0.15) Figure 24: Non-stationary mean tracking with SGD. We report the predicted mean ˆµt for all SGD variants in Figure 24. We see that after the first switch of the mean, the SGD without reset takes more time to learn the new mean compared to the version with parameters reset. Increasing the learning rate speeds up the adaptation to new data, but it still remains slower during the mean change from 2 to −2 compared to the version that resets parameters. This example highlights that resets could be highly beneficial for improving the performance of SGD which could be slowed down by the implicit regularization towards the previous parametersθt and the impact of the regularization strength induced by the learning rate. 36L Using arbitrary drift models L.1 Using arbitrary drift models The approach described in section 3.5 provides a general strategy of incorporating arbitrary Gaussian drift models p(θ|θt; ψt) = N(θ; f(θt; ψt); g2(θt; ψt)) which induces proximal optimization problem θt+1 = arg min θ Lt+1(θ) + 1 2g(θt; ψt)||θ − f(θt; ψt)||2 (45) The choice of f(θt; ψt) and g(θt; ψt) affects the behavior of the estimate θt+1 from (45) and ulti- mately depends on the problem in hand. The objective function of the form (45) was studied in context of online convex optimization in [21],[29], where the underlying algorithms estimated the deterministic drift model online. These worked demonstrated improved regret bounds depending on model estimation errors. This approach could also be used together with a Bayesian Neural Network (BNN). 37",
      "meta_data": {
        "arxiv_id": "2411.04034v1",
        "authors": [
          "Alexandre Galashov",
          "Michalis K. Titsias",
          "András György",
          "Clare Lyle",
          "Razvan Pascanu",
          "Yee Whye Teh",
          "Maneesh Sahani"
        ],
        "published_date": "2024-11-06T16:32:40Z",
        "venue": "NeurIPS 2024",
        "pdf_url": "https://arxiv.org/pdf/2411.04034v1.pdf"
      },
      "llm_extracted_info": {
        "main_contributions": "Introduces \"Soft Resets\", a learning framework for neural networks facing non-stationary data. The approach models parameter drift with an Ornstein–Uhlenbeck (OU) process whose adaptive drift coefficient γt is learned online, enabling parameters to be softly pulled back toward their initial distribution while automatically increasing the effective learning rate. Provides two realizations (fast MAP/proximal SGD and Bayesian variational update), supplies algorithms for online estimation of γt, and demonstrates superior plasticity and performance over hard-reset and other baselines in non-stationary supervised tasks and highly off-policy reinforcement learning.",
        "methodology": "1) Drift model: per-parameter or per-layer Gaussian OU process p(θt+1|θt,γt)=N(γtθt+(1−γt)μ0,(1−γt²)σ0²) that reverts weights toward the initialization. 2) Online estimation of γt by maximizing predictive log-likelihood with reparameterization gradients; includes ℓ2 prior to keep γt≈1 when data appear stationary. 3) Parameter updates:   a) Bayesian variant – online variational Bayes with mean-field Gaussian posterior; new prior obtained by convolving current posterior with drift; minimizes KL-regularized objective, updating mean and variance.   b) Fast MAP variant – solves proximal objective G=L+λ‖θ−θ̃t(γt)‖², giving modified SGD update θt+1=θ̃t−α̃t⊙∇L, where θ̃t and learning-rate vector α̃t depend on γt. 4) Algorithms provided for one-step (Soft Reset), multi-step, and proximal versions; complexity analysis and hyper-parameter guidance included.",
        "experimental_setup": "Supervised plasticity benchmarks: • Permuted MNIST, Random-label MNIST (data-efficient, 400 epochs/task), Random-label CIFAR-10 (memorization, 70 epochs/task); fixed 10k-example subsets, MLP (4×256 ReLU). • Permuted-patch MNIST with varying patch sizes; small CNN. Metrics: online accuracy per task and average across tasks. Baselines: Online SGD, Hard Reset, L2-Init, Shrink & Perturb, Continual Backprop variants. Hyper-parameter sweeps for all methods; results averaged over 3 seeds. Reinforcement learning: Soft-Actor-Critic (Brax implementation) on Hopper-v5 and Humanoid-v4; replay ratios 1, 32, 128 to control off-policyness; Soft Reset applied separately to policy and value networks; compared to vanilla SAC and scheduled hard resets. Compute: up to 3 h on single 40 GB A100 per run; memory/compute cost analysis provided.",
        "limitations": "• Bayesian variant is 15–30× costlier than vanilla SGD; even MAP variant doubles compute. • Performance gains largest when distribution shifts are infrequent or tasks share structure; limited benefit in rapidly switching scenarios. • γ per-parameter non-Bayesian updates found unstable; method sensitive to drift-learning rate ηγ. • Assumes isotropic Gaussian priors and independence across parameters; may mis-model complex weight correlations. • Experiments cover vision toy datasets and two MuJoCo-style control tasks; generality to large-scale architectures or NLP not shown. • Implementation not open-sourced due to IP constraints, hindering reproducibility.",
        "future_research_directions": "1) Theoretical regret or convergence analysis of Soft Resets in non-convex settings. 2) Richer drift models (e.g., parameter-group OUs, mixture or low-rank structures) and meta-learning of drift hyper-parameters. 3) Scalable uncertainty estimation (e.g., low-rank or ensemble approximations) to make Bayesian variant affordable for large networks. 4) Integration with continual-learning objectives to balance plasticity and forgetting. 5) Application to large-scale, real-world non-stationary problems (online vision, language models, streaming RL). 6) Automated tuning of ηγ, s, and λ via adaptive or meta-gradient methods. 7) Investigate interplay with optimizer choices (Adam, momentum, adaptive LR) and with architectural mechanisms like dropout or batch-norm."
      }
    },
    {
      "title": "DriftSurf: Stable-State / Reactive-State Learning under Concept Drift"
    },
    {
      "title": "ImageNet-E: Benchmarking Neural Network Robustness via Attribute Editing",
      "abstract": "Recent studies have shown that higher accuracy on ImageNet usually leads to\nbetter robustness against different corruptions. Therefore, in this paper,\ninstead of following the traditional research paradigm that investigates new\nout-of-distribution corruptions or perturbations deep models may encounter, we\nconduct model debugging in in-distribution data to explore which object\nattributes a model may be sensitive to. To achieve this goal, we create a\ntoolkit for object editing with controls of backgrounds, sizes, positions, and\ndirections, and create a rigorous benchmark named ImageNet-E(diting) for\nevaluating the image classifier robustness in terms of object attributes. With\nour ImageNet-E, we evaluate the performance of current deep learning models,\nincluding both convolutional neural networks and vision transformers. We find\nthat most models are quite sensitive to attribute changes. A small change in\nthe background can lead to an average of 9.23\\% drop on top-1 accuracy. We also\nevaluate some robust models including both adversarially trained models and\nother robust trained models and find that some models show worse robustness\nagainst attribute changes than vanilla models. Based on these findings, we\ndiscover ways to enhance attribute robustness with preprocessing, architecture\ndesigns, and training strategies. We hope this work can provide some insights\nto the community and open up a new avenue for research in robust computer\nvision. The code and dataset are available at\nhttps://github.com/alibaba/easyrobust.",
      "full_text": "ImageNet-E: Benchmarking Neural Network Robustness via Attribute Editing Xiaodan Li1, Yuefeng Chen1∗, Yao Zhu2, Shuhui Wang3∗, Rong Zhang1, Hui Xue1 1Alibaba Group 2Zhejiang University 3Inst. of Comput. Tech., CAS, China {fiona.lxd, yuefeng.chenyf, stone.zhangr, hui.xueh}@alibaba-inc.com ee zhuy@zju.edu.cn, wangshuhui@ict.ac.cn Adversarial Examples ImageNet-C BackgroundSize Position & Direction ILSVRC2012_val_00005614ILSVRC2012_val_00004577 ILSVRC2012_val_00009393 ImageNet-E Figure 1. Examples of the proposed ImageNet-E dataset. In contrast to adversarial examples or datasets like ImageNet-C [21] who add perturbation or corruptions to original images, we edit the object attributes with controls of backgrounds, sizes, positions and directions. Abstract Recent studies have shown that higher accuracy on Im- ageNet usually leads to better robustness against differ- ent corruptions. Therefore, in this paper, instead of fol- lowing the traditional research paradigm that investigates new out-of-distribution corruptions or perturbations deep models may encounter, we conduct model debugging in in- distribution data to explore which object attributes a model may be sensitive to. To achieve this goal, we create a toolkit for object editing with controls of backgrounds, sizes, po- sitions, and directions, and create a rigorous benchmark named ImageNet-E(diting) for evaluating the image clas- sifier robustness in terms of object attributes. With our ImageNet-E, we evaluate the performance of current deep learning models, including both convolutional neural net- works and vision transformers. We find that most models are quite sensitive to attribute changes. A small change in the background can lead to an average of 9.23% drop ∗ Corresponding author. This research is supported in part by the National Key Research and Development Progrem of China under Grant No.2020AAA0140000. on top-1 accuracy. We also evaluate some robust models including both adversarially trained models and other ro- bust trained models and find that some models show worse robustness against attribute changes than vanilla models. Based on these findings, we discover ways to enhance at- tribute robustness with preprocessing, architecture designs, and training strategies. We hope this work can provide some insights to the community and open up a new av- enue for research in robust computer vision. The code and dataset are available at https://github.com/ alibaba/easyrobust. 1. Introduction Deep learning has triggered the rise of artificial intel- ligence and has become the workhorse of machine intel- ligence. Deep models have been widely applied in vari- ous fields such as autonomous driving [27], medical sci- ence [32], and finance [37]. With the spread of these tech- niques, the robustness and safety issues begin to be essen- tial, especially after the finding that deep models can be easily fooled by negligible noises [15]. As a result, more researchers contribute to building datasets for benchmark- arXiv:2303.17096v1  [cs.CV]  30 Mar 2023ing model robustness to spot vulnerabilities in advance. Most of the existing work builds datasets for evaluat- ing the model robustness and generalization ability on out- of-distribution data [6, 21, 29] using adversarial examples and common corruptions. For example, the ImageNet- C(orruption) dataset conducts visual corruptions such as Gaussian noise to input images to simulate the possible pro- cessors in real scenarios [21]. ImageNet-R(enditions) con- tains various renditions (e.g., paintings, embroidery) of Im- ageNet object classes [20]. As both studies have found that higher accuracy on ImageNet usually leads to better robust- ness against different domains [21,50]. However, most pre- vious studies try to achieve this in a top-down way, such as architecture design, exploring a better training strategy, etc. We advocate that it is also essential to manage it in a bottom-up way, that is, conducting model debugging with the in-distribution dataset to provide clues for model repair- ing and accuracy improvement. For example, it is interest- ing to explore whether a bird with a water background can be recognized correctly even if most birds appear with trees or grasses in the training data. Though this topic has been investigated in studies such as causal and effect analysis [8], the experiments and analysis are undertaken on domain gen- eralization datasets. How a deep model generalizes to dif- ferent backgrounds is still unknown due to the vacancy of a qualified benchmark. Therefore, in this paper, we provide a detached object editing tool to conduct the model debug- ging from the perspective of object attribute and construct a dataset named ImageNet-E(diting). The ImageNet-E dataset is a compact but challenging test set for object recognition that contains controllable ob- ject attributes including backgrounds, sizes, positions and directions, as shown in Fig. 1. In contrast to ObjectNet [5] whose images are collected by their workers via posing ob- jects according to specific instructions and differ from the target data distribution. This makes it hard to tell whether the degradation comes from the changes of attribute or dis- tribution. Our ImageNet-E is automatically generated with our object attribute editing tool based on the original Im- ageNet. Specifically, to change the object background, we provide an object background editing method that can make the background simpler or more complex based on diffusion models [24, 46]. In this way, one can easily evaluate how much the background complexity can influence the model performance. To control the object size, position, and di- rection to simulate pictures taken from different distances and angles, an object editing method is also provided. With the editing toolkit, we apply it to the large-scale ImageNet dataset [41] to construct our ImageNet-E(diting) dataset. It can serve as a general dataset for benchmarking robustness evaluation on different object attributes. With the ImageNet-E dataset, we evaluate the perfor- mance of current deep learning models, including both con- volutional neural networks (CNNs), vision transformers as well as the large-scale pretrained CLIP [39]. We find that deep models are quite sensitive to object attributes. For ex- ample, when editing the background towards high complex- ity (see Fig. 1, the 3rd row in the background part), the drop in top-1 accuracy reaches 9.23% on average. We also find that though some robust models share similar top-1 accu- racy on ImageNet, the robustness against different attributes may differ a lot. Meanwhile, some models, being robust un- der certain settings, even show worse results than the vanilla ones on our dataset. This suggests that improving robust- ness is still a challenging problem and the object attributes should be taken into account. Afterward, we discover ways to enhance robustness against object attribute changes. The main contributions are summarized as follows: • We provide an object editing toolkit that can change the object attributes for manipulated image generation. • We provide a new dataset called ImageNet-E that can be used for benchmarking robustness to different ob- ject attributes. It opens up new avenues for research in robust computer vision against object attributes. • We conduct extensive experiments on ImageNet-E and find that models that have good robustness on adversar- ial examples and common corruptions may show poor performance on our dataset. 2. Related Work The literature related to attribute robustness benchmarks can be broadly grouped into the following themes: robust- ness benchmarks and attribute editing datasets. Existing ro- bustness benchmarks such as ImageNet-C(orruption) [21], ImageNet-R(endition) [20], ImageNet-Stylized [13] and ImageNet-3DCC [29] mainly focus on the exploration of the corrupted or out-of-distribution data that models may encounter in reality. For instance, the ImageNet-R dataset contains various renditions (e.g., paintings, embroidery) of ImageNet object classes. ImageNet-C analyzes image mod- els in terms of various simulated image corruptions ( e.g., noise, blur, weather, JPEG compression, etc.). Attribute editing dataset creation is a new topic and few studies have explored it before. Among them, ObjectNet [5] and ImageNet-9 (a.k.a. background challenge) [50] can be the representative. Specifically, ObjectNet collects a large real- world test set for object recognition with controls where object backgrounds, rotations, and imaging viewpoints are random. The images in ObjectNet are collected by their workers who image objects in their homes. It consists of 313 classes which are mainly household objects. ImageNet- 9 mainly creates a suit of datasets that help disentangle the impact of foreground and background signals on classifi- cation. To achieve this goal, it uses coarse-grained classesObject Removal x!!,bgx\" x!!,obj #(x!!|x) #(x!!|x) ⨀  ')(x!|x!*+) x!! x!!*+,bg x!!*+,obj ⨀  ⨀ #(x!!\"#|x) Figure 2. Attribute editing with DDPMs. Give an input image and its corresponding object mask, the object is firstly removed with inpainting operation to get the pure background image. Then, we leverage the diffusion process to edit the background image x0 and object image coherently. ⊙ denotes the element-wise blending of these two images using the object mask. For background editing, the background complexity objective function is added during the diffusion process (Alg. 1, line 5). For other object attributes editing, the object image needs to be transformed first (Alg. 2, line 1). with corresponding rectangular bounding boxes to remove the foreground and then paste the cut area with other back- grounds. It can be observed that there lacks a dataset that can smoothly edit the object attribute. 3. Preliminaries Since the editing tool is developed based on diffusion models, let us first briefly review the theory of denoising diffusion probabilistic models (DDPM) [24,46] and analyze how it can be used to generate images. According to the definition of the Markov Chain, one can always reach a desired stationary distribution from a given distribution along with the Markov Chain [14]. To get a generative model that can generate images from ran- dom Gaussian noises, one only needs to construct a Markov Chain whose stationary distribution is Gaussian distribu- tion. This is the core idea of DDPM. In DDPM, given a data distribution x0 ∼ q(x0), a forward noising process produces a series of latents x1, ...,xT of the same dimen- sionality as the data x0 by adding Gaussian noise with vari- ance βt ∈ (0, 1) at time t: q(xt|xt−1) = N( p 1 − βtxt−1, βtI), s.t.0 < βt < 1, (1) where βt is the diffusion rate. Then the distribution q(xt|x0) at any time t is: q(xt|x0) = N(√¯αt, (1 − ¯αt)I), xt = √¯αtx0 + √ 1 − ¯αtϵ (2) where ¯αt = Qt s=1(1 − βt), ϵ ∼ N(0, I). It can be proved that limt→∞ q(xt) = N(0, I). In other words, we can map the original data distribution into a Gaussian distribu- tion with enough iterations. Such a stochastic forward pro- cess is named as diffusion process since what the process q(xt|xt−1) does is adding noise to xt−1. To draw a fresh sample from the distribution q(x0), the Markov process is reversed. That is, beginning from a Gaussian noise sample xT ∼ N(0, I), a reverse sequence is constructed by sampling the posteriors q(xt−1|xt). To approximate the unknown function q(xt−1|xt), in DDPMs, a deep model pθ is trained to predict the mean and the co- variance of xt−1 given xt instead. Then the xt−1 can be sampled from the normal distribution defined as: pθ(xt−1|xt) = N(µθ(xt, t), Σθ(xt, t)). (3) In stead of inferring µθ(xt, t) directly, [24] propose to predict the noise ϵθ(xt, t) which was added to x0 to get xt with Eq. (2). Then µθ(xt, t) is: µθ(xt, t) = 1√¯αt \u0012 xt − βt√1 − ¯αt ϵθ(xt, t) \u0013 . (4) [24] keep the value of Σθ(xt, t) to be constant. As a result, given a sample xt at time t, with a trained model that can predict the noiseϵθ(xt, t), we can getµθ(xt, t) according to Eq. (4) to reach the xt−1 with Equation (3) and eventually we can get to x0. Previous studies have shown that diffusion models can achieve superior image generation quality compared to the current state-of-the-art generative models [1]. Besides, there have been plenty of works on utilizing the DDPMs to generate samples with desired properties, such as seman- tic image translation [36], high fidelity data generation from low-density regions [44], etc. In this paper, we also choose the DDPM adopted in [1] as our generator. 4. Attribute Editing with Diffusion Models and ImageNet-E Most previous robustness-related work has focused on the important challenges of robustness on adversarial ex- amples [6], common corruptions [21]. They have found that higher clean accuracy usually leads to better robustness.Therefore, instead of exploring a new corruption that mod- els may encounter in reality, we pay attention to the model debugging in terms of object attributes, hoping to provide new insights to clean accuracy improvement. In the fol- lowing, we describe our object attribute editing tool and the generated ImageNet-E dataset in detail. The whole pipeline can be found in Fig. 2. 4.1. Object Attribute Editing with Diffusion Models Background editing. Most existing corruptions conduct manipulations on the whole image, as shown in Fig. 1. Compared to adding global corruptions that may hinder the visual quality, a more likely-to-happen way in reality is to manipulate the backgrounds to fool the model. Besides, it is shown that there exists a spurious correlation between labels and image backgrounds [12]. From this point, a background corruption benchmark is needed to evaluate the model’s robustness. However, the existing background challenge dataset achieves background editing with copy-paste opera- tion, resulting an obvious artifacts in generated images [50]. This may leave some doubts about whether the evaluation is precise since the dataset’s distribution may have changed. To alleviate this concern, we adopt DDPM approach to in- corporate background editing by adding a guiding loss that can lead to backgrounds with desired properties to make the generated images stay in/close to the original distribu- tion. Specifically, we choose to manipulate the background in terms of texture complexity due to the hypothesis that an object should be observed more easily from simple back- grounds than from complicated ones. In general, the tex- ture complexity can be evaluated with the gray-level co- occurrence matrix (GLCM) [16], which calculates the gray- level histogram to show the texture characteristic. However, the calculation of GLCM is non-differentiable, thus it can- not serve as the conditional guidance of image generation. We hypothesize that a complex image should contain more frequency components in its spectrum and higher amplitude indicates greater complexity. Thus, we define the objective of complexity as: Lc = X |A(F(x))|, (5) where F is the Fourier transform [45], A extracts the am- plitude of the input spectrum. x is the evaluated image. Since minimizing this loss helps us generate an image with desired properties and should be conducted on the x0, we need a way of estimating a clean image x0 from each noisy latent representation xt during the denoising diffusion pro- cess. Recall that the process estimates at each step the noise ϵθ(xt, t) added to x0 to obtain xt. Thus, ˆx0 can be esti- mated via Equation (6) [1]. The whole optimization proce- dure is shown in Algorithm 1. ˆx0 = xt√¯αt − √1 − ¯αtϵθ(xt, t)√¯αt . (6) As shown in Fig. 3(a), with the proposed method, when we guide the generation procedure with the proposed ob- jective towards the complex direction, it will return images with visually complex backgrounds. We also provide the GLCM dissimilarity and contrast of each image to make a quantitative analysis of the generated images. A higher dis- similarity/contrast score indicates a more complex image background [16]. It can be observed that the complexity is consistent with that calculated with GLCM, indicating the effectiveness of the proposed method. Controlling object size, position and direction.In gen- eral, the human vision system is robust to position, direc- tion and small size changes. Whether the deep models are also robust to these object attribute changes is still un- known to researchers. Therefore, we conduct the image editing with controls of object sizes, positions and direc- tions to find the answer. For a valid evaluation on differ- ent attributes, all other variables should remain unchanged, especially the background. Therefore, we first disentangle the object and background with the in-painting strategy pro- vided by [54]. Specifically, we mask the object area in in- put image x. Then we conduct in-painting to remove the object and get the pure background image xb, as shown in Fig. 3(b) column 3. To realize the aforementioned object attribute controlling, we adopt the orthogonal transforma- tion. Denote P as the pixel locations of object in image x where P ∈ R3×No. No is the number of pixels belong to object and pi = [xi, yi, 1]T is the position of object’s i-th pixel. h′ ∈ [0, H− h], w′ ∈ [0, W− w] where [x, y, w, h] stand for the enclosing rectangle of the object with mask M. Then the newly edited x[Tattribute · P] = x[P] and M[Tattribute · P] = M[P], where Tsize=   s0 ∆x 0s∆y 0 0 1  , Tposition=   1 0w′ 0 1h′ 0 0 1  , Tdirection=   cosθ sinθ 0 −sinθcosθ0 0 0 1  . (7) where s is the resize scale. θ is the rotation angle. ∆x = (1 − s) · (x + w/2), ∆y = (1 − s) · (y + h/2). With the background image xb and edited object xo, a naive way is to place the object in the original im- age to the corresponding area of background image xb as M ⊙ xo + (1 − M) ⊙ xb. However, the result generated in this manner may look disharmonic, lacking a delicate adjustment to blending them together. Besides, as shown in Fig. 3(b) column 3, the object-removing operation may leave some artifacts behind, failing to produce a coherent and seamless result. To deal with this problem, we lever- age DDPM models to blend them at different noise levels along the diffusion process. Denote the image with de- sired object attribute as xo. Starting from the pure back- ground image xb at time t0, at each stage, we perform a guided diffusion step with a latentxt to obtain the xt−1 and at the same time, obtain a noised version of object imageComplexSimpleOriginal GLCM dissimilarity GLCM contrast Original      Mask   InpaintedPaste      Ours (a) (b) Figure 3. (a) Images generated with the proposed background complexity editing method. (b) Edited images with size changing. The Fr´echet inception distance (FID) for pasting is 50.64 while it is 32.59 for ours, indicating the effectiveness of the leveraging of DDPMs. Algorithm 1:Background editing input : source image x, mask M, diffusion model (µθ(xt), Σθ(xt)), ¯αt, λ, iteration steps t0 output: edited image x0 1 xt0 ∼ N(√¯αt0 x, (1 − ¯αt0 )I); 2 for t ← t0 to 1 do 3 ˆx0 ← xt√¯αt − √1−¯αtϵθ(xt,t)√¯αt ; 4 ∇bg ← ∇ˆx0 Lc(ˆx0); 5 xb t−1 ∼ N(µθ(xt) + λΣθ(xt)∇bg, Σθ(xt)); 6 xo ∼ N(√¯αtx, (1 − ¯αt)I); 7 xt−1 ← M ⊙ xo + (1 − M) ⊙ xb t−1; 8 end xo t−1. Then the two latents are blended with the mask M as xt−1 = M ⊙ xo t−1 + (1− M) ⊙ xt−1. The DDPM denois- ing procedure may change the background. Thus a proper initial timing is required to maintain a high resemblance to the original background. We set the iteration steps t0 as 50 and 25 in Algorithm 1 and 2 respectively. 4.2. ImageNet-E dataset With the tool above, we conduct object attribute edit- ing including background, size, direction and position changes based on the large-scale ImageNet dataset [41] and ImageNet-S [11], which provides the mask annotation. To guarantee the dataset quality, we choose the animal classes from ImageNet classes such as dogs, fishes and birds, since they appear more in nature without messy backgrounds. Classes such as stove and mortarboard are removed. Fi- nally, our dataset consists of47872 images with 373 classes based on the initial 4352 images, each of which is applied 11 transforms. Detailed information can be found in Ap- pendix A. For background editing, we choose three levels of the complexity, including λ = −20, λ= 20 and λ = 20-adv with adversarial guidance (see Sec.B for details) in- stead of complexity. Larger λ indicates stronger guidance towards high complexity. For the object size, we design Algorithm 2:Object size controlling input : source image x, mask M, diffusion model (µθ(xt), Σθ(xt)), ¯αt, iteration steps t0, ratio s output: edited image x0 1 xb ← ObjectRemoving(x, M); 2 x, M← Rescale (x, M, s); 3 xt0 ∼ N(√¯αt0 xb, (1 − ¯αt0 )I); 4 for t ← t0 to 1 do 5 xb t−1 ∼ N(µθ(xt), Σθ(xt)); 6 xo ∼ N(√¯αtx, (1 − ¯αt)I); 7 xt−1 ← M ⊙ xo + (1 − M) ⊙ xb t−1; 8 end four levels of sizes in terms of the object pixel rates ( = sum(M > 0.5)/sum(M ≥ 0)): [Full, 0.1, 0.08, 0.05] where ‘Full’ indicates making the object as large as possible while maintaining its whole body inside the image. Smaller rates indicate smaller objects. For object position, we find that some objects hold a high object pixel rate in the whole image, resulting in a small H − h. Take the first picture in Fig. 3 for example, the dog is big and it will make little visual differences after position changing. Thus, we adopt the data whose pixel rate is 0.05 as the initial images for the position-changing operation. In contrast to benchmarks like ImageNet-C [21] giving images from different domains so that the model robust- ness in these situations may be assessed, our effort aims to give an editable image tool that can conduct model de- bugging with in-distribution (ID) data, in order to iden- tify specific shortcomings of different models and provide some insights for clean accuracy improving. Thus, the data distribution should not differ much from the original Im- ageNet. We choose the out-of-distribution (OOD) detec- tion methods Energy [33] and GradNorm [26] to evaluate whether our editing tool will move the edited image out of its original distribution. These OOD detection methods aim to distinguish the OOD examples from the ID exam-Figure 4. Distributions of ID score of different datasets in terms of the quantities in Energy (the first row) and GradNorm (the second row) for in-distribution (ImageNet) and other datasets. Higher overlap indicates greater proximity to ImageNet. ples. The results are shown in Fig. 4. x-axis is the ID score in terms of the quantities in Energy and GradNorm and y-axis is the frequency of each ID score. A high ID score indicates the detection method takes the input sam- ple as the ID data. Compared to other datasets, our method barely changes the data distribution under both Energy (the 1st row) and GradNorm (the 2nd row) evaluation methods. Besides, the Fr ´echet inception distance (FID) [23] for our ImageNet-E is 15.57 under the random background setting, while it is 34.99 for ImageNet-9 (background challenge). These all imply that our editing tool can ensure the prox- imity to the original ImageNet, thus can give a controlled evaluation on object attribute changes. To find out whether the DDPM will induce some degradation to our evaluation, we have conducted experiment in Tab. 1 with the setting λ = 0 during background editing. This operation will first add noises to the original and then denoise them. It can be found in “Inver” column that the degradation is negligible compared to degradation induced by attribute changes. 5. Experiments We conduct evaluation experiments on various ar- chitectures including both CNNs (ResNet (RN) [19], DenseNet [25], EfficientNet (EF) [47], ResNest [53], ConvNeXt [35]) and transformer-based models (Vision- Transformer (ViT) [9], Swin-Transformer (Swin) [34]). Other state-of-the-art models that trained with extra data such as CLIP [39], EfficientNet-L2-Noisy-Student [51] are also evaluated in the Appendix. Apart from different sizes of these models, we have also evaluated their adversarially trained versions for comprehensive studies. We report the drop of top-1 accuracy as metric based on the idea that the attribute changes should induce little influence to a robust trained model. More experimental details and results of top- 1 accuracy can be found in the Appendix. 5.1. Robustness evaluation Normally trained models.To find out whether the widely used models in computer vision have gained robustness against changes on different object attributes, we conduct extensive experiments on different models. As shown in Tab. 1, when only the background is edited towards high complexity, the average drop in top-1 accuracy is 9.23% (λ = 20). This indicates that most models are sensi- tive to object background changes. Other attribute changes such as size and position can also lead to model perfor- mance degradation. For example, when changing the object pixel rate to 0.05, as shown in Fig. 1 row4 in the ‘size’ col- umn, while we can still recognize the image correctly, the performance drop is 18.34% on average. We also find that the robustness under different object attributes is improved along with improvements in terms of clean accuracy (Orig- inal) on different models. Accordingly, a switch from an RN50 (92.69% top-1 accuracy) to a Swin-S (96.21%) leads to the drop in accuracy decrease from 15.72% to 10.20% on average. By this measure, models have become more and more capable of generalizing to different backgrounds, which implies that they indeed learn some robust features. This shows that object attribute robustness can be a good way to measure future progress in representation learning. We also observe that larger networks possess better ro- bustness on the attribute editing. For example, swapping a Swin-S (96.21% top-1 accuracy) with the larger Swin- B (95.96% top-1 accuracy) leads to the decrease of the dropped accuracy from 10.20% to 8.99% when λ = 20 . In a similar fashion, a ConvNeXt-T (9.32% drop) is less robust than the giant ConvNeXt-B (7.26%). Consequently, models with even more depth, width, and feature aggrega- tion may attain further attribute robustness. Previous stud- ies [30] have shown that zero-shot CLIP exhibits better out- of-distribution robustness than the finetuned CLIP, which is opposite to our ImageNet-E as shown in Tab. 1. This may serve as the evidence that our ImageNet-E has a good prox- imity to ImageNet. We also find that compared with fully-supervised trained model under the same backbone (ViT- B), the CLIP fails to show a better attribute robustness. We think this may be caused by that the CLIP has spared some capacity for OOD robustness. HF All Original HF All Original Figure 5. Comparisons between vanilla models and adversari- ally trained models across different architectures in terms of size changes (left). Evaluation of adversarial models (RN50) trained with different perturbation budgets is provided in the right figure. Adversarially trained models. Adversarial training [42] is one of the state-of-the-art methods for improving the ad- versarial robustness of deep models and has been widely studied [2]. To find out whether they can boost the attribute robustness, we conduct extensive experiments in terms of different architectures and perturbation budgets (constraints of l2 norm bound). As shown in Fig. 5, the adversarially trained ones are not robust against attribute changes includ- ing both backgrounds and size-changing situations. The dropped accuracies are much greater compared to normally trained models. As the perturbation budget grows, the sit- uation gets worse. This indicates that adversarial training can do harm to robustness against attributes. 5.2. Robustness enhancements Based on the above evaluations, we step further to dis- cover ways to enhance the attribute robustness in terms of preprocessing, network design and training strategies. More details including training setting and numerical experimen- tal results can be found in Appendix C.5. Preprocessing. Given that an object can be inconspicuous due to its small size or subtle position, viewing an object at several different locations may lead to a more stable predic- tion. Having this intuition in mind, we perform the classical Ten-Crop strategy to find out if this operation can help to get a robustness boost. The Ten-Crop operation is executed by cropping all four corners and the center of the input im- age. We average the predictions of these crops together with their horizontal mirrors as the final result. We find this oper- ation can contribute a 0.69% and 1.24% performance boost on top-1 accuracy in both background and size changes sce- narios on average respectively. Network designs. Intuitively, a robust model should tend to focus more on the object of interest instead of the back- ground. Therefore, recent models begin to enhance the model by employing attention modules. Of these, the ResNest [53] can be a representative. The ResNest is a modularized architecture, which applies channel-wise at- tention on different network branches to leverage their suc- cess in capturing cross-feature interactions and learning di- verse representations. As it has achieved a great boost in the ImageNet dataset, it also shows superiority on ImageNet-E compared to ResNet. For example, a switch from RN50 decreases the average dropped accuracy from 15.72% to 12.57%. This indicates that the channel-wise attention mod- ule can be a good choice to improve the attribute robustness. Another representative model can be the vision transformer, which consists of multiple self-attention modules. To study whether incorporating transformer’s self-attention-like ar- chitecture into the model design can help attribute robust- ness generalization, we establish a hybrid architecture by directly feeding the output of res 3 block in RN50 into ViT- S as the input feature like [3]. The dropped accuracy de- creases by 1.04% compared to the original RN50, indicating the effectiveness of the self-attention-like architectures. Training strategy. a) Robust trained. There have been plenty of studies focusing on the robust training strategy to improve model robustness. To find out whether these works can boost the robustness on our dataset, we further evaluate these state-of-the-art models including SIN [13], Debiased- CNN [31], Augmix [22], ANT [40], DeepAugment [20] and model trained with lots of standard augmentations (RN50- T) [48]. As shown in Tab. 2, apart from the RN50-T, while the Augmix model shows the best performance against the background change scenario, the Debiased model holds the best in the object size change scenario. What we find unex- pectedly is the SIN performance. The SIN method features the novel data augmentation scheme where ImageNet im- ages are stylized with style transfer as the training data to force the model to rely less on textural cues for classifica- tion. Though the robustness boost is achieved on ImageNet- C (mCE 69.32%) compared to its vanilla model (mCE 76.7%), it fails to improve the robustness in both object background and size-changing scenarios. The drops of top- 1 accuracy for vanilla RN50 and RN50-SIN are 21.26% and 24.23% respectively, when the object size rate is 0.05, though they share similar accuracy on original ImageNet. This indicates that existing benchmarks cannot reflect the real robustness in object attribute changing. Therefore, a dataset like ImageNet-E is necessary for comprehensive evaluations on deep models. b) Masked image modeling. Considering that masked image modeling has demonstrated impressive results in self-supervised representation learn- ing by recovering corrupted image patches [4], it may be robust to the attribute changes. Therefore, we choose the Masked AutoEncoder (MAE) [17] as the training strat- egy since its objective is recovering images with only 25% patches. Specifically, we adopt the MAE training strategy with ViT-B backbone and then finetune it with ImageNetTable 1. Evaluations with different state-of-the-art models in terms of Top-1 accuracy and the corresponding drop of accuracy under background changes, size changes, random position (rp) and random direction (rd). Models Original Background changes Size changes PositionDirection Avg.Inver λ=−20 λ= 20 λ= 20-adv Random Full 0.1 0.08 0.05 rp rd RN50 92.69% 1.97% 7.30% 13.35% 29.92% 13.34% 2.71% 7.25% 10.51% 21.26% 26.46% 25.12% 15.72% DenseNet12192.10% 1.49% 6.29% 9.00% 29.20% 12.43% 3.50% 7.00% 10.68% 21.55% 26.53% 23.64% 14.98% EF-B0 92.85% 1.07% 7.10% 10.71% 34.88% 15.64% 3.03% 8.00% 11.57% 23.28% 27.91% 19.11% 16.12% ResNest50 95.38% 1.44% 6.33% 8.98% 26.62% 11.28% 2.53% 5.27% 8.01% 18.03% 21.37% 17.32% 12.57% ViT-S 94.14% 0.82% 6.42% 8.98% 31.12% 13.06% 0.80% 5.37% 8.59% 17.37% 22.86% 17.13% 13.17% Swin-S 96.21% 1.13% 5.18% 7.33% 23.50% 9.31% 1.27% 4.21% 6.29% 14.16% 17.35% 13.42% 10.20% ConvNeXt-T96.07% 1.43% 4.69% 6.26% 19.83% 7.93% 1.75% 3.28% 5.18% 12.76%15.71% 15.78% 9.32% RN101 94.00% 2.11% 7.05% 11.62% 29.47% 13.57% 2.57% 6.81% 10.12% 20.65% 25.85% 24.42% 15.21% DenseNet16992.37% 1.12% 5.81% 8.43% 27.51% 11.61% 2.25% 6.90% 10.41% 20.59% 24.93% 20.68% 13.91% EF-B3 94.97% 1.87% 7.77% 8.40% 29.90% 12.92% 1.36% 6.80% 10.16% 21.36% 24.98% 17.24% 14.09% ResNest101 95.54% 1.10% 5.58% 6.65% 23.03% 10.40% 1.35% 3.97% 6.53% 15.44% 19.11% 14.31% 10.64% ViT-B 95.38% 0.83% 5.32% 8.43% 26.60% 10.98% 0.62% 4.00% 6.30% 14.51% 18.82% 14.95% 11.05% Swin-B 95.96% 0.79% 4.46% 6.23% 21.44% 8.25% 0.99% 3.16% 5.04% 12.34% 15.38% 12.60% 8.99% ConvNeXt-B96.42%0.69% 3.75% 4.86% 16.49% 6.04% 0.99% 2.25% 3.36% 9.47% 12.40% 13.01% 7.26% CLIP-zeroshot80.01% 4.88% 11.56% 15.28% 36.14% 20.09% 3.33% 12.67% 15.77% 25.31%28.87% 21.57% 19.06% CLIP-finetuned93.68% 2.17% 9.82% 11.83% 38.33% 18.19% 9.06% 9.25% 12.67% 23.32% 28.56% 22.00% 18.30% Table 2. Evaluations with different robust models in terms of Top-1 accuracy and the corresponding dropped accuracy. Architectures Ori Background changes Size changes PositionDirection Avg.Inver λ=−20 λ= 20 λ= 20-adv Random Full 0.1 0.08 0.05 rp rd RN50 92.69% 1.97% 7.30% 13.35% 29.92% 13.34% 2.71% 7.25% 10.51% 21.26%26.46% 25.12% 15.72% RN50-Adversarial81.96%0.66% 4.75% 13.62% 37.87% 15.25% 4.87% 9.62% 13.94% 25.51%32.51% 31.96% 18.99% RN50-SIN 91.57% 2.23% 7.61% 12.19% 33.16% 13.58% 1.68% 8.30% 12.60% 24.23%29.16% 27.24% 16.98% RN50-Debiased93.34% 1.43% 6.09% 11.45% 27.99% 12.12% 1.98% 5.53% 8.76% 19.27% 24.01% 24.97% 14.22% RN50-Augmix 93.50% 0.98% 6.26% 8.38% 30.49% 12.94% 1.61% 6.40% 9.97% 21.42% 27.14% 22.42% 14.70% RN50-ANT 91.87% 1.68% 6.62% 11.94% 35.66% 15.36% 1.57% 7.12% 10.62% 21.49%26.66% 25.23% 16.23% RN50-DeepAugment92.88% 1.50% 6.62% 12.37% 32.40% 13.32% 1.36% 7.27% 10.62% 21.28%26.28% 21.29% 15.28% RN50-T 94.55%1.05% 5.65% 7.38% 21.89% 10.42% 2.11% 4.74% 7.83% 17.46%21.12% 19.60% 11.82% training data. We find that the robustness is improved. For example, the dropped accuracy decreases from 10.62% to 9.05% on average compared to vanilla ViT-B. 5.3. Failure case analysis To explore the reason why some robust trained mod- els may fail, we leverage the LayerCAM [28] to generate the heat map for different models including vanilla RN50, RN50+SIN and RN50+Debiased for comprehensive stud- ies. As shown in Fig. 6, the heat map of the Debiased model aligns better with the objects in the image than that of the original model. It is interesting to find that the SIN model sometimes makes wrong predictions even with its attention on the main object. We suspect that the SIN model relies too much on the shape. for example, the ‘sea urchin’ looks like the ‘acron’ with the shadow. However, its texture clearly in- dicates that it is the ‘sea urchin’. In contrast, the Debiased model which is trained to focus on both the shape and tex- ture can recognize it correctly. More studies can be found in Appendix C.4. 5.4. Model repairing To validate that the evaluation on ImageNet (IN)-E can help to provide some insights for model’s applicability and enhancement, we conduct a toy example for model repair- SINEdited DebiasedVanillaOriginal Figure 6. Heat maps for explaining which parts of the image dom- inate the model decision through LayerCAM [28]. ing. Previous evaluation shows that the ResNet50 is vul- nerable to background changes. Based on this observation, we randomly replace the backgrounds of objects with oth- ers during training and get a validation accuracy boost from 77.48% to 79.00%. Note that the promotion is not small as only 8781 training images with mask annotations are avail- able in ImageNet. We also step further to find out if the improved model can get a boost the OOD robustness, as shown in the Tab. 3. It can be observed that with the in- sights provided by the evaluation on ImageNet-E, one can explore the model’s attribute vulnerabilities and manage torepair the model and get a performance boost accordingly. Table 3. Model repairing results. Top-1 accuracy (%) is reported except for IN-C, which is mCE (mean Corruption Error). Higher top-1 accuracy and lower mCE indicate better performance. IN-E reports the average accuracy on ImageNet-E. Models IN IN-v2 IN-A IN-C↓ IN-R IN-Sketch IN-E RN50 77.5 65.7 6.5 68.6 39.6 27.5 83.7 RN50-repaired79.0 67.2 9.4 65.8 40.7 29.4 85.0 6. Conclusion and Future work In this paper, we put forward an image editing toolkit that can take control of object attributes smoothly. With this tool, we create a new dataset called ImageNet-E that can serve as a general dataset for benchmarking robust- ness against different object attributes. Extensive evalua- tions conducted on different state-of-the-art models show that most models are vulnerable to attribute changes, es- pecially the adversarially trained ones. Meanwhile, other robust trained models can show worse results than vanilla models even when they have achieved a great robustness boost on other robustness benchmarks. We further discover ways for robustness enhancement from both preprocessing, network designing and training strategies. Limitations and future work.This paper proposes to edit the object attributes in terms of backgrounds, sizes, posi- tions and directions. Therefore, the annotated mask of the interest object is required, resulting in a limitation of our method. Besides, since our editing toolkit is developed based on diffusion models, the generalization ability is de- termined by DDPMs. For example, we find synthesizing high-quality person images is difficult for DDPMs. Un- der the consideration of both the annotated mask and data quality, our ImageNet-E is a compact test set. In our future work, we would like to explore how to leverage the edited data to enhance the model’s performance, including both the validation accuracy and robustness.References [1] Omri Avrahami, Dani Lischinski, and Ohad Fried. Blended diffusion for text-driven editing of natural images. In Pro- ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 18208–18218, 2022. 3, 4 [2] Tao Bai, Jinqi Luo, Jun Zhao, Bihan Wen, and Qian Wang. Recent advances in adversarial training for adversarial ro- bustness. arXiv preprint arXiv:2102.01356, 2021. 7 [3] Yutong Bai, Jieru Mei, Alan L Yuille, and Cihang Xie. Are transformers more robust than cnns? Advances in Neural Information Processing Systems, 34:26831–26843, 2021. 7, 16 [4] Hangbo Bao, Li Dong, and Furu Wei. Beit: Bert pre-training of image transformers. Proceedings of the International Conference on Learning Representations (ICLR) , 2022. 7, 16 [5] Andrei Barbu, David Mayo, Julian Alverio, William Luo, Christopher Wang, Dan Gutfreund, Josh Tenenbaum, and Boris Katz. Objectnet: A large-scale bias-controlled dataset for pushing the limits of object recognition models. Ad- vances in neural information processing systems , 32, 2019. 2 [6] Nicholas Carlini and David Wagner. Adversarial examples are not easily detected: Bypassing ten detection methods. In Proceedings of the 10th ACM workshop on artificial intelli- gence and security, pages 3–14, 2017. 2, 3 [7] Xinlei Chen, Saining Xie, and Kaiming He. An empiri- cal study of training self-supervised vision transformers. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 9640–9649, 2021. 16 [8] Peng Cui and Susan Athey. Stable learning establishes some common ground between causal inference and ma- chine learning. Nature Machine Intelligence, 4(2):110–115, 2022. 2 [9] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl- vain Gelly, et al. An image is worth 16x16 words: Trans- formers for image recognition at scale. arXiv preprint arXiv:2010.11929, 2020. 6 [10] Noam Eshed. Novelty detection and analysis in convolu- tional neural networks. Master’s thesis, Cornell University, 2020. 13 [11] Shanghua Gao, Zhong-Yu Li, Ming-Hsuan Yang, Ming- Ming Cheng, Junwei Han, and Philip Torr. Large-scale unsu- pervised semantic segmentation. IEEE Transactions on Pat- tern Analysis and Machine Intelligence , pages 1–20, 2022. 5, 13 [12] Robert Geirhos, J ¨orn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, and Fe- lix A Wichmann. Shortcut learning in deep neural networks. Nature Machine Intelligence, 2(11):665–673, 2020. 4 [13] Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix A Wichmann, and Wieland Brendel. Imagenet-trained cnns are biased towards texture; increasing shape bias improves accuracy and robustness.arXiv preprint arXiv:1811.12231, 2018. 2, 7, 19 [14] Charles J Geyer. Practical markov chain monte carlo. Statis- tical science, pages 473–483, 1992. 3 [15] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572, 2014. 1 [16] Robert M Haralick, Karthikeyan Shanmugam, and Its’ Hak Dinstein. Textural features for image classification. IEEE Transactions on systems, man, and cybernetics , 11(6):610– 621, 1973. 4 [17] Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll´ar, and Ross Girshick. Masked autoencoders are scalable vision learners. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16000– 16009, 2022. 7 [18] Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll´ar, and Ross Girshick. Masked autoencoders are scalable vision learners. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16000– 16009, 2022. 16 [19] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceed- ings of the IEEE conference on computer vision and pattern recognition, pages 770–778, 2016. 6 [20] Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kada- vath, Frank Wang, Evan Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, et al. The many faces of robust- ness: A critical analysis of out-of-distribution generalization. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 8340–8349, 2021. 2, 7, 20 [21] Dan Hendrycks and Thomas Dietterich. Benchmarking neu- ral network robustness to common corruptions and perturba- tions. Proceedings of the International Conference on Learn- ing Representations, 2019. 1, 2, 3, 5 [22] Dan Hendrycks, Norman Mu, Ekin D. Cubuk, Barret Zoph, Justin Gilmer, and Balaji Lakshminarayanan. AugMix: A simple data processing method to improve robustness and uncertainty. Proceedings of the International Conference on Learning Representations (ICLR), 2020. 7, 20 [23] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilib- rium. Advances in neural information processing systems , 30, 2017. 6 [24] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffu- sion probabilistic models. Advances in Neural Information Processing Systems, 33:6840–6851, 2020. 2, 3 [25] Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kil- ian Q Weinberger. Densely connected convolutional net- works. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 4700–4708, 2017. 6 [26] Rui Huang, Andrew Geng, and Yixuan Li. On the impor- tance of gradients for detecting distributional shifts in the wild. Advances in Neural Information Processing Systems , 34:677–689, 2021. 5, 17 [27] Xiaowei Huang, Daniel Kroening, Wenjie Ruan, James Sharp, Youcheng Sun, Emese Thamo, Min Wu, and Xinping Yi. A survey of safety and trustworthiness of deep neural net- works: Verification, testing, adversarial attack and defence,and interpretability. Computer Science Review, 37:100270, 2020. 1 [28] Peng-Tao Jiang, Chang-Bin Zhang, Qibin Hou, Ming-Ming Cheng, and Yunchao Wei. Layercam: Exploring hierarchical class activation maps for localization. IEEE Transactions on Image Processing, 30:5875–5888, 2021. 8 [29] Oguzhan Fatih Kar, Teresa Yeo, and Amir Zamir. 3d com- mon corruptions for object recognition. In ICML 2022 Shift Happens Workshop, 2022. 2 [30] Ananya Kumar, Aditi Raghunathan, Robbie Jones, Tengyu Ma, and Percy Liang. Fine-tuning can distort pretrained fea- tures and underperform out-of-distribution. arXiv preprint arXiv:2202.10054, 2022. 6, 18 [31] Yingwei Li, Qihang Yu, Mingxing Tan, Jieru Mei, Peng Tang, Wei Shen, Alan Yuille, and Cihang Xie. Shape- texture debiased neural network training. arXiv preprint arXiv:2010.05981, 2020. 7, 20 [32] Geert Litjens, Thijs Kooi, Babak Ehteshami Bejnordi, Ar- naud Arindra Adiyoso Setio, Francesco Ciompi, Mohsen Ghafoorian, Jeroen Awm Van Der Laak, Bram Van Gin- neken, and Clara I S ´anchez. A survey on deep learning in medical image analysis. Medical image analysis, 42:60–88, 2017. 1 [33] Weitang Liu, Xiaoyun Wang, John Owens, and Yixuan Li. Energy-based out-of-distribution detection. Advances in Neural Information Processing Systems , 33:21464–21475, 2020. 5, 17 [34] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo. Swin transformer: Hierarchical vision transformer using shifted windows. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 10012–10022, 2021. 6 [35] Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feicht- enhofer, Trevor Darrell, and Saining Xie. A convnet for the 2020s. Proceedings of the IEEE/CVF Conference on Com- puter Vision and Pattern Recognition (CVPR), 2022. 6 [36] Chenlin Meng, Yutong He, Yang Song, Jiaming Song, Jia- jun Wu, Jun-Yan Zhu, and Stefano Ermon. Sdedit: Guided image synthesis and editing with stochastic differential equa- tions. In International Conference on Learning Representa- tions, 2021. 3 [37] Ahmet Murat Ozbayoglu, Mehmet Ugur Gudelek, and Omer Berat Sezer. Deep learning for financial applications: A survey. Applied Soft Computing, 93:106384, 2020. 1 [38] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An im- perative style, high-performance deep learning library. Ad- vances in neural information processing systems , 32, 2019. 16 [39] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learn- ing transferable visual models from natural language super- vision. In International Conference on Machine Learning , pages 8748–8763. PMLR, 2021. 2, 6, 18 [40] Evgenia Rusak, Lukas Schott, Roland S Zimmermann, Ju- lian Bitterwolf, Oliver Bringmann, Matthias Bethge, and Wieland Brendel. A simple way to make neural networks robust against diverse image corruptions. In European Con- ference on Computer Vision, pages 53–69. Springer, 2020. 7, 20 [41] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, San- jeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. Imagenet large scale visual recognition challenge. International journal of computer vision, 115(3):211–252, 2015. 2, 5 [42] Hadi Salman, Andrew Ilyas, Logan Engstrom, Ashish Kapoor, and Aleksander Madry. Do adversarially robust im- agenet models transfer better? Advances in Neural Informa- tion Processing Systems, 33:3533–3545, 2020. 7, 19 [43] Steffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bring- mann, Wieland Brendel, and Matthias Bethge. Improving robustness against common corruptions by covariate shift adaptation. Advances in Neural Information Processing Sys- tems, 33:11539–11551, 2020. 17 [44] Vikash Sehwag, Caner Hazirbas, Albert Gordo, Firat Oz- genel, and Cristian Canton. Generating high fidelity data from low-density regions using diffusion models. In Pro- ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11492–11501, 2022. 3 [45] Ian Naismith Sneddon. Fourier transforms. Courier Corpo- ration, 1995. 4 [46] Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsupervised learning using nonequilibrium thermodynamics. In International Confer- ence on Machine Learning, pages 2256–2265. PMLR, 2015. 2, 3 [47] Mingxing Tan and Quoc Le. Efficientnet: Rethinking model scaling for convolutional neural networks. In International conference on machine learning, pages 6105–6114. PMLR, 2019. 6 [48] Ross Wightman, Hugo Touvron, and Herv ´e J ´egou. Resnet strikes back: An improved training procedure in timm.arXiv preprint arXiv:2110.00476, 2021. 7 [49] Mitchell Wortsman, Gabriel Ilharco, Jong Wook Kim, Mike Li, Simon Kornblith, Rebecca Roelofs, Raphael Gon- tijo Lopes, Hannaneh Hajishirzi, Ali Farhadi, Hongseok Namkoong, et al. Robust fine-tuning of zero-shot models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7959–7971, 2022. 18 [50] Kai Xiao, Logan Engstrom, Andrew Ilyas, and Aleksander Madry. Noise or signal: The role of image backgrounds in object recognition. Proceedings of the International Confer- ence on Learning Representations, 2021. 2, 4 [51] Qizhe Xie, Minh-Thang Luong, Eduard Hovy, and Quoc V Le. Self-training with noisy student improves imagenet classification. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 10687– 10698, 2020. 6, 18 [52] Zhenda Xie, Zheng Zhang, Yue Cao, Yutong Lin, Jianmin Bao, Zhuliang Yao, Qi Dai, and Han Hu. Simmim: A simple framework for masked image modeling. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 9653–9663, 2022. 16[53] Hang Zhang, Chongruo Wu, Zhongyue Zhang, Yi Zhu, Haibin Lin, Zhi Zhang, Yue Sun, Tong He, Jonas Mueller, R Manmatha, et al. Resnest: Split-attention networks. In Proceedings of the IEEE/CVF Conference on Computer Vi- sion and Pattern Recognition , pages 2736–2746, 2022. 6, 7 [54] Chuanxia Zheng, Tat-Jen Cham, Jianfei Cai, and Dinh Phung. Bridging global context interactions for high-fidelity image completion. In Proceedings of the IEEE/CVF Confer- ence on Computer Vision and Pattern Recognition (CVPR) , pages 11512–11522, June 2022. 4 [55] Yao Zhu, Yuefeng Chen, Xiaodan Li, Kejiang Chen, Yuan He, Xiang Tian, Bolun Zheng, Yaowu Chen, and Qing- ming Huang. Toward understanding and boosting adversarial transferability from a distribution perspective. IEEE Trans- actions on Image Processing, 31:6487–6501, 2022. 17A. Details for ImageNet-E To guarantee the visual quality of the generated exam- ples, we choose the animal classes from ImageNet since they appear more in nature without messy backgrounds. Specifically, images whose coarse labels in [fish, shark, bird, salamander, frog, turtle, lizard, crocodile, dinosaur, snake, trilobite, arachnid, ungulate, monotreme, marsu- pial, coral, mollusk, crustacean, marine mammals, dog, wild dog, cat, wild cat, bear, mongoose, butterfly, echin- oderms, rabbit, rodent, hog, ferret, armadillo,primate] are picked. The corresponding coarse labels of each class we refer to can be found in [10] 1. Finally, our ImageNet-E consists of 373 classes. Since the number of masks pro- vided in ImageNet-S [11] in these classes is 4352, thus the number of images in each edited kind is 4352. The ImageNet-E contains 11 kinds of attributes editing, includ- ing 5 kinds of background editing and 4 kinds of size edit- ing, as well as one kind of position editing and one kind of direction editing. Finally, our ImageNet-E contains 47872 images. Experiments on more images can be found in sec- tion C.3. The comprehensive comparisons with the state- of-the-art robustness benchmarks are shown in Figure 7. In contrast to other benchmarks that investigate new out-of- distribution corruptions or perturbations deep models may encounter, w conduct model debugging with in-distribution data to explore which object attributes a model may be sen- sitive to. The examples in ImageNet-E are shown in Fig- ure 9. A demo video for our editing toolkit can be found at this url: https://drive.google.com/file/d/ 1h5EV3MHPGgkBww9grhlvrl--kSIrD5Lp/view? usp=sharing . Our code can be found at an anony- mous url: https://huggingface.co/spaces/ Anonymous-123/ImageNet-Editing. BenchmarksDescriptionClassesSamples ImageNet-A Challenging examples collected by-hand200 ImageNet-C Corruptions added on images1000 ImageNet-R Various renditions of ImageNet object classes200 ImageNet-3DCC3D common corruptions1000 ImageNet-9 Images whose objects and backgrounds are disentangledwith bbox370 ImageNet-E Images with attribute-edited objects373 Figure 7. Benchmark comparison. 1https://github.com/noameshed/novelty- detection/blob/master/imagenet categories synset.csv HF All Original HF All Original Figure 8. Comparisons between the amplitude supervision on high-frequency components (HF) and amplitude supervision on all frequency components (All). B. Background editing Intuitively, an image with complicated background tends to contain more high-frequency components, such as edges. Therefore, a straight-forward way is to define the back- ground complexity as the amplitude of high-frequency com- ponents. However, this operation can result in noisy back- grounds, instead of the ones with complicated textures. Therefore, we directly define complexity as the amplitude of all frequency components. The compared results are shown in Figure 8. It can be observed that the amplitude su- pervision on high-frequency components tends to make the model generate images with more noise. In contrast, am- plitude supervision on all frequency components can help to generate images with texture-complex backgrounds. To edit the background adversarially, we setLc = CE(f(x), y) where ‘CE’ is the cross entropy loss. f and y are the clas- sifier and label of x respectively. We adopt the classifier f from guided-diffusion2. C. Experimental details C.1. Details for metrics In this paper, we care more about how different attributes impact different models. Therefore, we choose the drop of top-1 accuracy as our evaluation metric. A lower dropped accuracy indicates higher robustness against our attribute 2https://github.com/openai/guided-diffusionFigure 9. Samples from ImageNet-E. From left to right, top to bottom, the images stand for background editing with λ = −20, λ = 20, λ = 20-adv, randomly shuffled backgrounds, size editing with rate 0.1 and 0.05, randomly rotate, random position, randomly rotate based on images with object pixel rate 0.05 respectively.Object Removal x!!,bgx\" x!!,obj #(x!!|x) #(x!!|x) ⨀  ')(x!|x!*+) x!! x!!*+,bg x!!*+,obj ⨀  ⨀ #(x!!\"#|x) Figure 10. Attribute editing with DDPMs. Give an input image and its corresponding object mask, the object is firstly removed with inpainting operation to get the pure background image. Then, we leverage the diffusion process to edit the background image x0 and object image coherently. ⊙ denotes the element-wise blending of these two images using the object mask. For background editing, the background complexity objective function is added during the diffusion process (Alg. 1, line 5). For other object attributes editing, the object image needs to be transformed first (Alg. 2, line 1). changes. The dropped accuracy is defined as: DA = accoriginal − acc. (8) The detailed top-1 accuracy (Top-1) and dropped accu- racy (DA)on our ImageNet-E are listed in Table 4, Table 5 and Table 6, Table 7. All the experiments are conducted for 5 runs and we report the mean value in the tables. C.2. Classes whose accuracy drops the greatest To find out which class gets the worst robustness against attribute changes, we plot the dropped accuracy in Fig- ure 11. The evaluated models are vanilla RN50 and its Debiased model. It can be observed that objects that have tentacles with simple backgrounds are more easily to be at- tacked. For example, the dropped accuracy of the ‘black widow’ class reaches 47% for both vanilla and Debiased models. In contrast, the impact is smaller for images with complicated backgrounds such as pictures from ‘squirrel monkey’. C.3. Experiments on more data To explore the model robustness against object attributes on large-scale datasets, we step further to conduct the im- age editing on all the images in the ImageNet-S validation set. Finally, the edited dataset ImageNet-E-L shares the same size as ImageNet-S, which consists of 919 classes and 10919 images. We conduct both background edit- ing and size editing to them. The evaluation results are shown in Table 8. The same conclusion can also be ob- served. For instance, most models show vulnerability against attribute changing since the average dropped accu- racies reach 12.22% and 22.21% in background and size changes respectively. When the model gets larger, the ro- bustness is improved. The consistency implies that using our ImageNet-E can already reflect the model robustness against object attribute changes. C.4. Bad case analysis To make a comprehensive study of how the model be- haves, we step further to make a comparison of the heat maps of the originals and edited ones. We choose the images that are recognized correctly at first but misclassi- fied after editing. All the attributes editing including back- ground, size, directions are explored. The heat maps are visualized in Figure 12. It can be observed that compared to the SIN and Debiased models, the vanilla RN50 is more likely to lose its focus on the interest area, especially in the size change scenario. For example, in the second row, as it puts his focus on the background, it returns a result with the ‘nail’ label. The same fashion is also observed in the background change scenario. The predicted label of ‘night snake’ turns into ‘spider web’ as the complex background has attracted its attention. In contrast, the SIN and Debi- ased models have robust attention mechanisms. The quan- titative results in Table 5 also validate this. The dropped accuracy of RN50 (13.35%) is higher than SIN (12.19%) and Debiased (11.45%) even though the original accuracy of SIN (0.9157) is lower than vanilla RN50 (0.9269). How- ever, the SIN also has its weakness. We find that though the SIN pays attention to the desired region, it can also make wrong predictions. As shown in the second row of Fig- ure 12, when the object size gets smaller, the shape-based SIN model tends to make wrong predictions,e.g., mistaking the ‘sea urchin’ as ’acorn’ due to the lack of texture anal- ysis. As a result, the dropped accuracy in the size change scenario is 24.23% for SIN, even lower than vanilla RN50, whose dropped accuracy is 21.26%. On the contrary, the Debiased model can recognize it correctly, profiting from its shape and texture-biased module. From the above obser- vation, we can conclude that the texture matters in the small object scenario.Table 4. Evaluations under different backgrounds. Models Ori Inver λ = −20 λ = 20 λ = 20-Adv Random Top-1 Top-1 DA Top-1 DA Top-1 DA Top-1 DA Top-1 DA RN50 92.69% 90.72% 1.97% 85.39% 7.30% 79.34% 13.35% 62.77% 29.92% 79.35% 13.34% DenseNet121 92.10% 90.61% 1.49% 85.81% 6.29% 83.10% 9.00% 62.90% 29.20% 79.67% 12.43% EF-B0 92.85% 91.78% 1.07% 85.75% 7.10% 82.14% 10.71% 57.97% 34.88% 77.21% 15.64% ResNest50 95.38% 93.94% 1.44% 89.05% 6.33% 86.40% 8.98% 68.76% 26.62% 84.10% 11.28% ViT-S 94.14% 93.32% 0.82% 87.72% 6.42% 85.16% 8.98% 63.02% 31.12% 81.08% 13.06% Swin-S 96.21% 95.08% 1.13% 91.03% 5.18% 88.88% 7.33% 72.71% 23.50% 86.90% 9.31% ConvNeXt-T 96.07% 94.64% 1.43% 91.38% 4.69% 89.81% 6.26% 76.24% 19.83% 88.14% 7.93% RN101 94.00% 91.89% 2.11% 86.95% 7.05% 82.38% 11.62% 64.53% 29.47% 80.43% 13.57% DenseNet169 92.37% 91.25% 1.12% 86.56% 5.81% 83.94% 8.43% 64.86% 27.51% 80.76% 11.61% EF-B3 94.97% 93.10% 1.87% 87.20% 7.77% 86.57% 8.40% 65.07% 29.90% 82.05% 12.92% ResNest101 95.54% 94.44% 1.10% 89.96% 5.58% 88.89% 6.65% 72.51% 23.03% 85.14% 10.40% ViT-B 95.38% 94.55% 0.83% 90.06% 5.32% 86.95% 8.43% 68.78% 26.60% 84.40% 10.98% Swin-B 95.96% 95.17% 0.79% 91.50% 4.46% 89.73% 6.23% 74.52% 21.44% 87.71% 8.25% ConvNeXt-B 96.42% 95.73% 0.69% 92.67% 3.75% 91.56% 4.86% 79.93% 16.49% 90.38% 6.04% Table 5. Evaluations with different robust models under different backgrounds. Models Ori Inver λ = −20 λ = 20 λ = 20-Adv Random Top-1 Top-1 DA Top-1 DA Top-1 DA Top-1 DA Top-1 DA RN50 92.69% 90.72% 1.97% 85.39% 7.30% 79.34% 13.35% 62.77% 29.92% 79.35% 13.34% RN50-A 81.96% 81.30% 0.66% 77.21% 4.75% 68.34% 13.62% 44.09% 37.87% 66.71% 15.25% RN50-SIN 91.57% 89.34% 2.23% 83.96% 7.61% 79.38% 12.19% 58.41% 33.16% 77.99% 13.58% RN50-debiasd 93.34% 91.91% 1.43% 87.25% 6.09% 81.89% 11.45% 65.35% 27.99% 81.22% 12.12% RN50-Augmix 93.50% 92.52% 0.98% 87.24% 6.26% 85.12% 8.38% 63.01% 30.49% 80.56% 12.94% RN50-ANT 91.87% 90.19% 1.68% 85.25% 6.62% 79.93% 11.94% 56.21% 35.66% 76.51% 15.36% RN50-DeepAugment 92.88% 91.38% 1.50% 86.26% 6.62% 80.51% 12.37% 60.48% 32.40% 79.56% 13.32% RN50-T 94.55% 93.50% 1.05% 88.90% 5.65% 87.17% 7.38% 72.66% 21.89% 84.13% 10.42% C.5. Details for robustness enhancements Network design—-self-attention-like architecture. The results in Table 1 show that most vision transformers show better robustness than CNNs in our scenario. Previous study has shown that the self-attention-like architecture may be the key to robustness boost [3]. Therefore, to ablate whether incorporating this module can help attribute robustness generalization, we create a hybrid architec- ture (RN50d-hybrid) by directly feeding the output of res 3 block in RN50d into ViT-S as the input feature. The results are shown in Table 9. As we can find that while the added module maintains the robustness on background changes, it can help to boost the robustness against size changes. Moreover, the RN50-hybrid can also boost the overall performance compared to ViT-S. Training strategy—-Masked image modeling. Con- sidering that masked image modeling has demonstrated im- pressive results in self-supervised representation learning by recovering corrupted image patches [4], it may be robust to the attribute changes. Thus, we test the Masked AutoEn- coder (MAE) [18] and SimMIM [52] training strategy based on ViT-B backbone. As shown in Table 10, the dropped ac- curacies decrease a lot compared to vanilla ViT-B, validat- ing the effectiveness of the masked image modeling strat- egy. Motivated by this success, we also test another kind of self-supervised-learning strategy. To be specific, we choose the representative method MoCo-V3 [7] in the contrastive learning family. After the end-to-end finetuning, it achieves top-1 83.0% accuracy on ImageNet. It can also improve the attribute robustness when compared to the vanilla ViT-B, showing the effectiveness of contrastive learning. C.6. Hardware Our experiments are implemented by PyTorch [38] and runs on RTX-3090TI. D. Further exploration on backgrounds Motivated by the models’ vulnerability against back- ground changes, especially for those complicated back- grounds. Apart from randomly picking the backgrounds from the ImageNet dataset as final backgrounds (ran- dom bg), we also collect background templates with abun- dant textures, including leopard, eight diagrams, checker and stripe to explore the performance on out-of-distributionTable 6. Evaluations under different object sizes. Models Ori Full 0.10 0.08 0.05 0.05-rp rd Top-1 Top-1 DA Top-1 DA Top-1 DA Top-1 DA Top-1 DA Top-1 DA RN50 92.69% 89.98% 2.71% 85.44% 7.25% 82.18% 10.51% 71.43% 21.26% 66.23% 26.46% 67.57% 25.12% DenseNet121 92.10% 88.60% 3.50% 85.10% 7.00% 81.42% 10.68% 70.55% 21.55% 65.57% 26.53% 68.46% 23.64% EF-B0 92.85% 89.82% 3.03% 84.85% 8.00% 81.28% 11.57% 69.57% 23.28% 64.94% 27.91% 73.74% 19.11% ResNest50 95.38% 92.85% 2.53% 90.11% 5.27% 87.37% 8.01% 77.35% 18.03% 74.01% 21.37% 78.06% 17.32% ViT-S 94.14% 93.34% 0.80% 88.77% 5.37% 85.55% 8.59% 76.77% 17.37% 71.28% 22.86% 77.01% 17.13% Swin-S 96.21% 94.94% 1.27% 92.00% 4.21% 89.92% 6.29% 82.05% 14.16% 78.86% 17.35% 82.79% 13.42% ConvNeXt-T 96.07% 94.32% 1.75% 92.79% 3.28% 90.89% 5.18% 83.31% 12.76% 80.36% 15.71% 80.29% 15.78% RN101 94.00% 91.43% 2.57% 87.19% 6.81% 83.88% 10.12% 73.35% 20.65% 68.15% 25.85% 69.58% 24.42% DenseNet169 92.37% 90.12% 2.25% 85.47% 6.90% 81.96% 10.41% 71.78% 20.59% 67.44% 24.93% 71.69% 20.68% EF-B3 94.97% 93.61% 1.36% 88.17% 6.80% 84.81% 10.16% 73.61% 21.36% 69.99% 24.98% 77.73% 17.24% ResNest101 95.54% 94.19% 1.35% 91.57% 3.97% 89.01% 6.53% 80.10% 15.44% 76.43% 19.11% 81.23% 14.31% ViT-B 95.38% 94.76% 0.62% 91.38% 4.00% 89.08% 6.30% 80.87% 14.51% 76.56% 18.82% 80.43% 14.95% Swin-B 95.96% 94.97% 0.99% 92.80% 3.16% 90.92% 5.04% 83.62% 12.34% 80.58% 15.38% 83.36% 12.60% ConvNeXt-B 96.42% 95.43% 0.99% 94.17% 2.25% 93.06% 3.36% 86.95% 9.47% 84.02% 12.40% 83.41% 13.01% Table 7. Evaluations with different robust models under different object sizes. Models Ori Full 0.10 0.08 0.05 0.05-rp rd Top-1 Top-1 DA Top-1 DA Top-1 DA Top-1 DA Top-1 DA Top-1 DA RN50 92.69% 89.98% 2.71% 85.44% 7.25% 82.18% 10.51% 71.43% 21.26% 66.23% 26.46% 67.57% 25.12% RN50-A 81.96% 77.09% 4.87% 72.34% 9.62% 68.02% 13.94% 56.45% 25.51% 49.45% 32.51% 50.00% 31.96% RN50-SIN 91.57% 89.89% 1.68% 83.27% 8.30% 78.97% 12.60% 67.34% 24.23% 62.41% 29.16% 64.33% 27.24% RN50-debiasd 93.34% 91.36% 1.98% 87.81% 5.53% 84.58% 8.76% 74.07% 19.27% 69.33% 24.01% 68.37% 24.97% RN50-Augmix 93.50% 91.89% 1.61% 87.10% 6.40% 83.53% 9.97% 72.08% 21.42% 66.36% 27.14% 71.08% 22.42% RN50-ANT 91.87% 90.30% 1.57% 84.75% 7.12% 81.25% 10.62% 70.38% 21.49% 65.21% 26.66% 66.64% 25.23% RN50-DeepAugment92.88% 91.52% 1.36% 85.61% 7.27% 82.26% 10.62% 71.60% 21.28% 66.60% 26.28% 71.59% 21.29% RN50-T 94.55% 92.44% 2.11% 89.81% 4.74% 86.72% 7.83% 77.09% 17.46% 73.43% 21.12% 74.95% 19.60% backgrounds. The evaluation results are shown in Table 12. It can be observed that the background changes can lead to a 13.34% accuracy drop. When the background is set to be a leopard or other images, the dropped accuracy can even reach 35.52%. Sometimes the robust models even show worse robustness. For example, when the background is eight diagrams, all the robust models show worse results than the vanilla RN50, which is quite unexpected. To com- prehend the behaviour behind it, we visualize the heat maps of the different models in Figure 7. An interesting find- ing is that deep models tend to make decisions with depen- dency on the backgrounds, especially when the background is complicated and can attract some attention. For example, when the background is the eight diagrams, the SIN takes the goldfish as a dishwasher. We suspect it has mistaken the background as dishes. In the same fashion, the Debiased model and ANT take the ‘sea slug’ with eight diagrams as a ‘shopping basket’, which seems to make sense since the ‘sea slug’ looks like a vegetable. E. Further discussion on the distribution In this paper, our effort aims to give an editable image tool that can edit the object’s attribute in the given image while maintaining it in the original distri- bution for model debugging. Thus, we choose the out- of-distribution (OOD) detection methods including En- ergy [33] and GradNorm [26] following DRA [55] as the evaluation methods to find out whether our editing tool will move the edited image out of its original distribution. In contrast to FID which indicates the divergence of two datasets, the OOD detection is used to indicate the extent of the deviance of a single input image from the in-distribution dataset. Covariate shift adaptation( a.k.a batch-norm adaptation, BNA) is a way for improving robustness against common corruptions [43]. Thus, it can help to get a top-1 accuracy performance boost in OOD data. One can easily find out if the provided dataset is OOD by checking whether the BNA can get a performance boost on its data. We have tested the full adaptation results using BNA on ResNet50. In con- trast to the promotion on other out-of-distribution dataset, we find that this operation induces little changes to top-1 ac- curacy on both ImageNet validation set (0.7615 → 0.7613) and our ImageNet-E ( 0.7934 → 0.7933 under λ = 20 , 0.6521 → 0.6514 under random position scenario, mean accuracy of 5 runs). This similar tendency implies that our ImageNet-E shares a similar property with ImageNet.Vanilla Debiased Figure 11. Dropped accuracy (%) in each class. Classes whose number of images is less than 15 or dropped accuracy is zero are removed. Table 8. Evaluations with more data. Models Original Background Size-0.05 Models Original Background Size-0.05 Top-1 Top-1 DA Top-1 DA Top-1 Top-1 DA Top-1 DA DenseNet121 86.60% 74.73% 11.87% 61.48% 25.12% DenseNet169 87.66% 76.26% 11.40% 63.57% 24.09% RN50 88.12% 71.64% 16.48% 63.13% 24.99% RN101 89.52% 75.33% 14.19% 65.11% 24.41% EF-B0 88.54% 75.64% 12.90% 62.16% 26.38% EF-B3 92.12% 80.81% 11.31% 66.18% 25.96% ResNest50 92.12% 80.61% 11.51% 70.05% 22.07% ResNest101 92.78% 83.46% 9.32% 72.67% 20.11% ViT-S 92.15% 78.94% 13.21% 69.30% 22.85% ViT-B 94.12% 83.04% 11.08% 75.65% 18.47% Swin-S 93.11% 82.98% 10.13% 75.36% 17.75% Swin-B 93.18% 84.11% 9.07% 76.99% 16.19% ConvNeXt-T 92.75% 84.00% 9.43% 76.41% 16.34% ConvNeXt-B 94.05% 86.41% 7.64% 80.34% 13.71% F. Further evaluation on more state-of-the-art models To provide evaluations on more state-of-the-art models, we step further to evaluate the CLIP [39] and EfficientNet- L2-Noisy-Student [51]. The average dropped accuracy in terms of different models can be found in Figure 13. CLIP shows a good robustness to out-of-distribution data [30]. Therefore, to find out whether the CLIP can also show a good robustness against attribute editing, we evaluate the CLIP model (Backbone ViT-B) with both the zero-shot and end-to-end finetuned version. To achieve this, we fine- tune the pretrained CLIP on the ImageNet training dataset based on prompt-initialized model following [49]. It ac- quires a 81.2% top-1 accuracy on ImageNet validation set while it is 68.3% for zero-shot version. The evaluation on ImageNet-E is shown in Table 11 and Table 13. Though previous studies have shown that the zero-shot CLIP model exhibits better out-of-distribution robustness than the fine- tuned ones, the finetuned CLIP shows better attribute ro- bustness on ImageNet-E, as shown in Table 11 and Ta- ble 13. The tendency on ImageNet-E is the same with Im- ageNet (IN) validation set and ImageNet-V2 (IN-V2). This implies that the ImageNet-E shows a better proximity to Im- ageNet than other out-of-distribution benchmarks such as ImageNet-C (IN-C), ImageNet-A (IN-A). Another finding is that the CLIP model fails to show better robustness than ViT-B while they share the same architectures. We suspect that this is caused by that CLIP may have spared some ca- pacity for out-of-distribution robustness. As the network gets larger, its attribute robustness gets better. While EfficientNet-L2-Noisy-Student is one of the top models on ImageNet-A benchmark [51], it also shows su- periority on ImageNet-E. To delve into the reason behind this, we test EfficientNet-L2-Noisy-Student-475 (EF-L2- NT-475) and EfficientNet-B0-Noisy-Student (EF-B0-NT). The EF-L2-NT-475 differs from EF-L2-NT in terms of in- put size, which former is 475 while it is 800 for the latter. It can be found that the input size can induce little improve- ment to the attribute robustness. In contrast, larger networks can benefit a lot to attribute robustness, which is consistent with the finding in Section 5.1. Evaluations on 91 state-of-the-art models can be found in Figure 14. All the evaluated models in this figure are allOriginal Size Original Background Original Direction SINDebiasedVanilla SINDebiasedVanilla SINDebiasedVanilla Figure 12. The heat map comparisons between original images and edited ones. Table 9. Ablation study of the self-attention-like architecture. Models Ori Background changes Size changes Position Direction Avg.Inver λ=−20 λ= 20 λ= 20-Adv Random Full 0.1 0.08 0.05 rp rd R50d 93.77% 1.23% 4.80% 6.48% 19.39% 8.28% 2.82% 4.36% 7.07% 16.95% 20.49% 19.31% 11.00% ViT-S 94.74% 1.66% 7.32% 10.64% 32.17% 14.39% 1.22% 7.10% 10.64% 20.29% 25.08% 17.22% 14.61% R50-hybrid95.40% 1.04% 5.64% 7.16% 21.54% 9.19% 1.37% 3.53% 5.92% 13.92%17.23% 14.12% 9.96% 65 70 75 80 85 90 Top-1 Accuracy on ImageNet(%) 0 5 10 15 20 25Average Dropped Accuracy on ImageNet-E(%) RN50 RN101 Deit-S Deit-B Swin-S Swin-B ConvNeXt-T ConvNeXt-B CLIP_B/16_zeroshot CLIP_B/16_FT CLIP_L/14@336_zeroshot CLIP_L/14@336_FT EF-B3 EF-B7 EF-B7-NT EF-L2-NT ResNet Deit Swin ConvNeXt CLIP-zeroshot CLIP-finetune EfficientNet Figure 13. The average accuracy drop of different models. The x-axis is the model’s top-1 accuracy on ImageNet. provided by the timm library, except for the MoCo-V3-FT and CLIP-FT, which are finetuned by us. G. Failure cases of generated images The failure cases of generated images are shown in Fig- ure 16. The diffusion model fails to generate high-quality person images. Though the object is reserved, the whole im- age looks quite wired. Therefore, we only keep the animal classes, resulting a compact set of ImageNet-E. However, extensive evaluations to 919 in Section C.3 have witnessed a same conclusion with evaluations on 373 classes. This implies that using our ImageNet-E can already reflect the model robustness against object attribute changes. H. Related literature to robustness enhance- ments Adversarial training. [42] focus on adversarially ro- bust ImageNet classifiers and show that they yield improved accuracy on a standard suite of downstream classification tasks. It provides a strong baseline for adversarial training. Therefore, we choose their officially released adversarially trained models3 as the evaluation model. Models with dif- ferent architectures are adopted here4. SIN [13] provides evidence that machine recognition to- day overly relies on object textures rather than global object shapes, as commonly assumed. It demonstrates the advan- tages of a shape-based representation for robust inference 3https://github.com/microsoft/robust-models-transfer 4https://github.com/alibaba/easyrobustTable 10. Ablation study of the self-supervised models. All the compared models are end-to-end finetuned on ImageNet except for ViT-B, which is supervised trained from the early start. Models Ori Background changes Size changes PositionDirection Avg.Inver λ=−20 λ= 20 λ= 20-Adv Random Full 0.1 0.08 0.05 rp rd ViT-B 95.38% 0.83% 5.32% 8.43% 26.60% 10.98% 0.62% 4.00% 6.30% 14.51% 18.82% 14.95% 11.05% CLIPfinetune 93.68% 2.17% 9.82% 11.83% 38.33% 18.19% 9.06% 9.25% 12.67% 23.32% 28.56% 22.00% 18.30% MoCo-v3 95.70% 0.55% 4.91% 7.33% 24.33% 9.92% 0.92% 3.76% 5.62% 13.61% 17.85% 15.20% 10.35% MAE-ViT-B96.12% 0.78% 4.77% 6.21% 21.09% 8.18% 0.78% 3.01% 4.86% 12.10%15.47% 14.00% 9.05% SimMIM 96.14% 0.75% 5.13% 6.76% 23.58% 9.33% 0.97% 3.22% 5.33% 13.18% 17.12% 13.62% 9.82% Standard supervised CNNsSupervised ViTsSelf-Supervised ViTsData-rich models Figure 14. The top-1 accuracy performance under different editing scenarios of 91 state-of-the-art models. Table 11. Evaluations on different robustness benchmarks. All results are top-1 accuracies(%) on corresponding datasets except for ImageNet-C, which is mCE (mean Corruption Error). Higher top-1 accuracy and lower mCE indicate better performance. Models IN IN-V2 IN-A IN-C IN-R IN-SketchIN-E CLIP-zero-shot68.3 61.9 50.1 43.1 77.6 48.3 62.1 CLIP-FT 81.2 70.7 35.3 47..9 65.0 44.9 77.2 (using their Stylized-ImageNet dataset to induce such a rep- resentation in neural networks) Debiased [31] shows that convolutional neural networks are often biased towards either texture or shape, depend- ing on the training dataset, and such bias degenerates model performance. Motivated by this observation, it develops a simple algorithm for shape-texture Debiased learning. To prevent models from exclusively attending to a single cue in representation learning, it augments training data with images with conflicting shape and texture information (e.g., an image of chimpanzee shape but with lemon texture) and provides the corresponding supervision from shape and tex- ture simultaneously. It empirically demonstrates the advan- tages of the shape-texture Debiased neural network training on boosting both accuracy and robustness. Augmix [22] focuses on the robustness improvement to unforeseen data shifts encountered during deployment. It proposes a data processing technique named Augmix that helps to improve robustness and uncertainty measures on challenging image classification benchmarks. ANT [40] demonstrates that a simple but properly tuned training with additive Gaussian and Speckle noise general- izes surprisingly well to unseen corruptions, easily reaching the previous state of the art on the corruption benchmark ImageNet-C and on MNIST-C. DeepAugment [20]. Motivated by the observation that using larger models and artificial data augmentations can improve robustness on real-world distribution shifts, con- trary to claims in prior work. It introduces a new data augmentation method named DeepAugment, which uses image-to-image neural networks for data augmentation. It improves robustness on their newly introduced ImageNet-R benchmark and can also be combined with other augmen- tation methods to outperform a model pretrained on 1000× more labeled data. There are some more tables and figures in the next pages.Table 12. Evaluation of images generated with different backgrounds. Models Original Randombg Leopard Eight diagrams Checker Stripe Top-1 DA Top-1 DA Top-1 DA Top-1 DA Top-1 DA RN50 92.69% 79.35% 13.34% 57.17% 35.52% 64.32% 28.37% 65.13% 27.56% 62.90% 29.79% RN50-A 81.96% 66.71% 15.25% 25.05% 56.91% 37.21% 44.75% 32.47% 49.49% 46.96% 35.00% RN50-SIN 91.57% 77.99% 13.58% 62.74% 28.83% 48.74% 42.83% 51.15% 40.42% 52.65% 38.92% RN50-debiasd 93.34% 81.22% 12.12% 68.58% 24.76% 62.68% 30.66% 67.10% 26.24% 63.16% 30.18% RN50-Augmix 93.50% 80.56% 12.94% 57.35% 36.15% 56.20% 37.30% 68.78% 24.72% 65.68% 27.82% RN50-ANT 91.87% 76.51% 15.36% 58.11% 33.76% 59.04% 32.83% 51.91% 39.96% 54.69% 37.18% RN50-DeepAugment92.88% 79.56% 13.32% 62.83% 30.05% 57.71% 35.17% 59.46% 33.42% 61.80% 31.08% R50-T 94.55% 84.13% 10.42% 72.93% 21.62% 73.98% 20.57% 79.42% 15.13% 76.43% 18.12% Original Random Leopard Eight diagrams Checker Stripe VanillaSINDebiasedAugmixANTDeepAugment VanillaSINDebiasedAugmixANTDeepAugment Figure 15. Heat maps under different backgrounds. Table 13. More evaluations on state-of-the-art models including CLIP and EfficientNet-L2-Noisy-Student. Models Ori Background changes Size changes PositionDirection Avg.Inver λ=−20 λ= 20 λ= 20-Adv Random Full 0.1 0.08 0.05 rp rd ViT-B/16 95.38%0.83% 5.32% 8.43% 26.60% 10.98% 0.62% 4.00% 6.30% 14.51% 18.82% 14.95% 11.05% Zero-shot CLIPRN50 72.38%6.03% 11.64% 16.72% 35.07% 21.82% 8.78% 14.39% 17.69% 26.48%29.79% 25.31% 20.77% CLIPRN101 73.35%4.51% 10.77% 14.42% 33.42% 19.63% 6.39% 14.53% 18.19% 26.58%30.08% 24.51% 19.85% CLIPRN50x4 77.18%4.64% 10.44% 13.27% 31.39% 18.51% 7.46% 12.37% 15.66% 24.23%27.19% 24.25% 18.48% CLIPRN50x16 82.10%4.39% 10.10% 12.41% 27.14% 16.62% 6.62% 11.10% 13.53% 22.09%25.27% 23.13% 16.80% CLIPRN50x64 85.66%4.77% 8.89% 10.79% 23.75% 13.44%6.39% 9.20% 11.92% 19.17%21.62% 20.57% 14.57% CLIPViT-B/32 74.08%5.55% 13.24% 18.64% 43.26% 26.39% 2.99% 15.59% 19.74% 29.05%33.37% 24.89% 22.72% CLIPViT-B/16 80.01%4.88% 11.56% 15.28% 36.14% 20.09% 4.88% 12.67% 15.77% 25.31%28.87% 21.57% 19.21% CLIPViT-L/14 87.61%4.35% 11.04% 14.46% 33.69% 18.35% 1.81%11.67% 15.09% 23.66%27.19% 18.05% 17.50% CLIPViT-L/14-33688.01%3.16% 9.07% 12.25% 29.69% 16.08% 3.16% 9.20% 11.78%19.94%22.89% 16.15%15.02% CLIPViT-L/14-33688.01%3.16% 9.07% 12.25% 29.69% 16.08% 3.16% 9.20% 11.78%19.94%22.89% 16.15%15.02% Finetune CLIPViT-B/16-FT93.68%2.17% 9.82% 11.83% 38.33% 18.19% 4.66% 9.25% 12.67% 23.32%28.56% 22.00% 17.86% CLIPViT-L/14-336-FT96.97%1.29% 5.16% 6.18% 19.93% 8.09% 1.29% 3.47% 4.90% 10.98%13.74%10.96% 8.47% EF-B0 92.85%1.07% 7.10% 10.71% 34.88% 15.64% 3.03% 8.00% 11.57% 23.28%27.91% 19.11% 16.12% EF-B0-NT 94.30%1.97% 8.43% 10.51% 34.93% 15.99% 1.79% 7.91% 11.50% 22.96%27.62% 19.07% 16.07% EF-B7 97.10%1.80% 6.37% 7.20% 23.36% 10.78% 1.65% 4.16% 6.25% 14.13% 17.12% 10.56% 10.16% EF-B7-NT 97.38%1.30% 5.26% 6.10% 19.96% 9.15% 0.55% 3.31% 4.75% 10.67% 12.87% 7.98% 8.06% EF-L2-NT-475 97.84%1.08% 3.60% 4.51% 14.88% 7.14% 0.51% 2.21% 2.71% 5.50% 7.35% 4.58% 5.30% EF-L2-NT 97.63%1.26% 3.50% 4.06% 12.73% 6.90% 0.71% 2.27%2.79% 5.01% 6.03% 4.55% 4.85%Figure 16. The failure cases of attribute editing.",
      "meta_data": {
        "arxiv_id": "2303.17096v1",
        "authors": [
          "Xiaodan Li",
          "Yuefeng Chen",
          "Yao Zhu",
          "Shuhui Wang",
          "Rong Zhang",
          "Hui Xue"
        ],
        "published_date": "2023-03-30T02:02:32Z",
        "venue": "CVPR 2023",
        "pdf_url": "https://arxiv.org/pdf/2303.17096v1.pdf"
      },
      "llm_extracted_info": {
        "main_contributions": "1) Introduces an object-attribute editing toolkit based on diffusion models that can independently manipulate background complexity, object size, position and direction in any ImageNet image. 2) Uses the toolkit to build ImageNet-E, a controlled in-distribution robustness benchmark (≈48 k images, 373 classes) that isolates the effect of those four attributes. 3) Provides the first large-scale study of attribute robustness across modern CNNs, Vision Transformers, CLIP, adversarially-trained and other ‘robust’ models, revealing large accuracy drops (e.g., +9 % drop from modest background change, >18 % from small size) and cases where “robust” models underperform vanilla ones. 4) Demonstrates simple ways to improve attribute robustness (ten-crop inference, attention-rich architectures, hybrid CNN-ViT, masked image modelling, data augmentation) and shows a proof-of-concept ‘model repair’ that lifts ImageNet accuracy by replacing training backgrounds.",
        "methodology": "• Background editing: remove object via in-painting, then run a DDPM reverse process with an amplitude-based Fourier loss that guides the background toward simpler or more complex textures (λ parameter or adversarial guidance). • Size/position/direction editing: geometrically transform the segmented object (scaling, translation, rotation) and blend it back with the original background while jointly denoising object and background latents inside the diffusion process to avoid artefacts. • Dataset construction: apply the toolkit to ImageNet-S images with available masks; keep animal-related classes to ensure high visual quality; generate multiple levels per attribute. • Robustness evaluation: measure top-1 accuracy and its drop relative to original images; analyse attention maps (LayerCAM) and OOD scores (Energy, GradNorm). • Robustness enhancement tests: preprocessing (Ten-Crop), architectural changes (ResNeSt, ConvNeXt, hybrid RN-ViT), training regimes (AugMix, Debiased-CNN, SIN, MAE, SimMIM, adversarial training) and a targeted background-randomisation retraining.",
        "experimental_setup": "Datasets: ImageNet validation images with masks from ImageNet-S; after filtering, 4 352 source images → 47 872 edited images (373 classes, 11 attribute levels). Extended version ImageNet-E-L (10 919 images, 919 classes) also reported. Attribute levels: background λ = −20, 0, 20, 20-adv, random; object size rates: Full, 0.10, 0.08, 0.05; random position, random rotation. Models: 24 standard CNN/Transformer backbones (ResNet, DenseNet, EfficientNet, ResNeSt, ConvNeXt, ViT, Swin), 7 adversarially-trained variants, 6 robustness-oriented models (SIN, Debiased, AugMix, ANT, DeepAugment, RN50-T), 9 CLIP variants, 4 Noisy-Student EfficientNets, plus several self-supervised (MAE, SimMIM, MoCo-v3). Metric: drop in top-1 accuracy relative to clean ImageNet val. Validation of in-distribution property: compare ID scores via Energy and GradNorm to ImageNet; compute FID (15.57 vs 34.99 for ImageNet-9). Hardware: RTX-3090Ti, PyTorch implementation.",
        "limitations": "• Requires accurate object masks; current benchmark limited to classes with ImageNet-S masks (mainly animals). • Diffusion editing struggles with humans and very complex objects; hence some categories omitted and dataset size remains modest. • Quality and diversity of edited images tied to the performance of the underlying DDPM. • Only four attributes considered; other influential factors (lighting, viewpoint, occlusion) not covered. • Evaluation limited to classification; impact on detection/segmentation not studied.",
        "future_research_directions": "1) Expand editing toolkit to additional attributes (illumination, occlusion, material) and to object categories lacking masks via automatic segmentation. 2) Integrate edited samples into training to systematically improve both clean and robust accuracy at scale; investigate curriculum or adversarial attribute augmentation. 3) Develop attribute-aware architecture search or loss functions that explicitly disentangle object from background. 4) Adapt the benchmark to other tasks such as detection, segmentation and multi-modal retrieval. 5) Improve diffusion-based editing for human subjects and real-time applications, possibly via text-driven or controllable diffusion models."
      }
    },
    {
      "title": "Measuring Robustness to Natural Distribution Shifts in Image Classification",
      "abstract": "We study how robust current ImageNet models are to distribution shifts\narising from natural variations in datasets. Most research on robustness\nfocuses on synthetic image perturbations (noise, simulated weather artifacts,\nadversarial examples, etc.), which leaves open how robustness on synthetic\ndistribution shift relates to distribution shift arising in real data. Informed\nby an evaluation of 204 ImageNet models in 213 different test conditions, we\nfind that there is often little to no transfer of robustness from current\nsynthetic to natural distribution shift. Moreover, most current techniques\nprovide no robustness to the natural distribution shifts in our testbed. The\nmain exception is training on larger and more diverse datasets, which in\nmultiple cases increases robustness, but is still far from closing the\nperformance gaps. Our results indicate that distribution shifts arising in real\ndata are currently an open research problem. We provide our testbed and data as\na resource for future work at https://modestyachts.github.io/imagenet-testbed/ .",
      "full_text": "Measuring Robustness to Natural Distribution Shifts in Image Classiﬁcation Rohan Taori Achal Dave Vaishaal Shankar UC Berkeley CMU UC Berkeley Nicholas Carlini Benjamin Recht Ludwig Schmidt Google Brain UC Berkeley UC Berkeley Abstract We study how robust current ImageNet models are to distribution shifts arising from natural variations in datasets. Most research on robustness focuses on synthetic image perturbations (noise, simulated weather artifacts, adversarial examples, etc.), which leaves open how robustness on synthetic distribution shift relates to distribution shift arising in real data. Informed by an evaluation of 204 ImageNet models in 213 diﬀerent test conditions, we ﬁnd that there is often little to no transfer of robustness from current synthetic to natural distribution shift. Moreover, most current techniques provide no robustness to the natural distribution shifts in our testbed. The main exception is training on larger and more diverse datasets, which in multiple cases increases robustness, but is still far from closing the performance gaps. Our results indicate that distribution shifts arising in real data are currently an open research problem. We provide our testbed and data as a resource for future work at https://modestyachts.github.io/imagenet-testbed/. 1 Introduction Reliable classiﬁcation under distribution shift is still out of reach for current machine learning [65, 68, 91]. As a result, the research community has proposed a wide range of evaluation protocols that go beyond a single, static test set. Common examples include noise corruptions [33, 38], spatial transformations [28, 29], and adversarial examples [5, 84]. Encouragingly, the past few years have seen substantial progress in robustness to these distribution shifts, e.g., see [13, 28, 34, 55, 57, 66, 93, 96, 105, 114, 115] among many others. However, this progress comes with an important limitation: all of the aforementioned distribution shifts aresynthetic: the test examples are derived from well-characterized image modiﬁcations at the pixel level. Synthetic distribution shifts are a good starting point for experiments since they are precisely deﬁned and easy to apply to arbitrary images. However, classiﬁers ultimately must be robust to distribution shifts arising naturally in the real world. These distribution shifts may include subtle changes in scene compositions, object types, lighting conditions, and many others. Importantly, these variations are not precisely deﬁned because they have not been created artiﬁcially. The hope is that an ideal robust classiﬁer is still robust to such natural distribution shifts. 1 arXiv:2007.00644v2  [cs.LG]  14 Sep 2020In this paper, we investigate how robust current machine learning techniques are to distribution shift arising naturally from real image data without synthetic modiﬁcations. To this end, we conduct a comprehensive experimental study in the context of ImageNet [18, 70]. ImageNet is a natural starting point since it has been the focus of intense research eﬀorts over the past decade and a large number of pre-trained classiﬁcation models, some with robustness interventions, are available for this task. The core of our experimental study is a testbed of 204 pre-trained ImageNet models that we evaluate in 213 diﬀerent settings, covering both the most popular models and distribution shifts. Our testbed consists of109 model predictions and is 100 times larger than prior work [27, 33, 47, 68]. This allows us to draw several new conclusions about current robustness interventions: Robustness measurements should control for accuracy.Existing work typically argues that an intervention improves robustness by showing that the accuracy on a robustness test set has improved (e.g., see [34, 40, 63, 102, 115]). We ﬁnd that in many cases, this improved robustness can be explained by the model performing better on the standard, unperturbed test set. For instance, using diﬀerent model architectures does not substantially improve the robustness of a model beyond what would be expected from having a higher standard accuracy. While training more accurate models is clearly useful, it is important to separate accuracy improvements from robustness improvements when interpreting the results. Current synthetic robustness measures do not imply natural robustness.Prior work often evaluates on synthetic distribution shifts to measure robustness [9, 32, 38]. We ﬁnd that current robustness measures for synthetic distribution shift are at most weakly predictive for robustness on the natural distribution shifts presently available. While there are good reasons to study synthetic forms of robustness – for instance, adversarial examples are interesting from a security perspective – synthetic distribution shifts alone do not provide a comprehensive measure of robustness at this time. Moreover, as the right plot in Figure 1 exempliﬁes, current robustness interventions are often (but not always) ineﬀective on the natural distribution shifts in our testbed. Training on more diverse data improves robustness.Across all of our experiments, the only intervention that improves robustness to multiple natural distribution shifts is training with a more diverse dataset. This overarching trend has not previously been identiﬁed and stands out only through our large testbed. Quantifying when and why training with more data helps is an interesting open question: while more data is generally helpful, we ﬁnd some models that are trained on 100 times more data than the standard ImageNet training set but do not provide any robustness. The goal of our paper is speciﬁcallynot to introduce a new classiﬁcation method or image dataset. Instead, our paper is a meta-study of current robustness research to identify overarching trends that span multiple evaluation settings. This is particularly important if the ultimate goal of a research direction is to produce models that function reliably in a wide variety of contexts. Our ﬁndings highlight robustness on real data as a clear challenge for future work. Due to the diminishing returns of larger training datasets, addressing this robustness challenge will likely require new algorithmic ideas and more evaluations on natural distribution shifts. 260 65 70 75 80 85 ImageNet (top-1, %) 45 50 55 60 65 70 75ImageNetV2 (top-1, %) Effective Robustness Hypothetical Robustness Intervention y = x Baseline accuracy Hypothetical robust model Standard models 60 65 70 75 80 85 ImageNet (top-1, %) 45 50 55 60 65 70 75 80 85ImageNetV2 (top-1, %) Simplified Distribution Shift Plot y = x Baseline accuracy Standard training Robustness intervention Trained with more data Figure 1: (Left) We plot 78 standard models trained on ImageNet without any robustness interventions, showing both their accuracy on the standard test set (ImageNet, x-axis) and on a test set with distribution shift (ImageNetV2, y-axis). All models lie below the y= xline: their accuracy under this distribution shift is lower than on the standard test set. Nevertheless, improvements in accuracy on the standard test set almost perfectly predict a consistent improvement under distribution shift, as shown by the linear ﬁt (red line). A hypothetical robustness intervention, shown in green, should provideeﬀective robustness, i.e., the intervention should improve the accuracy under distribution shift beyond what is predicted by the linear ﬁt. (Right) We plot most of the 204 models in our testbed, highlighting those with the highest eﬀective robustness using square markers. These models are still far from closing the accuracy gap induced by the distribution shift (ideally a robust model would fall on the y= x line). Figure 2 shows a more detailed version of this plot with error bars for all points. 2 Measuring robustness We ﬁrst discuss how to measure robustness as a quantity distinct from accuracy. In our experiments, we always have two evaluation settings: the “standard” test set, and the test set with distribution shift. For a modelf, we denote the two accuracies with acc1(f) and acc2(f), respectively. When comparing the robustness of two modelsfa and fb, one approach would be to rank the models by their accuracy under distribution shift. However, this approach does not disentangle the robustness of a model from its accuracy on the standard test set. As an example, consider a pair of models with accuracyacc1(fa) = 0.8, acc2(fa) = 0.75 (i.e., a 5% drop in accuracy from the distribution shift), andacc1(fb) = 0.9, acc2(fb) = 0.76 (a 14% drop). Modelfb has higher accuracy on the second test set, but overall sees a drop of 14% from the standard to the shifted test set. In contrast, the ﬁrst model sees only a 5% drop. Hence we would like to refer to the ﬁrst model as more robust, even though it achieves lower accuracy on the shifted test set. Eﬀective robustness.The core issue in the preceding example is that standard accuracy (acc1) acts as a confounder. Instead of directly comparing accuracies under distribution shift, we would 3like to understand if a modelfb oﬀers higher accuracy on the shifted test setbeyond what is expected from having higher accuracy on the original test set. We call this notion of robustness beyond a baseline eﬀective robustness. Graphically, eﬀective robustness corresponds to a model being above the linear trend (red line) given by our testbed of standard models in Figure 1 (left). To precisely deﬁne eﬀective robustness, we introduceβ(x), the baseline accuracy on the shifted test set for a given accuracyx on the standard test set. On the distribution shifts in our testbed, we instantiate β by computing the parameters of a log-linear ﬁt for the models without a robustness intervention (the red line in Figure 1). Empirically, this approach yields a good ﬁt to the data. For other distribution shifts, the baseline accuracy may follow diﬀerent trends and may also depend on properties beyond the standard accuracy, e.g., model architecture. Appendix I.1 contains detailed information on how to computeβ. Given the accuracy baselineβ, we deﬁne the eﬀective robustness of a model as ρ(f) =acc2(f) −β(acc1(f)) . A model without special robustness properties falls on the linear ﬁt and hence hasρ(f) = 0. The main goal of a robustness intervention is to increaseρ. Models with largeρ oﬀer robustness beyond what we can currently achieve with standard models. Relative robustness. Eﬀective robustness alone does not imply that a robustness intervention is useful. In particular, a robustness intervention could increaseρ for a model it is applied to, but at the same timedecreaseboth acc1 and acc2. Such a robustness intervention would oﬀer no beneﬁts. So to complement eﬀective robustness, we also introducerelative robustnessto directly quantify the eﬀect of an intervention on the accuracy under distribution shift. For a modelf′ with robustness intervention, derived from a modelf without the intervention, the relative robustness is τ(f′) =acc2(f′) −acc2(f). We graphically illustrate this notion of robustness in Appendix B.1. Overall, a useful robustness intervention should obtainboth positive eﬀective and relative robustness. As we will see, only few classiﬁcation models currently achieve this goal, and no models achieve both large eﬀective and relative robustness. 3 Experimental setup We now describe our experimental setup. A modelf is ﬁrst trained on a ﬁxed training set. We then evaluate this model on two test sets: the “standard” test set (denotedS1) and the test set with a distribution shift (denotedS2). A crucial question in this setup is what accuracy the modelf can possibly achieve on the test set with distribution shift. In order to ensure that the accuracy on the two test sets are comparable, we focus on natural distribution shifts where humans have thoroughly reviewed the test sets to include only correctly labeled images [2, 18, 39, 68, 76].1 This implies that an ideal robust classiﬁer does not have a substantial accuracy gap between the two test sets. Indeed, recent work experimentally conﬁrms that humans achieve similar classiﬁcation accuracy on the original ImageNet test set and the ImageNetV2 replication study (one of the distribution shifts in our testbed) [77]. 1For ObjectNet [2], Borji [7] has pointed out potential label quality issues, but also found that a substantial accuracy drop remains when taking these issues into account. 43.1 Types of distribution shifts At a high level, we distinguish between two main types of distribution shift. We use the term natural distribution shift for datasets that rely only on unmodiﬁed images. In contrast, we refer to distribution shifts assynthetic if they involve modiﬁcations of existing images speciﬁcally to test robustness. To be concrete, we next provide an overview of the distribution shifts in our robustness evaluation, with further details in Appendix E and visual overviews in Appendices A and J. 3.1.1 Natural distribution shifts We evaluate on seven natural distribution shifts that we classify into three categories. Consistency shifts. To evaluate a notion of robustness similar toℓp-adversarial examples but without synthetic perturbations, we measure robustness to small changes across video frames as introduced by Gu et al.[35] and Shankar et al.[76]. The authors assembled sets of contiguous video frames that appear perceptually similar to humans, but produce inconsistent predictions for classiﬁers. We deﬁneS1 to be the set of “anchor” frames in each video, and evaluate the accuracy under distribution shift by choosing the worst frame from each frame set for a classiﬁer. This is the “pm-k” metric introduced by Shankar et al. [76]. Dataset shifts.Next, we consider datasetsS2 that are collected in a diﬀerent manner fromS1 but still evaluate a classiﬁcation task with a compatible set of classes. These distribution shifts test to what extent current robustness interventions help with natural variations between datasets that are hard to model explicitly. We consider four datasets of this variety: (i) ImageNetV2, a reproduction of the ImageNet test set collected by Recht et al.[68]; (ii) ObjectNet, a test set of objects in a variety of scenes with 113 classes that overlap with ImageNet [2]; and, (iii) ImageNetVid-Robust-anchor and YTBB-Robust-anchor [76], which are the datasets constructed from only the anchor frames in the consistency datasets described above. These two datasets contain 30 and 24 super-classes of the ImageNet class hierarchy, respectively. For each of these distribution shifts, we deﬁneS1 to be a subset of the ImageNet test set with the same label set asS2 so that the accuracies are comparable. Adversarially ﬁltered shifts.Finally, we consider an adversarially collected dataset, ImageNet-A [39]. Hendrycks et al.[39] assembled the dataset by downloading a large number of labeled images from Flickr, DuckDuckGo, iNaturalist, and other sites, and then selected the subset that was misclassiﬁed by a ResNet-50 model. We include ImageNet-A in our testbed to investigate whether the adversarial ﬁltering process leads to qualitatively diﬀerent results. Since ImageNet-A contains only 200 classes, the standard test setS1 here is again a subset of the ImageNet test set that has the same 200 classes as ImageNet-A. 3.1.2 Synthetic distribution shifts The research community has developed a wide range of synthetic robustness notions for image classiﬁcation over the past ﬁve years. In our study, we consider the following classes of synthetic distribution shifts, which cover the most common types of image perturbations. 5Image corruptions.We include all corruptions from [38], as well as some corruptions from [33]. These include common examples of image noise (Gaussian, shot noise), various blurs (Gaussian, motion), simulated weather conditions (fog, snow), and “digital” corruptions such as various JPEG compression levels. We refer the reader to Appendix E.2 for a full list of the 38 corruptions. Style transfer.We use a stylized version of the ImageNet test set [34, 44]. Adversarial examples.We include untargeted adversarial perturbations bounded inℓ∞- orℓ2- norm by running projected gradient descent as described in [55]. We useε= {0.5 255, 2 255}for ℓ∞ and ε= {0.1,0.5}for ℓ2 (further details in Appendix E.3). 3.2 Classiﬁcation models Our model testbed includes 204 ImageNet models covering a variety of diﬀerent architectures and training methods. The models can be divided into the following three categories (see Appendix F for a full list of all models and their categories). Standard models.We refer to models trained on the ILSVRC 2012 training set without a speciﬁc robustness focus asstandard models. This category includes 78 models with architectures ranging from AlexNet to EﬃcietNet, e.g., [37, 50, 78, 85, 88]. Robust models. This category includes 86 models with an explicit robustness intervention such as adversarially robust models [13, 27, 72, 74, 101], models with special data augmentation [20, 28, 34, 41, 100, 108, 113], and models with architecture modiﬁcations [115]. Models trained on more data.Finally, our testbed contains 30 models that utilize substantially more training data than the standard ImageNet training set. This subset includes models trained on (i) Facebook’s collection of 1 billion Instagram images [56, 104], (ii) the YFCC 100 million dataset [104], (iii) Google’s JFT 300 million dataset [82, 102], (iv) a subset of OpenImages [98], or (v) a subset of the full ImageNet dataset of 21,841 classes [11, 49, 99]. 4 Main results We now present our main experiments. First, we measure how much eﬀective and relative robustness models achieve on the natural distribution shifts in our testbed. Then we investigate to what extent robustness on synthetic distribution shift is predictive of robustness on natural distribution shift. 4.1 Results on natural distribution shifts Following the categorization in Section 3, we measure the robustness of classiﬁcation models on three types of natural distribution shift. Appendix I.2 contains variations of the ﬁgures referenced in this sec- tion. Forfurtherdetail, wehavemadeinteractiveplotsavailableathttp://robustness.imagenetv2.org/. Dataset shifts.Figure 2 shows the eﬀective robustness of models on the four dataset shifts in our testbed. In each case, we ﬁnd that the standard test accuracy (x-axis) is a good predictor for the test accuracy under distribution shift (y-axis). The linear ﬁt is best for ImageNetV2, ObjectNet, 660 65 70 75 80 85 ImageNet (top-1, %) 45 50 55 60 65 70 75 80ImageNetV2 (top-1, %) Distribution Shift to ImageNetV2 55 60 65 70 75 80 85 90 ImageNet (class-subsampled) (top-1, %) 15 20 25 30 35 40 45 50 55 60 65 70ObjectNet (top-1, %) Distribution Shift to ObjectNet 93 94 95 96 97 98 99 ImageNet (class-subsampled) (top-1, %) 50 55 60 65 70 75 80 85 90ImageNet-Vid-Robust (pm-0, %) Distribution Shift to ImageNet-Vid-Anchors 95 96 97 98 99 ImageNet (class-subsampled) (top-1, %) 45 50 55 60 65 70YTBB-Robust (pm-0, %) Distribution Shift to YTBB-Anchors y = x Standard training Robustness intervention Trained with more data Linear fit Figure 2: Model accuracies on the four natural dataset shifts: ImageNetV2 (top left), ObjectNet (top right), ImageNet-Vid-Robust-anchor (bottom left), and YTBB-Robust- anchor (bottom right). These plots demonstrate that the standard test accuracy (x-axis) is a reliable predictor for the test accuracy under distribution shift (y-axis), especially for models trained without a robustness intervention. The notable outliers to this trend are some models trained on substantially more data. For ObjectNet, ImageNet-Vid-Robust- anchor, and YTBB-Robust-anchor, we show the accuracy on a subset of the ImageNet classes on the x-axis to match the label space of the target task (y-axis). Each data point corresponds to one model in our testbed and is shown with 99.5% Clopper-Pearson conﬁdence intervals. The axes were adjusted using logit scaling and the linear ﬁt was computed in the scaled space on only the standard models. The red shaded region is a 95% conﬁdence region for the linear ﬁt from 1,000 bootstrap samples. and ImageNet-Vid-Robust with respectiver2 scores of 1.00, 0.95, and 0.95, but is more noisy for YTBB-Robust (r2 = 0.83). The noisy ﬁt on YTBB-Robust is likely due to the fact that the categories in YTBB-Robust are not well aligned with those of ImageNet, where the models were trained [76]. Another potential reason is that the video test sets are signiﬁcantly smaller (2,530 images in YTBB and 1,109 images in ImageNet-Vid-Robust). 750 55 60 65 70 75 80 85 90 ImageNet-Vid-Robust (pm-0, %) 30 35 40 45 50 55 60 65 70 75 80ImageNet-Vid-Robust (pm-10, %) Distribution Shift to ImageNet-Vid-Robust 45 50 55 60 65 70 YTBB-Robust (pm-0, %) 30 35 40 45 50 55 60 65YTBB-Robust (pm-10, %) Distribution Shift to YTBB-Robust y = x Standard training Lp adversarially robust Other robustness intervention Trained with more data Linear fit Figure 3: Model accuracies on the two consistency shifts: ImageNet-Vid-Robust (left), and YTBB-Robust (right). Both plots are shown with evaluation on pm-0 (anchor frames) on the x-axis and pm-10 (worst case prediction in a 20-frame neighborhood) on the y-axis. This plot shows that most current robustness interventions do not provide robustness to consistency distribution shifts. The notable outliers to this trend areℓp-adversarially robust models and EﬃcientNet-L2 (NoisyStudent). We color the adversarially robust models separately in this ﬁgure to illustrate this phenomenon. Conﬁdence intervals, axis scaling, and the linear ﬁt are computed similarly to Figure 2. In the high accuracy regime (above the 76% achieved by a ResNet-50), the main outliers in terms of positive eﬀective robustness are models trained on substantially more data than the standard ImageNet training set. This includes a ResNet152 model trained on 11,000 ImageNet classes (ρ = 2.1%) [99], several ResNeXt models trained on 1 billion images from Instagram (ρ = 1.5%) [56], and the EﬃcientNet-L2 (NoisyStudent) model trained on a Google-internal JFT-300M dataset of 300 million images (ρ = 1.1%) [102]. However, not all models trained on more data display positive eﬀective robustness. For instance, a ResNet101 trained on the same JFT-300M dataset has an eﬀective robustness ofρ= −0.23% [82]. We conduct additional experiments to investigate the eﬀect of training data in Section 5. Appendix G contains a full list of models with their eﬀective robustness numbers. On YTBB-Robust, a few data augmentation strategies andℓp-robust models display positive eﬀective robustness; we investigate this further in Appendix B.2. Consistency shifts.We plot the eﬀective robustness of models on consistency shifts in Figure 3. Interestingly, we observe thatℓp-adversarially robust models display substantial eﬀective robustness to ImageNet-Vid-Robust (averageρ= 6.7%) and YTBB-Robust (averageρ= 4.9%). This suggests that these models are not only more robust to synthetic perturbations, but also oﬀer robustness for the perceptually small variations between consecutive video frames. However, these gains in eﬀective robustness do not necessarily lead to relative robustness. On average, relative robustness on both datasets is negative (averageτ = −8.5% on ImageNet-Vid-Robust and average τ = −0.7% on YTBB-Robust for ResNet50 models). See Appendix B.2 (Figure 10) for a visual comparison. Among the models trained on more data, only one achieves both high accuracy 880 90 95 96 97 98 99 ImageNet (class-subsampled) (top-1, %) 5 10 20 30 40 50 60 70 80ImageNet-A (top-1, %) Distribution Shift to Imagenet-A y = x Linear fit (piecewise) ResNet50 accuracy Standard training Robustness intervention Trained with more data Figure 4: Model accuracies on ImageNet-A, a dataset adversarially ﬁltered to contain only images incorrectly classiﬁed by a ResNet50 trained on ImageNet. This ﬁltering results in a ‘knee’ curve: models with lower ImageNet accuracy than ResNet-50 have near-chance performance on ImageNet-A, while models with higher ImageNet accuracy improve drastically on ImageNet-A. ImageNet classes were subsampled to match the class distribution of ImageNet-A. Conﬁdence intervals and axis scaling are computed similarly to Figure 2. The linear ﬁt is computed piecewise around the ResNet50 model accuracy. and substantial eﬀective robustness: EﬃcientNet-L2 (NoisyStudent) [102] hasρ= 2.4% andρ= 7.4% on ImageNet-Vid-Robust and YTBB-Robust, respectively. Adversarially ﬁltered shifts.ImageNet-A [39] was created by classifying a set of images with a ResNet50 and only keeping the misclassiﬁed images. Interestingly, this approach creates a “knee” in the resulting scatter plot (see Figure 4): models below a ResNet50’s standard accuracy have close to chance performance on ImageNet-A,2 and models above a ResNet50’s standard accuracy quickly close the accuracy gap. In the high accuracy regime, every percentage point improvement on ImageNet brings at least an 8% improvement on ImageNet-A. This is in contrast to datasets that are not constructed adversarially, where the initial accuracy drops are smaller, but later models make slow progress on closing the gap. These results demonstrate that adversarial ﬁltering does not necessarily lead to harder distribution shifts. 4.2 Results on synthetic distribution shifts Given the diﬃculty of collecting real world data to measure a model’s robustness to natural distribution shifts, an important question is whether there are synthetic proxies. We now study to what extent robustness to the above synthetic distribution shifts predicts robustness on these natural distribution shifts. 2Chance performance is 0.5% as ImageNet-A contains 200 classes. 960 65 70 75 80 85 ImageNet (top-1, %) 20 25 30 35 40 45 50 55 60 65 70Corruptions Averaged (top-1, %) Distribution Shift to Corruptions Averaged -5 0 5 10 15 20 Corruptions Averaged Effective Robustness -1 0 1 2 ImageNetV2 Effective Robustness Effective Robustness Scatterplot 60 65 70 75 80 85 ImageNet (top-1, %) 15 20 25 30 35 40 45 50 55 60Lp Attacks (top-1, %) Distribution Shift to Lp Attacks -15 -10 -5 0 5 10 15 20 25 30 35 40 45 Lp Attacks Effective Robustness -1 0 1 2 ImageNetV2 Effective Robustness Effective Robustness Scatterplot y = x Standard training Lp adversarially robust Other robustness intervention Trained with more data Linear fit Figure 5: Model accuracies under image corruptions (top row) andℓp-attacks (bottom row). Similar to Figure 2, the left plots show the eﬀective robustness for each synthetic distribution shift. Multiple non-standard models achieve substantial eﬀective robustness, corroborating recent research progress on creating models robust to synthetic shift. The right plots show the correlation between the eﬀective robustness for each synthetic shift and the ImageNetV2 distribution shift (top left in Figure 2) for the non-standard models. Both image corruptions andℓp-attacks are very weakly predictive of eﬀective robustness on ImageNetV2: there are several models that achieve high eﬀective robustness under the synthetic measures but little to no eﬀective robustness on ImageNetV2. In Figure 5, we analyze the predictiveness of two commonly studied synthetic robustness metrics: average accuracy on image corruptions [38], and average accuracy drop under a range of PGD adversarial attacks [55]. We compare these metrics with eﬀective robustness on ImageNetV2. While eﬀective robustness is only one aspect (c.f. Section 2), it is a necessary prerequisite for a model to have helpful robustness properties. The plots show that robustness under either of these synthetic distribution shifts does not imply that the corresponding model has eﬀective robustness on ImageNetV2 (the Pearson correlation coeﬃcients are r= 0.24 and r= −0.05 for image corruptions andℓp-adversarial attacks, respectively). Appendix C further extends the experiment by comparing both synthetic distribution shift measures with the 10remaining natural distribution shifts in our testbed and reaches similiar conclusions. Our analysis of the aggregate measures proposed in prior work does not preclude that speciﬁc synthetic distribution shifts do predict behavior on natural distribution shifts. Instead, our results show that averaging a large number of synthetic corruptions does not yield a comprehensive robustness measure that also predicts robustness on natural distribution shift. To extend on this analysis, in Appendix H we ﬁnd that no individual synthetic measure in our testbed is a consistent predictor of natural distribution shift, but some synthetic shifts are substantially more predictive than others. For instance,ℓp-robustness has the highest correlation with consistency shifts, and some image corruptions such as brightness or Gaussian blur have higher correlation with dataset shifts. However, our testbed indicates that these synthetic measures are not necessarily causal, i.e., models trained with brightness or Gaussian blur do not have substantial eﬀective robustness on dataset shifts. Further analyzing relationships between individual synthetic and natural distribution shifts is an interesting avenue for future work. 4.3 Takeaways and discussion To recap our results, we now discuss two of the central questions in our paper: Do current robustness interventions help on real data? And is synthetic robustness correlated with natural robustness? Across our study, current robustness interventions oﬀer little to no improvement on the natural distribution shifts presently available. For dataset shifts, we ﬁnd that models trained with substantially more data yield a small improvement. However, the amount of extra data needed is orders of magnitude larger than the standard ImageNet training set, and the models show only small gains (in the best case improving the accuracy drop from 8.6% to 7.5% on ImageNetV2 for EﬃcientNet-L2 NoisyStudent). These results suggest that current robustness interventions methods do not provide beneﬁts on the dataset shifts in our study. For consistency shifts, adversarially trained models generally have eﬀective robustness, but usually little or no relative robustness. On ImageNet-Vid-Robust, the baseline models without adversarial training still achieve higher accuracy under distribution shift. A notable outlier is EﬃcietNet-L2 (NoisyStudent) [102], which utilizes self-training and exhibits high eﬀective robustness in the high accuracy regime. Self-training has recently been shown to help adversarial robustness as well [10, 61, 94]. Investigating the eﬀect of self-training on robustness is an interesting direction for future work. Moreover, we ﬁnd that current aggregate metrics for synthetic robustness are at most weakly correlated with natural robustness. Eﬀective robustness under non-adversarial image corruptions or ℓp-attacks does not imply eﬀective robustness to natural distribution shifts. While much progress has been made on creating models robust to synthetic distribution shift, new methods may be needed to handle natural shifts. 1125 30 35 40 45 50 55 60 65 70 75 80 85 ImageNet (iid-subsampled) (top-1, %) 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 ImageNetV2 (iid- subsampled) (top-1, %) Robustness for Subsampling ImageNet y = x Linear fit Standard training Trained with more data No subsampling Subsample 1/2 Subsample 1/4 Subsample 1/8 Subsample 1/16 Subsample 1/32 80 85 90 95 ImageNet (class-subsampled) (top-1, %) 70 75 80 85 90 95 ImageNetV2 (class- subsampled) (top-1, %) Robustness for Subsampling ImageNet y = x Linear fit Standard training Trained with more data 1000 classes 500 classes 250 classes 125 classes Figure 6: To investigate the impact of training data on robustness, we vary the training data along two axes: the number of images per class (left), and the number of classes (right). Although models trained on more data provide improvements in eﬀective robustness, weﬁndthatsubsamplingthetrainingsethasnoimpactoneﬀectiverobustness. Conﬁdence intervals, axis scaling, and the linear ﬁt are computed similarly to Figure 2. 5 How does the amount of training data impact robustness? As discussed in Section 4.1, multiple models trained on more data achieve positive eﬀective robustness on dataset shifts. However, this eﬀect is not uniform. Among others, the ResNet101 model trained on JFT-300M has negligible eﬀective robustness (ρ= −0.23%) despite being trained on300×more data than standard ImageNet models. A possible explanation is that diﬀerences in label diversity or quality play a role in promoting robustness. We investigate the role of data in more detail with two experiments. Varying the number of images per class.We start by subsampling the ILSVRC-2012 training set by factors of {2, 4, 8, 16, 32} and show the impact on accuracy and robustness on ImageNetV2 in Figure 6. While larger training subsets yield higher accuracies, they do not improve eﬀective robustness, at least for ImageNetV2. Varying the number of classes.Next, we subsample ImageNet in a more biased way by varying the set of classes. First, we create three subsets of the ILSVRC training set with 500, 250, and 125 classes and train models on these subsets. We then evaluate all models on the 125 class subset and show the results in Figure 6. Varying the number of classes again aﬀects accuracies, but does not impact eﬀective robustness. Our experiments suggest that neither growing the number of images nor classes in an i.i.d. fashion are eﬀective robustness interventions. Nevertheless, Figure 2 shows that larger datasets can provide meaningful robustness improvements. This disparity may be due to limitations of emulating dataset growth by subsampling ILSVRC. For one, our experiments consider only i.i.d. subsets of the training images or classes. Another possibility is that increases in dataset size may only improve robustness after the dataset is large enough so that the accuracy on the original distribution is nearly saturated. Our experiments only observe dataset sizes smaller than ILSVRC, which may fall below this inﬂection point. Studying the eﬀect of data on robustness is an important direction for future work. 126 Related work Our work is best seen as a uniﬁcation of two independent lines of research—synthetic and natural distribution shift—not previously studied together. Synthetic distribution shifts have been studied extensively in the literature [28, 33, 38, 48, 57, 93]. We incorporate as many prior synthetic measures of robustness as possible. Our dataset largely conﬁrms the high-level results from these papers (see Appendix D for additional discussion). For example, Ford et al.[31] provide evidence for the relationship between adversarial robustness and robustness to Gaussian noise. The study of natural distribution shifts has been an equally extensive research direction [2, 68, 76, 91]. When examining each natural distribution shift individually, we conﬁrm the ﬁndings of earlier work that there is a consistent drop with a linear trend going from ImageNet to each of the other test sets [2, 68, 76]. We study the relationship between these two previously independent lines of work. By creating a testbed 100×larger than prior work [27, 33, 47, 68], we are able to make several new observations. For instance, we show that robustness to synthetic distribution shift often behaves diﬀerently from robustness to natural distribution shift. We argue that it is important to control for accuracy when measuring the eﬃcacy of a robustness intervention. Viewed in this light, most interventions do not provide eﬀective robustness. The main exception is training with more data, which improves robustness across natural distribution shifts. In some situations,ℓp-adversarial robustness helps with natural distribution shift that asks for consistency across similar looking images. Appendix K contains additional discussion of speciﬁc related work in more detail. For instance, Appendix K.2 revisits consistency shifts and explains why, in contrast to previous work [35], we ﬁnd consistency robustness is only weakly correlated with color corruption robustness. Concurrent and subsequent work. An early version of this paper with results on ImageNetV2 and ImageNet-Vid-Robust appeared on OpenReview in late 2019 [90]. Since then, two closely related papers have been published concurrently with the updated version of this paper. Djolonga et al.[21] evaluate 40 models on the same natural distribution shifts as our paper. Our testbed is larger and contains 200 models with more robustness interventions. Overall both papers reach similar conclusions. Their focus is more on the connections to transfer learning while we focus more on comparisons between synthetic and natural distribution shifts. Djolonga et al.[21] also explore the performance of various models with a synthetic image dataset. Hendrycks et al. [40] also study the connections between synthetic robustness and robustness to natural distribution shifts. This paper introduces a new dataset, ImageNet-R, that contains various renditions (sculptures, paintings, etc.) of 200 ImageNet classes as a new example of natural distribution shift. The paper then introduces DeepAugment, a new data augmentation technique based on synthetic image transformations, and ﬁnd that this robustness intervention is eﬀective on ImageNet-R. In Appendix K.1, we analyze the ImageNet-R test set and DeepAugment models, as well as the closely related ImageNet-Sketch test set [95], in more detail. At a high-level, ImageNet-R and ImageNet-Sketch follow the trends of the other dataset shifts in our testbed, with models trained on extra data providing the most robustness (up toρ= 29.1% on ImageNet-R, though the eﬀect is not uniform, similar to the other dataset shifts). After the models trained on more data, we ﬁnd that DeepAugment (in combination with AugMix [41]) achieves 13substantial eﬀective robustness (ρ = 11.2%). Interestingly, adversarial robustness also leads to eﬀective robustness on ImageNet-R. An AdvProp model [100] achieves the highest absolute accuracy on ImageNet-R for a model trained without extra data (57.8%) and has eﬀective robustnessρ= 7.5%. A model with feature denoising and trained with PGD-style robust optimization [55, 101] achieves the highest eﬀective robustness on ImageNet-R (ρ= 22.7%) and also positive relative robustness (τ = 5.7%). Domain adaptation / transfer learning. Our work is focused on generalizing to out-of- distribution datawithout ﬁne-tuning on the target distribution. A complementary approach uses data from the target domain in order to improve generalization on that particular domain [64]. Depending on the scenario, robustness (without ﬁne-tuning) or domain adaptation may be more appropriate. For instance, it may be challenging to record data from the distribution shift, which would prevent ﬁne-tuning before deployment. In some scenarios, we also expect our model to generalize without extra data (e.g., because humans can do so [77]). Concurrent work by Djolonga et al.[21] studies connections between robustness to distribution shifts and transfer learning. Investigating our testbed from the perspective of transfer learning is an interesting direction for future research. Domain generalization. Out-of-distribution generalization as measured in our robustness testbed is closely related to domain generalization [6, 60]. In domain generalization, the training algorithm has access to samples drawn from multiple diﬀerent distributions (domains). At test time, the model is evaluated on samples from a new domain that was not present in training. The idea is that having explicit knowledge of multiple domains at training time may help generalization to a new domain at test time. Several papers have proposed algorithms for domain generalization; we refer to Gulrajani & Lopez- Paz [36] for a comprehensive survey. Our testbed currently does not contain any algorithms explicitly following the domain generalization paradigm (though pre-training on a diﬀerent distribution and then ﬁne-tuning on ImageNet has similarities to domain generalization). A recent meta-study of domain generalization found that standard empirical risk minimization performs as well or better than the eight domain generalization algorithms they compared to [36]. This result of Gulrajani & Lopez-Paz [36] has similarities to our ﬁnding that robustness interventions currently rarely improve over the trend given by standard (ERM) models trained without a robustness intervention. Evaluating domain generalization approaches on the distribution shifts in our testbed may yield new insights into the performance characteristics of these algorithms. Distributionally robust optimization. Distributionally robust optimization (DRO) is another recently proposed technique to increase robustness to distribution shift [22, 23]. The DRO objective minimizes the worst case risk over all distributions close to the data distribution (or in the group DRO setting, the worst case risk over all deﬁned groups). DRO has been used to train adversarially robust models [79], vision models with higher worst-group accuracies [71], models less reliant on spurious correlations [81], and many others [24, 62]. For a more thorough discussion on DRO and related work, we refer the reader to [22]. We are currently unable to include DRO models as we are not aware of any pre-trained DRO models for ImageNet. We will add DRO models to our testbed as they become available. 14Adversarial ﬁltering. One of the distribution shifts in our testbed was obtained via adversarial ﬁltering (ImageNet-A, [39]). Architectures introduced after the model used to ﬁlter ImageNet-A made quick progress in closing the accuracy gap (see Section 4.1). A similar phenomenon occurred in natural language processing. Zellers et al.[111] introduced Swag, an adversarially ﬁltered test for grounded commonsense inference, a combination of natural language inference and commonsense reasoning. At the time of publication, the best model achieved 59% accuracy, while a human expert achieved 85%. Two months later, Devlin et al.[19] introduced the BERT model which achieves 86% accuracy on Swag. This provides further evidence that adversarial ﬁltering can create test sets that are only hard for a speciﬁc (existing) class of models. In the context of training sets, adversarial ﬁltering is similar to hard negative mining, which is often used to generate training data for detection models [17, 30, 69, 83]. Bras et al. [8] propose AFLite, an adversarial ﬁltering algorithm for both reﬁning training sets and creating harder test sets. They evaluate AFLite on natural language inference tasks and ImageNet classiﬁcation. An interesting question is whether combining their algorithm with a ResNet-50 and evaluating later models leads to similar phenomena as on ImageNet-A [39] and Swag [111]. Fairness in machine learning. Mitchell et al. [59] proposed model cards to document the performance of machine learning models in a variety of conditions. Their focus is on human-centered models and distribution shifts arising from demographic groups (race, gender, etc.). Our focus here is on ImageNet due to the large number of available models and distribution shifts, but the underlying problem is similar: machine learning models are often brittle under distribution shift. We remark that ImageNet is known to have geo-diversity deﬁciencies [75], among other issues [14, 25]. In the context of OpenImages [51], researchers have proposed the Inclusive Image dataset [1]. Adding OpenImages and Inclusive Images to our testbed and comparing these distribution shifts to our existing examples is an interesting direction for future work. Further domains. Our work is focused on the domain of image classiﬁcation. There is a long line of work considering robustness (either natural or synthetic) on other domains [26, 52, 58, 80, 106]. In the context of natural language processing, Belinkov & Bisk[4] explore language model robustness to synthetic versus natural one-word substitutions and reach similar high-level results, ﬁnding there is limited robustness transfer between the two distributions. 7 Conclusion The goal of robust machine learning is to develop methods that function reliably in a wide variety of settings. So far, this research direction has focused mainly on synthetic perturbations of existing test sets, highlighting important failure cases and initiating progress towards more robust models. Ultimately, the hope is that the resulting techniques also provide beneﬁts on real data. Our paper takes a step in this direction and complements the current synthetic robustness tests with comprehensive experiments on distribution shifts arising from real data. We ﬁnd that current image classiﬁcation models still suﬀer from substantial accuracy drops on natural distribution shifts. Moreover, current robustness interventions – while eﬀective against 15synthetic perturbations – yield little to no consistent improvements on real data. The only approach providing broad beneﬁts is training on larger datasets, but the gains are small and inconsistent. Overall, our results show a clear challenge for future research. Even training on 1,000 times more data is far from closing the accuracy gaps, so robustness on real data will likely require new algorithmic ideas and better understanding of how training data aﬀects robustness. Our results indicate two immediate steps for work in this area: robustness metrics should control for baseline accuracy, and robust models should additionally be evaluated on natural distribution shifts. We hope that our comprehensive testbed with nuanced robustness metrics and multiple types of distribution shift will provide a clear indicator of progress on the path towards reliable machine learning on real data. Broader Impact Robustness is one of the key problems that prevents deploying machine learning in the real world and harnessing the associated beneﬁts. A canonical example is image classiﬁcation for medical diagnosis. As was found when researchers attempted to deploy a neural network to detect diabetes from retina images, “an accuracy assessment from a lab goes only so far. It says nothing of how the AI will perform in the chaos of a real-world environment” [3]. Similarly, researcher also found that current methods for chest X-ray classiﬁcation are brittle even in the absence of recognized confounders [110]. If models were robust, then this transfer to the real world would be straightforward. Unfortunately, achieving robustness on real data is still a substantial challenge for machine learning. Our work studies how robust current image classiﬁcation methods are to distribution shifts arising in real data. We hope that our paper will have a positive eﬀect on the study of distribution shifts and allow researchers to more accurately evaluate to what extent a proposed technique increases the robustness to particular forms of distribution shift. This will allow researchers to better understand how a deployed system will work in practice, without actually having to deploy it ﬁrst and users potentially suﬀering negative consequences. However, there are several potential ways in which our study could cause unintended harm. It is possible that our paper might be used as an argument to stop performing research on some synthetic forms of robustness, e.g., adversarial examples or common corruptions. This is not our intention. These forms of corruption are interesting independent of any correlation to existing natural distribution shift (e.g., adversarial examples are a genuine security problem). We only capture a small number of natural distribution shifts among all the possible distribution shifts. We selected these shifts because they have been used extensively in the literature and are concrete examples of the types of distribution shift we would like models to be robust to. It is likely that there are shifts that we do not capture, and so even if the shifts we deﬁne were to be completely solved, other shifts would remain a concern. One signiﬁcant form of distribution shift we do not evaluate is dataset bias in representing diﬀerent demographic groups. For example, the Inclusive Images dataset [ 75] attempts to correct for the geographical bias introduced in the Open Images dataset [51] by including a more balanced representation of images from Africa, Asia, and South America. Neglecting such implicit biases in the data distribution can harm underrepresented demographic groups. Ultimately, evaluating 16on ﬁxed datasets may not be enough, and validating the fairness and safety of deployable machine learning requires careful analysis in the application domain. Finally, more reliable machine learning can also enable negative uses cases, e.g., widespread surveil- lance or autonomous weapon systems. As with many technologies, these risks require careful regulation and awareness of unintended consequences arising from technological advances. Acknowledgements We would like to thank Logan Engstrom, Justin Gilmer, Moritz Hardt, Daniel Kang, Jerry Li, Percy Liang, Nelson Liu, John Miller, Preetum Nakkiran, Rebecca Roelofs, Aman Sinha, Jacob Steinhardt, and Dimitris Tsipras for helpful conversations while working on this paper. This research was generously supported in part by ONR awards N00014-17-1-2191, N00014-17-1- 2401, and N00014-18-1-2833, the DARPA Assured Autonomy (FA8750-18-C-0101) and Lagrange (W911NF-16-1-0552) programs, a Siemens Futuremakers Fellowship, an Amazon AWS AI Research Award. 17References [1] Atwood, J., Baljekar, P., Barnes, P., Batra, A., Breck, E., Chi, P., Doshi, T., Elliott, J., Kour, G., Gaur, A., Halpern, Y., Jicha, H., Long, M., Saxena, J., Singh, R., and Sculley., D. The Inclusive Images competition, 2018.=https://ai.googleblog.com/2018/09/introducing-inclusive- images-competition.html. [2] Barbu, A., Mayo, D., Alverio, J., Luo, W., Wang, C., Gutfreund, D., Tenenbaum, J., and Katz, B. Objectnet: A large-scale bias-controlled dataset for pushing the limits of object recognition models. InAdvances in Neural Information Processing Systems (NeurIPS), 2019. http://papers.nips.cc/paper/9142-objectnet-a-large-scale-bias-controlled-data set-for-pushing-the-limits-of-object-recognition-models . [3] Beede, E., Baylor, E., Hersh, F., Iurchenko, A., Wilcox, L., Ruamviboonsuk, P., and Var- doulakis, L. M. A human-centered evaluation of a deep learning system deployed in clinics for the detection of diabetic retinopathy. InCHI Conference on Human Factors in Computing Systems, 2020. https://dl.acm.org/doi/abs/10.1145/3313831.3376718. [4] Belinkov, Y. and Bisk, Y. Synthetic and natural noise both break neural machine translation. In International Conference on Learning Representations (ICLR), 2018. https://arxiv.org/ abs/1711.02173. [5] Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G., and Roli, F. Evasion attacks against machine learning at test time. InEuropean Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECMLPKDD), 2013. https://arxiv.org/abs/1708.06131. [6] Blanchard, G., Lee, G., and Scott, C. Generalizing from several related classiﬁcation tasks to a new unlabeled sample. InAdvances in Neural Information Processing Systems (NIPS), 2011. https://papers.nips.cc/paper/4312-generalizing-from-several-related-clas sification-tasks-to-a-new-unlabeled-sample . [7] Borji, A. Objectnet dataset: Reanalysis and correction, 2020.https://arxiv.org/abs/2004 .02042. [8] Bras, R. L., Swayamdipta, S., Bhagavatula, C., Zellers, R., Peters, M. E., Sabharwal, A., and Choi, Y. Adversarial ﬁlters of dataset biases. InInternational Conference on Machine Learning (ICML), 2020. https://arxiv.org/abs/2002.04108. [9] Carlini, N., Athalye, A., Papernot, N., Brendel, W., Rauber, J., Tsipras, D., Goodfellow, I., Madry, A., and Kurakin, A. On evaluating adversarial robustness, 2019.https://arxiv.org/ abs/1902.06705. [10] Carmon, Y., Raghunathan, A., Schmidt, L., Liang, P., and Duchi, J. C. Unlabeled data improves adversarial robustness. In Advances in Neural Information Processing Systems (NeurIPS), 2019. https://arxiv.org/abs/1905.13736. [11] Chen, Y., Li, J., Xiao, H., Jin, X., Yan, S., and Feng, J. Dual path networks. InAdvances in Neural Information Processing Systems (NeurIPS), 2017. https://arxiv.org/abs/1707.016 29. 18[12] Chollet, F. Xception: Deep learning with depthwise separable convolutions. InConference on Computer Vision and Pattern Recognition (CVPR), 2017. https://arxiv.org/abs/1610.0 2357. [13] Cohen, J. M., Rosenfeld, E., and Kolter, J. Z. Certiﬁed adversarial robustness via randomized smoothing. In International Conference on Machine Learning (ICML), 2019. https://arxiv. org/abs/1902.02918. [14] Crawford, K. and Paglen, T. Excavating AI: The politics of training sets for machine learning, 2019. https://www.excavating.ai/. [15] Cubuk, E. D., Zoph, B., Mane, D., Vasudevan, V., and Le, Q. V. Autoaugment: Learning augmentation policies from data. InConference on Computer Vision and Pattern Recognition (CVPR), 2019. https://arxiv.org/abs/1805.09501. [16] Cubuk, E. D., Zoph, B., Shlens, J., and Le, Q. V. Randaugment: Practical automated data augmentation with a reduced search space, 2019.https://arxiv.org/abs/1909.13719. [17] Dalal, N. and Triggs, B. Histograms of oriented gradients for human detection. InConference on Computer Vision and Pattern Recognition (CVPR), 2005. https://ieeexplore.ieee.or g/document/1467360. [18] Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L. ImageNet: A large-scale hierarchical image database. In Conference on Computer Vision and Pattern Recognition (CVPR), 2009. http://www.image-net.org/papers/imagenet_cvpr09.pdf. [19] Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. BERT: Pre-training of deep bidirectional transformers for language understanding. InConference of the North American Chapter of the Association for Computational Linguistics (ACL), 2019. https://www.aclweb.org/antholo gy/N19-1423/. [20] DeVries, T. and Taylor, G. W. Improved regularization of convolutional neural networks with cutout, 2017. https://arxiv.org/abs/1708.04552. [21] Djolonga, J., Yung, J., Tschannen, M., Romijnders, R., Beyer, L., Kolesnikov, A., Puigcerver, J., Minderer, M., D’Amour, A., Moldovan, D., Gelly, S., Houlsby, N., Zhai, X., and Lucic, M. On robustness and transferability of convolutional neural networks, 2020.https://arxiv.or g/abs/2007.08558. [22] Duchi, J. and Namkoong, H. Learning models with uniform performance via distributionally robust optimization. To appear in the Annals of Statistics, 2018. https://arxiv.org/abs/18 10.08750. [23] Duchi, J. and Namkoong, H. Variance-based regularization with convex objectives.Journal of Machine Learning Research (JMLR), 2019. https://arxiv.org/abs/1610.02581. [24] Duchi, J., Hashimoto, T., and Namkoong, H. Distributionally robust losses for latent covariate mixtures, 2019. https://arxiv.org/abs/2007.13982. [25] Dulhanty, C. and Wong, A. Auditing ImageNet: Towards a model-driven framework for annotating demographic attributes of large-scale image datasets, 2019.https://arxiv.org/ abs/1905.01347. 19[26] Dunn, M., Sagun, L., Higgins, M., Guney, V. U., Cirik, V., and Cho, K. Searchqa: A new q&a dataset augmented with context from a search engine, 2017.https://arxiv.org/abs/1704 .05179. [27] Engstrom, L., Ilyas, A., Santurkar, S., and Tsipras, D. Robustness (python library), 2019. URL https://github.com/MadryLab/robustness. [28] Engstrom, L., Tran, B., Tsipras, D., Schmidt, L., and Madry, A. Exploring the landscape of spatial robustness. InInternational Conference on Machine Learning (ICML), 2019. https: //arxiv.org/abs/1712.02779. [29] Fawzi, A. and Frossard, P. Manitest: Are classiﬁers really invariant? In BMVC, 2015. https://arxiv.org/abs/1507.06535. [30] Felzenszwalb, P. F., Girshick, R. B., McAllester, D., and Ramanan, D. Object detection with discriminatively trained part-based models.IEEE Transactions on Pattern Analysis and Machine Intelligence, 2010. https://ieeexplore.ieee.org/document/5255236. [31] Ford, N., Gilmer, J., Carlini, N., and Cubuk, E. D. Adversarial examples are a natural consequence of test error in noise. InInternational Conference on Machine Learning (ICML), 2019. http://arxiv.org/abs/1901.10513. [32] Galloway, A., Tanay, T., and Taylor, G. W. Adversarial training versus weight decay, 2018. https://arxiv.org/abs/1804.03308. [33] Geirhos, R., Temme, C. R. M., Rauber, J., Schütt, H. H., Bethge, M., and Wichmann, F. A. Generalisation in humans and deep neural networks. InAdvances in Neural Information Processing Systems (NeurIPS), 2018. https://papers.nips.cc/paper/7982-generalisati on-in-humans-and-deep-neural-networks . [34] Geirhos, R., Rubisch, P., Michaelis, C., Bethge, M., Wichmann, F. A., and Brendel, W. ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness. In International Conference on Learning Representations (ICLR), 2019. https://arxiv.org/abs/1811.12231. [35] Gu, K., Yang, B., Ngiam, J., Le, Q., and Shlens, J. Using videos to evaluate image model robustness. InSafeML workshop International Conference on Learning Representations (ICLR), 2019. https://arxiv.org/abs/1904.10076. [36] Gulrajani, I. and Lopez-Paz, D. In search of lost domain generalization, 2020. https: //arxiv.org/abs/2007.01434. [37] He, K., Zhang, X., Ren, S., and Sun, J. Deep residual learning for image recognition. In Conference on Computer Vision and Pattern Recognition (CVPR), 2016. https://arxiv.or g/abs/1512.03385. [38] Hendrycks, D. and Dietterich, T. Benchmarking neural network robustness to common corruptions and perturbations. In International Conference on Learning Representations (ICLR), 2019. https://arxiv.org/abs/1903.12261. [39] Hendrycks, D., Zhao, K., Basart, S., Steinhardt, J., and Song, D. Natural adversarial examples, 2019. https://arxiv.org/abs/1907.07174. 20[40] Hendrycks, D., Basart, S., Mu, N., Kadavath, S., Wang, F., Dorundo, E., Desai, R., Zhu, T., Parajuli, S., Guo, M., Song, D., Steinhardt, J., and Gilmer, J. The many faces of robustness: A critical analysis of out-of-distribution generalization, 2020.https://arxiv.org/abs/2006 .16241. [41] Hendrycks, D., Mu, N., Cubuk, E. D., Zoph, B., Gilmer, J., and Lakshminarayanan, B. AugMix: A simple data processing method to improve robustness and uncertainty. InInternational Conference on Learning Representations (ICLR), 2020.https://arxiv.org/abs/1912.02781. [42] Hu, J., Shen, L., Albanie, S., Sun, G., and Wu, E. Squeeze-and-excitation networks. In Conference on Computer Vision and Pattern Recognition (CVPR), 2018. https://arxiv.or g/abs/1709.01507. [43] Huang, G., Liu, Z., van der Maaten, L., and Weinberger, K. Q. Densely connected convolutional networks. InConference on Computer Vision and Pattern Recognition (CVPR), 2017. https: //arxiv.org/abs/1608.06993. [44] Huang, X. and Belongie, S. Arbitrary style transfer in real-time with adaptive instance normalization. International Conference on Computer Vision (ICCV), 2017. https://arxiv. org/abs/1703.06868. [45] Iandola, F. N., Han, S., Moskewicz, M. W., Ashraf, K., Dally, W. J., and Keutzer, K. SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size, 2016. https://arxiv.org/abs/1602.07360. [46] Ioﬀe, S. and Szegedy, C. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In International Conference on Machine Learning (ICML), 2015. https://arxiv.org/abs/1502.03167. [47] Kang, D., Sun, Y., Brown, T., Hendrycks, D., and Steinhardt, J. Transfer of adversarial robustness between perturbation types, 2019.https://arxiv.org/abs/1905.01034. [48] Kang, D., Sun, Y., Hendrycks, D., Brown, T., and Steinhardt, J. Testing robustness against unforeseen adversaries, 2019.https://arxiv.org/abs/1908.08016. [49] Kolesnikov, A., Beyer, L., Zhai, X., Puigcerver, J., Yung, J., Gelly, S., and Houlsby, N. Big transfer (bit): General visual representation learning, 2019.https://arxiv.org/abs/1912.1 1370. [50] Krizhevsky, A., Sutskever, I., and Hinton, G. E. Imagenet classiﬁcation with deep convolutional neural networks. InAdvances in Neural Information Processing Systems (NIPS), 2012. https: //papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional- neural-networks. [51] Kuznetsova, A., Rom, H., Alldrin, N., Uijlings, J., Krasin, I., Pont-Tuset, J., Kamali, S., Popov, S., Malloci, M., Kolesnikov, A., and et al. The open images dataset v4.International Journal of Computer Vision (IJCV), 2020. https://arxiv.org/abs/1811.00982. [52] Kwiatkowski, T., Palomaki, J., Redﬁeld, O., Collins, M., Parikh, A., Alberti, C., Epstein, D., Polosukhin, I., Devlin, J., Lee, K., et al. Natural questions: a benchmark for question 21answering research.Transactions of the Association for Computational Linguistics, 7:453–466, 2019. https://arxiv.org/abs/1712.00559. [53] Liu, C., Zoph, B., Neumann, M., Shlens, J., Hua, W., Li, L.-J., Fei-Fei, L., Yuille, A., Huang, J., and Murphy, K. Progressive neural architecture search. InEuropean Conference on Computer Vision (ECCV), 2018. https://arxiv.org/abs/1712.00559. [54] Ma, N., Zhang, X., Zheng, H.-T., and Sun, J. Shuﬄenet v2: Practical guidelines for eﬃcient cnn architecture design. In Proceedings of the European Conference on Computer Vision (ECCV), 2018. https://arxiv.org/abs/1807.11164. [55] Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A. Towards deep learning models resistant to adversarial attacks. InInternational Conference on Learning Representations (ICLR), 2018. https://arxiv.org/abs/1706.06083. [56] Mahajan, D. K., Girshick, R. B., Ramanathan, V., He, K., Paluri, M., Li, Y., Bharambe, A., and van der Maaten, L. Exploring the limits of weakly supervised pretraining. InEuropean Conference on Computer Vision (ECCV), 2018. https://arxiv.org/abs/1805.00932. [57] Maini, P., Wong, E., and Kolter, J. Z. Adversarial robustness against the union of multiple perturbation models, 2019.https://arxiv.org/abs/1909.04068. [58] Miller, J., Krauth, K., Recht, B., and Schmidt, L. The eﬀect of natural distribution shift on question answering models. InInternational Conference on Machine Learning (ICML), 2020. https://arxiv.org/abs/2004.14444. [59] Mitchell, M., Wu, S., Zaldivar, A., Barnes, P., Vasserman, L., Hutchinson, B., Spitzer, E., Raji, I. D., and Gebru, T. Model cards for model reporting. InConference on Fairness, Accountability, and Transparency (FAT), 2019. https://arxiv.org/abs/1810.03993. [60] Muandet, K., Balduzzi, D., and Schölkopf, B. Domain generalization via invariant feature representation. In International Conference on Machine Learning (ICML), 2013. https: //arxiv.org/abs/1301.2115. [61] Najaﬁ, A., Maeda, S.-i., Koyama, M., and Miyato, T. Robustness to adversarial perturbations in learning from incomplete data. InAdvances in Neural Information Processing Systems (NeurIPS), 2019. https://arxiv.org/abs/1905.13021. [62] Oren, Y., Sagawa, S., Hashimoto, T. B., and Liang, P. Distributionally robust language modeling. In Conference on Empirical Methods in Natural Language Processing (EMNLP), 2019. https://arxiv.org/abs/1909.02060. [63] Orhan, A. E. Robustness properties of facebook’s resnext wsl models, 2019.https://arxiv. org/abs/1907.07640. [64] Pan, S. J. and Yang, Q. A survey on transfer learning.IEEE Transactions on Knowledge and Data Engineering, 2010. https://ieeexplore.ieee.org/document/5288526. [65] Quionero-Candela, J., Sugiyama, M., Schwaighofer, A., and Lawrence, N. D.Dataset Shift in Machine Learning. The MIT Press, 2009. 22[66] Raghunathan, A., Steinhardt, J., and Liang, P. Certiﬁed defenses against adversarial examples. In International Conference on Learning Representations (ICLR), 2018. https://arxiv.org/ abs/1801.09344. [67] Real, E., Shlens, J., Mazzocchi, S., Pan, X., and Vanhoucke, V. Youtube-boundingboxes: A large high-precision human-annotated data set for object detection in video. InCVPR, 2017. [68] Recht, B., Roelofs, R., Schmidt, L., and Shankar, V. Do imagenet classiﬁers generalize to imagenet? In International Conference on Machine Learning (ICML), 2019. https: //arxiv.org/abs/1902.10811. [69] Rowley, H. A., Baluja, S., and Kanade, T. Human face detection in visual scenes. InAdvances in Neural Information Processing Systems (NIPS). 1996. https://papers.nips.cc/paper/1 168-human-face-detection-in-visual-scenes . [70] Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A. C., and Fei-Fei, L. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision, 2015. https://arxiv.or g/abs/1409.0575. [71] Sagawa, S., Koh, P. W., Hashimoto, T. B., and Liang, P. Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization. In International Conference on Learning Representations (ICLR), 2020. https://arxiv.org/ abs/1911.08731. [72] Salman, H., Yang, G., Li, J., Zhang, P., Zhang, H., Razenshteyn, I., and Bubeck, S. Provably robust deep learning via adversarially trained smoothed classiﬁers. InAdvances in Neural Information Processing Systems (NeurIPS), 2019. https://arxiv.org/abs/1906.04584. [73] Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., and Chen, L.-C. Mobilenetv2: Inverted residuals and linear bottlenecks. InConference on Computer Vision and Pattern Recognition (CVPR), 2018. https://arxiv.org/abs/1801.04381. [74] Shafahi, A., Najibi, M., Ghiasi, A., Xu, Z., Dickerson, J., Studer, C., Davis, L. S., Taylor, G., and Goldstein, T. Adversarial training for free! InAdvances in Neural Information Processing Systems (NeurIPS), 2019. https://arxiv.org/abs/1904.12843. [75] Shankar, S., Halpern, Y., Breck, E., Atwood, J., Wilson, J., and Sculley, D. No classiﬁcation without representation: Assessing geodiversity issues in open data sets for the developing world, 2017.https://arxiv.org/abs/1711.08536. [76] Shankar, V., Dave, A., Roelofs, R., Ramanan, D., Recht, B., and Schmidt, L. Do image classiﬁers generalize across time?, 2019.https://arxiv.org/abs/1906.02168. [77] Shankar, V., Roelofs, R., Mania, H., Fang, A., Recht, B., and Schmidt, L. Evaluating machine accuracy on imagenet. InInternational Conference on Machine Learning (ICML), 2020. [78] Simonyan, K. and Zisserman, A. Very deep convolutional networks for large-scale image recognition. In International Conference on Learning Representations (ICLR), 2015. https: //arxiv.org/abs/1409.1556. 23[79] Sinha, A., Namkoong, H., Volpi, R., and Duchi, J. Certifying some distributional robustness with principled adversarial training. InInternational Conference on Learning Representations (ICLR), 2018. https://arxiv.org/abs/1710.10571. [80] Sperber, M., Niehues, J., and Waibel, A. Toward robust neural machine translation for noisy input sequences. InInternational Workshop on Spoken Language Translation (IWSLT), 2017. http://workshop2017.iwslt.org/downloads/P04-Paper.pdf. [81] Srivastava, M., Hashimoto, T., and Liang, P. Robustness to spurious correlations via human annotations. In International Conference on Machine Learning (ICML), 2020. https://arxi v.org/abs/2007.06661. [82] Sun, C., Shrivastava, A., Singh, S., and Gupta, A. Revisiting unreasonable eﬀectiveness of data in deep learning era. InInternational Conference on Computer Vision (ICCV), 2017. https://arxiv.org/abs/1707.02968. [83] Sung, K. . and Poggio, T. Example-based learning for view-based human face detection.IEEE Transactions on Pattern Analysis and Machine Intelligence, 1998. https://ieeexplore.ieee. org/document/655648. [84] Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., and Fer- gus, R. Intriguing properties of neural networks. InInternational Conference on Learning Representations (ICLR), 2014. https://arxiv.org/abs/1312.6199. [85] Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V., and Rabinovich, A. Going deeper with convolutions. InConference on Computer Vision and Pattern Recognition (CVPR), 2015. https://arxiv.org/abs/1409.4842v1. [86] Szegedy, C., Vanhoucke, V., Ioﬀe, S., Shlens, J., and Wojna, Z. Rethinking the inception architecture for computer vision. InConference on Computer Vision and Pattern Recognition (CVPR), 2016. https://arxiv.org/abs/1512.00567. [87] Szegedy, C., Ioﬀe, S., Vanhoucke, V., and Alemi, A. Inception-v4, inception-resnet and the impact of residual connections on learning. InAAAI Conference on Artiﬁcial Intelligence (AAAI), 2017. https://arxiv.org/abs/1602.07261. [88] Tan, M. and Le, Q. V. Eﬃcientnet: Rethinking model scaling for convolutional neural networks. In International Conference on Machine Learning (ICML), 2019. https://arxiv.org/abs/ 1905.11946. [89] Tan, M., Chen, B., Pang, R., Vasudevan, V., Sandler, M., Howard, A., and Le, Q. V. Mnasnet: Platform-aware neural architecture search for mobile. InConference on Computer Vision and Pattern Recognition (CVPR), 2019. https://arxiv.org/abs/1807.11626. [90] Taori, R., Dave, A., Shankar, V., Carlini, N., Recht, B., and Schmidt, L. When robustness doesn’t promote robustness: Synthetic vs. natural distribution shifts on imagenet, 2019. https://openreview.net/pdf?id=HyxPIyrFvH. [91] Torralba, A., Efros, A. A., et al. Unbiased look at dataset bias. InConference on Computer Vision and Pattern Recognition (CVPR), 2011. https://ieeexplore.ieee.org/document/5 995347. 24[92] Touvron, H., Vedaldi, A., Douze, M., and Jégou, H. Fixing the train-test resolution discrepancy. In Advances in Neural Information Processing Systems (NeurIPS), 2019. https://arxiv.or g/abs/1906.06423. [93] Tramer, F. and Boneh, D. Adversarial training and robustness for multiple perturbations. In Advances in Neural Information Processing Systems (NeurIPS), 2019. https://arxiv.org/ abs/1904.13000. [94] Uesato, J., Alayrac, J.-B., Huang, P.-S., Stanforth, R., Fawzi, A., and Kohli, P. Are labels required for improving adversarial robustness? InAdvances in Neural Information Processing Systems (NeurIPS), 2019. https://arxiv.org/abs/1905.13725. [95] Wang, H., Ge, S., Xing, E. P., and Lipton, Z. C. Learning robust global representations by penalizing local predictive power. In Advances in Neural Information Processing Systems (NeurIPS), 2019. https://arxiv.org/abs/1905.13549. [96] Wong, E., Schmidt, F. R., and Kolter, J. Z. Wasserstein adversarial examples via projected sinkhorn iterations. InInternational Conference on Machine Learning (ICML), 2019. https: //arxiv.org/abs/1902.07906. [97] Wu, B., Chen, W., Fan, Y., Zhang, Y., Hou, J., Liu, J., and Zhang, T. Tencent ml- images: A large-scale multi-label image database for visual representation learning.IEEE Access, 7:172683–172693, 2019. ISSN 2169-3536. doi: 10.1109/access.2019.2956775. URL http://dx.doi.org/10.1109/ACCESS.2019.2956775. [98] Wu, B., Chen, W., Fan, Y., Zhang, Y., Hou, J., Liu, J., and Zhang, T. Tencent ml-images: A large-scale multi-label image database for visual representation learning.IEEE Access, 7, 2019. [99] Wu, W. Classifying images into 11k classes with pretrained model, 2016.https://github.c om/tornadomeet/ResNet and https://github.com/awslabs/deeplearning-benchmark/bl ob/master/image_classification/common/modelzoo.py#L41. [100] Xie, C., Tan, M., Gong, B., Wang, J., Yuille, A., and Le, Q. V. Adversarial examples improve image recognition, 2019.https://arxiv.org/abs/1911.09665. [101] Xie, C., Wu, Y., van der Maaten, L., Yuille, A., and He, K. Feature denoising for improving adversarial robustness. InConference on Computer Vision and Pattern Recognition (CVPR), 2019. https://arxiv.org/abs/1812.03411. [102] Xie, Q., Luong, M.-T., Hovy, E., and Le, Q. V. Self-training with noisy student improves imagenet classiﬁcation. InConference on Computer Vision and Pattern Recognition (CVPR), 2019. https://arxiv.org/abs/1911.04252. [103] Xie, S., Girshick, R., Dollár, P., Tu, Z., and He, K. Aggregated residual transformations for deep neural networks. InConference on Computer Vision and Pattern Recognition (CVPR), 2016. https://arxiv.org/abs/1611.05431. [104] Yalniz, I. Z., Jégou, H., Chen, K., Paluri, M., and Mahajan, D. Billion-scale semi-supervised learning for image classiﬁcation, 2019.https://arxiv.org/abs/1905.00546. [105] Yang, F., Wang, Z., and Heinze-Deml, C. Invariance-inducing regularization using worst-case 25transformations suﬃces to boost accuracy and spatial robustness. InAdvances in Neural Information Processing Systems (NeurIPS), 2019. https://arxiv.org/abs/1906.11235. [106] Yang, Z., Qi, P., Zhang, S., Bengio, Y., Cohen, W., Salakhutdinov, R., and Manning, C. D. Hotpotqa: A dataset for diverse, explainable multi-hop question answering. InConference on Empirical Methods in Natural Language Processing (EMNLP), 2018. https://arxiv.org/ab s/1809.09600. [107] Yin, D., Lopes, R. G., Shlens, J., Cubuk, E. D., and Gilmer, J. A fourier perspective on model robustness in computer vision. InAdvances in Neural Information Processing Systems (NeurIPS), 2019. https://arxiv.org/abs/1906.08988. [108] Yun, S., Han, D., Oh, S. J., Chun, S., Choe, J., and Yoo, Y. Cutmix: Regularization strategy to train strong classiﬁers with localizable features. InInternational Conference on Computer Vision (ICCV), 2019. https://arxiv.org/abs/1905.04899. [109] Zagoruyko, S. and Komodakis, N. Wide residual networks. In British Machine Vision Conference (BMVC), 2016. https://arxiv.org/abs/1605.07146. [110] Zech, J., Badgeley, M. A., Liu, M., Costa, A. B., Titano, J. J., and Oermann, E. K. Variable generalization performance of a deep learning model to detect pneumonia in chest radiographs: A cross-sectional study.PLOS Medicine, 2018. https://www.ncbi.nlm.nih.gov/pmc/artic les/PMC6219764. [111] Zellers, R., Bisk, Y., Schwartz, R., and Choi, Y. SWAG: A large-scale adversarial dataset for grounded commonsense inference. InEmpirical Methods in Natural Language Processing (EMNLP), 2018. https://www.aclweb.org/anthology/D18-1009/. [112] Zhai, X., Puigcerver, J., Kolesnikov, A., Ruyssen, P., Riquelme, C., Lucic, M., Djolonga, J., Pinto, A. S., Neumann, M., Dosovitskiy, A., Beyer, L., Bachem, O., Tschannen, M., Michalski, M., Bousquet, O., Gelly, S., and Houlsby, N. The visual task adaptation benchmark, 2019. https://arxiv.org/abs/1910.04867. [113] Zhang, H., Cisse, M., Dauphin, Y. N., and Lopez-Paz, D. mixup: Beyond empirical risk minimization. In International Conference on Learning Representations (ICLR), 2017. https: //arxiv.org/abs/1710.09412. [114] Zhang, H., Yu, Y., Jiao, J., Xing, E., Ghaoui, L. E., and Jordan, M. I. Theoretically principled trade-oﬀ between robustness and accuracy. InInternational Conference on Machine Learning (ICML), 2019. http://proceedings.mlr.press/v97/zhang19p.html. [115] Zhang, R. Making convolutional networks shift-invariant again. InInternational Conference on Machine Learning (ICML), 2019. https://arxiv.org/abs/1904.11486. [116] Zhang, X., Li, Z., Loy, C. C., and Lin, D. Polynet: A pursuit of structural diversity in very deep networks. InConference on Computer Vision and Pattern Recognition (CVPR), 2016. https://arxiv.org/abs/1611.05725. [117] Zoph, B., Vasudevan, V., Shlens, J., and Le, Q. V. Learning transferable architectures for scalable image recognition. In Conference on Computer Vision and Pattern Recognition (CVPR), 2018. https://arxiv.org/abs/1707.07012. 26A Testbed overview greyscale imagenet-a imagenet-c.brightness.1_in-memory imagenet-c.brightness.1_on-disk imagenet-c.brightness.2_in-memory imagenet-c.brightness.2_on-disk imagenet-c.brightness.3_in-memory imagenet-c.brightness.3_on-disk imagenet-c.brightness.4_in-memory imagenet-c.brightness.4_on-disk imagenet-c.brightness.5_in-memory imagenet-c.brightness.5_on-disk imagenet-c.contrast.1_in-memory imagenet-c.contrast.1_on-disk imagenet-c.contrast.2_in-memory imagenet-c.contrast.2_on-disk imagenet-c.contrast.3_in-memory imagenet-c.contrast.3_on-disk imagenet-c.contrast.4_in-memory imagenet-c.contrast.4_on-disk imagenet-c.contrast.5_in-memory imagenet-c.contrast.5_on-disk imagenet-c.defocus_blur.1_in-memory imagenet-c.defocus_blur.1_on-disk imagenet-c.defocus_blur.2_in-memory imagenet-c.defocus_blur.2_on-disk imagenet-c.defocus_blur.3_in-memory imagenet-c.defocus_blur.3_on-disk imagenet-c.defocus_blur.4_in-memory imagenet-c.defocus_blur.4_on-disk imagenet-c.defocus_blur.5_in-memory imagenet-c.defocus_blur.5_on-disk imagenet-c.elastic_transform.1_in-memory imagenet-c.elastic_transform.1_on-disk imagenet-c.elastic_transform.2_in-memory imagenet-c.elastic_transform.2_on-disk imagenet-c.elastic_transform.3_in-memory imagenet-c.elastic_transform.3_on-disk imagenet-c.elastic_transform.4_in-memory imagenet-c.elastic_transform.4_on-disk imagenet-c.elastic_transform.5_in-memory imagenet-c.elastic_transform.5_on-disk imagenet-c.fog.1_in-memory imagenet-c.fog.1_on-disk imagenet-c.fog.2_in-memory imagenet-c.fog.2_on-disk imagenet-c.fog.3_in-memory imagenet-c.fog.3_on-disk imagenet-c.fog.4_in-memory imagenet-c.fog.4_on-disk imagenet-c.fog.5_in-memory imagenet-c.fog.5_on-disk imagenet-c.frost.1_in-memory imagenet-c.frost.1_on-disk imagenet-c.frost.2_in-memory imagenet-c.frost.2_on-disk imagenet-c.frost.3_in-memory imagenet-c.frost.3_on-disk imagenet-c.frost.4_in-memory imagenet-c.frost.4_on-disk imagenet-c.frost.5_in-memory imagenet-c.frost.5_on-disk imagenet-c.gaussian_blur.1_in-memory imagenet-c.gaussian_blur.1_on-disk imagenet-c.gaussian_blur.2_in-memory imagenet-c.gaussian_blur.2_on-disk imagenet-c.gaussian_blur.3_in-memory imagenet-c.gaussian_blur.3_on-disk imagenet-c.gaussian_blur.4_in-memory imagenet-c.gaussian_blur.4_on-disk imagenet-c.gaussian_blur.5_in-memory imagenet-c.gaussian_blur.5_on-disk imagenet-c.gaussian_noise.1_in-memory imagenet-c.gaussian_noise.1_on-disk imagenet-c.gaussian_noise.2_in-memory imagenet-c.gaussian_noise.2_on-disk imagenet-c.gaussian_noise.3_in-memory imagenet-c.gaussian_noise.3_on-disk imagenet-c.gaussian_noise.4_in-memory imagenet-c.gaussian_noise.4_on-disk imagenet-c.gaussian_noise.5_in-memory imagenet-c.gaussian_noise.5_on-disk imagenet-c.glass_blur.1_on-disk imagenet-c.glass_blur.2_on-disk imagenet-c.glass_blur.3_on-disk imagenet-c.glass_blur.4_on-disk imagenet-c.glass_blur.5_on-disk imagenet-c.impulse_noise.1_in-memory imagenet-c.impulse_noise.1_on-disk imagenet-c.impulse_noise.2_in-memory imagenet-c.impulse_noise.2_on-disk imagenet-c.impulse_noise.3_in-memory imagenet-c.impulse_noise.3_on-disk imagenet-c.impulse_noise.4_in-memory imagenet-c.impulse_noise.4_on-disk imagenet-c.impulse_noise.5_in-memory imagenet-c.impulse_noise.5_on-disk imagenet-c.jpeg_compression.1_in-memory imagenet-c.jpeg_compression.1_on-disk imagenet-c.jpeg_compression.2_in-memory imagenet-c.jpeg_compression.2_on-disk imagenet-c.jpeg_compression.3_in-memory imagenet-c.jpeg_compression.3_on-disk imagenet-c.jpeg_compression.4_in-memory imagenet-c.jpeg_compression.4_on-disk imagenet-c.jpeg_compression.5_in-memory imagenet-c.jpeg_compression.5_on-disk imagenet-c.motion_blur.1_in-memory imagenet-c.motion_blur.1_on-disk imagenet-c.motion_blur.2_in-memory imagenet-c.motion_blur.2_on-disk imagenet-c.motion_blur.3_in-memory imagenet-c.motion_blur.3_on-disk imagenet-c.motion_blur.4_in-memory imagenet-c.motion_blur.4_on-disk imagenet-c.motion_blur.5_in-memory imagenet-c.motion_blur.5_on-disk imagenet-c.pixelate.1_in-memory imagenet-c.pixelate.1_on-disk imagenet-c.pixelate.2_in-memory imagenet-c.pixelate.2_on-disk imagenet-c.pixelate.3_in-memory imagenet-c.pixelate.3_on-disk imagenet-c.pixelate.4_in-memory imagenet-c.pixelate.4_on-disk imagenet-c.pixelate.5_in-memory imagenet-c.pixelate.5_on-disk imagenet-c.saturate.1_in-memory imagenet-c.saturate.1_on-disk imagenet-c.saturate.2_in-memory imagenet-c.saturate.2_on-disk imagenet-c.saturate.3_in-memory imagenet-c.saturate.3_on-disk imagenet-c.saturate.4_in-memory imagenet-c.saturate.4_on-disk imagenet-c.saturate.5_in-memory imagenet-c.saturate.5_on-disk imagenet-c.shot_noise.1_in-memory imagenet-c.shot_noise.1_on-disk imagenet-c.shot_noise.2_in-memory imagenet-c.shot_noise.2_on-disk imagenet-c.shot_noise.3_in-memory imagenet-c.shot_noise.3_on-disk imagenet-c.shot_noise.4_in-memory imagenet-c.shot_noise.4_on-disk imagenet-c.shot_noise.5_in-memory imagenet-c.shot_noise.5_on-disk imagenet-c.snow.1_in-memory imagenet-c.snow.1_on-disk imagenet-c.snow.2_in-memory imagenet-c.snow.2_on-disk imagenet-c.snow.3_in-memory imagenet-c.snow.3_on-disk imagenet-c.snow.4_in-memory imagenet-c.snow.4_on-disk imagenet-c.snow.5_in-memory imagenet-c.snow.5_on-disk imagenet-c.spatter.1_in-memory imagenet-c.spatter.1_on-disk imagenet-c.spatter.2_in-memory imagenet-c.spatter.2_on-disk imagenet-c.spatter.3_in-memory imagenet-c.spatter.3_on-disk imagenet-c.spatter.4_in-memory imagenet-c.spatter.4_on-disk imagenet-c.spatter.5_in-memory imagenet-c.spatter.5_on-disk imagenet-c.speckle_noise.1_in-memory imagenet-c.speckle_noise.1_on-disk imagenet-c.speckle_noise.2_in-memory imagenet-c.speckle_noise.2_on-disk imagenet-c.speckle_noise.3_in-memory imagenet-c.speckle_noise.3_on-disk imagenet-c.speckle_noise.4_in-memory imagenet-c.speckle_noise.4_on-disk imagenet-c.speckle_noise.5_in-memory imagenet-c.speckle_noise.5_on-disk imagenet-c.zoom_blur.1_in-memory imagenet-c.zoom_blur.1_on-disk imagenet-c.zoom_blur.2_in-memory imagenet-c.zoom_blur.2_on-disk imagenet-c.zoom_blur.3_in-memory imagenet-c.zoom_blur.3_on-disk imagenet-c.zoom_blur.4_in-memory imagenet-c.zoom_blur.4_on-disk imagenet-c.zoom_blur.5_in-memory imagenet-c.zoom_blur.5_on-disk imagenet-r imagenet-sketch imagenet-vid-robust_pm0 imagenet-vid-robust_pm10 imagenetv2-matched-frequency imagenetv2-matched-frequency-format-val imagenetv2-matched-frequency-format-val_subsampled_class_1_8 imagenetv2-threshold-0.7-format-val imagenetv2-threshold0.7 imagenetv2-top-images-format-val imagenetv2-topimages objectnet-1.0-beta pgd.l2.eps0.1 pgd.l2.eps0.5 pgd.linf.eps0.5 pgd.linf.eps2 stylized_imagenet val val-on-imagenet-a-classes val-on-imagenet-r-classes val-on-objectnet-classes val-on-vid-robust-classes val-on-ytbb-robust-classes val_subsampled_class_1_8 ytbb-robust_pm0 ytbb-robust_pm10 Evaluation Setting efficientnet-l2-noisystudent FixResNeXt101_32x48d_v2 FixResNeXt101_32x48d instagram-resnext101_32x48d efficientnet-b8-advprop-autoaug BiT-M-R152x4-ILSVRC2012 efficientnet-b7-advprop-autoaug instagram-resnext101_32x32d BiT-M-R101x3-ILSVRC2012 efficientnet-b6-advprop-autoaug efficientnet-b7-randaug efficientnet-b7-autoaug efficientnet-b5-advprop-autoaug resnext101_32x8d_swsl instagram-resnext101_32x16d BiT-M-R50x3-ILSVRC2012 efficientnet-b6-autoaug FixPNASNet efficientnet-b5-autoaug efficientnet-b5-randaug resnext101_32x4d_swsl efficientnet-b5 pnasnet5large instagram-resnext101_32x8d efficientnet-b4-advprop-autoaug efficientnet-b4-autoaug BiT-M-R101x1-ILSVRC2012 nasnetalarge efficientnet-b4 resnext50_32x4d_swsl resnext101_32x16d_ssl resnext101_32x8d_ssl senet154 resnet50_swsl efficientnet-b3-advprop-autoaug efficientnet-b3-autoaug resnext101_32x4d_ssl polynet BiT-M-R50x1-ILSVRC2012 resnext50_32x4d_ssl inceptionresnetv2 se_resnext101_32x4d efficientnet-b3 inceptionv4 resnext101_32x8d_deepaugment_augmix resnet101_cutmix efficientnet-b2-autoaug FixResNet50CutMix_v2 dpn107 FixResNet50CutMix efficientnet-b2-advprop-autoaug dpn131 dpn92 resnext101_32x8d resnet50_ssl dpn98 google_resnet101_jft-300M FixResNet50_v2 se_resnext50_32x4d FixResNet50 resnext101_64x4d efficientnet-b2 wide_resnet101_2 xception efficientnet-b1-autoaug se_resnet152 resnet50_cutmix efficientnet-b1-advprop-autoaug wide_resnet50_2 se_resnet101 resnet152 resnet101-tencent-ml-images resnet50_feature_cutmix resnext101_32x4d resnet101_lpf3 efficientnet-b1 resnet101_lpf5 resnet101_lpf2 se_resnet50 resnext50_32x4d resnet50_augmix resnet50_mixup fbresnet152 resnet101 inceptionv3 densenet161 efficientnet-b0-advprop-autoaug resnet50_cutout FixResNet50_no_adaptation dpn68b resnet50_lpf5 densenet201 efficientnet-b0-autoaug resnet50_lpf3 resnet50_lpf2 resnet50_trained_on_SIN_and_IN_then_finetuned_on_IN resnet50_deepaugment efficientnet-b0 resnet50-vtab-rotation cafferesnet101 resnet152-imagenet11k resnet50_aws_baseline resnet50 resnet50_imagenet_100percent_batch64_original_images dpn68 resnet50_deepaugment_augmix resnet50-randomized_smoothing_noise_0.00 densenet169 resnet50-vtab resnet50_with_brightness_aws resnet50_with_spatter_aws densenet121_lpf3 densenet121_lpf5 densenet121_lpf2 resnet50_with_saturate_aws resnet50_trained_on_SIN_and_IN resnet34_lpf2 densenet121 resnet34_lpf3 vgg19_bn resnet34_lpf5 resnet50-vtab-exemplar nasnetamobile vgg16_bn_lpf5 vgg16_bn_lpf2 vgg16_bn_lpf3 resnet50_with_frost_aws resnet50_with_jpeg_compression_aws bninception mnasnet1_0 vgg16_bn resnet34 resnet18_swsl resnet50_with_gaussian_noise_aws resnet50_with_gaussian_noise_contrast_motion_blur_jpeg_compression_aws mobilenet_v2_lpf2 resnet18_ssl mobilenet_v2_lpf3 mobilenet_v2_lpf5 vgg19 vgg16_lpf5 vgg16_lpf3 vgg16_lpf2 resnet50_with_contrast_aws mobilenet_v2 resnet50_with_fog_aws resnet18_lpf3 vgg16 vgg13_bn resnet18_lpf2 resnet18_lpf5 resnet18-rotation-standard_40 resnet50_imagenet_subsample_1_of_2_batch64_original_images vgg11_bn resnet50-randomized_smoothing_noise_0.25 vgg13 googlenet/inceptionv1 resnet18 shufflenet_v2_x1_0 resnet18-rotation-worst10_30 vgg11 resnet18-rotation-random_30 resnet18-rotation-worst10_40 resnet50_with_pixelate_aws resnet18-rotation-random_40 facebook_adv_trained_resnext101_denoiseAll resnet50-smoothing_adversarial_DNN_2steps_eps_512_noise_0.25 mnasnet0_5 resnet50_with_motion_blur_aws resnet18-rotation-nocrop_40 facebook_adv_trained_resnet152_denoise bninception-imagenet21k resnet50-randomized_smoothing_noise_0.50 resnet50_with_greyscale_aws resnet50_imagenet_subsample_1_of_4_batch64_original_images resnet50_linf_eps4_robust facebook_adv_trained_resnet152_baseline resnet50-smoothing_adversarial_DNN_2steps_eps_512_noise_0.50 resnet50-vtab-semi-exemplar resnet50_with_zoom_blur_aws resnet50-vtab-semi-rotation shufflenet_v2_x0_5 resnet50_adv-train-free resnet50-smoothing_adversarial_PGD_1step_eps_512_noise_0.25 resnet50_trained_on_SIN squeezenet1_1 squeezenet1_0 resnet50_l2_eps3_robust alexnet_lpf2 alexnet_lpf3 alexnet_lpf5 alexnet resnet50-smoothing_adversarial_PGD_1step_eps_512_noise_0.50 resnet50-randomized_smoothing_noise_1.00 resnet50-smoothing_adversarial_DNN_2steps_eps_512_noise_1.00 resnet50_imagenet_subsample_1_of_8_batch64_original_images resnet50_linf_eps8_robust resnet50-smoothing_adversarial_PGD_1step_eps_512_noise_1.00 resnet50_imagenet_subsample_1_of_16_batch64_original_images resnet50_with_defocus_blur_aws resnet50_imagenet_subsample_1_of_32_batch64_original_images resnet50_imagenet_subsample_125_classes_batch64_original_images resnet50_imagenet_subsample_250_classes_batch64_original_images resnet50_imagenet_subsample_500_classes_batch64_original_images Model 87 85 75 48 88 82 80 81 94 86 85 88 88 68 50 88 99 98 93 1e+02 1e+02 97 68 64 83 68 86 82 86 81 85 80 84 78 82 75 86 79 85 77 84 72 81 53 72 25 83 74 80 67 72 52 62 38 51 27 85 79 74 58 75 67 64 53 39 24 86 78 85 75 85 70 83 65 79 50 80 74 71 62 63 52 61 50 56 44 85 80 82 71 76 57 67 43 45 21 83 77 80 72 75 62 64 47 44 26 68 54 25 17 9.4 75 72 75 65 72 59 61 45 45 27 82 75 81 73 80 70 75 63 69 53 84 77 81 70 74 56 63 40 54 30 83 78 83 76 77 71 72 62 69 54 86 80 83 76 86 81 82 77 77 70 83 76 79 70 73 60 58 41 44 27 76 72 70 57 70 59 61 49 58 41 85 81 82 76 77 71 68 64 62 54 83 77 81 75 73 64 67 55 57 44 74 68 65 58 60 50 52 43 45 36 80 59 86 72 78 78 93 84 84 87 87 58 38 86 98 97 90 1e+02 1e+02 96 69 58 83 69 86 82 86 81 85 80 83 78 82 75 86 79 85 77 84 72 81 53 72 25 83 74 80 67 72 52 62 38 51 27 85 79 73 58 75 67 64 53 39 23 86 78 85 75 84 70 83 65 79 50 80 74 71 62 63 52 61 50 56 44 85 80 82 71 76 57 67 43 45 21 83 77 80 72 75 62 63 47 43 26 68 54 25 17 9.3 75 72 74 65 72 59 61 45 44 27 82 75 81 73 80 70 76 63 69 53 84 77 81 70 74 56 63 40 54 30 83 78 83 76 78 71 72 62 70 54 86 80 83 76 86 81 82 77 77 70 82 76 79 70 73 60 58 41 44 27 76 72 70 57 70 59 61 48 58 41 84 81 81 76 77 71 68 64 62 54 83 77 81 74 73 63 67 55 57 44 74 68 65 58 60 50 52 43 45 36 80 59 86 72 78 78 93 85 84 88 87 58 37 86 98 97 90 1e+02 1e+02 96 69 58 81 61 85 82 85 82 84 81 83 79 80 76 85 80 84 78 83 75 79 60 67 32 80 76 75 71 64 59 52 47 40 36 82 79 62 58 71 69 59 57 33 29 84 78 83 76 81 71 79 65 70 50 79 75 69 64 60 55 58 53 52 47 84 80 79 74 70 64 58 52 35 30 81 78 77 74 70 66 57 53 36 34 71 60 34 25 15 73 73 71 68 67 64 54 51 37 35 79 78 77 76 75 74 70 68 62 59 83 78 78 73 68 61 54 47 44 37 79 79 80 78 73 74 66 67 64 61 85 81 82 77 85 82 81 77 76 71 81 78 76 72 68 64 51 48 36 34 75 73 68 59 69 60 60 50 56 45 84 81 80 77 77 70 67 64 60 54 81 78 79 76 69 67 61 59 50 49 85 70 66 61 59 53 51 46 46 38 80 59 85 73 77 77 92 84 84 87 87 59 57 12 18 9.4 39 85 98 97 89 1e+02 99 96 68 57 83 47 85 83 85 82 84 81 84 80 82 77 84 80 83 78 81 72 71 49 42 16 84 76 82 71 80 59 78 46 74 33 85 79 80 63 84 74 81 65 72 37 83 78 82 75 81 70 80 65 76 51 82 78 76 68 69 59 67 57 62 50 85 80 83 73 81 63 78 49 70 29 84 81 84 78 82 72 79 62 69 42 76 67 39 28 17 83 78 82 75 79 73 72 63 61 45 85 80 84 79 84 78 84 75 82 71 85 80 84 76 83 66 80 51 78 40 85 81 85 79 84 76 83 70 83 66 85 82 85 81 85 82 83 80 80 76 84 80 83 77 82 72 78 58 72 44 80 78 76 66 74 68 66 59 64 49 85 82 83 79 82 77 80 74 77 68 85 81 84 79 82 74 81 69 78 61 76 73 70 66 61 59 53 52 44 43 58 46 83 73 76 76 92 83 83 86 86 53 47 85 97 97 89 1e+02 1e+02 96 68 60 80 59 85 79 84 79 83 78 81 75 79 72 85 77 84 76 83 71 78 55 69 26 80 71 77 66 72 55 66 43 59 32 84 75 77 56 77 65 69 53 49 24 84 75 83 72 80 67 76 62 69 50 82 75 76 66 71 58 70 56 66 50 83 76 79 69 74 57 70 46 57 26 82 76 80 73 76 66 70 55 58 38 67 56 28 20 15 79 74 77 70 76 66 69 55 59 41 81 75 79 74 79 73 77 68 73 62 82 75 80 69 76 60 68 47 62 38 82 77 82 76 80 72 77 62 76 53 83 75 81 74 84 77 80 72 75 66 82 76 79 71 76 65 68 51 59 40 78 73 73 61 71 63 62 54 61 46 84 78 82 74 81 72 74 70 68 64 83 76 81 74 77 67 73 61 68 53 75 68 68 61 58 53 51 47 42 39 55 43 86 73 75 75 92 82 82 85 85 50 37 85 98 97 90 1e+02 99 96 73 62 82 47 85 82 85 82 84 81 83 79 82 76 84 79 83 77 81 70 71 43 39 11 83 74 82 68 79 54 74 39 69 26 85 79 80 63 83 72 79 61 62 29 83 77 82 74 81 69 80 63 77 47 81 76 73 65 66 55 64 53 58 46 85 80 83 70 80 58 75 44 64 22 84 79 83 75 81 67 77 51 68 27 74 62 29 20 13 83 76 81 71 79 67 74 51 66 28 84 79 84 78 84 77 83 73 81 68 84 79 84 73 82 60 78 40 74 28 84 79 85 78 83 72 81 60 81 49 85 81 85 80 85 82 83 79 80 74 84 79 83 74 81 66 76 46 70 29 79 76 74 60 71 64 61 55 58 44 84 82 82 78 81 74 78 72 75 65 84 79 83 78 81 70 80 62 77 51 75 70 65 61 55 52 46 44 37 36 54 42 84 73 76 76 92 83 83 86 86 52 81 60 18 42 85 97 96 89 1e+02 1e+02 96 67 59 81 58 85 82 84 81 84 80 82 78 80 76 85 80 84 78 83 74 79 59 67 31 79 75 75 71 64 58 51 46 38 34 81 79 61 58 71 69 58 57 32 28 84 78 83 76 81 71 77 65 68 50 79 74 68 64 59 55 57 53 51 46 83 80 79 74 70 63 58 50 31 27 80 78 76 73 68 64 54 51 33 31 71 60 33 23 13 74 73 70 68 66 62 53 49 35 32 79 77 76 75 75 73 68 66 59 56 82 78 77 72 67 59 52 44 41 34 79 79 79 78 72 73 65 66 62 61 85 80 82 77 84 82 81 77 75 70 80 77 75 71 67 63 49 46 34 32 75 73 69 59 68 59 58 48 55 43 83 81 80 76 78 70 66 65 58 53 80 78 78 75 69 65 62 58 52 48 85 69 65 60 59 53 51 45 46 37 79 58 84 69 77 77 93 84 83 86 86 58 56 13 18 10 39 85 97 97 89 1e+02 99 95 68 57 79 52 84 78 84 78 83 76 81 73 77 69 84 76 83 74 81 69 74 50 60 20 79 69 76 64 70 51 62 39 53 29 83 74 76 55 73 60 63 46 40 19 83 73 81 70 78 63 72 57 56 42 80 72 72 62 66 53 64 52 60 45 82 76 78 67 73 55 66 42 51 23 80 75 77 71 71 63 62 50 45 31 62 47 18 13 9.8 77 72 74 67 70 62 60 49 46 33 80 74 79 72 78 70 75 65 70 58 82 73 79 66 74 54 65 39 58 30 82 76 82 75 79 69 74 58 72 50 83 74 80 71 83 77 79 70 71 61 80 74 76 69 71 62 59 46 48 32 75 69 70 55 66 57 55 47 54 39 83 78 80 73 79 69 69 65 63 57 81 74 79 72 72 64 67 57 58 48 70 63 61 54 50 46 42 39 34 31 51 37 84 72 74 73 92 81 81 85 85 46 30 85 97 96 89 1e+02 99 96 72 61 82 42 85 82 84 82 84 81 83 79 81 76 83 79 82 76 80 70 68 45 36 13 82 74 81 68 77 54 72 40 66 27 84 79 78 62 82 72 77 60 56 28 83 77 82 74 80 69 80 64 77 49 80 76 72 64 64 54 62 52 56 45 84 79 82 71 79 58 74 45 61 24 83 79 82 75 80 66 76 51 65 27 73 63 29 20 12 82 75 81 70 79 66 73 53 62 30 84 79 83 77 83 77 82 73 80 68 84 79 83 74 81 62 76 43 72 31 84 79 84 78 82 74 81 66 80 55 84 81 84 80 84 82 82 79 79 74 83 79 82 73 80 65 75 46 68 31 78 75 73 62 71 63 62 53 59 43 84 81 81 78 80 74 78 71 74 65 83 79 83 77 81 68 79 61 76 50 74 70 66 62 56 53 46 45 37 36 54 41 83 72 75 76 92 83 83 86 86 50 80 42 62 18 44 85 97 96 88 1e+02 99 96 68 59 81 42 85 82 84 82 84 80 83 78 82 74 83 79 82 76 79 69 68 47 43 20 82 74 81 69 78 56 75 43 70 33 84 79 78 61 80 70 75 56 57 28 83 76 82 73 80 68 79 64 75 49 80 75 72 65 66 55 64 53 59 47 84 80 82 72 79 60 75 47 63 28 83 79 82 75 80 69 74 58 61 39 70 56 23 16 8.9 83 76 81 72 79 69 73 59 67 43 83 79 83 77 83 76 81 72 80 67 84 79 83 74 81 63 78 48 75 38 83 79 84 78 83 74 81 67 79 55 83 80 82 78 84 82 83 78 81 73 83 77 82 74 80 68 74 55 69 42 77 75 73 60 69 64 61 55 61 42 84 82 80 78 80 74 78 70 75 64 83 77 82 75 81 69 79 64 76 57 73 71 65 63 56 56 47 48 40 40 52 41 81 70 75 75 91 82 82 86 86 53 72 39 10 43 85 97 96 88 1e+02 99 95 67 57 80 40 84 80 84 80 83 78 82 76 80 72 83 76 82 72 78 61 64 29 30 6.1 81 69 78 62 73 45 67 30 59 18 84 77 77 58 79 62 70 46 44 17 82 73 81 70 80 64 79 58 74 40 75 69 62 53 53 41 51 39 45 32 83 77 79 65 74 49 68 34 53 15 81 75 79 69 76 57 69 40 54 18 64 45 10 5.4 3.6 82 72 78 66 75 61 66 44 54 23 82 75 82 72 81 71 80 65 78 58 83 75 82 66 79 51 74 30 68 18 83 77 84 75 81 71 79 61 79 50 84 78 84 76 84 80 81 76 75 68 81 74 79 67 76 56 68 35 57 20 74 70 66 47 62 53 51 43 41 24 83 79 80 74 78 69 76 67 72 58 82 73 80 71 77 60 74 52 69 41 69 64 58 53 46 43 37 36 28 28 46 32 78 65 74 75 92 81 81 85 85 50 67 35 9.3 33 84 97 96 87 1e+02 99 95 65 54 81 36 84 81 84 81 83 80 82 78 81 76 83 78 82 76 79 69 66 45 35 13 81 73 79 67 74 54 68 40 60 28 83 78 77 60 81 72 76 62 55 32 81 75 80 72 77 67 75 62 69 47 80 75 72 64 63 54 61 52 55 45 84 78 80 69 76 56 69 42 53 23 83 78 81 74 78 66 72 51 58 24 73 63 32 23 15 82 75 80 71 78 67 71 51 58 26 83 78 82 77 82 76 81 72 79 68 83 78 82 73 79 62 73 44 68 32 83 79 83 78 81 73 79 66 78 59 84 80 84 80 84 81 82 78 79 73 83 78 81 73 78 65 71 45 62 28 77 74 72 61 70 62 61 53 58 44 83 81 81 77 80 74 76 69 72 61 83 79 82 77 79 69 77 62 73 51 74 70 67 63 58 55 50 47 41 39 54 42 80 71 75 75 91 82 82 85 86 50 81 43 62 15 45 84 97 96 88 1e+02 99 95 66 58 79 51 84 81 84 81 83 80 81 78 79 74 84 79 83 77 82 73 76 58 63 30 79 74 74 70 63 58 52 46 39 34 80 78 59 56 70 68 56 56 29 27 82 77 81 75 79 70 75 63 65 48 77 74 66 62 57 53 56 51 50 45 83 79 78 73 69 62 58 50 34 29 79 76 74 71 65 62 50 48 31 29 70 58 32 24 14 70 71 66 64 62 59 48 46 32 30 78 76 76 74 74 72 67 65 57 56 81 77 76 71 65 60 51 44 41 35 79 78 79 77 73 73 66 67 64 62 84 79 81 76 84 81 80 76 73 68 78 76 73 69 64 60 45 43 32 30 72 71 64 55 65 57 55 45 51 41 82 80 77 75 75 69 62 63 55 52 79 76 76 73 64 62 56 54 46 44 71 68 64 59 57 51 49 44 44 36 76 56 83 69 75 75 92 83 82 85 86 56 55 13 15 9.3 38 84 97 96 88 1e+02 99 95 69 56 80 53 84 81 84 81 83 79 81 77 78 74 84 79 83 77 82 73 76 57 62 28 78 74 74 69 62 56 49 43 36 31 80 78 60 57 70 68 58 56 32 27 82 77 82 74 79 69 76 64 67 49 77 73 66 62 56 52 54 51 47 44 82 79 77 72 68 61 56 48 31 25 79 77 75 72 66 63 52 50 32 32 69 56 29 22 13 69 71 65 65 60 59 48 47 32 32 78 76 76 74 74 72 68 66 59 57 81 77 76 71 66 59 51 43 41 34 78 78 79 77 71 72 64 65 60 60 83 79 81 76 83 80 80 76 73 69 79 76 74 70 65 62 46 45 32 32 73 72 67 57 66 57 56 46 52 41 81 80 78 75 74 70 63 61 56 50 79 76 76 74 66 64 58 56 48 46 84 68 64 59 58 52 50 44 44 37 79 58 83 69 76 76 92 83 83 86 86 56 56 21 23 17 38 84 97 96 88 1e+02 99 95 70 58 78 46 84 77 83 76 82 74 79 71 76 66 83 74 83 71 81 64 74 42 59 14 78 66 75 58 67 42 58 30 48 21 82 72 74 52 70 55 56 38 28 11 82 70 81 65 78 58 76 52 67 36 78 69 70 57 62 47 61 46 55 39 82 74 77 62 71 47 63 33 45 16 80 73 77 68 72 60 64 47 49 29 59 44 17 13 9 76 69 74 63 71 58 63 46 50 31 79 72 78 70 77 68 74 62 70 54 80 71 77 61 69 46 57 29 48 20 80 74 81 73 77 65 70 49 65 36 81 71 78 67 83 75 77 68 70 58 80 71 76 67 72 59 61 42 51 29 72 65 65 48 62 51 49 41 45 29 83 75 78 69 77 63 60 58 52 49 80 71 79 69 73 60 68 53 61 43 65 58 53 48 43 40 34 33 28 26 48 34 82 70 73 73 92 81 81 85 84 41 27 84 97 96 88 99 99 95 70 58 80 37 84 81 83 80 83 79 81 77 79 73 83 77 82 73 78 64 62 32 26 6.8 81 70 79 63 74 46 67 31 60 20 84 77 76 58 78 65 69 50 42 20 82 74 81 71 80 65 79 58 74 40 75 71 63 56 53 44 51 42 45 34 84 78 81 67 76 51 70 36 55 17 81 76 79 70 76 59 69 40 55 15 66 47 13 7.7 5.3 82 73 79 67 77 62 68 45 54 20 82 76 81 73 81 72 79 67 76 59 83 76 82 68 78 53 72 34 66 23 83 77 83 75 80 71 78 61 77 51 84 79 83 77 83 80 80 76 75 69 81 75 79 68 76 57 68 35 59 19 74 71 67 51 63 56 53 45 43 32 83 80 80 75 78 70 76 67 72 59 82 75 81 72 77 61 74 53 70 40 67 64 56 54 44 44 35 37 28 29 48 35 80 68 74 74 91 82 82 85 85 50 70 21 37 8.9 35 84 97 96 87 99 99 95 65 54 78 33 83 79 83 78 82 76 80 73 77 69 83 77 83 75 83 71 80 54 70 22 80 67 77 61 71 45 65 30 56 19 83 75 74 57 77 60 67 45 34 15 82 74 81 71 79 64 75 57 65 39 76 70 64 56 55 46 53 43 46 37 83 74 79 64 72 50 64 34 47 13 81 73 78 65 74 53 64 37 47 19 62 45 17 11 6.9 77 68 75 60 72 53 63 36 48 20 81 72 80 69 79 67 76 61 71 53 82 72 81 62 75 43 63 24 53 16 83 75 83 73 81 68 78 59 76 54 81 74 79 71 82 77 77 71 69 62 80 71 78 63 73 51 61 32 49 20 73 66 65 47 62 50 51 40 49 29 82 77 78 71 76 64 66 59 59 50 81 72 79 69 73 55 68 46 60 35 70 64 60 54 49 45 40 38 32 31 42 31 79 64 73 73 91 81 81 85 85 44 59 9.6 15 7.6 30 84 96 96 87 99 99 95 65 50 79 32 84 80 83 79 82 78 81 75 79 72 82 76 81 72 77 64 62 34 28 7.7 78 70 75 63 68 47 60 34 50 23 83 76 75 57 77 63 67 49 38 20 81 74 80 70 77 64 74 58 67 42 75 70 63 55 53 43 51 41 45 34 83 76 76 65 69 50 60 38 43 20 81 75 78 69 74 58 65 40 45 18 66 50 14 8 4.6 80 72 76 66 71 61 59 43 43 21 81 75 80 73 80 71 78 67 75 60 82 75 80 68 76 55 68 36 61 25 82 76 82 74 79 69 75 60 73 49 83 78 83 77 83 79 80 75 75 68 81 74 78 67 73 56 62 35 50 21 74 70 66 51 63 55 50 44 40 31 83 79 79 74 77 68 74 65 69 56 81 74 80 72 75 61 71 53 66 41 68 64 58 54 48 45 39 37 30 30 49 36 79 66 73 74 90 81 81 85 85 49 70 17 36 7.4 38 84 96 96 87 99 99 95 64 53 79 32 83 80 83 79 82 78 81 75 80 71 81 75 79 71 74 61 55 34 19 9.7 79 70 76 64 71 50 63 38 53 26 83 77 75 58 77 66 69 52 48 24 80 72 78 69 75 62 71 57 61 39 77 71 67 58 58 47 56 45 50 38 82 77 78 67 72 53 63 40 45 22 81 76 79 71 72 61 59 46 48 23 67 53 18 10 6.5 80 73 73 68 64 63 51 49 39 29 81 75 80 72 80 71 78 66 75 60 82 76 80 70 77 59 71 42 65 31 82 77 82 75 79 71 76 62 73 52 82 77 80 75 83 80 81 77 77 71 81 74 78 68 72 60 65 41 57 27 72 70 66 52 64 56 56 46 56 35 82 79 78 74 76 69 74 66 69 58 81 73 80 69 75 60 73 54 69 44 69 66 60 57 52 49 43 42 34 34 49 38 79 67 73 73 90 81 80 84 84 50 70 21 37 9.1 40 84 96 96 87 99 99 95 65 54 78 42 83 80 83 79 81 78 80 76 77 72 82 77 82 75 80 71 74 54 59 27 76 71 71 66 58 52 46 40 34 28 78 76 57 54 68 66 55 53 29 27 81 75 80 72 77 67 72 60 59 42 75 72 63 59 53 49 50 47 44 41 81 77 75 69 65 58 52 45 29 25 77 74 72 68 62 57 47 43 26 24 67 55 28 20 11 67 68 64 61 59 55 44 41 26 25 76 74 73 71 71 69 64 62 54 51 79 75 73 69 61 56 45 39 35 29 77 76 78 75 71 71 65 65 62 60 82 78 79 74 82 79 78 74 71 66 76 73 70 66 61 55 42 37 27 25 69 69 61 52 62 53 51 42 47 37 81 79 76 73 73 66 58 59 49 48 77 74 74 71 62 57 53 49 42 37 67 64 60 55 53 47 45 39 39 32 73 54 82 67 74 74 91 82 82 85 85 53 54 11 14 8.3 35 83 96 96 87 99 99 95 67 55 77 26 83 79 82 78 81 76 79 73 75 68 80 73 77 67 71 56 47 26 11 4.6 78 68 75 61 68 45 59 32 49 21 82 74 74 55 75 62 65 48 42 21 79 70 77 66 74 58 70 51 60 33 74 68 61 52 51 40 49 38 42 30 82 75 77 64 69 50 60 36 42 18 79 73 76 66 71 54 62 38 47 19 64 48 18 11 6.7 77 71 74 64 72 57 64 41 51 22 81 74 80 71 79 70 76 64 72 56 82 73 79 66 75 53 67 37 60 26 81 74 81 73 78 68 76 59 74 47 80 74 77 71 82 77 77 71 70 63 79 72 76 64 71 53 60 33 49 20 72 68 63 47 60 52 48 40 42 27 82 78 78 72 76 66 69 62 62 53 80 73 78 69 72 57 68 49 61 37 67 63 59 54 51 46 43 40 33 32 45 32 77 63 73 73 90 80 80 84 84 47 73 22 38 8.7 33 83 96 96 87 99 99 95 64 53 77 23 82 79 82 78 81 77 79 74 76 70 82 77 82 76 81 73 78 59 66 28 77 69 73 63 64 51 56 38 45 27 81 75 70 56 75 65 64 51 32 21 82 74 81 71 79 64 75 56 66 37 76 71 64 58 54 48 52 46 45 39 82 75 75 65 66 54 55 43 37 22 79 73 76 68 70 58 59 43 40 25 66 52 22 15 9 76 69 73 63 69 57 58 43 41 26 79 74 78 71 77 69 73 64 67 56 81 74 78 66 70 50 56 31 45 21 80 76 79 75 77 71 73 65 70 61 80 75 77 72 82 78 77 72 69 64 78 72 75 66 69 56 55 38 42 25 72 68 64 50 63 53 52 42 47 33 81 78 77 72 76 67 66 61 59 51 79 73 77 70 69 58 63 50 55 39 83 65 60 56 51 48 43 41 37 33 44 33 79 62 72 72 89 80 80 84 84 46 65 16 28 8.1 34 83 96 95 86 99 99 94 65 51 78 45 82 80 82 79 81 78 80 76 77 72 82 78 81 76 80 71 74 55 61 28 77 72 72 67 60 54 48 41 36 30 78 76 58 55 67 66 55 54 30 27 80 75 79 72 77 67 73 60 62 44 75 71 62 59 52 50 50 48 44 41 81 77 76 70 66 58 53 46 31 25 77 74 73 69 63 59 48 45 27 26 67 54 29 21 12 68 68 65 62 60 56 46 43 29 28 76 74 74 72 72 70 66 64 56 54 79 75 73 68 62 56 48 40 39 31 77 76 78 75 71 71 64 64 60 59 82 78 79 74 82 79 78 74 71 66 77 74 71 67 62 58 43 40 29 27 70 69 62 54 62 54 52 43 47 38 79 78 74 72 73 67 57 57 47 46 77 75 75 72 64 61 56 53 45 42 83 65 59 55 53 47 45 40 39 32 76 55 85 70 74 74 91 81 81 84 85 53 54 23 25 19 36 83 96 96 87 99 99 95 69 56 79 27 83 80 82 79 82 78 80 76 78 73 81 76 79 73 75 65 60 38 30 10 77 70 74 64 68 50 60 37 50 26 81 76 72 56 78 70 73 59 48 29 79 73 77 69 75 63 72 58 65 43 78 73 69 62 60 51 58 49 51 42 82 76 76 66 70 52 63 39 45 21 81 76 79 72 76 63 70 48 57 25 71 61 33 24 15 80 73 78 68 76 63 69 47 57 26 81 76 80 75 80 73 78 69 75 64 81 76 79 71 75 60 68 41 60 29 81 77 82 76 79 71 75 64 74 56 82 79 82 78 82 79 80 76 76 71 81 76 79 71 76 62 68 43 59 28 74 72 68 57 66 58 55 48 55 41 82 79 78 74 77 70 72 65 67 56 81 76 80 74 77 66 74 58 69 47 71 67 62 59 55 51 47 44 39 36 53 40 79 66 72 72 89 80 80 84 84 48 79 43 62 19 43 83 96 95 86 99 99 94 65 54 78 27 82 78 82 77 81 76 79 74 77 70 81 74 79 70 74 61 55 32 19 7 76 68 71 60 62 45 52 32 42 21 81 75 71 55 73 61 60 45 28 17 80 71 78 68 76 61 73 54 64 36 74 68 61 53 51 41 49 39 42 32 81 74 73 63 65 49 54 36 36 18 79 73 76 66 70 54 61 35 42 13 64 46 12 6.6 4.5 79 70 75 64 70 58 60 41 44 18 79 73 78 71 77 69 75 64 71 58 80 73 78 66 72 51 60 32 50 21 79 74 80 72 75 67 69 57 67 47 82 76 82 74 82 78 78 74 73 66 78 71 75 64 70 51 58 30 46 16 71 67 64 49 62 52 53 42 48 32 81 77 77 72 75 65 71 60 65 50 79 72 77 69 72 56 68 47 62 35 65 61 54 51 46 43 37 35 30 28 48 34 76 63 72 72 90 80 80 84 84 48 72 20 37 8.2 36 83 96 95 86 99 99 94 62 52 75 37 82 76 81 75 80 73 77 69 73 64 82 74 81 72 79 66 73 47 57 17 78 65 75 57 66 40 56 28 46 19 81 71 72 52 71 54 58 38 28 12 80 70 79 65 76 58 74 52 65 35 76 67 67 55 58 45 57 43 51 37 81 73 77 61 70 46 62 31 44 15 79 70 75 64 70 53 61 39 46 21 60 45 16 12 9 74 63 71 56 68 51 60 37 47 21 78 70 77 68 76 65 72 59 66 48 79 70 76 61 70 47 60 31 51 23 80 72 78 69 75 60 68 43 64 32 80 71 76 67 81 74 75 67 66 57 78 69 74 62 69 52 58 34 48 21 70 63 62 46 59 50 47 40 45 30 81 75 76 67 75 61 59 54 50 43 78 69 77 66 70 55 64 47 56 37 63 56 52 46 41 38 34 31 28 25 44 30 81 67 72 71 90 80 80 84 84 39 27 83 96 96 87 99 99 94 68 56 77 23 82 79 82 79 81 78 80 76 78 73 82 77 82 76 81 72 77 58 64 27 77 68 72 62 63 49 53 36 41 24 81 75 69 55 75 64 63 49 30 19 81 74 80 71 78 64 76 58 69 40 75 71 64 59 54 48 51 46 45 39 81 75 74 65 65 53 55 41 36 20 79 74 76 69 71 60 61 47 44 28 66 52 21 15 8.6 75 67 72 62 69 58 59 45 44 28 79 74 78 72 77 70 73 64 68 57 80 74 77 66 70 50 55 30 42 19 80 76 79 75 77 71 73 65 69 60 82 77 80 74 82 79 80 75 75 68 78 73 75 67 70 58 58 41 46 28 72 68 64 51 62 53 52 43 49 35 81 78 77 72 75 66 64 60 57 49 79 74 77 70 70 59 65 50 58 39 83 62 53 51 44 43 34 35 29 28 45 33 78 62 72 72 90 80 80 84 84 47 69 25 40 14 37 83 96 95 86 99 99 94 65 51 75 24 82 78 81 77 79 75 77 72 73 67 79 72 76 67 70 55 49 25 13 4.4 76 66 71 59 62 43 51 29 40 19 81 74 71 54 71 60 59 46 33 20 78 69 76 65 73 57 69 50 60 32 72 66 58 50 48 38 46 36 39 29 81 74 73 62 63 47 53 33 35 16 77 71 73 63 66 50 54 34 34 16 61 44 15 9.3 6.2 74 68 71 59 67 52 55 35 38 19 79 72 77 70 76 68 73 62 68 54 80 72 77 64 71 49 60 30 50 21 78 72 78 70 74 65 68 56 66 47 79 73 76 69 81 77 75 70 67 61 77 70 72 61 65 49 50 29 36 16 69 66 60 46 58 49 46 38 41 26 81 77 76 70 73 64 66 59 58 50 77 71 75 67 67 53 60 44 51 32 65 60 54 49 46 40 38 33 31 26 44 30 75 61 71 71 89 79 79 83 83 46 72 25 42 9.4 32 82 95 95 85 99 99 94 62 50 76 33 82 79 81 78 80 77 78 74 75 70 81 76 80 74 78 68 70 47 51 20 74 69 68 62 54 47 40 33 28 23 77 75 55 52 63 61 47 47 22 21 80 73 78 70 75 63 70 56 57 37 73 70 60 56 50 45 48 43 41 37 80 76 73 66 61 52 47 38 23 18 75 72 68 65 57 53 40 38 20 20 64 49 22 15 8.4 64 63 59 55 53 49 37 35 20 20 75 73 72 69 69 67 61 58 49 46 77 73 70 64 55 49 38 32 29 23 76 75 76 74 69 69 61 61 58 56 81 76 78 72 81 78 77 73 68 63 74 71 66 62 55 51 35 33 21 21 67 66 57 47 57 48 45 36 40 31 79 78 73 70 70 62 54 54 44 42 75 72 71 68 57 54 48 44 37 34 63 61 54 51 48 43 40 36 35 29 69 50 82 63 73 73 90 80 80 84 84 49 51 12 12 8.8 29 82 96 96 86 99 99 94 65 51 74 33 82 78 81 78 80 76 78 74 75 70 81 76 80 74 78 68 71 50 55 23 74 71 69 66 58 54 47 43 36 32 76 74 57 53 65 64 49 53 20 27 79 72 77 69 74 63 70 56 58 39 72 70 60 58 50 48 48 46 42 39 79 76 73 68 63 58 51 46 28 25 75 74 70 68 60 59 45 45 25 26 66 54 28 21 13 61 67 61 61 57 56 43 43 25 27 74 73 71 70 69 68 63 61 54 52 77 74 72 69 62 58 47 43 38 34 76 75 76 74 71 70 65 65 62 60 81 76 78 72 81 78 76 72 67 63 74 72 67 66 57 56 39 39 25 27 67 67 58 51 59 51 47 39 42 34 79 77 73 70 70 64 49 54 39 43 74 73 70 69 57 57 49 49 39 39 68 65 60 56 54 49 46 42 41 35 50 35 80 66 71 71 89 79 79 83 83 47 51 14 15 8.8 30 82 96 95 85 99 99 94 62 51 74 29 82 78 81 78 80 76 78 74 74 70 81 76 80 73 78 68 71 49 56 21 74 70 69 65 57 53 46 41 35 30 76 74 57 53 64 64 47 52 16 25 79 72 78 69 74 63 70 56 56 38 72 69 59 57 49 47 47 45 40 38 79 76 73 68 63 57 51 44 28 24 75 73 70 67 59 57 45 44 25 26 66 54 26 19 11 62 65 62 60 58 56 43 43 25 26 74 72 71 70 69 67 62 60 52 51 77 74 71 68 60 56 45 40 35 30 75 75 75 73 69 70 63 64 59 58 81 76 77 71 81 78 75 72 67 64 74 72 67 65 57 56 39 39 25 27 66 66 57 49 57 50 45 38 41 33 79 77 73 70 70 63 49 54 39 42 74 72 70 69 58 57 50 49 40 39 67 64 59 55 53 48 44 40 40 33 49 34 78 62 71 71 89 79 79 83 83 46 50 12 13 8.6 29 82 96 95 86 99 99 94 62 50 73 19 81 78 80 76 78 74 75 71 70 66 81 71 74 66 66 56 46 30 16 7.3 70 67 62 60 46 47 32 34 20 23 78 75 64 58 66 64 51 51 24 25 81 69 72 65 67 58 63 52 50 36 81 67 51 52 38 41 35 38 28 31 81 73 64 63 49 50 36 38 18 20 81 71 67 63 54 50 35 34 14 15 64 50 24 17 11 81 69 64 61 55 52 35 33 15 16 81 71 70 68 68 66 61 60 50 50 76 72 69 65 57 53 40 36 29 26 81 73 73 71 54 63 36 49 29 38 81 73 74 70 79 76 71 68 61 58 81 70 64 61 52 49 31 29 16 16 64 65 52 44 53 48 41 35 33 26 81 77 74 70 71 63 53 55 43 44 81 71 69 67 54 53 43 43 30 31 81 64 59 55 51 47 43 40 36 32 42 30 74 58 70 70 88 78 79 83 83 43 62 16 36 9.2 29 81 95 95 83 99 99 94 61 47 75 30 81 77 80 77 79 75 77 72 73 68 80 74 79 72 77 66 67 45 46 18 73 68 66 61 52 45 38 31 26 20 76 73 53 50 61 60 44 45 18 19 78 72 77 68 73 62 68 55 55 37 71 68 57 54 47 43 45 41 38 34 79 75 72 65 59 51 46 37 24 17 73 70 66 62 52 49 34 33 15 15 62 47 21 15 9.2 63 63 57 53 50 46 32 30 16 15 73 71 70 68 68 65 60 57 49 45 75 71 66 61 49 43 31 25 21 16 74 73 75 72 66 67 58 59 54 53 80 75 76 71 80 77 75 71 66 61 72 69 62 60 49 47 28 27 16 16 64 63 54 45 54 45 42 32 36 27 78 76 72 68 70 60 48 49 37 36 73 70 68 66 51 50 41 39 29 28 62 60 53 50 45 42 37 35 32 27 68 50 82 63 72 71 90 79 79 83 83 48 52 13 12 8.8 28 81 95 95 85 99 99 94 65 50 77 17 81 78 80 77 80 76 78 74 76 70 79 74 77 70 71 61 52 33 19 8.1 73 66 68 60 58 45 47 33 36 23 79 74 66 53 74 67 65 56 36 28 77 70 75 66 72 58 70 53 63 37 75 71 64 58 54 47 51 44 45 37 79 73 71 62 62 49 52 35 33 18 78 74 75 69 70 61 60 47 41 24 69 59 33 24 16 77 70 73 65 70 61 59 46 42 26 78 74 77 72 76 71 74 67 70 61 78 73 75 67 68 54 55 36 44 25 78 75 79 73 74 66 66 56 64 47 81 77 80 76 80 77 78 74 74 68 78 73 75 68 69 59 57 42 46 28 70 68 63 53 61 54 50 42 50 36 80 77 76 71 74 66 67 60 61 49 78 74 77 72 71 63 66 56 60 46 67 63 58 54 50 46 41 39 33 31 50 37 77 65 70 70 89 78 79 83 83 44 79 47 62 16 40 81 95 95 84 99 99 93 63 53 75 18 81 77 80 76 79 74 77 72 75 67 79 71 76 67 70 56 48 27 15 5.8 71 64 64 57 51 43 40 31 29 21 78 73 65 52 68 58 51 41 18 13 77 68 75 64 73 57 70 51 63 34 70 65 56 48 45 36 42 33 36 26 78 71 67 59 55 45 43 33 25 17 76 71 72 63 64 48 50 29 29 9.7 63 46 14 8.1 5.6 76 69 71 63 66 55 51 33 32 12 76 71 75 69 74 67 70 62 65 55 78 71 73 63 62 47 44 29 33 19 75 73 76 70 69 65 61 57 59 48 80 75 80 73 80 76 76 71 70 63 76 69 71 60 64 46 48 24 34 12 68 64 58 44 58 48 47 37 40 26 79 76 75 69 72 62 66 57 58 46 76 69 74 66 67 52 61 42 52 30 62 57 50 47 42 39 33 32 26 25 45 33 76 61 70 70 88 78 78 83 83 44 69 17 34 7.3 35 81 95 95 84 99 99 94 61 50 73 24 81 78 80 77 79 75 76 73 73 69 80 75 79 72 77 67 69 46 52 18 73 68 67 62 55 49 43 36 32 26 75 73 55 51 61 61 44 48 14 21 78 71 76 67 72 59 67 53 54 36 71 68 57 55 47 45 45 43 39 36 79 74 71 66 61 53 47 39 25 20 73 71 67 64 54 53 37 38 16 19 64 51 24 17 10 61 62 58 56 52 51 34 36 16 20 73 72 70 69 68 67 61 59 51 49 76 73 71 66 59 54 44 38 34 28 74 74 73 72 67 68 59 62 55 56 80 75 76 70 80 77 74 71 65 62 72 70 64 62 52 51 31 32 17 20 65 64 55 47 55 48 43 36 39 30 78 76 72 69 68 61 47 52 37 40 73 71 69 67 55 53 45 44 33 33 65 62 58 53 52 46 44 39 39 32 47 31 77 62 70 70 88 78 79 82 83 45 51 11 12 8.5 28 81 95 95 85 99 99 93 62 50 73 20 80 76 79 75 78 73 75 70 71 65 77 70 74 65 68 54 51 28 23 6 74 64 70 57 61 41 50 29 39 19 79 72 67 52 67 58 52 43 24 17 76 67 73 61 70 54 68 48 58 30 71 66 57 51 46 39 43 36 36 29 79 72 73 60 64 44 54 30 32 14 75 68 70 58 60 43 45 27 24 12 61 46 19 12 7.9 72 61 67 50 61 42 44 26 25 13 77 70 75 67 73 65 67 57 57 46 78 70 74 61 64 45 49 28 38 19 77 70 76 67 69 59 54 42 45 29 77 71 74 68 79 75 73 67 64 58 75 67 69 56 60 41 40 23 25 13 64 63 52 41 50 43 37 31 31 21 79 76 74 69 71 63 60 56 53 45 76 69 73 64 63 47 56 37 44 26 81 60 54 51 45 43 38 36 33 29 42 29 74 57 70 70 88 78 79 82 83 45 54 12 19 7.9 28 81 95 95 84 99 99 93 61 47 72 25 80 72 79 71 77 68 74 64 70 58 80 69 79 66 77 60 70 39 53 12 74 57 70 48 59 30 48 18 36 11 79 67 69 47 64 48 49 32 19 8.1 78 65 77 60 74 52 71 46 62 30 72 61 61 47 53 37 51 35 45 29 79 68 73 52 64 35 54 22 33 9.3 76 63 72 56 65 44 55 28 38 11 50 34 11 8.3 5.8 70 56 67 47 64 39 53 24 38 10 76 65 74 62 73 60 68 52 60 41 76 63 72 52 64 36 50 20 40 13 76 67 77 64 72 57 65 44 63 30 77 66 73 61 78 70 71 60 60 48 75 61 70 53 63 41 50 22 38 11 65 57 56 39 53 42 40 31 37 22 79 71 72 61 70 52 51 45 41 33 75 62 73 58 64 44 57 35 48 25 57 49 45 39 35 31 27 25 23 19 39 25 76 61 68 68 89 77 77 82 82 35 29 6.6 7.7 6.2 22 80 95 95 84 99 99 94 63 51 72 20 80 77 79 76 78 74 75 71 71 67 79 73 78 71 76 64 66 42 46 15 71 67 65 60 51 45 39 32 28 22 75 72 54 50 58 58 40 44 12 18 77 70 75 66 71 59 66 51 51 33 69 66 54 52 43 42 41 40 34 33 78 73 70 64 58 50 45 36 23 18 71 69 64 61 50 48 31 32 12 15 61 45 19 13 7.7 56 60 52 53 45 47 28 30 12 15 72 70 68 66 66 64 57 55 46 44 75 71 68 63 53 48 34 30 24 20 73 73 73 71 66 67 58 59 54 54 79 74 75 68 79 76 73 69 63 59 70 67 61 58 48 45 25 26 13 16 62 62 52 42 52 44 40 32 34 26 77 75 70 67 67 59 43 48 32 36 71 69 66 64 50 47 39 37 27 26 62 60 54 50 47 42 38 35 34 28 45 31 77 60 70 69 88 77 78 82 82 43 47 12 11 8.8 24 80 95 95 83 99 99 93 60 47 75 15 80 76 80 75 79 74 77 72 75 69 80 74 79 72 77 67 68 47 44 17 73 64 67 57 56 43 44 30 33 20 78 71 62 50 70 61 57 47 25 18 79 70 78 67 75 59 72 51 63 34 72 66 57 52 46 41 43 38 37 31 79 71 71 60 58 46 47 34 27 17 76 70 72 63 65 53 55 40 38 24 63 49 20 13 7.9 72 62 68 56 64 51 53 38 38 24 76 70 74 67 73 65 69 59 62 50 76 70 71 61 60 45 45 28 35 19 78 73 76 71 73 67 67 60 62 54 79 74 76 71 80 76 77 72 72 65 75 69 71 62 65 52 51 36 40 24 67 63 58 44 54 46 43 35 42 29 78 75 73 67 71 60 57 51 49 39 76 69 73 66 64 53 57 45 48 34 80 57 51 47 44 39 36 32 29 26 44 33 76 59 70 69 89 77 78 82 83 44 65 25 36 14 32 80 95 94 83 99 99 93 65 50 71 14 80 77 79 75 76 73 73 69 68 63 75 69 71 63 63 51 40 22 12 3.9 67 64 60 58 45 45 31 32 19 21 77 74 61 57 66 63 52 52 24 26 73 67 69 62 64 54 59 48 45 32 67 66 50 51 38 40 35 38 28 31 77 72 65 61 50 49 36 37 17 20 75 70 68 63 53 49 32 29 11 10 63 50 25 18 11 67 65 59 56 51 49 31 29 13 11 72 70 69 68 67 65 60 57 48 45 75 71 69 64 58 53 43 38 33 28 74 73 75 72 65 66 54 57 53 49 75 71 72 68 78 75 70 66 59 55 73 69 64 60 49 46 24 22 12 11 61 62 50 43 51 46 40 35 34 28 78 76 71 68 68 60 50 53 41 40 73 70 69 65 49 48 36 35 24 23 80 62 57 53 49 46 41 39 35 31 40 27 72 57 69 69 87 78 78 82 82 41 61 17 26 11 26 80 94 94 83 99 99 93 59 45 72 13 80 76 79 75 77 72 74 69 70 63 76 69 72 63 64 52 38 22 7.7 3.8 71 64 64 56 51 40 39 28 28 19 77 72 64 52 66 59 52 45 27 21 74 66 72 60 68 52 65 45 56 27 69 63 53 47 43 35 40 33 33 26 77 71 67 59 56 44 44 32 26 16 74 68 68 60 58 46 42 28 21 11 60 46 19 13 8 70 65 65 55 59 47 42 28 23 12 75 71 74 68 72 66 68 59 61 50 76 70 73 63 65 51 52 35 43 26 75 70 75 67 69 62 62 55 60 48 76 70 72 67 79 74 72 67 64 58 73 67 66 57 57 44 37 22 23 11 65 62 55 42 54 45 42 33 34 23 78 75 73 68 70 60 60 54 51 43 73 67 70 63 58 48 51 37 39 25 64 58 54 49 46 41 39 34 31 27 42 29 74 59 68 68 88 77 77 81 81 43 71 22 35 9.2 31 80 94 94 82 99 99 93 61 50 75 16 80 76 79 75 78 73 77 71 74 67 80 73 79 71 78 67 72 49 53 18 72 62 66 56 55 40 43 27 31 17 77 70 61 48 65 57 48 42 17 14 79 70 78 67 76 59 73 52 65 34 71 66 56 51 45 40 43 38 36 31 78 70 69 58 58 44 45 31 25 14 75 68 71 62 64 50 52 37 34 20 60 45 17 11 5.7 69 59 65 52 61 47 49 34 33 21 75 69 73 66 72 64 66 57 59 47 76 69 71 60 59 45 43 29 33 21 77 72 76 71 73 67 67 59 62 53 79 74 76 70 80 75 77 70 70 62 74 67 69 59 63 48 48 32 36 22 64 61 55 42 52 42 40 31 38 25 78 74 72 66 70 58 54 49 44 36 74 67 72 63 63 50 57 42 49 33 80 56 54 46 47 40 40 33 33 27 42 32 75 59 69 69 88 78 78 82 82 43 62 16 25 9 28 80 94 94 83 99 99 93 64 49 72 11 80 78 79 77 77 75 75 73 73 70 78 75 77 74 76 71 71 61 62 41 78 74 76 72 71 65 62 55 51 43 75 75 54 53 72 71 65 64 42 41 74 71 72 67 67 62 64 57 53 44 74 72 65 63 57 55 55 53 49 47 79 77 77 73 73 67 68 60 51 43 77 75 75 72 71 68 66 61 55 48 74 68 48 40 29 75 74 73 70 71 68 66 61 57 50 75 73 73 71 72 70 67 65 61 59 79 76 77 74 74 69 66 56 57 44 79 77 79 77 77 76 73 72 67 66 76 74 73 71 78 76 73 71 69 66 77 75 74 72 71 68 64 60 57 52 71 70 63 59 62 59 53 49 50 45 78 77 75 72 74 68 64 61 57 50 77 75 76 74 72 69 69 65 64 60 70 69 63 61 59 56 51 49 47 39 52 38 79 67 69 69 88 77 77 82 82 41 44 80 94 94 82 99 99 93 67 54 71 12 79 75 79 74 77 72 74 69 70 65 78 71 77 69 74 62 63 39 40 12 69 63 61 57 46 42 33 29 23 19 74 70 53 49 57 56 40 43 12 17 76 68 74 63 69 56 64 50 51 33 68 64 51 49 40 37 38 35 30 28 76 70 66 60 52 46 37 33 18 16 69 67 61 59 48 46 30 30 12 13 58 44 18 12 7.9 58 55 52 48 44 43 27 27 12 14 69 68 66 64 63 62 54 54 41 42 73 69 66 61 53 47 37 30 27 21 64 69 68 66 46 56 29 41 25 31 78 72 74 67 78 74 71 68 60 57 68 65 59 56 46 43 25 24 13 14 60 60 49 40 51 43 38 31 32 25 77 74 68 64 64 54 47 45 38 33 68 66 63 61 48 45 38 35 27 25 80 58 52 48 44 40 36 33 31 26 39 28 73 55 68 68 87 77 77 81 81 42 55 15 22 10 24 80 94 94 82 99 99 93 62 48 73 10 80 76 79 75 78 73 76 70 72 66 77 70 74 65 68 55 48 27 15 5.5 68 63 60 55 46 40 33 28 23 19 76 71 58 49 65 58 49 42 16 13 76 67 74 63 71 55 69 48 61 32 68 63 52 47 40 35 38 32 32 26 76 71 64 58 51 44 38 32 20 16 73 69 68 61 60 49 46 31 26 12 63 48 16 10 5.8 74 66 70 59 65 52 51 33 30 13 74 70 72 68 70 66 66 60 59 52 75 70 70 62 58 47 41 29 30 19 74 71 70 69 65 61 55 52 50 46 79 74 79 72 79 75 74 69 68 61 73 68 68 59 60 47 44 27 30 14 64 62 54 41 54 44 42 33 32 24 78 74 73 67 70 60 62 53 53 41 74 69 72 65 64 53 57 44 48 33 61 56 49 45 42 37 34 31 27 23 43 30 73 58 68 69 87 77 77 81 81 41 70 16 31 6.9 33 80 94 94 82 99 99 93 61 49 70 13 79 73 78 71 76 69 72 64 67 58 78 67 77 62 73 50 58 20 32 4.2 70 54 64 43 48 26 34 15 24 8.7 77 67 61 46 52 48 31 33 7.1 10 77 63 76 58 74 49 71 42 62 25 65 59 46 42 33 30 31 27 24 21 77 66 68 48 53 30 38 18 17 6.7 69 59 60 46 45 27 26 12 8.6 3.6 47 31 11 6.9 5 49 40 47 26 40 20 22 10 7.9 3.6 71 63 67 59 64 56 51 45 33 32 73 62 63 48 46 29 27 15 17 9.4 56 62 54 56 28 44 12 27 5.8 15 78 69 73 61 78 71 69 61 54 47 67 57 57 41 43 25 21 9.7 10 4.5 52 54 38 30 41 34 27 24 21 16 76 71 63 59 58 45 32 37 23 25 68 59 62 51 45 30 34 20 23 12 55 51 43 41 36 34 29 27 24 22 34 22 73 52 67 67 87 76 76 80 80 30 39 11 14 8.3 15 80 94 94 82 99 99 93 59 43 73 9.9 80 76 79 75 77 73 75 70 71 65 74 68 70 63 60 50 34 22 7.5 3.9 63 61 55 55 41 41 28 29 17 19 73 71 51 49 63 60 48 48 19 21 71 64 65 58 58 49 54 43 39 28 69 67 54 52 42 41 39 39 32 32 74 70 61 58 44 42 28 28 11 13 74 70 69 65 60 55 44 41 23 22 63 52 26 19 11 68 63 63 57 58 52 42 38 23 22 73 71 71 69 69 67 64 61 54 53 73 70 65 62 51 47 33 29 22 20 72 72 73 71 60 64 45 51 38 40 76 72 74 69 78 74 73 69 67 62 73 70 68 63 58 54 38 36 23 23 61 61 51 43 51 45 41 35 38 30 77 75 70 67 66 58 49 50 41 39 74 71 71 68 60 56 51 47 39 36 80 58 50 48 42 40 34 33 30 26 43 31 76 59 68 68 86 77 77 81 81 41 69 20 26 8.6 29 80 94 94 82 99 99 92 64 50 70 12 79 73 78 71 76 69 72 64 67 58 78 67 77 62 72 50 58 20 32 4.2 70 54 63 43 48 26 34 15 24 8.6 77 67 61 46 52 48 31 33 7.1 10 78 63 76 58 73 49 70 42 62 25 65 59 46 42 33 30 31 27 24 21 77 66 68 48 54 30 38 18 17 6.7 69 59 60 46 45 27 26 12 8.5 3.6 47 31 11 6.8 5 49 40 47 26 40 20 22 10 7.8 3.6 71 63 67 59 64 56 51 46 33 32 73 62 63 48 46 29 27 15 17 9.4 56 62 54 56 28 44 12 27 5.8 15 78 69 73 61 78 71 69 61 54 47 67 57 57 41 43 25 21 9.7 11 4.5 52 54 37 30 40 34 27 24 21 16 76 71 64 59 57 45 32 37 22 24 68 59 62 51 45 30 34 20 23 12 55 51 43 41 36 33 29 27 24 22 34 22 72 52 67 67 86 76 75 80 80 30 39 11 14 8.4 15 80 94 94 81 99 99 93 59 43 74 11 79 76 79 75 78 73 76 71 73 66 77 71 74 67 67 57 44 29 15 7.2 68 62 62 55 49 41 38 29 27 19 76 71 58 50 68 62 55 48 22 18 75 67 72 62 69 53 67 47 58 30 71 66 56 50 44 38 41 36 34 29 76 70 66 58 54 44 43 32 25 16 75 70 71 65 64 53 51 37 32 16 65 53 23 16 11 74 67 69 60 64 53 51 36 34 18 75 71 74 69 72 68 69 63 63 56 75 70 70 63 59 48 42 29 30 19 75 73 75 71 68 63 56 51 50 43 79 74 78 74 79 75 75 71 70 64 75 70 70 63 63 52 47 32 34 19 65 64 55 45 54 46 41 35 35 27 78 75 72 68 70 60 61 54 53 41 76 71 74 68 66 57 59 48 51 37 62 59 51 49 44 42 37 35 31 27 44 32 75 61 68 68 88 77 77 81 82 41 77 41 55 12 34 80 94 94 82 99 99 93 63 49 72 9.4 79 76 79 75 77 73 75 70 71 65 74 69 70 63 62 52 36 24 9.5 4.4 63 60 54 53 39 38 26 25 16 16 73 71 51 50 63 60 49 49 22 23 71 65 66 59 60 50 55 45 41 30 68 66 53 51 42 41 38 38 32 32 75 70 61 56 43 38 28 25 12 11 74 70 69 65 59 55 44 40 21 21 61 49 23 16 10 67 63 62 58 57 53 41 38 22 22 72 70 70 68 68 67 63 61 54 53 73 70 66 62 51 47 33 29 22 19 71 72 71 70 57 62 43 50 38 41 76 72 74 68 78 74 73 69 66 62 73 70 67 63 57 54 37 35 21 23 62 62 52 44 52 46 42 36 39 30 77 75 70 67 66 58 51 50 42 39 74 70 71 67 58 56 48 47 36 35 79 58 49 47 42 39 34 32 29 25 43 30 74 60 68 68 86 76 77 81 81 40 68 20 25 8.2 30 79 94 93 82 99 99 93 64 50 70 11 79 75 78 74 76 72 73 68 69 63 74 68 70 62 61 50 36 23 8.4 4.6 63 61 56 54 40 39 26 27 16 17 72 70 52 49 62 60 47 48 18 21 70 64 66 58 59 49 54 42 39 26 67 64 50 49 38 38 35 36 29 29 74 70 61 57 43 40 28 27 11 12 72 68 65 61 51 47 31 28 10 9 62 49 24 17 11 61 57 54 49 47 42 27 24 9.9 8.9 71 70 69 67 66 65 59 57 46 45 72 69 66 61 52 47 35 31 25 22 69 71 69 69 55 62 43 50 40 42 74 69 71 65 77 73 70 66 61 57 71 67 62 58 48 44 24 21 11 10 59 59 48 40 49 43 38 32 32 26 77 74 68 65 63 54 47 46 37 34 72 68 67 64 50 47 38 35 25 23 79 57 49 47 42 40 34 33 30 26 41 30 74 57 67 67 85 76 76 81 81 40 62 14 18 8 25 79 94 94 83 99 99 93 62 48 70 10 79 75 77 74 75 71 72 67 67 61 74 68 70 62 62 49 41 23 15 5.1 68 63 61 57 49 44 36 31 24 21 73 70 53 50 62 60 49 49 23 25 71 64 67 58 61 50 57 44 43 27 67 64 50 49 38 37 36 35 29 28 76 70 65 60 50 46 35 33 16 17 70 68 62 60 46 44 25 26 7.2 9 61 48 23 17 11 61 60 54 52 44 44 21 24 6.5 9.8 71 69 68 66 66 64 58 57 45 45 74 69 67 61 55 46 38 29 27 20 68 70 70 68 52 61 40 48 37 38 74 69 71 66 77 73 69 65 56 53 69 67 59 56 44 42 20 21 7.9 11 59 60 45 38 48 42 35 30 27 21 76 74 69 66 65 57 45 49 37 38 69 67 65 63 49 46 38 35 25 24 79 58 53 49 47 41 40 35 35 28 43 29 73 57 68 67 86 76 76 81 81 41 58 14 20 9.8 29 79 94 94 82 99 99 93 60 45 70 16 79 76 78 75 76 73 74 70 70 65 78 72 77 69 74 62 62 39 38 13 70 65 64 59 49 43 36 30 24 20 73 71 51 49 57 56 39 42 11 16 75 68 73 64 69 56 63 49 48 31 68 65 53 51 42 40 40 38 33 31 76 72 68 62 56 48 43 34 21 15 70 67 61 58 45 44 25 27 7.8 11 59 44 18 12 7.6 54 56 49 48 42 41 23 25 7.8 11 70 68 67 65 64 62 55 52 43 40 72 69 63 60 46 43 28 25 20 17 72 71 72 70 63 65 53 55 47 48 78 73 73 67 78 75 71 68 61 57 68 65 58 55 43 41 20 21 8.6 12 60 60 49 40 50 42 37 30 32 24 76 74 68 65 64 56 42 46 32 32 69 67 64 61 47 44 36 33 23 23 59 58 50 48 44 40 36 33 32 27 44 29 75 58 68 68 87 76 76 81 81 41 50 12 12 9.1 23 79 94 94 82 99 99 92 58 45 72 9.2 79 75 78 74 77 73 74 69 70 64 79 68 69 63 60 51 35 24 8.6 4.4 63 60 54 52 38 37 25 25 15 16 73 71 51 49 61 60 47 47 19 21 79 64 66 59 59 50 54 44 39 29 79 66 53 51 42 40 39 38 32 31 79 70 61 56 42 38 27 25 11 11 79 69 68 64 58 53 42 39 21 21 61 49 23 17 11 79 61 60 55 54 50 39 36 21 21 79 70 70 68 68 66 62 60 53 52 73 69 66 62 51 46 33 29 23 20 79 71 72 69 57 61 42 48 40 39 79 71 73 68 78 74 73 68 66 62 79 69 66 62 56 52 35 33 20 21 61 61 51 43 51 45 41 35 37 29 79 74 69 66 65 56 50 50 42 39 79 69 70 66 58 54 49 45 36 34 79 57 49 47 40 38 32 31 27 24 43 30 75 59 68 68 86 76 76 81 82 40 68 19 25 8.2 29 79 94 94 81 99 99 93 64 49 73 9.9 79 75 78 74 77 72 75 70 72 65 79 72 78 71 77 67 72 52 58 23 79 59 63 52 51 37 39 24 28 15 79 69 59 45 65 55 50 41 19 15 79 68 76 63 72 55 68 47 60 31 79 65 55 50 43 39 40 36 34 30 79 69 68 55 54 42 42 29 24 11 79 67 70 59 62 47 48 31 28 16 60 45 18 12 7.7 79 52 63 46 58 40 44 27 26 14 79 68 72 65 70 62 65 55 57 45 79 67 69 58 58 42 42 25 31 15 79 72 75 70 71 65 64 56 59 49 79 74 76 69 79 74 75 69 67 60 79 66 68 58 59 44 42 26 30 15 79 60 51 40 50 42 38 31 36 25 79 73 68 64 66 54 45 45 37 33 79 67 71 62 59 46 51 36 39 25 79 54 46 44 38 35 29 28 23 21 45 32 76 56 68 67 87 76 76 81 81 38 61 25 20 1.3 26 79 94 93 82 99 99 93 63 48 70 11 78 71 77 69 75 66 72 62 67 55 77 65 75 59 70 46 53 17 26 3.1 72 53 67 43 55 24 42 13 29 7.1 77 65 60 44 53 45 32 29 7.5 7.7 76 61 74 55 70 46 67 40 58 25 65 58 47 40 35 28 32 26 25 19 78 65 71 46 60 27 46 15 22 5 68 58 58 45 41 27 21 13 5.4 3.4 45 28 9.6 6.8 4.8 54 39 47 26 38 19 18 9.3 5.4 3.2 72 61 70 57 67 54 57 44 43 31 74 61 66 46 52 28 34 14 24 9.3 64 61 69 57 47 48 33 31 29 18 76 66 71 60 77 69 69 59 55 47 67 56 56 41 40 25 18 9.4 7.4 3.9 50 52 40 30 38 33 27 23 25 16 74 69 59 57 54 45 28 36 19 23 68 58 63 51 44 30 33 20 21 12 53 49 40 39 34 31 27 25 23 20 36 23 69 51 67 67 86 75 75 80 80 34 39 7.7 8.1 7.2 15 79 94 94 81 99 99 93 58 41 69 10 79 76 77 75 75 72 71 68 66 62 79 69 70 63 62 51 38 22 10 3.8 66 63 59 57 43 43 29 30 18 20 76 73 61 57 63 61 48 49 18 22 79 65 67 60 62 52 56 45 41 29 79 64 46 48 33 35 30 33 23 26 79 71 64 60 51 48 37 36 16 17 79 69 64 60 49 43 31 26 11 9.6 61 47 21 14 9 79 61 56 52 48 43 29 24 11 9.6 79 69 68 66 66 64 58 55 46 44 74 69 67 62 54 49 37 33 27 24 79 72 73 71 64 65 52 55 51 47 79 70 70 67 77 74 68 66 56 54 79 67 61 57 47 42 25 21 11 10 59 61 46 39 49 44 36 32 28 23 79 75 68 67 64 57 45 49 36 36 79 68 67 64 49 46 37 35 25 22 79 61 54 52 45 44 38 37 32 30 39 25 72 56 68 68 86 76 77 81 81 40 58 14 19 8 26 79 94 93 81 99 99 93 60 46 70 11 78 71 77 69 75 67 72 62 67 55 77 65 75 59 70 46 53 17 26 3 72 53 67 43 55 24 42 13 29 7.2 77 66 60 44 53 45 31 29 7.5 7.7 76 61 74 55 70 46 67 40 58 24 65 58 47 40 35 28 31 26 25 19 78 65 71 47 60 27 47 15 22 5 68 58 58 45 41 27 21 13 5.4 3.3 45 28 9.6 6.7 4.8 54 39 47 26 38 19 18 9.3 5.2 3.1 72 61 70 57 67 54 57 44 43 31 74 60 66 46 52 28 34 14 24 9.3 64 61 69 57 47 48 33 31 29 18 76 66 71 60 77 69 69 59 55 46 67 56 56 41 40 25 18 9.3 7.4 3.9 50 52 40 30 37 33 27 23 24 15 74 70 59 57 54 46 28 36 19 23 68 58 62 51 44 30 33 20 21 12 52 49 40 39 34 31 26 25 23 20 36 23 69 51 67 67 86 75 75 80 80 34 38 7.8 8 7.2 15 79 94 94 81 99 99 93 58 41 70 7.3 79 76 78 75 76 73 74 70 70 66 77 72 76 69 73 63 62 42 40 15 66 63 58 57 45 44 33 32 22 22 72 70 51 48 62 59 48 47 21 22 75 68 72 64 66 56 60 48 45 32 69 65 54 52 44 41 42 40 35 33 74 70 63 59 47 47 32 35 14 18 71 68 65 61 54 50 39 35 20 18 61 48 23 16 10 63 60 58 53 52 47 36 33 20 18 71 69 68 67 66 65 59 58 47 47 73 69 65 61 49 44 31 27 21 18 71 71 72 70 56 62 41 48 37 39 77 73 73 68 78 74 72 68 63 59 79 67 62 58 51 47 31 28 20 16 62 61 52 43 52 45 40 33 36 29 79 74 69 66 65 57 46 48 37 35 79 68 66 64 50 48 40 37 28 26 79 58 51 49 44 41 36 34 32 28 43 30 73 57 67 67 85 75 76 80 80 38 58 13 15 8.6 28 79 94 94 82 99 99 92 60 47 70 8.7 78 75 77 73 75 71 72 67 67 61 73 66 69 60 61 47 34 20 7 3.6 66 61 58 53 44 38 31 26 22 17 74 70 58 49 64 58 49 43 20 18 72 63 70 58 66 49 63 41 53 23 66 61 49 44 37 32 35 30 28 23 75 69 62 56 48 40 35 28 19 14 72 66 66 58 54 45 38 28 17 11 59 44 18 12 7.2 68 63 62 54 56 46 40 29 21 13 73 68 71 65 69 63 63 56 55 46 74 68 68 60 56 45 40 29 29 20 71 68 71 66 63 59 54 50 49 43 74 68 70 64 77 73 69 64 59 54 70 65 63 55 53 43 33 23 19 12 62 59 49 36 50 40 37 29 29 19 77 73 72 65 68 57 58 50 50 39 70 65 66 60 53 44 44 34 33 23 60 55 49 45 42 38 36 31 29 24 39 26 71 57 67 67 87 76 76 80 80 40 71 22 35 7.2 28 79 93 93 82 99 99 93 60 47 70 7.4 78 74 77 73 74 70 70 66 65 60 73 67 69 61 59 49 36 23 12 5.6 65 62 58 56 44 41 32 30 22 21 72 69 51 48 61 59 46 48 18 22 70 63 66 57 59 48 53 41 37 24 65 62 47 46 35 35 33 33 27 26 74 69 63 59 48 45 34 33 15 17 69 67 60 58 44 44 25 27 8.2 11 59 47 22 16 10 59 58 52 51 43 44 23 27 9 12 70 68 67 65 64 62 56 54 44 43 73 68 65 60 52 46 36 31 26 22 79 69 71 68 53 59 38 44 42 35 79 68 70 65 76 72 65 61 53 49 79 65 56 55 42 41 19 21 9.2 12 55 57 41 36 42 39 29 27 25 21 79 73 66 63 61 52 41 43 32 30 79 65 62 60 44 43 33 32 21 21 79 57 52 48 46 41 38 34 33 28 40 28 72 55 67 66 86 76 76 80 81 40 60 13 20 8.2 24 79 94 94 81 99 99 93 61 46 72 9.1 79 74 78 74 77 72 75 69 72 65 79 72 77 70 76 65 69 47 47 17 70 60 63 52 51 36 37 24 26 15 76 68 60 46 64 55 46 39 14 13 79 67 76 62 73 53 69 45 59 26 79 63 52 47 40 35 37 33 31 26 79 68 67 55 54 39 41 27 21 12 79 65 67 56 57 42 41 25 20 9.8 56 41 14 8.6 4.8 79 55 59 46 54 39 37 22 18 9.4 79 67 71 64 70 61 64 52 55 42 74 66 68 56 55 41 38 26 29 18 79 70 74 68 70 63 63 55 58 48 79 73 75 69 78 74 75 68 69 58 79 63 65 52 56 38 36 19 22 10 61 58 50 36 47 39 34 28 31 21 79 73 70 64 67 54 52 45 42 33 79 64 69 59 57 41 49 31 37 21 79 53 47 42 41 34 34 28 27 22 41 30 73 56 67 67 87 77 76 81 81 41 63 14 22 6.4 27 79 93 94 82 99 99 92 63 48 72 8.4 78 74 78 73 76 72 74 69 71 64 75 69 72 64 64 53 41 24 11 4.4 65 61 56 54 41 39 29 27 19 18 73 70 53 47 61 56 43 40 14 13 72 65 69 61 64 53 59 47 44 30 66 62 50 45 39 33 36 31 30 25 74 69 60 56 46 42 33 30 17 15 71 67 66 59 56 46 42 29 21 11 60 45 14 8.3 5.1 73 66 67 59 62 51 44 31 24 12 72 69 70 66 68 65 63 59 56 51 73 68 67 60 52 44 34 26 23 17 71 70 72 67 62 60 52 51 49 46 78 73 77 71 77 74 72 68 66 60 71 66 65 57 56 45 38 25 25 13 63 60 52 40 52 43 42 33 33 24 77 73 71 65 67 57 59 51 50 39 72 67 70 64 60 51 53 43 44 32 57 54 45 44 39 36 31 29 25 23 42 30 70 58 67 67 87 75 75 81 81 38 70 16 31 6.4 31 79 94 94 81 99 99 92 60 47 68 9.3 78 76 77 74 75 72 71 68 66 62 73 69 69 63 61 51 41 26 15 6.8 67 63 60 57 46 43 33 31 22 20 75 73 59 56 66 64 54 53 26 27 70 65 66 59 59 51 54 44 39 28 65 64 47 49 35 37 32 35 25 28 76 71 65 60 53 48 41 36 21 17 72 69 64 60 52 46 35 29 16 12 62 50 26 19 12 64 61 57 52 49 44 34 28 18 13 71 69 67 66 65 63 56 53 43 40 73 69 67 62 56 49 41 34 31 25 73 72 73 71 61 63 46 50 46 42 73 70 69 66 76 74 67 65 56 53 71 68 62 58 51 45 31 25 18 14 58 60 45 40 47 44 35 33 30 26 76 75 68 66 64 56 46 49 36 35 71 69 67 65 52 49 43 39 31 27 79 60 54 51 46 43 39 36 33 29 40 27 73 56 68 67 87 76 76 81 81 38 64 16 25 8.6 27 79 93 93 82 99 99 92 59 45 69 7.3 78 73 77 72 75 70 71 66 66 61 77 69 75 65 71 55 55 28 29 7.2 65 59 56 52 39 35 26 23 17 15 72 68 52 47 52 53 33 38 9.2 14 74 64 71 59 66 51 61 44 46 26 64 61 46 44 33 33 31 31 24 24 74 68 62 55 46 40 31 26 13 12 66 62 56 53 41 37 23 22 7.9 8.7 53 38 15 11 7.3 49 48 45 39 38 33 20 19 7.5 8.9 67 65 62 62 59 59 46 50 30 38 70 65 59 55 41 38 24 22 15 14 51 65 51 62 26 49 11 29 5.2 17 77 70 72 64 77 72 68 64 55 52 64 60 53 48 39 34 19 18 9.1 9.8 55 55 41 33 44 36 31 25 24 19 75 72 65 60 59 48 36 39 26 26 65 61 58 55 41 37 31 27 20 18 79 54 48 44 39 36 32 30 27 24 35 24 72 53 66 66 85 75 75 79 80 38 50 20 25 11 19 79 93 93 80 99 99 92 61 46 72 9 78 75 78 74 76 73 74 70 71 66 75 70 72 66 64 55 41 29 16 7.4 66 62 59 55 45 41 33 28 23 19 74 71 53 48 67 62 54 48 21 19 70 65 66 60 60 52 55 45 40 29 69 65 54 50 43 38 40 35 33 28 74 70 64 58 51 44 39 31 21 16 74 69 69 63 61 52 47 36 27 17 64 53 24 16 11 72 66 66 59 60 52 45 35 28 17 74 71 72 69 71 68 67 62 60 55 74 70 68 63 57 50 42 34 32 24 73 72 74 70 63 62 51 50 47 43 78 74 77 73 77 75 74 70 68 62 73 69 68 62 60 51 43 33 31 20 63 62 53 43 53 45 42 33 37 27 76 74 71 66 68 58 58 52 49 39 74 70 72 67 63 56 57 48 48 38 61 58 51 49 44 41 36 34 28 26 43 31 72 61 67 67 85 75 75 80 81 38 76 43 55 12 33 79 93 93 80 99 99 92 60 48 69 6 78 74 76 72 73 69 70 65 64 58 78 65 67 59 57 46 34 19 11 4.2 65 61 57 54 41 38 29 27 18 18 72 68 51 47 57 56 40 42 14 17 78 61 64 55 57 45 52 39 37 23 78 61 47 44 34 33 32 31 25 24 78 69 62 57 46 42 31 29 13 14 78 65 58 55 42 40 23 22 8 7.8 58 44 19 13 8.8 78 54 48 45 40 37 21 21 8.3 8.6 78 66 65 63 62 61 52 53 38 41 71 66 62 56 45 39 28 23 19 16 78 68 67 65 47 56 32 42 28 33 78 67 69 64 75 72 65 61 52 49 78 63 56 52 40 38 19 18 8.8 9 52 54 38 32 39 35 27 23 20 17 78 73 64 62 58 50 36 40 27 28 78 64 62 59 44 41 34 31 23 20 78 55 48 45 41 37 33 30 29 24 39 25 71 53 67 66 86 75 76 80 80 38 61 14 21 8.3 22 78 93 93 81 99 99 92 58 45 68 8.5 78 75 76 73 74 71 71 67 65 61 72 68 68 62 59 50 38 25 15 6.6 66 62 59 55 45 41 32 30 21 20 75 72 59 55 66 64 54 53 28 28 70 64 65 59 59 51 55 45 40 29 65 64 47 48 34 36 32 34 25 27 76 70 65 58 51 46 38 35 19 18 72 68 64 60 51 45 33 28 13 11 61 48 23 16 10 64 61 57 52 50 44 31 27 14 12 70 69 67 65 64 62 55 52 42 38 73 69 67 62 55 49 37 32 27 23 72 71 73 69 58 60 44 47 41 38 73 69 69 66 76 73 67 64 56 53 70 67 62 58 50 44 28 23 14 12 58 60 45 39 46 43 34 31 29 24 76 74 69 66 65 57 45 48 35 35 71 68 66 63 51 48 41 37 28 25 78 60 53 51 46 44 38 37 33 30 39 25 72 55 67 67 87 76 76 80 80 38 64 17 25 7.1 27 78 93 93 81 99 99 92 61 46 69 6.1 78 74 76 73 74 70 71 67 66 60 73 67 69 60 61 48 38 20 11 3.9 67 63 60 56 46 42 33 29 21 18 72 70 50 48 61 60 46 47 18 22 70 63 65 57 59 48 53 41 38 25 66 63 49 47 37 36 34 33 27 26 75 70 65 59 51 45 36 32 15 15 68 66 59 57 42 43 20 25 4.6 9.9 60 46 21 15 9.5 57 56 49 47 38 40 17 23 4.2 11 70 69 67 66 65 64 56 57 42 45 73 68 66 60 53 46 37 30 27 21 66 69 68 67 44 58 29 42 26 33 73 68 69 65 76 73 68 63 56 52 67 65 57 55 40 41 15 21 5.1 11 58 58 44 36 45 40 32 28 25 21 75 73 68 65 64 56 43 46 35 33 68 66 64 62 47 45 35 35 21 24 78 56 50 46 44 38 36 31 31 25 41 29 73 57 67 67 86 75 75 80 80 40 59 11 13 7.3 26 78 93 93 81 99 99 92 61 47 70 8 78 75 77 74 75 72 73 68 69 63 78 72 77 69 76 63 71 44 57 18 61 61 50 54 34 39 22 27 14 18 72 69 50 46 62 59 43 45 13 17 73 65 69 59 63 50 58 42 42 24 67 64 51 49 39 37 36 35 30 29 73 69 55 58 40 44 27 31 12 14 67 65 57 56 40 40 20 23 5.4 9.5 63 50 19 12 7 47 56 43 45 36 36 17 19 4.8 8.7 69 68 65 64 62 62 53 54 41 43 71 67 62 58 46 41 28 23 19 15 68 70 69 69 52 59 34 43 26 29 77 71 73 66 77 74 72 67 64 58 67 63 55 53 39 39 17 20 8 11 59 58 48 37 48 37 37 26 31 21 76 73 68 64 64 55 45 45 35 33 68 65 63 60 44 43 33 34 21 24 54 54 44 43 36 36 28 29 24 22 28 72 54 66 67 86 75 75 80 80 40 24 78 93 81 99 99 92 60 45 68 7 78 73 76 72 75 70 71 66 66 61 76 69 74 65 70 55 54 28 29 7.7 65 59 56 52 39 36 26 24 17 15 72 68 52 48 52 52 34 38 11 15 74 65 71 60 66 52 60 45 45 29 64 60 46 44 34 33 31 31 24 24 74 68 61 55 45 40 30 27 12 12 65 62 52 52 32 34 13 17 2.9 5.2 53 38 14 9.6 6.5 49 47 40 38 29 31 11 15 2.8 5 66 65 62 61 59 58 47 49 30 36 69 65 58 54 40 37 23 22 15 14 52 64 60 62 35 51 22 34 15 25 77 70 72 64 77 72 69 64 55 52 63 60 49 48 31 32 11 14 4.4 6.3 54 55 41 34 44 38 31 27 25 21 75 72 64 61 59 49 36 39 26 26 65 61 58 55 37 35 26 25 16 16 78 55 46 45 39 38 32 31 28 25 36 25 72 53 66 66 84 75 75 79 80 38 49 19 23 11 19 78 93 93 80 99 99 92 60 44 69 5.9 78 75 77 74 76 72 73 69 69 64 77 71 75 69 72 62 60 41 36 15 63 61 56 55 43 43 32 32 21 22 71 69 50 48 60 58 46 46 20 22 74 68 71 63 65 55 60 49 45 32 67 64 53 50 42 40 39 38 33 32 73 69 60 57 44 45 30 35 14 19 70 67 64 60 52 49 36 34 17 16 60 47 22 16 10 61 59 55 51 49 45 33 31 17 16 70 69 68 66 65 64 57 57 44 46 72 68 65 61 52 47 35 31 25 21 70 70 69 69 55 61 41 49 32 39 77 72 73 67 77 74 71 67 62 58 69 66 61 58 50 46 29 28 17 16 60 60 49 41 49 44 38 32 35 28 75 73 67 64 63 54 47 47 38 35 70 67 65 63 50 48 39 38 28 27 78 57 50 48 43 40 36 33 31 27 42 29 73 57 66 66 86 75 75 80 80 36 56 11 14 8.6 27 78 93 93 80 99 99 92 60 46 69 6 77 74 76 72 74 70 70 66 65 60 73 66 69 61 61 50 41 24 17 6.2 65 62 58 55 43 42 31 30 19 20 72 69 51 48 56 56 38 43 13 18 70 63 66 57 60 49 54 42 38 26 64 61 47 45 34 34 32 32 25 25 75 69 62 58 45 45 30 34 13 17 67 65 56 55 40 38 21 20 6.3 6.2 58 45 20 14 9.5 55 54 47 43 38 35 19 19 6.5 7.4 69 67 66 64 64 62 56 54 45 43 72 67 63 58 48 42 31 26 22 17 66 69 66 66 48 58 35 45 34 37 73 68 69 65 75 72 66 62 53 50 65 63 52 51 36 34 15 14 6 6.7 55 57 40 34 41 37 28 25 21 18 75 73 66 63 62 54 44 47 36 35 66 64 60 58 40 38 29 27 18 17 78 57 50 47 43 39 36 32 31 26 40 28 71 55 66 66 86 75 76 80 80 39 58 11 14 7.7 24 78 93 93 80 99 99 92 59 45 68 7.2 77 73 76 72 74 69 70 65 65 59 71 64 66 57 55 42 23 13 2.8 1.8 63 59 54 52 39 37 27 26 18 17 72 68 55 48 61 57 46 43 20 18 68 60 63 54 55 44 49 37 32 20 64 59 47 42 35 30 33 28 26 21 73 68 59 54 44 40 31 29 17 14 69 64 62 55 48 39 30 21 8.8 5.6 57 42 16 9.9 6.2 65 60 57 49 49 40 31 21 11 6.6 70 67 68 64 66 62 60 55 52 44 72 66 65 58 52 44 35 27 24 18 70 68 71 67 63 61 54 52 51 47 72 66 68 62 76 71 68 62 57 51 68 62 59 51 46 36 23 15 11 6.1 59 57 46 34 47 37 35 26 26 18 76 72 69 63 66 55 55 49 47 37 68 63 63 58 46 39 35 28 23 17 58 55 47 45 40 37 33 30 26 23 37 24 71 57 66 66 85 75 74 79 79 38 70 18 31 6.2 27 78 93 93 80 99 99 92 58 46 68 5.3 77 73 76 72 73 69 69 65 64 59 72 65 68 59 60 47 38 21 15 4.9 65 61 59 55 43 40 30 27 19 18 71 69 50 47 57 55 40 42 14 18 69 61 65 55 58 47 53 41 38 26 64 61 48 46 36 35 33 33 26 26 74 69 63 58 48 44 31 30 12 14 67 65 57 56 40 41 20 24 5.3 8.6 57 44 20 15 9.7 55 54 47 45 38 38 17 22 5.2 9.3 68 67 66 64 63 62 55 55 44 44 71 67 62 57 46 41 29 25 20 16 65 68 66 66 51 57 40 45 35 37 72 67 68 64 75 71 66 62 53 50 65 64 54 53 38 39 15 19 5.7 9.7 55 56 43 37 43 38 31 27 25 20 75 72 66 62 61 52 43 44 35 33 67 66 62 60 44 43 32 33 19 21 78 56 50 46 43 39 36 32 31 26 39 27 72 54 66 66 84 75 75 80 80 38 60 11 14 7.7 24 78 93 93 80 99 99 92 58 45 69 5.5 77 73 75 72 73 69 70 65 64 59 73 66 69 61 62 51 43 26 19 7.2 65 62 58 55 43 41 31 29 20 20 72 69 50 47 55 55 38 42 14 18 70 63 66 58 60 49 54 42 39 26 63 61 46 45 34 33 32 32 26 25 74 69 62 58 44 45 29 33 14 17 66 65 57 56 41 40 18 22 2.5 6.7 57 43 19 13 8.7 57 57 48 46 38 38 15 20 2.4 7 68 67 65 64 63 61 54 52 40 39 71 67 61 56 43 39 25 23 17 15 66 68 68 66 51 58 34 42 29 31 72 67 69 64 75 71 65 61 52 48 65 63 54 52 38 37 13 17 3.5 7.9 56 56 41 34 41 37 29 25 21 18 75 72 67 63 63 53 43 45 34 33 66 64 60 59 42 40 30 30 16 19 78 55 46 44 40 37 32 30 29 24 40 25 71 55 66 66 85 75 75 80 80 39 58 10 13 6.8 24 78 93 93 80 99 99 92 60 45 67 6.2 78 74 75 72 73 69 68 64 62 58 78 65 65 58 55 44 31 17 9 4 64 59 56 52 41 38 29 27 19 18 74 70 57 53 63 60 49 48 22 23 78 61 63 55 56 46 51 40 36 25 78 62 43 45 30 33 28 31 21 24 78 68 62 56 47 43 35 31 18 15 78 67 62 59 50 44 32 27 12 9.9 59 46 22 15 9.5 78 59 55 50 47 42 29 24 12 9.7 78 67 66 64 63 61 55 53 43 41 72 67 65 60 52 47 36 30 26 22 78 69 71 68 55 59 40 46 38 36 78 68 68 65 75 71 65 62 53 50 78 66 60 56 47 43 25 21 12 10 55 56 41 35 43 39 30 27 24 20 78 73 66 63 61 52 42 44 32 32 78 67 65 62 48 46 38 35 26 23 78 57 49 48 42 40 34 34 29 27 37 24 70 54 66 66 86 74 74 79 79 36 65 16 23 6.2 25 78 93 93 80 99 99 91 59 44 68 4.8 78 73 76 72 73 69 69 64 63 58 78 65 67 58 58 45 35 19 11 4.4 64 60 57 53 42 38 29 26 19 17 71 68 50 47 56 55 40 42 14 17 78 61 64 55 57 46 52 39 36 23 78 61 46 44 34 32 32 30 25 23 78 68 63 56 47 43 33 30 13 14 78 64 55 53 36 36 14 17 2.1 4.6 56 41 17 12 8.1 78 53 44 42 33 33 12 16 1.9 4.7 78 67 65 64 63 61 55 54 44 44 70 65 61 56 45 40 28 24 19 17 78 67 67 66 50 58 40 48 36 41 78 66 68 63 75 71 65 61 52 48 78 62 51 50 33 33 9.7 13 2.8 5.5 53 54 39 33 41 35 28 24 22 18 78 72 65 62 59 50 37 42 29 30 78 64 59 58 39 37 26 26 14 15 78 55 48 45 42 38 34 31 30 25 38 25 72 54 66 66 86 74 75 79 79 37 55 13 14 8.9 21 78 93 93 80 99 99 92 59 44 67 3.8 77 74 75 72 73 69 69 65 63 58 75 69 73 65 70 58 61 38 44 13 72 63 67 58 58 47 46 33 33 21 73 69 51 47 62 60 48 49 21 25 69 62 66 56 60 47 54 40 39 23 66 62 50 47 38 36 36 34 29 27 76 70 69 61 61 50 51 38 30 18 69 66 61 59 47 46 24 29 5.5 10 60 48 25 20 14 65 60 55 52 46 44 23 27 6 11 68 66 65 63 63 61 57 55 48 47 76 70 73 65 66 54 51 36 39 24 68 69 69 67 54 60 41 49 33 42 71 67 67 62 74 71 65 60 56 48 68 66 59 57 47 45 24 26 12 15 59 59 46 40 46 41 32 28 25 22 75 73 67 63 63 53 47 45 38 33 70 68 66 64 52 50 43 41 31 31 64 61 56 54 55 49 47 41 45 33 41 28 71 58 65 65 86 75 75 80 80 36 64 14 19 7 26 78 93 93 79 99 99 92 58 46 68 6.5 77 73 76 72 74 70 71 67 66 62 76 69 74 66 71 58 58 35 37 12 66 60 59 53 44 38 30 25 20 16 72 68 50 47 55 54 39 40 14 17 74 67 72 64 68 57 64 52 51 36 67 63 51 48 40 37 37 35 30 29 74 68 64 56 50 41 37 28 17 13 68 64 61 56 47 42 28 26 8.8 9.8 55 41 17 13 9.3 57 53 52 45 44 38 25 23 8.2 9.6 68 66 65 63 62 60 54 52 43 40 71 66 63 57 48 41 31 25 22 17 66 66 65 63 52 57 37 45 28 34 76 71 70 65 76 72 70 66 58 55 66 62 56 51 43 38 21 19 9.1 9.8 60 59 48 40 49 42 37 30 32 25 75 72 68 63 63 53 44 44 33 31 66 63 60 57 43 38 32 28 20 18 77 56 50 47 43 40 36 34 31 27 40 27 71 53 65 65 86 74 74 80 80 37 49 13 17 7.8 25 77 93 93 79 99 99 92 59 45 69 4.7 77 74 76 73 75 71 72 68 68 63 77 71 74 68 71 62 58 40 36 15 64 60 56 53 42 40 30 28 20 19 70 68 48 46 59 57 44 44 18 19 77 66 68 61 62 53 56 45 42 29 77 63 50 48 39 37 37 35 30 28 77 68 62 56 47 42 31 29 12 15 77 66 63 58 51 46 36 31 19 15 58 44 19 13 8.5 77 58 55 51 49 44 34 29 19 16 77 68 68 65 65 63 57 56 44 44 71 67 62 57 45 40 27 24 18 16 77 69 69 68 53 59 39 45 33 37 77 71 71 66 76 73 70 66 61 56 77 64 61 56 50 44 32 27 20 16 59 59 47 39 48 42 36 30 33 25 77 73 68 64 63 54 44 45 36 34 77 65 65 61 50 46 40 37 29 26 77 55 47 44 40 37 33 30 29 24 41 29 72 54 66 65 85 75 75 80 80 36 60 11 15 7.8 27 77 92 93 80 99 99 92 61 46 67 4.7 77 73 75 72 72 69 68 64 63 58 71 65 67 59 59 47 38 22 15 5.2 66 61 59 55 44 40 32 28 22 18 71 68 49 47 59 58 44 46 18 21 68 61 64 56 57 47 52 41 38 25 64 61 47 45 35 34 32 32 26 25 74 69 64 58 51 45 38 32 20 16 66 64 56 54 39 38 19 21 4.2 7.1 58 46 22 16 11 55 52 46 43 36 35 16 19 4.1 7.1 69 67 66 64 63 61 55 53 42 39 71 66 63 57 48 41 32 25 22 16 64 66 69 65 49 55 37 42 34 34 72 67 68 63 74 71 65 61 53 49 64 63 53 51 37 36 14 16 5 8.2 54 56 40 35 41 38 29 26 23 20 74 72 65 61 61 50 40 42 31 30 66 64 60 58 41 39 29 29 17 18 77 56 48 47 42 39 35 32 31 26 39 27 72 54 66 65 85 74 74 79 79 38 58 10 12 7.5 25 77 93 93 80 99 99 92 61 45 70 9.2 77 73 76 72 75 70 73 67 69 61 75 68 73 63 68 53 45 21 11 3.1 67 55 60 47 46 30 32 18 21 11 74 67 57 44 65 56 52 42 24 16 74 62 71 56 67 46 64 40 54 24 67 62 51 47 41 36 38 34 32 27 75 66 65 50 51 33 37 20 18 8.3 72 66 68 59 60 47 47 32 28 16 56 41 15 9.8 6.1 67 55 62 48 57 42 44 28 26 15 73 66 71 64 70 61 65 55 59 47 72 64 66 52 51 34 33 18 23 11 74 69 72 67 69 62 62 53 57 46 76 71 72 66 77 72 72 66 66 57 71 64 66 56 58 44 41 27 29 17 57 56 46 36 44 38 31 27 31 22 74 71 66 61 62 52 45 43 36 31 71 65 68 61 57 45 49 37 40 27 77 50 42 39 35 31 28 25 22 19 39 28 71 54 66 66 85 74 74 79 80 38 59 14 21 7.9 27 77 93 93 79 99 99 92 60 44 68 4.2 77 74 76 73 74 71 72 68 68 64 76 70 75 68 72 61 61 38 38 13 64 60 56 53 43 40 31 28 21 19 70 68 49 47 58 57 44 45 16 20 73 67 71 63 65 55 58 47 44 30 67 63 53 49 42 39 40 37 33 31 72 68 61 56 45 42 30 31 13 16 68 65 61 57 48 44 33 30 16 15 58 44 21 15 9.5 58 54 53 47 47 41 31 28 16 15 69 67 66 65 63 62 53 54 39 41 71 66 63 56 47 40 28 23 18 15 67 69 68 67 53 59 39 45 32 34 76 71 71 66 76 73 70 66 60 56 68 64 59 55 47 43 28 26 17 16 59 58 49 40 50 43 39 31 34 26 74 72 66 63 62 54 45 47 37 36 69 66 65 62 50 47 40 38 29 27 77 55 47 45 41 37 33 30 28 24 40 29 71 55 65 65 86 74 75 79 80 37 57 11 13 8.4 26 77 92 93 80 99 99 92 60 46 70 5.3 77 74 76 72 75 71 72 67 68 63 73 68 69 63 60 51 33 21 7.9 3.8 62 58 53 51 38 37 26 25 17 16 70 68 48 46 64 61 48 47 17 18 68 63 64 57 56 49 51 42 35 25 67 63 50 47 38 34 36 32 29 26 71 67 58 54 44 40 32 28 16 13 72 67 67 61 58 50 42 34 21 15 62 50 23 16 10 69 62 63 54 57 47 41 31 23 15 71 69 68 66 67 65 60 59 51 50 70 67 62 58 45 41 26 24 17 16 70 70 71 69 59 59 46 45 40 38 76 72 76 72 76 73 72 67 66 60 71 66 66 59 56 49 38 30 27 18 59 58 48 38 47 40 36 28 30 22 75 72 68 64 65 55 53 48 44 35 72 68 70 65 60 53 52 45 42 35 53 54 44 45 38 37 31 31 26 24 40 28 71 56 65 65 85 74 74 79 79 34 75 42 51 9.5 29 77 92 93 79 99 99 91 60 48 67 4.4 76 72 75 71 74 69 70 65 65 60 75 68 73 64 70 56 56 30 32 8 63 58 55 51 39 36 27 24 18 16 70 67 49 45 51 52 32 37 8.6 13 72 63 69 58 63 48 56 41 40 25 63 59 44 42 32 31 30 29 23 22 72 66 59 54 44 40 30 27 13 12 64 61 53 52 37 38 19 22 5.4 8.9 53 38 15 11 7.7 48 45 42 38 34 33 17 20 5.4 8.8 65 64 61 61 59 58 49 49 35 38 68 64 57 53 39 36 22 20 13 13 59 65 59 62 35 50 19 32 13 24 75 69 70 63 76 71 68 63 54 51 62 59 50 48 36 35 15 18 6.5 9.9 52 54 39 32 42 35 29 24 22 19 73 71 61 59 55 47 32 37 24 25 63 60 56 54 39 37 28 28 18 18 77 52 43 42 36 35 29 28 25 22 35 24 69 52 64 64 85 73 73 78 78 36 49 11 11 8.3 20 77 92 92 78 99 99 91 59 43 67 4.4 77 73 76 72 74 69 71 66 66 60 75 68 73 64 67 55 50 29 24 7.5 62 59 54 52 38 37 26 25 16 16 70 67 47 45 51 53 34 40 10 15 72 64 68 59 63 51 58 44 43 28 64 62 47 45 35 33 32 31 25 24 72 68 60 55 44 41 30 28 12 12 64 63 53 53 36 37 17 21 4.6 8.3 54 40 16 12 7.5 52 50 43 41 33 34 14 19 4.5 8.2 66 65 63 62 60 60 51 52 38 40 68 65 58 54 41 38 24 22 16 14 58 64 63 62 38 52 25 37 22 29 74 69 69 64 75 72 68 64 56 52 63 62 50 50 35 35 14 17 5.9 9.4 54 56 43 36 45 38 35 28 29 22 73 71 63 61 58 50 34 39 25 26 64 63 58 57 38 38 28 28 17 18 52 53 43 43 37 35 30 29 26 23 39 27 69 52 65 65 84 74 74 79 79 28 52 9.9 12 8.1 23 77 93 93 79 99 99 92 59 44 65 6.1 76 73 75 71 72 68 68 64 63 58 71 65 66 59 58 47 34 21 9.5 4.4 63 59 54 52 38 38 25 26 16 16 70 68 49 46 65 61 54 50 27 26 67 60 62 54 54 44 49 38 34 22 64 62 48 47 36 36 34 34 28 28 73 67 61 55 44 41 29 28 13 13 66 64 56 55 39 39 20 21 5.8 6.5 62 50 24 17 11 46 54 39 43 31 33 15 17 5.5 6.2 68 67 64 64 62 61 51 52 38 40 70 66 62 57 46 41 28 24 18 16 67 70 66 68 56 63 47 53 48 44 71 65 66 61 74 70 65 61 53 50 64 63 52 51 35 36 14 15 6.1 6.8 56 56 43 35 42 37 29 25 25 20 75 72 66 62 62 53 41 43 32 30 66 65 60 59 38 40 27 29 17 18 77 55 48 46 41 37 33 30 29 24 39 28 74 54 65 65 84 74 74 79 79 37 46 8.8 12 7.9 22 77 93 93 80 99 99 92 60 46 66 3.8 76 72 74 71 72 68 68 63 62 56 71 64 67 58 59 46 38 21 15 5.3 63 58 55 51 39 35 26 22 15 14 71 67 50 47 51 51 32 37 7.9 13 68 61 64 55 58 47 53 40 37 25 62 59 45 43 33 32 31 30 24 23 73 67 61 54 44 39 28 26 12 12 65 62 55 52 37 35 18 18 3.8 6.1 56 42 18 12 7.8 52 51 43 41 34 33 15 17 3.6 6.3 67 65 63 61 61 58 52 50 39 39 69 64 57 51 39 34 22 19 14 12 62 66 63 63 44 53 32 40 28 34 71 66 67 62 73 70 63 58 51 46 63 60 51 48 35 33 13 14 3.8 7.3 52 53 37 30 40 34 27 23 20 17 73 71 64 60 59 48 38 39 29 27 65 63 59 56 40 36 29 26 18 16 77 54 47 44 40 37 33 30 29 24 37 25 70 53 65 65 85 74 74 79 79 36 57 10 13 7.5 20 77 92 92 79 99 99 92 57 42 67 3.9 77 73 76 72 74 70 71 67 67 63 75 69 73 66 69 59 54 35 29 11 63 60 56 53 42 38 29 26 20 17 69 67 48 47 59 57 44 45 17 20 72 66 69 61 63 53 56 45 41 28 66 62 51 47 40 37 38 35 31 29 72 67 61 56 47 42 32 30 14 15 68 64 59 55 45 41 27 24 10 9.5 58 45 21 15 10 57 53 50 46 42 39 25 23 10 10 68 66 65 63 62 60 53 52 40 40 69 65 60 55 44 38 27 22 17 15 68 68 69 65 54 57 41 44 38 36 75 70 70 65 76 72 70 66 61 56 66 62 55 52 41 38 21 19 11 10 57 57 46 38 47 40 35 30 30 24 74 71 66 62 61 52 43 44 35 33 67 64 61 58 42 41 31 30 21 20 77 54 44 44 39 37 31 30 28 24 41 28 70 53 65 65 85 74 74 79 79 36 62 12 14 8.2 26 77 93 92 80 99 99 91 59 45 68 5.1 76 72 75 71 74 69 71 65 67 60 71 64 67 57 57 43 29 14 5 1.9 59 56 48 47 32 32 20 21 12 12 70 67 49 45 59 55 39 38 11 12 69 61 65 55 59 46 53 38 37 21 62 58 44 39 32 27 30 25 23 19 70 65 54 50 37 35 25 23 11 8.5 68 62 60 53 48 37 31 19 13 5 56 40 13 7.7 5.2 68 60 60 48 52 38 33 18 15 5.1 68 66 66 63 64 61 58 55 51 46 70 64 61 54 43 37 24 21 15 13 64 66 63 63 50 53 38 42 30 34 76 69 75 69 75 71 69 64 62 55 67 61 58 50 46 35 27 15 16 6.8 57 55 44 32 46 37 34 26 25 18 74 70 67 61 63 51 56 47 45 33 68 62 64 58 51 42 42 32 31 21 50 49 39 38 32 30 24 23 20 17 39 26 69 54 64 64 85 73 73 79 79 34 69 18 30 5.7 27 77 92 92 79 99 99 91 59 47 67 3.5 76 72 74 71 72 68 68 63 62 57 70 64 66 58 57 46 37 22 15 6 63 59 56 52 41 37 28 25 17 17 71 67 50 47 50 52 32 37 8.8 14 67 60 63 54 55 45 49 38 34 22 61 59 44 42 32 31 30 29 24 23 73 67 61 56 44 41 28 28 12 13 64 61 54 50 38 32 20 15 5.1 4.6 55 40 17 12 8.3 50 48 44 39 37 31 18 16 5.2 5.3 67 65 63 61 60 59 51 50 38 38 69 64 58 52 41 36 23 20 15 13 62 67 63 63 38 53 23 36 24 26 70 66 67 62 74 70 63 59 50 46 62 59 50 45 35 29 15 12 5.6 5.8 52 54 37 31 39 34 27 23 19 16 73 71 63 60 58 50 38 42 30 30 64 61 57 54 39 33 28 23 17 14 77 54 47 44 40 37 33 30 29 25 37 25 68 52 65 65 85 73 74 78 79 36 57 11 13 7.2 21 77 92 92 79 99 99 92 58 43 66 3.1 76 72 74 70 71 67 67 63 61 56 70 64 65 57 56 45 33 18 10 4.1 63 59 54 50 37 35 25 23 15 15 70 67 49 46 50 52 31 38 6.9 14 67 60 62 53 55 45 50 38 34 22 61 58 43 41 31 30 29 28 22 21 73 67 60 54 40 38 25 26 10 12 63 61 51 50 33 33 14 16 2.9 5 55 41 17 12 7.9 51 50 41 39 31 31 13 15 3.1 5.4 67 65 63 61 60 58 51 49 39 37 68 63 57 51 39 34 22 19 15 12 61 65 64 63 40 51 25 35 24 27 71 66 67 62 73 70 63 59 49 46 61 59 47 46 30 30 9.2 12 3 5.4 51 53 35 29 38 33 25 22 18 16 73 71 64 60 59 48 36 39 27 27 62 61 55 54 33 33 22 22 12 13 77 52 45 42 38 35 31 28 27 23 37 25 70 52 65 65 84 73 74 78 79 37 54 9.9 12 7.5 20 77 92 92 79 99 99 91 58 42 66 2.3 76 72 74 70 72 68 68 64 62 57 70 64 66 58 57 47 35 23 12 6.3 63 58 55 51 41 37 29 26 19 17 70 67 49 45 57 55 41 43 15 19 67 60 63 54 55 45 50 38 36 22 63 59 45 43 33 32 30 30 24 23 72 67 60 54 45 41 31 29 14 14 64 62 54 52 36 34 18 18 5.3 6.5 55 41 18 13 9.2 56 51 45 42 35 34 16 17 5.6 7.1 66 65 63 62 60 59 51 51 38 40 69 64 60 54 45 39 29 23 20 16 61 64 65 61 39 50 26 36 23 27 70 65 67 62 74 70 64 59 50 47 63 60 50 47 34 32 14 14 6.3 7.7 53 54 39 34 41 36 28 25 23 19 73 71 64 60 59 50 37 39 28 28 64 62 57 56 38 35 29 25 19 16 77 52 44 43 38 35 31 29 27 23 39 27 69 53 65 65 84 73 74 79 79 37 57 12 14 8 24 77 92 92 78 99 99 92 58 43 67 3.5 76 74 75 72 73 70 70 67 66 62 72 68 68 64 61 54 42 31 18 9.6 70 67 65 62 52 50 39 38 28 26 71 70 49 48 61 61 48 49 21 24 67 64 63 58 57 50 54 47 42 33 68 65 55 52 45 43 42 40 36 34 76 72 69 65 59 55 47 45 27 25 73 71 70 68 63 62 51 53 35 42 66 55 30 23 16 70 68 66 65 62 62 51 54 37 45 71 68 68 65 66 63 55 52 37 35 72 70 66 62 52 48 33 29 22 19 75 74 75 73 72 70 63 60 36 44 71 68 68 65 74 72 66 64 57 54 73 70 69 67 62 61 45 51 33 42 60 60 49 44 48 43 38 34 34 28 74 72 67 64 66 57 43 44 34 32 73 71 72 69 64 63 57 58 47 50 55 57 45 47 38 39 30 32 26 25 42 30 74 58 65 65 85 74 74 79 79 36 68 19 24 7.7 28 77 92 92 78 99 99 91 64 49 65 4.5 76 72 74 70 72 67 67 62 61 55 69 62 64 55 53 40 24 12 3.8 1.9 60 57 49 49 34 34 22 22 14 14 69 66 49 45 60 57 45 43 18 19 66 58 60 51 51 40 45 33 29 17 61 57 44 39 32 28 29 25 23 19 70 66 54 51 39 37 27 25 13 11 66 62 57 52 42 34 21 15 4.5 2.9 55 41 16 10 6.6 63 57 53 45 43 35 21 14 5 2.9 68 66 66 63 64 60 57 53 47 43 69 64 61 56 48 41 30 25 21 17 66 67 67 65 56 57 45 47 40 40 70 65 66 61 74 70 64 60 52 48 64 60 54 47 38 30 16 9.7 5.5 3.3 56 54 41 31 43 34 31 23 22 15 74 71 67 61 63 51 51 44 41 31 65 61 60 54 41 34 30 23 18 12 52 51 44 41 37 34 29 28 25 22 35 23 68 55 64 64 84 73 73 78 78 33 69 19 30 6.9 23 77 92 92 78 98 99 91 58 45 66 4.1 76 72 74 71 72 68 68 63 62 56 70 64 65 57 55 44 31 18 9.6 4.4 60 59 51 52 37 37 24 25 15 16 68 66 45 44 52 52 35 38 11 14 66 59 60 52 53 43 46 35 31 19 61 58 42 40 30 28 28 26 21 20 70 67 55 55 41 42 29 30 12 13 64 62 54 50 35 33 17 17 4.7 5.7 53 38 15 11 7.1 50 51 41 40 31 31 14 15 4.5 6.1 67 66 64 62 61 60 51 52 38 40 68 64 59 54 41 36 22 19 13 12 60 66 64 64 39 53 21 34 15 24 70 66 66 62 74 70 64 59 50 46 62 60 49 47 32 31 12 13 4.7 6.5 52 53 37 30 38 32 25 20 19 14 73 71 63 60 58 49 34 38 26 26 64 62 56 55 34 34 23 24 13 15 49 50 39 40 33 32 26 26 22 21 23 66 49 64 64 84 73 73 78 78 39 18 77 92 79 98 99 91 56 41 66 2.7 76 73 74 72 72 69 68 64 62 58 69 65 64 59 55 47 32 22 11 5.7 63 61 57 54 43 40 32 29 22 19 68 67 44 44 58 58 44 46 19 22 65 61 60 55 52 45 45 38 29 22 62 61 44 44 32 32 30 30 23 24 72 68 62 57 49 44 37 32 19 14 65 63 55 52 39 35 20 18 5.5 6.2 57 43 18 13 8.8 57 53 48 43 38 34 18 17 5.8 6.6 68 67 64 64 62 61 53 53 40 41 67 65 58 56 43 40 27 24 18 16 68 68 69 66 53 58 38 44 35 36 70 67 66 62 73 71 63 60 49 47 64 62 52 49 37 33 16 14 6.5 7.1 51 54 36 31 38 34 25 22 20 16 73 72 64 62 59 51 38 41 29 29 66 64 60 58 41 37 30 27 19 17 76 54 44 44 38 37 31 31 28 25 38 25 69 53 64 64 84 73 73 78 78 33 62 14 17 8.4 23 76 92 92 78 99 99 91 58 44 70 19 76 75 75 74 73 72 70 69 66 64 72 70 68 66 62 58 43 33 15 7.7 70 67 65 62 52 49 40 36 28 25 72 72 50 51 57 59 38 45 8.8 16 68 67 64 62 58 55 54 49 42 33 65 65 49 49 37 38 35 36 28 29 75 72 68 64 58 53 46 41 24 22 63 67 49 55 27 35 9.4 15 1.9 3.7 61 48 19 13 7.9 44 44 33 32 23 25 7 11 1.5 3.2 71 70 68 68 66 65 54 54 37 36 72 70 65 63 53 50 38 34 29 25 65 69 69 68 50 58 36 42 32 30 73 71 71 68 74 74 67 67 56 56 62 64 46 50 27 32 7.8 11 2.5 4.9 56 61 45 43 46 46 36 35 30 28 73 74 64 65 60 57 40 44 30 31 64 65 57 58 35 35 24 23 13 13 76 58 48 47 41 39 33 32 28 25 39 28 78 61 67 66 85 75 75 80 80 45 61 21 27 13 25 76 93 94 80 99 99 91 65 51 65 2.4 76 71 73 69 70 66 66 61 59 54 76 62 63 55 52 41 28 16 8.2 3.6 61 57 53 49 39 35 26 23 17 15 69 66 47 44 52 52 36 39 12 15 76 57 59 51 52 42 47 35 32 20 76 57 41 40 29 29 27 27 20 21 76 66 59 53 44 39 31 27 13 12 76 60 51 48 33 30 15 14 3 3.5 54 39 17 12 8.4 76 46 41 37 31 28 12 12 2.7 3.5 76 64 62 61 60 58 51 50 39 39 67 63 56 51 39 35 23 21 16 14 76 64 62 61 39 49 27 36 26 28 76 64 65 60 72 69 60 57 46 43 76 58 48 44 31 28 11 10 4 4.6 48 51 32 28 34 31 22 21 16 14 76 70 60 58 53 46 32 37 25 25 76 61 57 54 37 33 26 23 15 13 76 52 43 42 38 35 31 29 27 23 35 23 69 50 64 64 85 72 73 77 78 35 55 11 12 7.9 19 76 92 92 78 99 99 91 57 42 65 0 75 71 74 70 71 67 67 62 61 56 70 62 65 55 55 42 31 17 10 4.2 61 57 53 49 38 34 26 23 17 15 76 66 47 44 54 53 37 39 12 15 67 59 62 53 55 44 50 38 35 23 61 58 43 41 30 29 28 27 21 21 72 65 59 52 43 37 29 26 13 12 62 59 50 47 31 30 13 15 2.6 4.5 53 39 16 12 8.3 51 47 40 38 29 30 10 14 2.3 4.6 66 64 62 60 59 57 47 47 32 33 67 62 57 51 41 35 24 20 17 13 60 63 65 61 39 49 24 32 20 23 70 64 65 60 73 69 62 57 48 44 59 57 45 43 29 27 9.1 11 3.2 5.1 50 52 36 30 37 33 25 22 19 16 72 70 62 58 57 45 34 36 26 24 61 59 54 53 35 32 24 23 14 14 76 52 43 43 37 35 30 29 26 23 36 24 68 52 63 63 84 72 73 78 78 36 56 11 11 7.2 20 76 92 92 78 99 99 91 57 44 65 1.8 76 71 73 69 70 65 65 60 59 53 76 61 62 54 51 40 28 16 8.2 3.4 62 57 53 49 38 34 26 23 17 15 69 66 47 44 52 51 36 38 11 15 76 57 59 50 51 40 46 34 31 20 76 57 40 39 27 27 26 25 19 18 76 65 59 53 44 38 31 26 14 12 76 60 49 48 31 31 13 15 3.1 4.8 53 39 18 13 8.7 76 49 40 39 29 30 11 14 2.9 5 76 64 62 60 58 57 48 48 34 35 67 62 57 51 41 34 24 19 16 13 76 62 61 59 35 47 21 31 17 23 76 64 65 59 72 68 60 56 45 42 76 58 46 45 30 29 10 13 3.6 6.1 47 50 31 26 33 29 21 18 14 13 76 70 61 58 55 45 34 37 25 25 76 60 55 53 36 34 25 24 15 15 76 51 43 42 37 35 31 29 27 23 35 23 70 51 64 63 83 73 73 78 78 35 56 11 13 7.8 19 76 91 92 77 98 99 91 59 43 67 3.6 76 72 75 71 73 69 70 65 66 60 70 64 65 57 56 45 29 18 6.3 3.7 57 54 46 46 30 31 18 20 10 12 68 66 47 44 62 58 51 47 22 21 65 58 59 51 51 42 47 36 33 21 64 61 47 46 36 36 33 34 27 28 70 65 54 49 36 33 23 21 8.5 8.8 68 64 61 57 49 46 32 30 12 12 58 45 20 14 8.6 54 52 48 43 42 37 26 24 11 11 67 66 62 63 59 61 46 52 29 40 68 64 59 55 43 39 25 22 15 14 66 68 65 67 56 61 43 49 32 37 72 67 68 63 74 70 68 63 60 55 67 64 59 55 47 44 25 24 12 12 56 56 45 37 45 39 34 27 32 24 73 70 65 61 59 51 41 42 33 30 68 64 63 60 47 45 36 35 24 23 76 50 41 40 34 33 27 26 23 20 39 26 69 53 63 63 84 73 73 78 78 35 45 8.4 11 7 25 76 92 92 78 98 99 91 61 44 66 3.9 75 74 74 72 72 70 69 67 66 63 74 71 72 69 69 64 61 50 46 26 73 70 71 67 64 59 55 48 42 35 71 70 49 49 65 64 54 54 30 30 68 66 64 61 59 55 56 52 44 39 68 67 57 56 49 47 47 46 42 40 75 73 72 68 67 62 60 53 42 32 72 70 69 65 63 58 55 49 42 35 68 61 38 32 23 70 68 67 63 63 59 55 49 45 37 71 68 68 66 67 64 60 58 51 50 74 72 72 69 67 62 56 49 45 36 74 73 75 73 72 70 66 64 56 57 71 69 67 65 73 72 67 65 61 58 72 69 68 65 63 58 53 47 46 39 64 64 55 51 53 50 42 39 37 34 74 73 69 66 68 61 54 51 46 39 73 71 71 68 65 61 60 56 54 49 63 64 56 57 51 52 43 44 39 35 47 33 73 60 64 64 83 73 73 79 79 35 70 26 32 6.6 36 76 92 92 78 98 99 91 65 52 64 1.9 76 71 73 69 70 65 65 61 59 54 76 62 64 55 53 41 29 16 9.3 3.7 61 57 53 50 37 34 25 23 16 14 69 66 47 43 53 52 37 39 13 14 76 58 60 51 52 42 48 36 32 21 76 57 39 39 27 28 26 26 20 19 76 66 60 53 45 39 29 26 13 12 76 60 51 48 33 29 15 14 3.5 4 53 38 17 12 8.3 76 48 41 37 32 28 13 12 3.4 4.1 76 65 62 61 59 58 48 48 34 35 68 63 57 52 39 34 21 18 13 11 76 63 59 60 39 48 24 33 21 25 76 64 66 60 72 69 60 56 47 43 76 58 47 43 31 27 11 11 4.5 5.2 48 51 32 28 34 30 22 20 16 14 76 70 61 58 54 45 32 37 25 25 76 59 55 52 35 30 25 21 16 13 76 52 42 41 36 34 29 27 26 21 35 23 68 51 64 64 83 73 73 78 78 34 56 10 12 7.3 20 76 92 92 77 99 99 91 61 44 66 3.2 76 72 75 71 73 69 70 66 66 61 74 69 73 66 69 59 56 37 32 12 62 59 55 51 40 37 27 25 18 17 68 66 47 45 56 55 41 42 15 17 71 66 69 62 63 54 57 46 42 30 65 61 50 47 39 36 37 34 30 28 71 67 60 55 45 41 28 28 11 13 66 63 58 54 46 40 29 24 12 9.7 56 42 19 14 9.2 55 51 49 42 42 35 26 21 12 9.5 67 66 64 63 61 60 52 52 40 40 68 64 59 53 41 35 23 18 14 12 65 66 67 64 47 55 35 41 35 32 74 70 69 64 74 71 68 64 58 54 66 62 57 52 44 38 24 20 13 10 58 56 46 37 46 39 34 27 30 22 73 71 65 62 60 52 38 41 31 29 67 64 62 59 46 42 36 32 24 20 76 52 42 42 36 35 29 28 26 22 40 27 70 53 64 64 84 72 72 78 78 35 55 11 12 8.8 25 76 92 92 78 98 99 91 59 45 64 1.6 75 72 74 71 73 69 69 65 64 59 70 64 65 58 55 45 30 18 9.7 4.1 60 57 53 49 37 34 25 22 16 15 67 66 45 44 54 53 38 40 14 16 67 61 62 55 54 46 49 39 34 24 64 61 47 44 35 33 33 31 26 24 70 66 58 53 45 39 31 27 13 12 64 60 54 50 38 35 21 19 6.9 6.7 54 40 17 12 7.8 53 49 45 40 36 33 18 17 6.5 6.9 67 65 63 62 61 60 52 51 38 39 66 63 55 51 38 34 21 19 13 12 67 67 67 65 48 55 31 39 27 30 74 70 70 65 75 72 69 65 59 54 63 59 51 47 36 33 16 15 7.6 7.4 53 54 42 34 43 37 32 26 28 21 72 71 62 60 57 48 35 38 27 26 65 62 59 56 40 37 29 27 19 17 50 52 41 42 34 34 27 28 24 22 25 69 52 64 64 84 72 73 77 78 32 22 76 91 78 98 99 91 59 44 63 2 75 71 75 71 75 70 74 69 74 66 75 62 65 56 56 44 36 21 17 7.3 61 56 53 49 38 34 27 23 17 15 68 65 45 42 53 52 37 39 12 15 75 57 60 50 52 41 47 34 31 18 75 59 43 42 32 31 29 29 22 22 75 65 58 52 45 39 32 28 16 13 75 60 53 51 38 37 21 23 7.8 10 54 41 18 13 9.7 75 50 43 42 34 35 17 20 6.9 9.6 75 63 62 60 60 58 52 52 42 43 67 62 57 51 41 34 24 19 16 13 75 64 63 62 44 51 31 38 25 30 75 63 64 59 73 68 64 58 53 47 75 58 50 47 36 35 16 19 8 11 49 52 36 31 37 34 27 23 23 19 75 70 61 58 56 47 35 38 27 26 75 60 58 54 42 39 32 31 21 22 75 51 42 41 36 34 29 27 26 22 37 25 69 50 63 63 83 71 71 77 77 34 59 11 14 7.7 21 75 91 91 77 98 99 91 58 43 63 2.2 75 71 72 69 69 65 64 59 57 52 75 61 61 53 49 39 23 13 6 3 61 57 54 51 39 36 27 25 18 16 68 66 48 45 59 57 44 44 16 20 75 56 57 48 48 38 43 32 29 18 75 58 43 41 30 30 27 28 21 21 75 65 59 54 47 40 35 29 18 14 75 60 46 49 26 32 10 16 2.3 5.1 57 46 22 16 12 75 54 37 41 26 32 8.4 14 2.1 5.1 75 63 62 60 59 57 49 46 34 30 66 62 56 51 39 34 23 19 15 13 75 65 51 63 28 50 14 31 14 20 75 63 63 58 72 68 59 55 44 42 75 59 44 46 26 31 8 13 2.7 6.4 55 54 40 32 43 34 30 23 21 16 75 71 75 66 74 59 74 45 74 35 75 61 54 55 34 37 24 26 14 17 75 53 43 43 37 36 30 29 26 23 34 22 68 51 63 63 83 72 72 77 77 33 58 11 13 7.8 20 75 91 92 77 99 99 90 59 44 64 2.8 74 71 73 69 70 66 66 61 60 54 68 60 63 53 52 38 27 13 7.3 2.8 61 56 52 48 36 32 23 20 14 12 68 65 46 42 50 50 34 37 11 14 65 57 59 50 52 41 48 36 34 22 60 57 42 40 30 29 27 27 21 21 71 65 58 51 41 36 25 23 8.7 9.8 60 58 49 45 30 27 12 11 2.1 2.2 51 38 17 12 8.3 49 44 38 32 28 23 9.8 8.8 2.2 2.2 65 63 62 59 59 57 51 49 39 37 66 61 56 48 39 31 22 17 14 11 62 63 66 60 47 50 35 38 34 31 69 64 64 59 72 68 61 57 47 43 58 56 44 40 28 24 8.6 8.1 2.7 2.9 51 51 36 29 37 31 25 21 19 15 71 69 61 57 56 46 36 37 27 25 60 58 52 50 32 29 22 19 12 11 75 51 43 41 36 33 29 27 26 21 36 24 69 52 62 62 83 72 72 77 77 35 55 8.5 10 6.6 20 75 91 92 77 98 99 90 57 41 63 3.2 74 71 73 69 70 66 66 61 60 55 69 62 64 56 56 44 35 20 13 5.1 60 56 52 48 35 31 22 19 13 11 68 65 47 44 49 50 33 37 11 14 66 59 62 54 56 45 50 39 35 23 60 57 43 40 32 30 30 28 23 22 71 65 58 51 40 36 25 22 9.1 8.6 60 58 50 47 36 31 18 17 3.8 5.3 51 37 16 12 8.2 50 47 42 37 34 30 16 16 4 5.9 65 63 62 60 59 58 51 49 39 38 67 61 57 50 40 33 23 18 15 11 64 64 67 63 49 52 37 41 37 36 68 64 64 59 72 69 62 58 50 45 58 56 47 44 33 30 13 14 4.7 6.4 51 51 36 30 38 33 26 22 19 15 71 69 61 57 56 46 33 37 25 25 61 59 55 52 37 34 28 24 17 16 75 51 44 42 38 34 30 28 27 22 37 25 68 50 63 63 83 72 72 77 77 36 56 9.7 12 7.2 20 75 91 92 76 99 99 90 56 41 64 2.7 74 71 73 69 70 66 66 61 59 54 69 62 64 56 55 44 34 19 13 4.7 61 57 53 49 38 34 26 22 17 14 69 66 47 44 49 50 33 37 10 13 66 59 61 53 54 44 49 37 33 22 61 58 43 41 32 29 29 27 23 21 71 65 59 53 43 39 29 27 12 12 61 59 50 46 31 28 14 12 3.2 3.5 53 39 16 11 8.2 47 45 36 33 27 25 10 11 2.8 3.6 65 63 61 59 59 57 50 48 36 35 66 62 55 50 39 33 23 19 15 12 65 65 64 62 45 51 30 37 30 29 68 64 64 60 72 68 61 58 49 45 59 57 46 42 29 25 9.8 9.6 3.7 4.5 50 52 36 29 37 32 26 21 18 15 71 70 61 58 55 47 36 38 26 25 61 59 54 52 35 31 24 21 14 13 75 51 41 40 35 33 28 27 25 21 36 24 70 51 63 63 83 72 73 77 78 36 55 9.3 11 7.3 20 75 91 91 77 98 99 90 58 42 67 2.4 75 71 73 69 70 66 67 62 61 55 75 59 60 51 49 37 27 14 8.2 3.1 60 55 51 47 34 31 21 20 13 13 67 65 43 41 54 52 36 38 12 14 75 55 58 48 51 39 47 35 37 22 75 57 41 40 29 28 26 26 20 20 75 64 57 51 41 36 27 24 12 10 75 58 51 47 36 31 20 16 6.8 5.3 53 39 15 10 7.2 75 45 38 34 31 26 17 13 6.7 5.1 75 63 62 60 60 58 52 52 42 43 65 61 55 49 36 31 19 16 11 9.9 75 63 66 61 45 52 31 39 31 31 75 71 75 70 75 71 74 68 74 64 75 55 49 43 37 29 18 14 8.2 7.4 45 50 32 30 33 32 22 22 19 19 75 69 59 57 54 46 33 35 25 23 75 57 57 50 43 34 35 25 25 17 75 48 37 38 32 30 25 24 21 19 36 24 67 49 62 62 83 72 72 77 77 34 53 9.8 11 7.5 23 75 91 91 77 98 99 90 60 43 65 1.9 74 71 73 69 70 66 67 63 62 57 69 63 65 58 59 49 44 28 23 8.5 61 57 55 52 45 41 35 30 25 21 68 65 47 44 60 59 47 48 21 24 66 60 62 55 56 47 50 41 37 26 62 59 46 44 35 34 32 32 26 26 70 65 58 53 43 43 33 34 16 17 65 63 59 57 48 46 33 33 15 19 56 45 23 18 13 59 55 52 48 46 43 30 31 15 19 66 64 63 62 61 59 54 52 43 41 67 63 61 56 50 43 37 30 29 22 66 66 68 64 53 56 44 46 39 39 69 65 66 62 72 69 64 59 53 49 64 62 57 54 46 44 28 29 16 20 56 56 45 38 46 41 36 31 31 26 71 70 64 61 61 53 42 43 33 32 65 62 61 57 48 42 40 35 30 27 75 50 41 42 37 36 30 29 27 23 41 30 68 52 63 63 83 72 72 77 77 33 58 12 15 7.2 51 75 91 91 77 98 98 90 58 44 64 2.5 74 70 72 68 69 65 65 60 59 54 69 62 65 56 57 45 37 21 15 4.9 60 55 51 47 35 31 22 20 13 12 68 64 47 44 52 51 36 37 11 14 66 58 61 53 55 44 49 37 33 21 59 56 42 41 30 30 28 28 22 22 71 64 58 51 41 36 26 24 11 10 62 60 51 49 35 31 16 14 3.6 3.4 52 37 13 9 5.7 51 50 43 39 34 30 15 13 4 3.5 64 62 60 58 57 55 48 46 36 35 67 62 57 51 41 36 24 21 17 15 66 65 63 62 48 52 35 40 29 32 68 63 64 59 71 68 60 57 48 45 60 58 48 44 32 29 12 11 4.8 4.7 50 51 35 29 37 31 25 20 18 15 71 69 62 58 57 47 37 36 27 24 62 60 56 53 37 33 26 23 16 14 74 51 44 41 38 34 31 27 27 22 36 24 68 51 62 62 82 71 71 77 77 33 56 9.6 11 7.2 20 74 91 91 76 98 98 90 59 43 63 2.2 74 70 73 69 71 67 68 63 63 58 72 65 70 62 65 53 49 28 23 7.8 59 55 50 47 35 33 24 22 15 14 67 64 45 42 52 50 37 38 13 15 69 63 67 58 61 51 55 44 40 27 62 58 46 43 35 32 33 31 26 25 70 64 57 51 41 36 25 25 9.8 12 64 60 55 51 41 36 24 20 8.2 6.9 53 39 17 12 8.3 53 48 45 39 38 32 22 18 8.7 7.1 64 62 60 59 58 56 48 48 35 36 66 61 56 51 40 35 24 20 15 13 62 64 65 62 44 51 31 36 27 27 72 67 67 61 73 69 66 62 56 51 62 58 52 47 39 33 19 16 9.6 7.6 52 52 41 33 41 34 29 23 25 19 71 68 60 57 54 45 37 38 29 26 64 60 59 55 41 37 31 27 20 17 74 52 44 43 38 35 31 29 26 23 37 24 69 51 62 62 82 71 71 77 77 34 53 9 11 7.7 21 74 91 91 76 98 99 90 59 43 63 2.5 74 70 72 68 69 65 65 61 59 54 68 62 64 55 56 44 36 19 14 4.3 60 55 52 47 35 32 22 19 13 11 68 64 46 43 52 51 35 37 12 14 65 58 61 52 54 43 49 37 34 22 60 57 42 41 30 29 28 28 22 21 71 64 58 52 42 37 27 24 11 8.9 63 60 54 51 39 36 20 20 4.7 6 53 38 15 10 6.7 53 51 46 41 38 34 19 18 5.1 6.3 64 62 61 59 58 56 50 47 39 36 67 61 57 50 40 33 23 18 15 11 66 65 65 62 53 54 42 44 39 38 68 63 64 60 71 68 60 56 48 45 61 59 51 47 37 33 15 15 5 7 50 52 36 29 37 32 24 21 17 14 71 69 62 58 59 48 38 38 29 25 63 60 58 55 41 37 32 28 21 18 74 49 42 39 34 31 27 25 23 19 36 25 66 49 62 62 83 71 71 77 77 33 56 9.3 11 7.1 20 74 91 91 75 98 98 90 56 41 64 2.9 74 69 72 67 69 64 65 59 60 53 68 59 63 51 54 37 32 14 11 3.5 57 51 46 42 29 26 17 15 9.5 8.6 67 63 46 42 44 45 26 30 6.3 9.1 66 56 62 49 56 40 51 35 36 20 58 54 39 37 28 26 26 24 20 18 69 61 51 45 33 30 21 18 7.8 6.3 56 55 44 43 27 25 12 11 3 3.4 47 32 12 8.3 5.7 32 47 25 34 19 24 8 11 2.4 3.6 61 59 57 55 53 52 43 43 31 31 65 58 54 45 36 28 20 16 13 10 54 59 55 55 35 42 19 26 15 14 68 62 64 58 71 67 61 56 48 44 55 53 40 38 25 22 8.6 8.2 3.2 3.9 50 51 36 28 38 30 26 20 16 13 71 68 61 57 57 48 32 37 24 26 57 56 50 49 31 28 22 18 13 10 74 47 39 37 32 30 25 24 21 19 33 22 66 47 62 62 82 71 71 76 77 32 42 7.8 9.4 6.4 17 74 90 91 75 98 98 90 57 41 63 3.1 73 70 72 68 69 65 65 60 58 53 68 60 63 54 55 40 32 15 11 3 59 54 51 46 35 32 23 20 14 12 68 64 47 43 52 50 35 36 11 13 65 56 60 50 53 41 47 34 31 20 59 56 41 39 30 28 27 26 21 20 71 64 57 50 41 35 27 24 11 11 62 60 52 49 36 33 16 14 3.7 3.4 52 38 16 11 6.5 50 49 42 38 34 30 15 13 3.8 3.8 64 61 60 58 58 55 49 48 38 38 67 61 56 50 40 33 24 19 16 13 66 64 66 61 50 52 37 41 35 35 68 63 64 59 71 67 61 57 50 46 60 58 48 45 33 29 13 11 5 4.6 49 50 35 28 37 32 25 21 19 15 71 68 61 57 56 46 37 38 28 26 62 60 56 53 37 34 26 23 16 13 74 49 42 40 36 32 29 26 25 21 36 23 68 50 63 62 84 71 71 76 77 33 56 9.6 11 7.3 20 74 90 91 75 98 98 90 60 44 67 3 74 71 74 70 73 69 73 67 72 65 72 66 70 62 66 55 55 33 33 9.6 57 54 49 46 33 31 21 20 12 12 65 64 41 40 52 51 36 38 11 13 67 61 63 56 57 47 52 40 38 26 63 60 47 45 36 34 33 32 27 25 68 63 54 49 38 35 25 24 9.9 9.3 66 62 59 55 49 43 35 30 17 15 51 36 13 8.2 5.1 54 49 47 41 42 36 29 24 16 13 64 62 61 59 59 57 52 51 43 43 65 61 54 49 36 31 18 15 11 9.3 61 64 63 61 41 51 28 37 24 28 73 69 71 67 73 70 72 66 69 62 65 61 57 52 47 41 30 25 19 16 52 53 42 34 43 37 34 28 32 23 71 69 62 59 57 49 37 39 28 27 66 62 62 58 49 43 40 35 30 26 45 47 35 36 29 29 22 22 19 17 26 68 51 62 62 83 71 71 77 77 32 25 74 91 75 98 99 90 59 42 64 3.6 74 71 73 70 71 68 69 65 64 60 73 68 72 65 69 59 57 37 25 9.5 58 54 49 46 33 32 21 20 13 13 67 65 44 41 60 56 45 42 17 16 67 61 63 55 55 45 48 38 32 22 61 58 43 42 32 31 30 29 23 23 70 64 54 50 39 36 27 24 11 10 65 62 58 55 45 43 28 26 10 9.9 53 40 16 11 7.1 52 50 44 40 38 34 23 21 9.4 9.2 65 63 62 60 60 58 53 50 43 41 66 62 58 51 41 34 23 19 15 12 66 67 68 65 59 60 51 52 49 46 73 68 69 63 73 70 68 63 57 52 64 61 55 52 43 40 23 20 12 10 53 52 41 32 42 36 31 25 26 20 71 69 62 58 58 46 43 42 34 29 64 61 59 56 43 40 34 31 23 21 74 45 35 35 30 28 23 23 20 17 34 24 69 48 62 61 82 71 71 76 76 31 53 13 18 8 24 74 90 91 75 98 98 90 61 43 64 3 73 68 71 66 68 63 64 58 58 51 68 58 63 50 53 35 28 12 7.7 2.8 55 49 44 40 27 24 16 13 8.7 7.3 67 62 47 42 44 44 26 29 6.1 8.8 65 55 61 48 53 38 48 32 33 18 57 53 39 36 27 25 25 23 19 17 68 60 51 43 34 28 21 17 7.6 5.2 53 53 39 39 21 21 7.7 8.2 1.7 2 46 30 11 7.6 5 32 44 23 30 17 21 5.9 7.9 1.5 2.1 60 58 55 54 51 51 40 40 28 28 64 56 52 42 33 25 17 13 11 8.7 50 57 49 53 32 42 18 25 12 11 68 61 64 57 71 66 60 54 46 41 49 50 34 34 19 19 6 5.6 2.4 2.2 49 49 34 25 38 28 25 18 14 11 70 67 61 56 56 46 32 35 23 24 52 54 44 46 23 25 15 15 7.9 8.2 74 46 39 36 32 29 26 24 22 19 32 21 64 47 62 61 82 70 71 75 76 31 51 8.2 9.7 6.5 16 74 90 91 75 98 98 90 57 41 64 3.1 73 68 71 66 68 63 64 58 57 50 69 59 65 52 56 38 33 14 11 3.6 55 48 43 39 27 24 16 14 9.5 7.9 67 62 47 42 41 42 21 26 4.2 6.7 66 55 62 49 55 40 51 33 36 19 58 53 40 36 29 25 27 23 21 17 68 60 50 43 32 27 20 17 7.6 5.8 54 54 38 40 17 23 4.2 9.1 0.75 2.3 46 31 11 7.9 5.7 29 46 20 31 13 21 3 8 0.58 2.4 59 57 54 52 50 49 38 38 23 26 64 57 52 44 34 27 18 14 12 9.2 48 57 48 52 30 39 16 23 7.6 11 68 61 64 57 71 65 58 53 45 41 51 51 33 36 15 20 3.1 6.6 0.96 2.7 49 48 34 25 37 28 25 18 15 11 69 66 59 54 55 45 33 35 24 23 54 54 45 47 21 26 12 17 6 9.2 74 46 39 37 33 30 26 25 23 20 31 20 64 46 62 62 82 70 71 76 76 31 48 8.2 8.9 6.5 14 74 90 91 75 98 98 90 58 41 64 3.1 73 68 71 66 69 63 65 58 59 52 69 60 65 53 56 39 34 15 11 3.8 56 49 44 39 27 24 16 14 9.5 8.3 67 62 47 42 42 43 23 28 4.8 7.7 66 56 62 50 56 41 51 35 35 20 58 54 40 37 29 26 27 24 21 18 69 61 51 43 32 27 19 16 7.7 6.2 53 53 36 38 17 20 4.5 8.2 0.78 2.1 46 31 11 7.8 5.1 29 47 19 33 12 23 3.1 8.2 0.67 2.2 60 58 55 53 52 50 41 40 30 29 65 57 52 44 34 27 18 14 12 9.4 50 57 50 53 30 39 16 21 12 9.2 68 61 64 57 71 66 59 54 45 41 49 51 31 34 15 19 3.5 6.4 1.3 2.8 50 49 36 26 38 28 24 17 16 12 70 67 61 55 57 45 32 36 23 25 52 54 42 46 19 25 11 16 5.5 9.4 74 46 40 37 33 30 26 25 23 20 32 21 63 46 62 62 82 71 71 76 77 32 49 8.3 9.7 6.6 15 74 90 91 75 98 98 90 59 42 59 2.2 74 69 72 67 70 63 66 58 60 50 74 57 59 46 43 27 11 4.4 1.5 0.8 58 52 49 45 33 30 21 19 13 12 66 62 43 39 56 55 41 43 15 20 74 54 58 45 50 34 48 31 36 19 74 64 73 55 72 47 72 46 72 40 74 61 55 48 41 35 28 23 13 9.8 74 59 46 49 26 33 9.7 17 1.8 5.3 56 47 28 22 15 74 48 35 40 23 32 6.7 15 1.1 4.6 74 60 59 57 57 54 46 45 31 31 64 60 53 49 36 32 20 17 13 11 74 60 57 57 43 50 29 37 20 27 74 60 60 55 71 65 58 53 43 39 74 58 42 46 24 31 7 12 2.4 5.9 62 61 54 46 52 44 42 32 42 30 74 68 64 59 61 52 32 35 25 24 74 61 52 54 29 34 18 23 9.3 14 74 50 41 41 35 33 28 27 24 21 36 23 66 49 62 62 82 70 71 76 76 31 55 10 12 7.6 21 74 90 91 74 98 98 90 57 43 62 2.6 74 72 70 69 67 66 62 60 54 52 74 59 53 50 37 33 9.7 7.6 1.2 1 60 57 53 50 39 36 27 24 18 15 66 65 43 43 60 58 48 46 24 22 74 55 48 46 37 35 31 29 15 15 74 60 42 43 30 31 28 29 21 22 74 65 59 53 47 40 35 29 18 13 74 60 49 42 27 20 9.7 6.5 2.6 1.8 61 51 27 20 14 74 51 40 32 27 20 9.4 6.3 2.8 1.9 74 70 73 68 72 67 71 62 68 51 64 62 51 50 34 33 19 18 13 12 74 70 72 70 59 62 38 39 34 25 74 65 62 60 69 68 55 54 40 40 74 58 46 40 28 21 9.4 7 4 3.3 44 51 28 28 27 29 16 18 14 14 74 71 60 59 55 47 35 37 28 25 74 62 58 54 37 31 25 20 15 12 74 52 41 43 33 35 26 28 22 22 37 23 69 53 61 61 82 71 71 77 77 32 70 35 39 8.8 20 74 90 90 76 98 99 89 63 47 62 3.4 73 71 71 69 68 66 64 61 58 54 67 63 63 57 54 43 30 16 8.4 3.6 61 56 53 48 38 33 25 21 16 13 67 65 46 45 58 57 44 45 17 20 64 59 59 53 52 44 47 38 32 23 59 57 42 40 30 28 28 26 22 20 70 65 59 52 45 36 32 24 14 9.9 59 56 48 41 31 23 14 9.2 3.2 2.2 52 37 15 10 7.4 51 44 39 30 29 21 12 7.7 3.2 2 66 64 63 60 60 57 50 45 33 29 65 62 56 51 40 34 24 19 16 13 64 65 66 63 34 45 19 26 26 20 67 64 61 57 70 68 60 57 49 45 59 55 45 38 29 22 11 7.5 4.8 3.4 48 52 34 30 36 34 25 23 19 16 70 70 60 59 55 49 31 35 24 24 61 58 55 50 34 28 23 18 13 9.7 74 50 39 41 35 34 28 28 25 22 37 24 69 49 62 62 83 71 71 77 77 33 52 11 12 9.6 24 74 90 91 76 98 98 89 60 42 61 2.9 72 68 70 66 67 62 62 57 55 49 65 56 58 48 46 32 19 9.4 4.3 2.1 56 51 45 43 28 27 17 16 10 9.1 66 62 44 40 53 52 36 38 12 16 61 53 55 45 47 35 41 29 25 15 53 52 33 33 21 21 19 19 14 14 68 61 52 47 35 31 22 19 8.8 7 55 54 42 42 22 24 7.2 7.9 1.1 1.3 48 33 13 9 6.6 45 45 31 31 21 21 6.2 6.7 1.2 1.4 61 60 57 56 54 53 45 44 32 32 64 59 54 48 37 31 21 18 14 12 52 59 51 56 34 43 22 30 21 24 65 59 61 55 70 65 57 53 45 41 53 52 37 37 20 21 5 5.4 1.7 1.9 45 46 28 21 32 26 19 16 12 10 70 67 60 55 54 44 36 36 25 23 55 54 46 47 25 25 16 16 8.2 8.1 73 44 36 35 31 28 24 22 21 18 32 20 63 46 61 60 83 69 70 75 75 32 48 8.8 10 7.7 18 73 90 90 75 98 98 89 54 39 63 2.7 73 68 71 66 68 63 64 58 58 51 68 58 63 51 54 36 31 13 9.8 3.6 55 49 44 40 27 25 16 14 9.8 8.6 67 62 47 42 43 43 24 28 6.1 8 65 55 60 48 54 39 49 32 35 17 56 53 38 36 26 25 25 23 19 17 69 60 50 43 32 28 19 17 8.1 6.5 54 54 39 40 19 22 5.6 8.5 0.69 2.2 45 30 10 7 4.9 25 46 19 33 14 23 4.3 8.5 0.65 2.4 59 57 54 53 50 50 40 39 27 26 63 56 51 43 33 26 17 14 11 9.2 45 57 44 52 24 37 13 20 6.5 9.6 67 60 63 56 70 66 59 54 46 42 51 52 34 36 17 20 3.7 6.5 0.94 2.8 48 48 33 25 36 28 23 18 13 10 69 67 58 54 54 46 32 36 22 25 54 55 45 47 22 27 13 17 6.1 9.7 73 45 37 35 31 28 24 23 20 18 30 20 66 47 61 61 81 70 70 76 76 31 41 8.1 8.9 6.6 14 73 90 91 74 98 98 90 57 40 61 1.9 72 69 71 67 68 64 64 59 58 53 67 61 63 54 54 42 33 18 12 4.6 59 55 52 48 37 33 26 22 16 14 66 64 43 41 54 52 39 40 15 16 64 57 59 51 52 42 46 35 31 20 59 56 41 39 29 28 27 26 20 20 69 63 58 51 44 38 30 25 13 11 60 59 49 48 29 29 11 12 2 2.8 53 41 18 12 8.5 48 47 37 36 27 27 8.8 11 1.7 3 64 62 61 59 58 56 50 49 39 38 65 60 55 49 39 33 23 19 16 13 62 63 64 61 46 51 35 40 32 33 67 63 62 58 70 67 59 55 47 44 58 57 44 43 27 26 8.2 9.1 2.7 3.9 48 50 34 28 36 31 25 20 19 15 69 68 60 57 55 46 34 37 26 25 59 58 52 51 31 30 22 20 12 12 73 48 39 38 33 31 27 25 23 20 36 23 68 48 61 61 83 70 70 76 76 31 57 9.7 11 7.2 22 73 90 90 76 98 98 89 58 43 63 6.2 73 69 72 68 70 66 67 62 62 57 71 65 70 61 65 53 49 28 21 6.9 60 55 52 46 35 28 21 16 12 9.2 66 64 41 40 49 47 33 34 11 12 68 61 66 57 59 48 53 40 36 23 60 56 43 40 32 29 30 27 24 21 70 64 59 51 45 34 30 20 10 6.4 58 56 44 43 22 24 6.2 8.6 1 1.7 50 34 12 8.6 5.7 38 42 25 28 16 19 4.3 6.5 0.9 1.6 63 62 59 57 56 54 46 43 33 30 64 59 52 45 34 28 18 14 11 9.5 64 64 66 62 55 55 46 46 44 40 71 66 65 60 72 68 65 60 54 49 55 54 38 38 20 22 4.5 6.3 1.4 2.5 51 51 38 30 40 33 28 22 22 17 69 68 59 56 54 45 32 34 22 22 57 56 48 49 25 26 15 17 7.9 8.8 45 46 36 35 31 28 24 23 21 18 52 36 70 51 63 62 83 71 71 76 77 33 48 9.2 9.5 8 21 73 91 91 76 98 99 89 60 43 59 2.5 73 70 70 68 67 65 62 60 56 52 73 57 50 47 32 28 6.4 5 0.92 0.82 61 58 55 52 42 38 30 26 20 16 66 65 43 43 62 59 52 50 29 28 73 51 43 41 32 30 27 25 14 12 73 60 45 45 33 34 31 32 24 25 73 66 61 55 50 42 39 30 20 13 73 60 72 47 70 25 68 9.7 64 2.6 60 52 32 26 19 73 54 68 37 66 24 63 8.5 54 2.7 73 67 67 64 66 62 58 54 43 38 64 61 52 49 35 33 20 19 14 13 73 68 70 67 61 61 45 46 36 31 73 63 60 57 69 67 57 54 44 41 73 59 72 44 70 25 65 9.7 50 4.6 50 53 34 32 32 32 19 20 18 17 73 70 62 61 59 50 38 38 30 27 73 62 72 56 71 33 69 22 66 14 73 54 44 45 35 37 29 31 24 24 37 23 69 55 61 61 81 70 70 76 76 30 71 46 49 9.6 21 73 90 90 74 98 98 89 61 46 61 2.7 73 71 70 69 67 66 63 62 57 55 73 70 73 69 73 67 73 60 72 42 65 61 61 56 51 42 41 29 29 19 67 67 45 46 60 59 47 47 19 21 73 63 62 58 54 49 47 42 30 25 73 60 46 45 36 35 34 33 28 27 73 67 63 59 54 48 45 35 28 16 73 61 71 53 69 37 66 20 61 6.6 59 47 24 18 12 73 54 69 44 68 35 64 18 59 6.8 73 68 72 65 71 63 69 57 67 46 73 70 72 69 72 67 71 64 70 60 73 69 70 69 53 57 32 36 24 25 73 65 62 60 69 68 57 56 47 44 73 60 71 50 69 36 64 17 58 9.2 50 54 38 35 34 34 22 23 21 19 73 70 58 59 54 47 34 34 26 23 73 62 72 57 70 40 68 30 65 20 73 63 59 57 55 51 49 45 43 36 36 23 71 53 60 60 82 69 69 76 76 32 55 13 16 7.6 22 73 90 90 74 98 98 89 62 46 60 1.9 72 67 69 64 66 60 61 55 53 47 64 55 57 45 45 29 18 8 3.4 1.8 53 49 42 41 26 26 16 17 10 10 65 60 42 38 50 49 33 35 11 13 60 51 54 43 46 33 42 28 27 15 52 50 32 32 21 21 19 19 14 14 66 59 47 44 30 30 19 19 8.7 7.8 50 53 34 37 16 18 3.8 5.9 0.53 1.2 46 32 12 8.1 5.9 37 42 25 28 16 18 2.9 5.3 0.44 1.2 60 58 56 54 53 51 43 42 30 30 62 57 51 45 34 28 18 15 12 9.2 44 57 44 53 25 38 15 22 8.2 16 65 58 60 54 69 63 56 51 43 39 47 50 31 33 15 17 2.8 4.9 0.79 1.9 43 45 28 22 31 25 19 16 12 10 68 65 59 54 53 43 33 34 22 21 50 53 42 45 22 24 14 15 7.1 8.6 73 45 36 35 30 28 23 23 20 18 32 20 62 43 60 59 80 68 69 74 75 31 46 8 8.2 7.5 17 73 89 89 73 98 98 89 53 39 61 3.7 72 69 71 67 69 65 65 61 60 55 71 64 69 60 64 52 47 27 20 6.5 60 54 52 46 36 28 21 16 12 9 65 63 43 41 49 48 33 34 11 13 66 60 62 54 56 45 50 38 35 22 58 55 41 39 30 29 28 27 22 21 69 63 58 50 45 35 31 21 11 6.1 57 56 46 43 28 25 11 10 1.9 2.4 50 35 13 8.4 5.5 38 41 30 27 22 19 7.9 7.3 1.5 2.2 62 59 57 54 53 50 42 39 29 27 64 59 52 48 34 32 18 17 12 12 64 63 66 61 55 54 45 44 40 38 70 64 64 58 71 67 63 58 52 47 55 54 41 38 25 22 8 7.2 2.7 3.1 48 49 35 28 38 31 26 21 21 16 68 67 59 55 53 44 29 32 21 21 57 56 49 48 28 26 18 17 9.7 9.1 46 47 37 37 32 31 26 25 23 20 36 21 69 49 61 61 84 70 71 76 76 31 49 9.4 10 8.5 18 73 90 91 74 98 98 89 56 41 60 2.4 72 67 69 64 66 61 61 55 54 47 64 55 57 47 45 31 18 8.7 3.3 1.8 52 48 41 40 25 26 16 17 9.7 11 64 60 43 38 49 48 31 34 10 13 61 51 55 44 46 34 42 28 28 14 53 50 33 31 22 20 20 19 14 13 65 59 46 44 31 29 20 19 8.6 8.1 51 52 35 37 16 18 4.9 6.5 0.74 1.5 46 32 11 7.9 5.7 42 44 28 29 18 19 4.4 6 0.73 1.5 60 58 56 53 52 50 42 41 29 29 62 56 51 43 35 27 20 15 13 10 47 57 41 54 33 42 23 28 15 23 65 58 60 54 69 64 57 52 44 41 49 50 32 33 16 17 3.7 5.1 1.2 2.2 44 45 28 22 30 24 19 15 12 9.5 69 65 59 54 54 44 33 34 22 22 52 53 44 45 24 24 16 16 8.2 8.8 73 43 34 33 28 26 22 21 19 16 32 19 63 44 60 60 82 68 68 74 75 30 46 8 8.6 7.6 17 73 89 90 74 98 98 88 53 38 60 2.1 72 67 69 65 66 61 61 55 54 47 64 55 57 47 45 31 19 9.1 3.9 2 53 49 42 41 26 27 16 17 9.3 11 64 60 43 39 49 48 32 34 10 13 61 51 55 44 46 33 42 28 27 14 52 50 32 31 21 20 19 18 14 13 66 60 47 45 31 30 19 20 8.1 8.9 50 52 34 37 15 20 4.1 7 0.85 1.6 46 32 12 8.2 6.1 41 43 29 31 18 22 4 7.2 0.78 1.8 60 58 56 54 53 51 43 42 29 30 62 56 50 43 34 27 20 15 13 9.7 51 58 49 55 32 42 19 27 16 20 64 58 60 54 69 64 56 51 43 40 47 50 30 34 14 18 3.2 5.6 1.1 2.2 44 45 29 23 32 25 20 16 13 10 68 65 58 53 52 43 36 35 26 23 51 53 42 46 22 26 14 17 7.4 9.7 73 43 34 33 28 26 22 21 18 16 32 20 60 42 60 60 81 69 69 74 75 30 47 8 8.7 7.5 17 73 89 90 74 98 98 89 51 37 60 2.1 72 67 69 64 66 60 61 54 53 46 65 55 59 46 46 30 19 9.3 4.6 2.2 51 45 39 36 23 20 13 10 7.2 5.8 66 60 45 39 42 42 24 27 6.5 7.8 62 52 57 44 50 35 45 30 30 17 53 50 33 31 21 20 19 18 14 13 67 58 47 40 28 24 17 13 6.2 4.3 52 50 37 35 18 16 5.3 4.6 0.92 0.88 42 27 9 6 4.2 26 36 19 24 13 15 3.7 3.6 0.74 0.76 57 55 52 50 47 46 35 35 22 23 61 53 46 39 27 23 13 12 8.8 7.8 38 56 39 50 16 32 7.8 15 5.1 7.1 64 59 59 52 69 64 55 49 41 37 48 47 31 30 15 14 3.9 3.7 1.3 1.4 42 44 27 21 30 24 19 15 10 8.9 68 65 55 51 49 40 23 28 14 16 51 50 42 42 20 21 12 12 6.5 6.6 72 43 36 34 29 26 23 21 19 16 29 18 63 45 60 60 80 69 69 74 74 28 52 10 13 7.3 12 72 89 90 73 98 98 89 58 40 58 2.5 71 67 69 64 66 60 61 54 53 45 65 55 59 45 46 29 18 8.7 4.1 2.2 52 45 39 35 22 20 12 11 7.1 5.9 66 60 44 39 41 40 23 26 6.4 7.5 63 52 58 45 51 35 47 31 33 17 54 51 33 32 22 21 20 19 14 13 67 58 47 40 29 24 17 13 6.2 4.6 51 50 35 34 16 15 5.2 4.9 1.2 1.1 43 28 8.2 5.4 3.8 16 33 12 22 8.9 15 3.4 4.6 0.99 1.1 57 55 51 50 47 46 33 34 18 21 61 53 46 39 27 22 14 12 8.6 7.6 33 54 27 47 14 28 7.1 12 4.4 5.5 65 59 58 52 69 63 55 49 41 36 46 46 28 29 13 13 3.6 3.5 1.6 1.4 43 44 28 21 30 23 19 14 11 8.6 68 65 55 52 50 40 21 27 13 16 50 50 40 42 17 20 10 11 5.2 5.8 72 44 36 34 29 27 23 21 19 17 29 18 64 45 60 60 82 69 69 74 74 28 50 9.8 12 7.3 12 72 89 90 74 98 98 89 58 41 59 2.5 71 67 69 64 66 60 61 54 53 46 65 55 59 45 45 29 17 8.1 3.8 2 51 45 39 36 23 21 13 11 7.4 6.2 65 60 44 39 41 41 24 26 6.3 7.7 63 52 58 45 51 35 46 30 31 16 54 51 34 32 23 21 21 19 15 14 67 58 48 40 29 24 17 14 6.5 4.9 49 49 33 34 15 16 4.1 5.2 0.72 1.1 43 27 9.2 6.3 4.4 19 35 12 23 8 15 2.5 5 0.66 1.2 57 55 51 50 47 46 35 35 21 22 60 53 46 39 27 22 14 12 8.9 7.7 40 57 36 51 14 32 7.1 16 5 7.7 65 59 59 53 68 63 55 49 40 36 45 46 27 29 13 14 3.1 4.2 1 1.8 44 44 29 21 31 24 19 15 11 9.1 68 65 56 52 51 40 24 27 16 16 48 50 38 41 17 20 9.8 12 4.9 6.6 72 44 36 34 30 27 23 22 20 17 29 19 62 45 59 59 81 68 68 74 74 28 49 9.6 11 7.4 12 72 89 90 73 98 98 89 56 39 59 2.3 71 66 69 64 66 60 60 54 53 46 65 55 59 46 45 29 17 8 3.8 2 51 45 39 35 22 19 12 10 7 6 66 60 44 39 42 41 24 27 6.2 7.7 63 53 58 45 51 36 46 31 31 17 55 51 35 32 23 21 21 19 16 14 67 58 48 39 29 23 16 13 6 4.4 48 49 31 32 14 15 4 4.8 0.81 1.2 43 28 10 7.1 4.9 23 34 14 23 8.1 16 2.2 5.1 0.7 1.3 56 55 50 49 45 44 30 32 16 18 60 53 46 38 26 22 13 11 8.3 7.7 38 58 33 52 14 31 6.5 13 2.9 5.5 65 59 59 53 68 63 54 49 40 36 44 45 26 27 13 13 3.8 3.9 1.6 1.8 45 45 29 22 31 24 19 15 11 9.6 68 65 55 52 50 40 22 28 13 16 48 49 38 40 18 19 11 12 6.5 6.3 72 43 36 34 29 27 23 22 19 17 29 18 62 44 59 59 81 68 69 74 74 28 49 9.5 11 7.4 12 72 89 90 72 98 98 89 58 41 60 1.7 72 69 70 67 67 63 62 58 54 50 72 67 73 66 73 63 73 54 73 33 58 53 50 45 36 31 24 21 16 14 65 62 42 40 54 53 39 40 14 16 72 59 62 53 53 43 46 35 29 19 72 56 42 41 31 30 30 29 23 23 72 62 55 48 41 35 29 24 14 11 72 57 47 45 27 26 7.6 8.6 0.93 1.5 51 38 18 13 8.5 72 40 33 29 22 19 4.8 5.6 0.67 1.1 72 60 59 57 57 54 48 46 37 35 63 59 53 48 37 32 21 18 13 12 72 62 60 59 48 51 37 41 34 35 72 60 59 55 68 65 54 51 38 36 72 55 42 39 23 21 4.2 5 0.99 1.7 46 49 33 29 33 31 22 20 18 16 72 67 56 55 51 43 26 31 20 20 72 57 51 49 27 26 15 15 6.3 7.2 72 47 36 38 33 32 27 27 24 22 34 21 66 45 59 59 81 68 68 74 74 30 43 9 9.8 7.7 20 72 89 89 73 98 98 89 58 40 59 1.8 71 66 69 64 65 60 60 54 53 46 63 54 57 45 44 29 19 8.1 3.5 1.8 54 49 42 40 26 26 16 16 9.8 9.6 64 60 42 38 52 50 35 37 12 14 59 50 53 42 45 32 40 26 24 13 52 50 31 31 20 20 18 18 13 13 65 59 48 44 32 29 19 19 8.2 8 50 51 34 37 15 18 3.4 5.5 0.48 1 45 31 12 8.4 6.4 36 42 23 27 15 18 2.6 5 0.39 1 60 58 57 55 54 52 45 43 32 30 61 55 49 43 33 27 19 15 13 10 45 56 40 54 25 36 14 21 9.9 16 64 58 59 54 68 63 55 50 42 38 46 49 30 32 14 17 2.5 4.6 0.74 1.7 43 45 27 21 29 24 18 15 11 9 68 65 58 53 52 43 32 34 22 20 49 52 40 43 20 22 12 14 5.7 7.8 72 44 34 34 28 27 23 22 19 17 31 19 61 42 59 59 80 67 68 74 74 30 46 8.1 8.9 7.1 17 72 88 89 73 98 98 88 54 38 58 2.3 72 66 68 64 64 60 58 54 50 45 72 64 70 61 66 53 53 32 34 9.7 56 49 49 42 34 27 23 18 15 12 64 59 39 36 47 48 30 35 7.7 12 72 68 75 67 75 65 74 62 73 52 72 56 43 42 31 32 30 30 24 25 72 59 54 46 40 31 27 21 12 9.3 72 52 36 37 12 16 1.5 4.6 0.17 0.83 47 34 14 10 7.5 72 36 19 23 7.5 13 0.46 2.6 0.17 0.51 72 57 53 52 49 48 37 37 24 26 61 56 51 45 34 29 19 16 12 10 72 56 52 52 29 41 17 26 13 19 72 62 60 55 64 60 44 40 27 24 72 49 31 31 10 14 1 3 0.29 1.1 45 48 35 31 35 32 24 22 20 20 72 65 55 52 49 40 26 30 21 21 72 53 45 44 16 19 6.6 10 2.2 4.6 72 43 34 34 30 29 23 23 20 19 34 20 65 46 59 58 82 67 68 74 74 30 41 9.4 10 8.2 19 72 89 90 73 98 98 89 57 40 59 1.9 71 67 69 65 66 62 62 57 55 50 65 58 60 50 50 37 27 14 8.6 3.5 55 50 46 42 30 27 19 17 11 11 65 61 44 41 50 47 34 33 12 13 61 53 55 46 47 37 41 31 26 17 55 52 37 35 25 24 24 22 18 17 68 60 54 46 36 31 22 20 8.9 8.6 56 53 43 40 26 23 10 9 2.4 2.4 48 34 13 9.3 6.4 41 42 32 29 23 20 9.1 7.6 2.6 2.4 60 58 56 54 53 50 42 40 30 28 62 56 49 43 33 28 19 16 13 11 62 60 62 57 43 45 28 31 23 23 64 59 59 54 68 64 56 52 44 40 54 51 40 37 25 22 8.6 7.8 3.3 3.5 46 46 30 23 31 26 19 16 13 11 68 65 58 53 54 42 31 33 24 22 56 54 49 47 30 28 21 19 12 11 72 46 39 36 33 30 27 25 24 20 34 22 64 44 59 59 81 68 68 73 73 28 54 9 10 7 17 72 88 89 72 98 98 88 55 38 58 2.6 71 66 69 64 65 60 60 54 52 45 64 54 57 44 44 28 18 8.3 4.1 2.1 50 44 38 35 22 19 12 10 6.8 5.8 65 59 44 39 42 41 24 27 6.2 8 61 51 55 43 48 34 43 29 29 15 52 50 32 30 20 19 19 18 13 12 67 57 46 39 27 23 16 13 5.7 4.1 50 48 34 33 14 14 3.3 4 0.59 0.78 42 27 9.8 6.7 4.7 25 34 15 22 8.8 13 2.1 3.2 0.49 0.75 56 54 50 49 46 45 33 33 19 20 59 52 44 38 26 22 13 11 8.2 7.5 33 54 33 47 15 30 7.9 14 5 7.4 64 58 58 52 68 62 53 48 39 35 45 45 26 27 11 12 2.4 2.7 0.9 1 42 44 26 21 30 24 18 15 10 8.8 67 65 55 51 49 40 21 27 12 16 48 49 38 40 16 18 8.7 10 4.2 5 72 43 36 33 29 27 23 22 19 17 28 18 61 43 59 59 80 68 68 73 74 28 52 9.6 12 7.1 12 72 89 89 72 98 98 88 55 40 60 2.1 71 65 69 63 66 60 61 54 54 47 64 54 59 46 47 30 22 9.1 5.6 2.1 52 46 41 37 24 21 14 11 7.9 6.3 64 60 44 40 41 41 23 26 5.6 7.6 61 51 56 44 48 34 43 28 29 15 54 50 35 33 24 22 22 21 17 15 66 57 48 40 29 24 18 13 6.6 4.3 47 48 29 32 9.4 13 1.8 3.3 0.31 0.65 42 28 11 7.9 5.8 11 34 5.8 20 3.7 12 1.1 2.9 0.35 0.74 56 54 49 49 45 45 32 34 18 21 60 53 47 40 29 24 16 13 11 8.9 42 53 41 47 18 30 7.4 13 2.6 5.7 65 58 60 53 68 62 54 49 39 36 44 45 25 28 9 13 1.5 2.9 0.43 1.2 44 43 29 20 31 23 19 14 11 8.5 67 64 56 51 52 41 22 29 14 17 47 49 38 40 15 19 8.1 11 3.5 5.8 72 43 36 34 30 28 24 23 21 18 29 18 62 43 59 59 80 67 67 73 74 28 40 6.9 7.7 6.2 11 72 89 89 72 98 98 88 55 39 59 1.6 70 67 69 65 66 61 61 57 55 49 65 57 60 51 51 38 29 16 10 4 56 51 47 43 32 29 20 17 12 10 65 61 44 41 48 47 32 33 10 11 61 53 56 47 48 38 43 31 27 17 56 52 38 35 26 24 24 23 18 17 67 60 55 47 39 33 25 22 10 8.3 56 54 44 42 25 24 7.8 8.6 1 1.5 48 35 13 9.5 6 43 44 33 31 24 22 6.7 7.8 1.1 1.5 60 58 56 54 52 50 41 40 26 26 62 57 51 45 35 29 20 16 13 11 62 60 60 57 42 46 25 31 18 23 64 59 59 55 68 64 55 52 43 39 54 52 40 38 23 22 6.2 6.6 2.1 2.5 46 47 31 24 33 28 22 18 14 11 68 65 58 53 53 42 29 30 21 19 56 55 49 48 29 28 19 18 11 10 71 46 38 36 32 30 26 24 23 19 33 21 63 44 59 59 80 68 68 74 74 29 53 9.1 9.7 7.2 17 71 88 89 72 98 98 88 55 39 58 1.7 70 67 68 65 65 61 60 56 53 48 65 57 59 50 49 35 24 12 6.7 2.7 55 50 46 42 31 27 19 16 11 9.2 65 61 44 41 49 47 31 33 8.4 11 60 52 55 46 48 36 42 31 28 17 55 53 37 36 26 25 24 23 18 17 67 60 53 46 37 32 24 21 9.9 7.4 56 54 44 42 25 25 8.2 10 1.1 2.2 48 34 13 8.8 6.2 45 44 34 32 24 24 6.7 9.1 1 2.2 60 58 56 54 54 51 44 41 31 28 62 57 52 46 36 30 21 17 14 11 62 60 62 57 41 45 25 30 21 22 64 60 58 54 67 64 56 52 43 39 54 52 40 38 24 23 6.7 8.2 2 3.3 46 47 31 26 33 28 22 18 15 13 67 65 58 53 53 42 31 32 23 21 56 54 49 47 29 28 19 19 11 11 71 48 40 38 34 31 27 26 24 20 32 20 63 45 59 58 80 68 68 74 74 28 55 9.2 9.7 7.2 16 71 89 89 72 98 98 89 55 39 58 1.9 71 67 69 66 66 62 61 57 55 50 65 58 60 51 50 37 23 12 5.1 2.3 55 49 45 40 29 25 18 15 11 9 64 61 42 40 50 48 35 35 12 13 61 54 55 47 47 37 41 30 26 16 56 53 37 36 26 25 24 23 18 17 67 60 53 44 35 28 21 17 8 6.6 57 54 45 41 27 22 9.4 7 1.5 1.5 48 34 14 9.9 7 37 38 29 25 21 17 6.5 5.3 1.1 1.4 61 59 57 56 54 53 45 44 32 32 61 56 49 43 31 26 17 14 11 9.8 59 60 61 57 38 44 26 32 25 26 64 60 59 55 68 65 57 53 44 41 56 53 42 38 25 20 6.8 5.3 2 2 45 47 32 26 34 29 23 19 17 13 67 66 56 54 51 42 28 31 21 21 58 55 52 48 31 27 19 17 9.8 8.5 44 45 35 35 30 29 24 23 22 19 34 22 66 45 59 58 80 68 68 74 74 29 54 9.6 11 7.4 19 71 88 89 72 98 98 89 57 41 56 1.3 71 66 67 64 63 60 58 54 50 46 71 55 53 46 39 31 16 9.5 4 2.3 54 49 45 41 30 28 20 18 13 12 63 60 42 40 50 49 35 37 13 16 71 50 50 42 40 32 35 26 21 13 71 51 33 33 22 22 20 20 15 15 71 59 51 45 36 31 24 21 11 9.3 71 50 38 35 22 19 8.3 8 2 2.6 48 36 15 11 7.8 71 36 29 24 20 17 7.1 7.3 2 2.7 71 58 57 55 54 52 44 43 30 29 60 56 49 45 34 28 20 16 13 11 71 58 62 56 33 42 21 28 19 21 71 57 57 52 66 63 51 48 34 33 71 48 35 32 20 18 5.7 6.3 1.9 2.9 39 43 24 22 26 24 16 15 11 11 71 65 53 52 46 39 25 30 19 20 71 51 45 42 25 22 16 14 8.9 8.2 71 45 35 36 29 29 23 23 20 18 30 18 63 47 58 58 79 67 67 73 73 28 54 12 13 8.9 16 71 88 89 71 98 98 88 54 40 58 1.7 69 64 67 62 64 59 59 53 51 46 62 53 56 45 44 30 20 9 5.5 2.3 52 46 42 37 26 21 15 12 9.4 7.6 63 58 42 38 42 41 25 27 7.6 8.1 59 50 54 44 46 34 41 28 26 15 53 49 34 31 22 21 21 19 15 14 65 57 49 41 32 25 19 14 7.3 5.3 46 46 27 29 9 11 1.7 2.8 0.35 0.57 43 29 11 7.8 5.5 16 34 11 18 6.8 10 1.3 2.5 0.36 0.69 57 55 52 50 48 46 36 35 21 20 60 53 47 40 29 24 16 13 11 8.7 52 57 50 52 26 37 10 18 9.4 10 63 57 58 52 67 62 53 48 38 34 43 43 24 25 9.4 11 1.8 2.5 0.7 1.1 42 43 27 20 29 23 17 14 11 8.7 66 63 54 50 48 39 21 28 13 18 48 47 38 38 16 17 9.1 9.1 4.2 4.4 70 43 36 34 31 28 25 23 21 18 28 17 61 43 57 57 80 66 66 73 73 26 49 8 8.9 6.2 12 70 87 88 71 98 98 88 55 39 54 2 71 69 68 66 64 61 57 55 48 44 71 40 24 23 6.6 6.1 0.86 0.8 0.36 0.34 55 51 47 44 34 31 23 20 15 13 63 60 40 39 63 60 56 52 36 33 71 29 16 16 7 6.6 4.5 4.3 1.3 1.4 71 60 45 44 32 32 30 30 22 23 71 60 54 46 41 35 32 24 16 11 71 67 60 58 38 34 14 10 2.7 2.3 57 49 36 29 20 71 63 50 48 37 32 12 8.3 2.8 2.2 71 66 68 65 67 64 65 60 60 55 62 59 52 48 37 34 23 20 16 14 71 67 69 66 62 63 56 57 53 51 71 58 55 53 67 64 52 50 39 38 71 67 56 54 37 32 13 10 5.4 4.5 51 52 35 32 28 28 17 16 15 15 71 68 61 58 60 49 37 37 29 26 71 68 65 63 44 40 30 26 18 15 71 52 47 46 36 36 31 30 24 23 37 22 64 52 58 58 79 67 67 73 73 27 70 70 70 45 20 70 88 89 72 98 98 88 57 45 56 1.8 69 63 66 61 62 56 57 50 48 42 60 50 53 40 39 24 14 6.7 2.9 1.6 46 41 34 32 19 18 11 9.4 6.5 5.2 63 57 42 37 40 38 22 24 6.9 7.5 58 47 51 39 43 30 38 25 23 12 49 47 29 28 18 17 16 16 12 11 64 54 42 35 24 21 14 12 5.3 3.7 45 44 27 26 9.1 9 1.8 2 0.39 0.45 38 24 7.9 5.6 4.4 18 31 11 18 6.6 10 1.3 1.8 0.38 0.44 52 51 46 45 41 41 27 29 14 16 56 49 41 35 23 20 12 11 8.1 7.2 34 51 32 45 13 26 6.7 12 4.4 5.7 61 55 55 49 65 60 50 44 36 32 40 41 21 22 8.3 8.6 1.6 1.8 0.67 0.73 37 39 22 16 25 19 15 11 7.8 6.4 64 61 51 46 44 35 18 24 11 14 44 45 34 35 13 15 7.4 8.4 3.6 4.2 70 40 33 31 27 25 21 20 18 16 26 16 60 41 57 57 80 66 66 72 72 25 50 9.4 11 6.8 10 70 87 88 70 98 98 87 54 38 60 1.7 69 66 68 65 67 63 64 59 58 52 68 62 66 58 62 50 43 24 14 5 52 46 42 37 27 22 16 13 9.1 6.9 62 59 39 37 53 50 38 38 12 14 62 56 58 50 50 40 44 33 28 18 57 54 40 38 29 27 27 25 21 19 65 58 50 41 33 26 21 16 8.2 5 59 56 52 46 39 32 21 16 4.6 4.3 49 35 13 8.3 5.3 45 41 37 31 31 23 15 11 3.5 3.4 61 58 58 54 55 51 48 42 38 31 60 55 48 42 31 25 16 13 10 8 63 61 64 60 55 53 46 44 43 37 68 63 62 58 69 65 62 57 52 46 59 55 49 43 36 29 14 11 5.3 4.3 47 47 35 28 37 30 26 21 23 17 66 64 55 52 50 40 30 31 23 21 59 56 54 50 35 30 24 20 14 11 70 42 31 32 25 25 19 20 17 15 36 23 65 45 58 58 80 67 67 73 73 29 57 11 14 5.7 21 70 87 89 71 97 98 87 59 41 56 1.1 69 66 67 64 64 60 59 56 53 49 62 56 57 49 46 35 23 12 6.9 2.8 54 49 46 41 30 26 19 16 11 9.4 62 60 41 39 51 49 36 37 13 15 58 51 52 44 43 34 37 27 21 14 53 50 35 33 23 22 21 21 15 15 66 59 52 44 38 31 24 19 9.3 7.1 53 49 40 36 22 19 7.4 6.8 1.4 1.6 48 35 15 11 7.5 38 38 27 25 19 17 5.7 5.7 1.3 1.6 59 57 55 54 52 51 43 41 30 28 60 55 48 42 31 26 18 15 12 10 60 59 62 57 38 43 23 29 23 23 62 58 57 53 66 63 55 51 41 39 50 47 36 32 20 17 5.5 5.3 2 2.3 42 45 28 23 31 26 20 17 13 11 66 64 55 52 49 41 26 31 19 20 53 50 46 43 26 23 17 15 8.8 7.9 70 44 35 35 29 28 23 23 21 18 33 20 62 41 57 57 79 66 67 73 73 27 52 9.1 10 6.9 17 70 87 88 71 97 98 87 54 38 55 2.3 68 64 66 61 62 57 57 51 49 43 59 51 51 41 36 25 13 6.1 2.7 1.2 52 47 43 38 27 23 15 13 8.4 7.3 62 57 39 36 56 52 44 41 21 20 54 47 47 39 39 30 36 26 21 14 50 48 31 30 20 20 19 19 14 14 65 57 49 42 34 28 22 16 7.6 5.3 42 44 22 29 5.6 12 1.2 3.2 0.3 0.75 46 34 15 11 7.9 17 31 7.2 16 3.2 9 0.69 2.4 0.24 0.69 54 55 44 50 37 45 19 30 7.7 15 59 54 47 42 31 26 17 14 11 8.8 56 56 49 51 25 38 12 20 8.7 13 60 55 55 49 65 60 52 47 38 36 38 41 18 25 5.7 11 1 3 0.44 1.3 37 41 23 21 26 24 16 16 11 11 64 62 51 48 45 36 23 27 17 18 43 46 32 37 11 17 5.3 10 2.2 5.3 69 42 31 33 28 27 22 22 20 17 30 18 59 37 56 56 77 64 65 71 71 27 38 9.7 9.6 8.9 17 69 86 87 70 97 98 87 50 32 55 1 68 65 66 63 63 60 58 54 51 47 62 55 56 47 45 32 19 8.7 4.1 1.6 52 46 42 38 26 24 15 14 8.6 7.8 65 60 45 42 55 50 41 38 17 16 57 51 51 43 42 33 37 27 21 13 52 50 33 31 22 20 20 19 14 13 66 57 49 42 32 28 20 17 8 5.7 53 51 42 38 25 21 9.7 8.6 1.7 1.9 45 32 14 9.4 6.2 38 33 29 23 21 16 6.9 6.2 1.5 1.7 58 54 53 49 49 45 37 33 22 19 59 54 47 42 31 27 18 15 12 10 60 59 60 56 37 43 20 25 19 18 61 56 55 52 65 62 52 49 37 35 51 48 38 34 24 20 7.5 6.7 2.6 2.6 43 44 28 24 31 27 21 18 14 12 65 64 53 50 47 37 23 27 17 17 54 51 47 44 29 25 19 16 11 9.4 43 43 34 35 29 28 23 23 20 18 29 16 63 46 57 57 79 66 66 72 72 29 58 11 15 5.3 15 69 87 88 69 97 98 87 53 40 55 1.6 68 63 65 60 61 56 55 50 47 41 58 49 50 39 34 22 11 6.1 2.5 1.5 47 41 36 32 21 17 12 9.3 7 5.3 62 56 41 36 45 42 28 28 9.6 9.1 55 45 47 37 38 27 34 23 20 11 49 46 29 27 17 17 16 15 11 10 63 53 44 36 27 21 16 11 6 3.5 43 43 25 28 8.6 11 1.8 2.9 0.38 0.63 39 26 9.8 7 5.1 11 28 8.8 16 5.5 9.6 1.2 2.2 0.34 0.58 55 52 49 47 45 43 31 31 16 18 56 49 40 35 24 20 13 11 8.3 7.4 41 53 39 48 15 29 5.9 10 5.5 4.7 60 54 54 49 64 59 49 44 34 31 40 41 22 24 8.6 10 1.8 2.4 0.75 1 37 39 22 18 25 20 15 12 8.6 7.1 64 62 51 47 45 34 18 24 11 15 45 45 35 36 14 16 7.8 8.8 3.8 4.4 69 40 33 31 26 25 21 20 18 16 27 16 57 41 56 56 77 65 65 71 71 24 57 12 14 6.6 11 69 87 87 69 97 98 87 55 38 55 1.3 68 66 66 64 63 61 58 56 51 48 62 57 58 49 47 34 23 10 6.1 2.1 53 48 43 40 28 25 17 15 10 8.7 65 61 45 42 52 49 37 36 13 15 58 52 52 45 44 35 38 28 22 14 50 50 31 32 20 21 18 19 13 14 66 58 50 44 35 30 23 19 9.6 7 47 48 32 33 13 15 2.5 4 0.28 0.87 46 33 13 9.4 6.7 24 26 17 15 9.3 9.2 1.3 2.7 0.21 0.8 57 56 52 50 46 46 31 32 16 17 60 55 48 43 31 27 17 15 11 9.8 58 58 56 55 28 38 14 20 13 13 61 58 56 54 66 64 53 51 39 37 45 46 29 29 13 14 2.1 3.4 0.54 1.4 41 45 28 24 32 29 21 19 14 12 64 65 52 51 46 40 21 29 15 18 49 49 40 40 19 20 10 11 4.3 5.6 42 44 33 34 29 28 23 22 20 18 29 17 62 44 56 56 79 66 66 72 72 28 49 8.7 9.8 6.9 16 69 87 88 70 97 98 87 55 39 53 1.3 68 65 66 62 62 58 57 52 49 44 60 53 54 44 40 28 15 6.8 3.3 1.6 50 45 40 37 24 23 14 14 8.5 8.1 64 60 45 42 52 48 37 35 14 15 56 49 49 41 40 31 35 26 20 13 50 48 31 29 19 18 18 17 13 12 65 56 47 41 30 27 19 17 7.7 5.8 51 47 37 32 19 15 5.8 4.5 1.1 0.95 43 31 13 9.3 6.2 33 29 23 17 15 11 4.2 3.5 1.1 0.9 57 54 53 49 49 45 36 32 20 18 59 54 46 42 30 26 16 15 11 10 59 58 58 55 38 42 20 24 16 16 60 56 54 50 64 61 51 47 36 33 49 45 32 28 16 13 4.2 3.3 1.5 1.3 41 43 26 23 30 26 20 17 13 11 64 63 51 49 44 36 22 26 16 16 51 48 43 39 21 18 13 10 6.4 5.2 41 43 33 34 29 28 23 23 21 18 28 15 61 44 56 56 78 65 65 71 71 28 58 12 15 6 14 69 86 88 68 97 98 86 54 40 50 2.8 68 70 64 68 60 64 54 58 45 50 68 60 51 52 40 39 21 16 8.1 4.3 67 61 60 56 45 42 32 28 21 18 68 68 45 46 63 61 52 51 26 27 68 55 45 48 38 39 33 33 21 18 68 56 33 39 22 28 21 27 16 21 68 68 66 58 52 46 36 34 16 16 68 53 33 39 13 19 2.8 5.6 0.49 1.1 62 49 24 16 11 68 45 21 28 11 17 1.8 4 0.38 0.92 68 63 59 59 57 56 48 43 34 26 69 64 56 51 36 33 19 18 12 11 68 71 74 71 73 70 72 67 72 59 68 60 51 55 64 67 47 52 34 39 68 52 30 36 13 19 2.1 4.7 0.55 1.6 37 49 22 27 22 28 13 18 9.2 12 68 69 54 58 48 48 19 34 14 23 68 56 43 48 21 26 11 16 4.7 8.3 68 55 45 45 36 37 29 30 24 24 28 14 67 49 57 57 79 65 66 72 72 30 46 10 11 8.1 14 68 87 87 71 97 98 87 59 42 54 1.6 68 66 65 64 62 60 57 55 50 47 61 56 56 48 45 33 21 9.8 5.4 2 52 47 42 39 26 24 15 14 9.5 8.7 65 61 44 42 50 48 35 34 13 13 56 51 50 44 41 33 36 27 22 14 50 49 30 31 19 20 17 19 13 14 66 58 49 43 32 29 20 18 9 6.5 46 47 30 31 11 13 2.2 3.2 0.45 0.75 45 32 12 8.1 5.1 23 27 14 14 7 8.5 1.4 2.3 0.4 0.66 57 55 52 50 47 46 29 32 12 17 59 55 47 43 31 27 17 15 12 10 57 57 52 54 31 41 16 24 14 16 59 57 55 52 64 63 51 49 37 35 43 44 24 26 9.5 11 1.7 2.6 0.71 1 40 45 26 23 30 29 21 19 13 12 63 64 51 50 45 38 19 27 13 17 46 47 36 37 14 16 6.7 8.8 2.8 4.2 42 43 33 34 28 27 22 22 19 17 28 16 63 43 56 56 77 65 65 71 71 28 47 8.3 9.4 6.8 14 68 86 88 68 97 98 86 54 36 57 4.9 68 64 68 64 67 62 64 58 58 51 68 34 23 14 2.9 1.9 0.37 0.37 0.34 0.34 68 39 35 32 22 20 15 14 11 9.3 69 53 38 35 62 56 59 54 50 45 68 18 11 7.1 3.6 2.1 2.9 1.6 0.81 0.49 68 60 56 49 46 38 43 35 34 27 68 51 42 34 29 23 20 16 11 7.9 68 63 56 56 40 41 22 22 8.1 6.3 48 40 32 25 16 68 53 26 41 21 31 12 14 5.9 4.5 68 61 65 60 65 60 63 58 62 57 68 50 48 41 36 30 24 20 18 15 68 60 64 59 56 56 51 52 52 48 68 55 57 50 68 63 61 55 50 44 68 61 52 53 39 39 20 19 12 9.5 68 56 54 46 50 42 40 30 44 34 68 63 64 57 65 54 45 38 40 30 68 62 58 58 42 42 33 32 24 22 68 45 44 39 37 32 33 29 27 24 49 31 59 46 55 55 76 65 65 71 71 27 26 4.8 69 66 28 68 86 86 70 96 98 86 55 44 50 2.4 68 66 65 63 61 59 55 52 45 43 68 33 18 17 4.7 4.4 0.48 0.48 0.24 0.3 51 48 44 40 31 29 22 20 15 14 59 58 37 37 61 59 56 53 39 36 68 21 9.6 11 3.8 4.1 2.5 2.6 0.82 0.52 68 56 45 41 32 30 30 28 21 21 68 57 50 43 38 32 28 23 16 12 68 66 64 62 51 49 27 24 6 4.5 54 46 36 29 19 68 65 59 57 49 47 24 20 6 4.4 68 64 66 63 65 62 63 60 61 56 59 56 51 47 37 34 24 21 18 16 68 64 65 62 60 59 56 56 55 52 68 55 52 49 63 61 48 45 35 33 68 66 62 60 49 48 23 19 9.6 8 50 51 35 33 26 26 14 13 14 15 68 66 60 56 60 48 38 35 29 24 68 66 66 64 53 52 42 39 27 23 68 50 46 44 37 35 32 31 25 24 38 22 62 48 55 55 77 64 64 71 71 25 68 68 68 48 19 68 86 86 70 97 98 86 57 45 52 1.9 66 62 63 59 59 55 53 48 44 39 55 46 45 36 28 20 7.9 4.7 1.8 1.3 44 42 32 33 18 19 10 11 6 6.3 59 55 38 35 49 46 34 34 14 15 50 43 42 35 33 25 29 21 16 10 44 43 25 24 15 15 13 13 9.1 9 59 53 36 37 22 22 13 13 5.3 4.6 40 42 23 23 7.2 6.6 1.2 1.5 0.18 0.41 40 27 10 6.9 5 27 31 13 14 6.3 6.7 0.77 1.3 0.2 0.42 55 52 50 48 47 45 34 33 18 20 55 50 42 38 27 23 15 13 10 8.8 39 52 41 49 18 30 9.7 15 9.8 9.9 57 52 52 46 62 58 46 43 33 31 37 39 20 20 7.7 7.3 1.1 1.7 0.35 0.75 32 37 18 15 22 19 13 12 7.6 6.9 63 60 50 46 42 33 24 27 16 17 41 42 32 33 14 13 7.9 7.1 3.6 3.4 68 38 29 30 24 24 19 19 16 15 25 14 56 37 54 54 77 63 63 69 70 24 42 9 10 8.1 13 68 86 86 68 97 98 86 50 35 48 2.5 67 68 64 66 60 62 54 56 46 48 67 57 50 49 38 34 19 11 8.7 2.7 66 60 61 53 51 35 40 23 29 14 66 66 45 45 62 61 51 52 23 29 67 53 46 46 38 37 35 31 23 18 67 53 24 36 13 24 12 23 7.8 17 67 67 62 56 51 41 40 25 21 7.4 67 50 26 34 7.5 14 1.2 3.8 0.27 0.72 55 42 22 17 10 67 37 14 22 5 13 0.59 2.4 0.22 0.58 67 61 54 56 50 52 37 40 22 25 73 68 73 67 73 64 72 60 71 56 67 64 64 63 44 51 26 34 27 23 67 59 50 52 63 65 47 49 33 35 67 47 22 29 6.4 13 0.86 2.7 0.36 0.99 40 49 28 29 29 31 18 21 13 15 67 67 51 55 46 45 19 31 14 21 67 51 36 42 12 19 5 10 1.9 4.6 67 60 55 52 53 46 47 40 41 32 29 13 65 46 56 56 78 65 65 71 71 28 35 8.9 9.3 7.8 16 67 86 87 69 97 97 86 57 40 53 2 65 60 63 58 59 54 55 49 48 42 58 50 52 42 41 28 17 8.2 4 1.6 49 41 40 33 24 18 13 8.5 6.6 4.5 57 53 35 31 46 43 31 31 11 11 55 48 50 42 43 34 38 28 24 16 50 46 32 31 22 21 20 20 15 15 61 53 48 37 32 22 19 11 5.2 2.4 43 38 28 22 12 8.6 3.6 2.9 0.77 0.88 42 31 12 8.3 4.9 30 26 18 14 11 8.2 2.6 2.6 0.7 0.86 52 50 46 44 42 41 28 29 14 16 54 48 41 35 25 20 13 10 8.6 6.8 54 52 50 48 36 37 23 24 17 17 58 53 54 49 62 57 52 47 40 36 42 38 27 21 13 9.6 3.4 2.9 1.2 1.4 39 40 28 22 30 25 20 16 15 11 61 59 50 46 45 36 24 25 18 16 47 43 39 35 21 17 13 10 6.8 5.6 39 37 30 29 24 22 19 17 16 13 35 22 59 39 54 54 76 61 62 69 69 26 52 10 11 8.5 18 65 85 85 67 96 97 85 54 35 54 4.9 65 61 65 61 64 59 61 55 56 49 65 29 20 12 2.2 1.5 0.32 0.32 0.28 0.29 65 36 31 28 20 18 13 12 9.2 8.3 65 50 37 32 59 53 56 51 48 43 65 15 10 5.7 2.9 1.6 2.4 1.3 0.66 0.42 65 57 53 45 42 34 39 31 31 24 65 47 38 30 25 20 18 14 9.4 7.2 65 60 50 53 31 38 13 20 3.2 6 45 36 29 22 14 65 49 21 37 15 28 6.7 13 2.3 4 65 58 62 57 62 57 60 55 59 54 65 47 44 38 32 27 22 18 16 14 65 57 60 56 52 53 48 48 48 45 65 51 55 47 64 60 58 52 48 42 65 58 46 50 30 37 12 18 5.6 9 65 53 51 44 48 40 38 29 41 33 65 60 61 55 62 52 43 36 37 27 65 59 53 55 35 40 26 31 17 21 65 41 41 36 34 30 30 26 25 22 49 30 55 43 53 53 75 62 62 68 69 25 26 3.2 65 63 27 65 84 84 69 96 97 85 54 42 53 3.9 65 63 62 61 60 57 55 52 48 45 56 53 50 46 38 31 14 7.9 2.1 1.1 53 48 46 41 32 27 20 15 12 8.8 57 56 35 35 49 47 35 36 13 14 51 49 45 42 36 33 31 27 18 14 50 49 33 33 22 22 20 21 15 16 62 57 52 44 39 31 27 19 11 5.8 52 49 39 33 20 14 7.1 4.4 1.6 1.1 47 34 14 9.2 6.5 43 35 30 21 20 13 6.2 3.6 1.5 1.1 60 58 57 55 55 53 45 43 29 28 52 50 40 37 24 22 13 11 7.7 7 59 59 60 58 43 46 23 27 14 16 58 55 53 50 61 60 50 47 38 35 50 45 35 28 19 13 6 3.7 2.5 1.7 38 42 25 21 27 25 17 16 13 11 60 61 50 49 45 39 26 28 19 18 53 49 45 40 24 18 15 11 8.7 5.5 39 41 31 32 24 24 18 19 15 15 34 22 65 46 54 54 76 63 64 70 70 29 59 25 28 9.6 17 65 86 86 67 97 97 84 57 38 46 2.2 65 62 61 60 56 55 49 46 39 36 65 25 11 10 2.6 2.4 0.5 0.56 0.36 0.36 49 45 42 38 29 27 21 19 14 13 56 55 36 35 60 56 56 51 40 37 65 15 6.1 6.1 1.9 2.2 1.4 1.5 0.5 0.34 65 53 42 39 30 27 28 25 21 19 65 54 48 40 36 30 27 21 15 11 65 63 63 61 56 54 36 36 12 11 52 44 35 28 19 65 62 61 59 56 53 33 31 12 11 65 62 63 61 63 60 62 59 60 56 57 53 49 44 37 34 25 22 18 16 65 60 63 59 57 57 53 53 55 51 65 51 48 46 59 57 43 42 31 29 65 63 63 61 55 53 32 31 16 15 51 51 37 33 27 26 13 13 16 16 65 63 59 55 60 49 39 35 29 25 65 63 64 63 57 55 48 46 34 33 65 47 44 42 36 35 32 31 27 25 36 20 60 47 51 51 74 60 60 67 68 23 64 64 64 53 18 64 83 84 67 96 97 84 54 43 67 2.3 63 55 57 51 52 45 45 37 37 28 63 41 42 32 29 21 12 6.9 3.1 1.7 38 32 28 23 13 10 6.4 4.9 3.5 2.6 50 47 25 23 31 31 14 18 2.1 3.1 63 38 39 30 30 22 27 18 16 9.4 63 40 26 24 17 16 15 14 11 11 63 45 35 27 20 13 10 6.4 3.1 1.7 63 44 41 32 28 19 15 8.3 4.9 2.1 30 17 4.2 2.6 1.7 63 31 32 23 25 17 13 7.4 5.2 2.5 63 49 50 46 47 44 40 38 30 29 48 42 35 28 18 13 7.5 5.3 4.5 3.1 63 46 48 43 24 31 15 19 13 13 63 61 65 62 58 52 47 39 37 29 63 40 37 28 26 17 12 6.5 6.2 3.1 31 35 18 16 21 18 12 11 9.5 8.2 63 56 42 41 36 28 21 23 15 14 63 41 42 34 27 19 19 13 13 7.6 63 28 20 19 15 13 11 9.9 8.7 7.1 29 22 61 41 51 51 74 59 60 65 66 23 47 8.5 11 6.1 15 63 82 83 65 96 97 84 59 39 45 1.2 63 59 59 55 53 50 47 43 38 35 63 43 36 32 21 18 6.1 4.6 1.7 1.3 43 40 35 33 22 20 14 13 8.9 8 55 53 37 35 47 45 34 34 14 15 63 39 35 32 27 23 23 19 13 8.9 63 41 24 24 15 15 13 13 9.3 9.5 63 51 41 36 28 24 18 15 7.9 6 63 38 21 21 7.5 8 1.5 2.2 0.37 0.51 41 30 13 9.9 7 63 22 12 12 6.2 6.9 1.2 1.9 0.37 0.5 63 50 49 46 45 42 29 30 13 16 49 46 37 35 24 21 13 12 8.9 7.8 63 53 53 51 22 34 12 18 7.4 13 63 49 46 43 56 54 38 36 24 24 63 35 19 19 8.2 8.5 1.3 2.1 0.51 0.8 28 33 16 14 18 17 10 9.5 7 6.6 63 58 42 42 35 29 15 21 11 13 63 40 31 31 14 13 7.6 7.8 3.5 4.2 63 38 29 30 24 24 20 20 17 16 24 12 55 40 51 51 75 59 60 65 66 21 50 12 14 9.7 11 63 82 84 62 96 97 83 52 36 46 1.9 62 59 61 57 57 53 51 47 41 37 33 27 15 12 3.1 2.3 0.51 0.51 0.47 0.47 42 38 34 31 22 19 15 13 9.8 8.5 54 52 36 35 57 53 54 50 41 38 23 19 11 8.9 4.3 3.4 3.6 2.7 1.1 0.88 55 52 39 36 26 24 24 22 16 15 57 49 41 33 28 22 20 15 10 7.3 49 56 33 46 13 26 3.6 9.9 0.78 2.2 46 38 29 23 14 15 45 5.8 30 2.9 19 0.96 6.1 0.5 1.6 60 57 60 56 59 56 58 54 56 52 54 48 45 39 33 28 21 18 15 13 58 57 60 56 55 54 51 50 50 46 52 48 47 43 59 56 47 44 34 31 47 54 29 42 13 25 3.2 8.4 1.1 3.7 47 48 35 32 31 28 19 17 18 16 60 59 55 52 53 47 30 30 25 23 50 56 42 51 19 31 11 20 5.9 11 48 43 42 38 34 31 30 28 25 23 40 22 59 45 50 50 72 59 59 67 67 21 63 60 63 55 20 62 82 82 64 95 97 83 57 46 51 3.8 62 58 62 58 61 56 58 52 52 46 62 27 17 11 1.8 1.3 0.35 0.35 0.34 0.34 62 34 30 27 20 18 13 12 9.2 8.3 62 47 33 30 55 50 53 48 44 40 62 14 8.5 5.5 2.3 1.6 1.9 1.2 0.51 0.4 62 54 49 42 38 32 36 29 28 23 62 45 37 30 25 20 18 14 9.4 7.2 62 56 47 50 28 36 11 18 2.2 5.2 42 35 27 22 14 62 46 20 35 13 26 4.6 11 1.3 3.4 62 55 59 55 59 54 58 53 56 51 62 44 41 36 31 26 21 18 16 14 62 54 58 53 50 50 45 46 46 43 62 49 52 45 61 57 55 49 44 39 62 55 43 47 27 34 10 16 4.2 7.9 62 50 48 41 44 37 34 27 38 30 62 57 58 51 59 49 38 31 33 24 62 56 50 52 32 37 23 28 14 19 62 39 39 34 32 28 28 25 24 21 47 29 54 43 50 50 73 59 59 65 66 22 25 2.8 62 61 25 62 82 82 67 94 96 83 52 39 43 2.3 63 60 59 57 54 52 46 43 36 33 63 21 8.7 8.2 2.2 2.1 0.42 0.48 0.32 0.32 49 45 41 38 29 26 21 18 14 12 54 54 34 34 58 56 55 52 42 39 63 11 3.6 4.4 1 1.3 0.72 0.9 0.22 0.34 63 50 38 35 27 25 25 23 18 17 62 54 47 40 36 29 27 21 15 11 63 60 61 60 58 56 42 42 16 17 51 44 35 28 19 62 61 61 59 58 55 39 38 16 16 62 60 61 60 61 60 60 58 59 56 56 52 48 44 36 32 25 21 18 16 62 59 60 58 56 56 53 53 53 49 63 49 45 43 57 56 41 39 28 27 62 61 61 60 57 55 37 38 21 21 49 50 35 33 26 24 12 12 14 14 63 60 57 54 58 49 38 35 28 23 63 61 62 61 58 56 51 50 39 39 63 47 45 42 36 34 32 31 26 25 35 19 56 45 49 49 73 58 59 66 66 21 62 62 62 50 17 62 81 82 65 95 97 82 55 42 55 1.6 61 58 61 58 61 57 60 56 59 54 59 54 58 51 54 45 44 27 26 8.5 42 39 34 32 20 18 12 11 6.6 6 51 51 30 30 41 40 27 28 7 9 54 48 49 43 42 34 36 28 24 16 50 48 36 35 26 26 24 23 19 19 55 50 40 35 26 22 15 13 5.4 4.3 52 48 45 41 34 30 22 19 9.2 7.9 41 29 10 7 4.2 39 36 35 30 30 26 18 16 8.4 7 53 51 50 48 48 45 41 39 32 32 48 46 35 33 19 18 9.1 8.5 5.5 5.4 54 53 52 50 39 42 27 31 25 25 61 58 60 56 61 57 59 54 57 50 51 47 42 39 33 29 18 15 9.8 8.8 38 39 29 24 29 26 21 18 22 17 57 56 46 44 42 34 23 25 17 16 53 50 49 45 35 32 28 25 20 17 30 34 22 25 18 19 13 15 12 11 21 58 39 50 50 71 59 59 65 65 19 18 62 81 60 97 97 82 55 36 41 2.5 61 63 56 59 51 54 43 47 34 38 61 50 44 41 34 27 19 9.8 8.9 2.6 61 55 58 51 51 43 44 35 35 27 60 60 38 40 44 52 26 40 5.7 17 61 47 43 40 39 34 38 32 30 21 61 44 23 27 14 17 13 16 9.8 12 61 61 56 53 46 43 36 34 19 18 61 36 20 21 5.5 7.4 0.89 1.9 0.23 0.37 47 38 23 19 16 61 18 8.9 9 3.4 4.7 0.47 1.1 0.2 0.27 61 48 39 40 32 34 17 20 7.3 9 67 64 66 61 61 54 53 44 45 36 61 52 50 47 22 32 14 20 12 13 61 52 43 45 54 58 34 38 21 24 61 33 16 17 4.5 6.5 0.51 1.3 0.25 0.48 31 41 20 22 20 24 10 15 8.1 10 61 61 40 47 32 33 11 22 6.9 13 61 37 27 27 8.1 9.6 3.4 5 1.2 2.2 61 65 71 64 71 63 70 62 70 61 23 9.9 61 41 50 49 73 58 59 64 65 25 26 8.8 9.1 8.2 11 61 82 83 64 96 97 82 54 37 43 1.7 60 57 57 54 53 50 47 43 39 35 50 44 42 36 30 23 12 7 3.6 1.8 41 38 32 30 20 18 12 11 7.9 6.8 52 50 33 31 39 38 27 27 8.5 9.5 44 39 37 32 29 23 23 18 12 7.9 44 42 26 25 17 16 15 15 11 10 54 49 39 34 25 21 15 13 6 5.5 42 39 27 24 11 8.8 2.9 2.4 0.67 0.55 39 26 10 7 4.7 30 27 18 15 11 8.7 2.4 2.2 0.58 0.55 51 49 47 45 44 42 33 32 19 19 48 45 36 33 22 20 12 10 7.8 6.8 52 52 52 50 35 40 19 25 18 17 52 48 44 41 56 53 41 38 29 27 41 37 25 21 11 8.6 2.4 2 0.94 0.9 31 34 18 15 20 17 11 9.8 7.7 7 56 56 44 43 38 31 19 22 14 14 45 42 36 33 17 14 9.7 7.8 4.6 3.6 31 34 24 25 20 20 15 16 13 13 13 58 38 49 49 72 57 58 65 65 24 11 61 80 62 96 96 82 53 36 42 1.7 59 56 56 53 52 48 45 41 36 33 45 39 35 28 20 14 6.2 3.2 1.5 0.78 42 36 33 28 19 16 11 8.8 6.5 4.8 52 49 33 31 51 47 43 40 24 22 40 34 31 26 22 17 19 14 9 6.3 39 37 21 20 12 12 11 10 7.5 7.1 55 48 39 32 25 19 15 11 5.7 3.4 23 28 9.5 13 2 4 0.52 1.1 0.28 0.32 38 27 11 8.3 6 12 17 3.9 6.6 1.6 3.2 0.42 0.83 0.28 0.31 47 46 40 41 34 37 20 26 10 14 46 42 33 30 20 18 12 11 8.2 7.5 50 49 49 46 29 33 14 17 9.7 11 49 45 43 40 55 52 38 36 25 24 23 26 8.5 12 2.3 4.3 0.52 0.99 0.33 0.51 26 31 14 13 17 17 10 10 6.1 6.2 56 55 42 39 35 27 18 22 13 14 31 33 21 24 5.8 8.4 2.7 4.5 1.2 2.1 61 33 24 26 20 21 16 17 15 14 25 12 50 29 48 47 69 56 57 63 64 18 37 8.7 10 8.3 12 61 79 81 61 94 96 81 45 27 44 1.7 60 57 58 55 54 51 47 43 37 34 26 21 11 8.1 1.9 1.5 0.36 0.34 0.33 0.32 39 34 30 27 19 16 12 11 7.9 6.8 52 49 34 32 55 50 51 46 37 34 17 14 7.4 5.8 2.6 2.1 2 1.6 0.64 0.52 51 47 32 30 20 18 17 16 11 11 55 46 37 29 25 19 17 12 8.2 5.8 43 52 27 41 10 22 2.7 8.1 0.6 1.9 43 35 26 20 12 15 41 6.6 26 3.2 16 0.85 5 0.37 1.5 58 55 57 54 57 53 55 52 53 49 51 45 42 36 30 25 19 16 14 12 55 55 58 54 52 51 47 46 47 43 49 45 44 41 57 54 44 40 31 28 40 50 23 37 10 21 2.4 7 0.96 3.3 41 43 29 27 25 23 15 13 14 13 58 57 51 48 50 42 29 29 23 21 45 52 35 46 15 26 8.5 17 4.5 9.2 60 39 38 34 31 28 27 24 22 20 37 20 56 43 48 47 71 57 57 64 64 20 60 57 60 53 17 60 80 81 63 95 96 81 55 43 42 2.2 61 59 57 56 52 50 44 42 33 31 61 18 6.5 6.2 1.5 1.3 0.38 0.42 0.44 0.42 46 42 39 36 27 24 19 17 13 11 53 52 33 33 57 54 54 51 43 40 61 9.1 3 3.4 0.76 1.1 0.56 0.74 0.18 0.3 61 47 36 32 23 21 21 19 14 13 61 51 45 38 33 26 24 19 14 10 61 59 60 58 54 52 37 37 13 12 49 41 33 26 18 61 59 58 57 54 52 33 33 12 11 61 59 60 58 59 58 59 57 57 55 54 51 46 41 34 31 23 21 18 16 61 57 59 57 54 54 51 50 52 48 61 47 44 42 55 53 38 36 26 24 61 59 59 58 52 51 32 31 16 16 47 49 34 31 25 25 12 12 13 13 61 59 55 53 56 48 36 33 27 23 61 59 60 59 54 53 46 46 33 32 61 45 42 40 35 34 31 30 26 25 35 18 54 42 47 47 69 56 57 64 64 19 61 60 60 53 16 60 79 80 63 94 96 81 54 43 50 2.4 59 59 58 57 56 55 54 53 51 50 57 56 55 53 51 49 43 39 32 23 40 38 32 30 23 23 16 18 11 12 53 53 35 35 56 55 53 51 39 37 54 53 52 51 47 47 44 44 38 36 50 50 40 40 33 33 31 32 27 28 57 52 37 32 19 21 12 15 6 8.2 52 50 47 43 40 36 31 28 20 18 47 37 23 19 14 46 43 40 37 35 33 27 25 19 19 56 54 52 49 49 46 41 37 32 27 51 49 44 42 36 34 28 25 22 20 55 57 57 56 43 49 34 39 35 35 59 58 55 55 58 58 51 50 39 37 50 47 44 39 37 33 27 24 20 18 45 47 38 37 38 38 32 31 30 30 58 58 53 52 50 46 33 35 27 26 49 45 44 38 32 27 26 22 20 17 60 37 25 30 25 29 19 23 19 18 40 30 59 39 49 49 72 57 57 64 64 21 45 11 13 8.6 55 60 80 81 61 96 96 81 54 37 41 1.1 57 53 53 49 48 44 40 36 31 27 41 35 30 24 16 11 5 2.9 1.5 1 36 31 27 23 16 13 9.2 7.4 6 5 50 46 30 27 36 35 24 25 10 11 39 33 31 25 23 17 19 14 9.6 6.3 36 34 17 17 9.3 8.8 8.1 7.8 5.2 5 51 43 34 27 20 15 12 8.9 5.4 3.7 18 25 6.1 9.7 1.4 2.5 0.48 0.82 0.25 0.36 33 21 8 5.8 4.3 6.1 12 2.4 4.7 1.3 2.3 0.48 0.77 0.24 0.34 38 42 27 35 20 30 8.9 16 4.2 7.7 43 40 30 28 17 16 9.1 8.5 6.1 5.8 44 45 38 40 17 25 8.8 12 6.5 7.5 46 42 41 36 52 48 35 32 24 22 18 23 5.9 9.2 1.8 3.1 0.63 1 0.4 0.56 24 27 13 11 15 13 8.2 7.5 5 4.8 52 52 37 36 30 24 11 15 7.7 8.8 26 30 17 21 4.2 6.7 2.2 3.6 1.1 1.9 58 31 23 24 19 19 15 15 13 12 23 12 50 32 45 45 69 54 54 61 62 17 40 7.7 9.3 6.9 9.2 58 78 79 57 94 96 79 49 31 37 1.3 57 53 53 50 48 44 40 37 31 28 41 35 30 25 16 12 5 3.1 1.5 0.95 35 29 26 21 14 11 8.5 6.9 5.3 4.2 50 46 30 27 33 31 20 21 8 8.5 38 33 30 25 22 16 18 13 9.1 5.5 36 33 17 15 9.2 8.1 8 7.2 5.2 4.6 52 42 33 24 19 13 11 8.1 4.9 3 26 24 11 9.6 2.8 2.4 0.88 0.81 0.45 0.39 30 19 7.3 5.4 3.8 17 16 6.7 6.7 3.1 3 0.81 0.77 0.45 0.38 46 43 40 37 35 32 22 20 11 9.8 39 36 25 23 13 12 7.1 6.7 5 4.7 43 44 40 40 15 20 7 8.8 6.6 5.8 46 42 38 34 52 48 35 32 24 22 25 24 10 9.3 3.3 3.1 0.98 0.98 0.61 0.63 23 26 13 10 14 12 7.7 6.5 4.8 3.8 52 51 37 34 31 24 13 16 8.9 8.7 33 31 23 22 7.8 7.3 4 3.8 1.9 1.9 58 30 23 23 18 18 14 14 13 11 23 11 50 32 45 45 68 53 53 60 61 16 45 9.3 11 7.1 7.5 58 77 79 58 94 96 79 51 33 41 1.6 58 55 56 53 52 49 46 43 38 34 28 24 13 11 2.8 2.3 0.57 0.54 0.42 0.42 41 38 35 32 25 23 18 17 13 11 50 48 32 32 53 50 50 47 41 38 17 15 7.4 6.6 2.6 2.3 2 1.7 0.64 0.6 50 47 34 31 23 20 20 18 14 13 53 47 40 34 30 25 23 19 14 10 52 52 43 43 28 27 12 12 2.7 3.2 44 38 31 25 17 47 47 35 35 26 25 9.6 9.6 2.3 2.8 56 54 55 53 55 52 54 50 52 48 50 46 43 39 33 30 23 21 18 16 53 53 56 53 51 50 48 47 48 45 47 44 42 39 54 52 41 38 28 26 51 50 41 40 27 26 11 11 4.6 5.4 44 44 31 28 27 24 15 13 15 13 57 55 52 49 50 43 32 29 25 20 53 52 48 48 32 32 23 23 14 14 44 42 39 37 33 32 30 28 25 24 36 19 53 42 46 45 68 54 54 61 62 17 58 58 58 51 17 58 78 79 60 94 96 79 55 44 34 1.5 56 53 53 49 47 44 39 35 29 25 38 33 26 22 12 9.5 2.9 2.1 0.85 0.7 36 31 28 23 16 13 9.5 7.3 5.8 4.5 49 45 31 29 46 41 38 34 21 19 35 31 26 22 18 14 15 12 6.8 5.3 40 37 22 20 13 12 11 10 7.7 7 50 42 34 26 21 15 13 8.4 5.4 3.5 36 33 21 18 8.2 6.4 2.2 2 0.47 0.54 35 24 12 8.4 6.1 26 23 13 10 6.7 5.4 1.6 1.4 0.4 0.46 50 45 47 41 45 39 37 32 27 23 43 39 31 28 19 18 11 10 8 7.4 45 48 48 46 25 34 14 17 11 9.2 42 38 35 32 50 47 30 27 18 17 34 31 19 15 8 6.3 2.1 1.9 0.93 0.93 26 28 16 13 16 14 9.7 8 6.8 5.8 53 51 39 37 33 24 16 17 11 11 38 35 30 26 12 9.8 6.3 5.5 3.2 2.8 57 31 23 25 19 21 16 17 14 14 22 10 50 35 44 44 67 52 52 59 59 14 54 26 29 7.3 7.8 57 77 78 56 94 95 79 47 32 34 1.7 56 52 53 49 47 43 39 35 29 25 39 34 27 23 13 9.9 2.9 2.1 0.9 0.72 36 31 28 23 16 13 9.6 6.7 5.8 3.8 49 45 31 29 47 42 39 34 21 19 35 31 26 23 18 15 15 12 7 5.6 39 37 21 20 12 12 11 11 7.5 7.1 50 42 34 26 21 15 13 7.9 5.2 2.7 37 34 22 19 8.5 7 2.3 2.3 0.6 0.64 35 24 12 8.6 6.3 27 24 14 11 6.9 5.7 1.6 1.7 0.53 0.52 50 45 47 42 45 39 38 33 29 24 43 39 32 29 20 18 12 11 8.5 7.6 46 48 49 47 23 34 13 17 13 9.8 42 39 35 32 49 46 30 28 18 17 35 32 19 16 8.3 6.6 2.2 2 0.98 0.95 27 29 17 13 17 14 10 8.6 7.2 6.1 53 51 39 36 34 24 17 16 11 9.9 39 36 31 27 12 9.9 6.7 5.5 3.3 2.9 57 31 23 24 19 21 16 17 13 14 22 11 50 35 44 44 69 51 52 58 59 14 55 29 32 7.7 7.9 57 77 78 56 94 96 78 46 32 34 1.7 55 52 52 48 47 43 39 35 29 25 37 32 25 21 11 8.5 2.5 1.8 0.82 0.61 35 31 27 24 16 13 9.3 7.1 5.4 4 49 45 31 29 46 41 38 34 21 19 33 29 24 21 16 13 13 11 5.9 4.8 40 37 22 21 13 12 12 11 8 7.6 50 42 33 27 21 15 13 8.6 4.7 2.9 38 35 24 20 9.4 7.2 2.6 2 0.63 0.55 35 25 12 8.7 6.3 29 25 15 12 7.9 5.9 1.7 1.5 0.56 0.44 51 47 48 44 46 41 39 35 30 26 43 39 32 29 20 17 11 10 8.2 7.3 48 48 51 47 27 35 14 18 11 9.6 42 38 35 32 49 46 30 27 19 17 36 32 21 17 9.3 7.1 2.4 2 1.1 0.93 27 29 17 14 16 14 9.7 8.4 7 6 52 51 39 36 33 24 16 17 11 10 40 37 32 28 14 11 7.5 5.7 3.7 2.9 57 30 22 24 18 20 15 16 13 13 22 11 51 36 44 43 68 52 52 58 58 14 54 31 33 7.7 7.9 57 77 77 56 94 96 79 46 33 34 1.8 55 52 52 48 47 43 39 35 28 25 37 32 26 21 13 9.2 2.8 1.8 0.81 0.63 35 30 27 22 15 12 8.9 6.8 5.6 4.2 48 44 30 28 45 40 37 32 19 17 34 30 26 22 17 14 14 11 6.4 4.8 39 36 21 19 12 11 10 9.7 6.8 6.3 50 41 33 25 20 14 12 7.8 4.9 3.3 34 31 21 16 7.8 5.1 2.1 1.5 0.56 0.38 33 23 11 7.9 5.6 25 21 12 8.6 6.3 4.2 1.4 0.96 0.47 0.34 49 44 45 40 42 38 34 31 25 22 42 38 30 27 18 16 10 9.2 7.3 6.7 44 46 46 43 19 29 11 15 9.1 8.1 41 38 35 32 49 46 30 27 18 16 32 28 18 13 7.7 5.2 2 1.5 0.94 0.69 25 27 15 11 15 13 8.9 7.4 5.9 4.9 52 51 38 36 32 23 15 16 10 9.5 37 34 29 25 11 8.6 6.3 4.7 3.1 2.4 57 29 22 23 18 19 15 16 13 13 22 11 49 32 44 43 68 51 51 58 58 14 51 18 20 6.9 7.4 57 76 77 56 94 95 78 45 31 36 2.3 56 53 52 49 45 44 36 34 25 24 56 11 3.9 3.5 0.96 0.94 0.46 0.46 0.42 0.46 44 41 38 35 27 25 19 17 13 12 47 47 30 31 53 51 51 48 43 40 56 4.8 1.5 1.7 0.56 0.5 0.52 0.42 0.16 0.18 56 41 29 26 18 17 17 16 12 11 56 49 44 37 33 27 25 19 14 10 56 54 55 53 54 51 48 45 30 28 46 40 33 27 18 56 54 55 53 53 51 47 44 30 27 56 54 55 54 55 53 54 53 53 51 50 47 43 39 33 30 24 22 18 17 56 52 54 52 50 49 47 47 48 45 56 41 38 37 50 48 33 31 21 20 56 54 55 54 54 52 45 43 34 32 46 46 34 32 24 25 11 12 14 14 56 54 53 51 54 48 37 33 28 23 56 54 55 54 54 52 50 49 44 43 56 42 40 38 34 32 31 29 26 24 32 16 51 39 42 42 66 50 51 58 58 16 55 55 55 49 14 55 75 75 58 91 94 76 50 39 34 2.4 53 51 49 49 43 42 35 33 24 23 53 11 3.7 3.8 1.1 1 0.44 0.42 0.32 0.28 44 41 39 35 28 25 20 17 14 12 46 46 28 30 51 49 49 47 41 38 53 4.8 1.3 1.8 0.48 0.6 0.38 0.44 0.34 0.18 54 40 29 27 20 17 17 16 12 11 53 48 43 37 33 27 26 19 15 11 53 52 53 52 51 50 47 45 33 31 46 40 33 27 19 53 51 52 51 52 50 46 43 33 31 53 52 53 52 53 51 52 51 51 50 48 46 42 39 33 31 24 22 19 17 53 51 51 50 48 49 45 46 46 44 53 40 36 34 48 46 32 30 21 20 53 52 53 52 52 50 46 44 36 35 45 46 35 33 25 24 13 12 14 14 53 52 51 49 52 47 36 33 27 22 53 52 53 52 51 50 49 47 44 43 53 42 40 38 35 33 31 30 26 25 31 14 50 35 41 41 65 49 50 57 58 16 53 53 53 49 14 53 72 74 56 91 95 75 48 36 32 2.2 53 51 49 48 42 41 34 32 23 22 53 10 3.6 3.5 1.3 1.2 0.38 0.36 0.32 0.28 43 41 38 35 28 26 20 18 14 13 45 45 28 29 50 48 49 46 41 39 53 4.1 1.3 1.5 0.46 0.56 0.32 0.42 0.2 0.22 53 37 27 24 17 15 16 13 11 9.4 53 47 43 37 34 28 26 20 15 11 53 51 53 51 51 49 46 44 34 32 45 40 34 27 19 53 51 52 50 50 49 45 43 34 31 53 51 52 51 52 51 52 50 51 49 47 45 42 39 33 31 25 22 20 17 53 50 51 50 47 48 45 45 46 44 53 38 34 33 47 46 31 30 20 19 53 52 53 51 51 49 46 44 37 36 44 44 33 30 23 22 10 11 12 12 53 51 51 48 52 47 36 33 27 22 53 52 53 51 51 49 49 47 44 43 53 42 40 38 34 33 31 30 26 25 31 13 47 35 40 40 63 48 48 56 56 15 52 52 52 48 13 52 72 72 55 91 94 74 49 37 28 1.1 52 47 45 43 39 37 31 29 22 20 52 28 19 18 8.7 7.8 2.4 2 0.81 0.72 32 29 24 22 14 13 8.7 7.9 5.3 4.9 45 42 30 28 42 38 35 32 19 18 52 25 18 17 11 11 9.7 8.8 4.6 4 52 27 13 13 6.8 6.7 6.3 6 4.1 3.9 52 39 29 24 18 15 11 9.7 5 3.8 52 25 12 10 3.6 3.1 0.93 0.9 0.32 0.34 31 22 11 8.2 5.9 52 15 6.2 5.4 3 2.6 0.75 0.71 0.3 0.32 52 41 39 37 36 35 25 25 13 14 39 35 28 26 18 17 11 9.9 7.8 7.2 52 44 47 44 22 31 9.1 14 7.2 8.9 52 36 30 29 43 41 23 23 13 13 52 23 10 9 3.7 3.3 0.75 0.81 0.39 0.43 20 24 9.4 8.7 10 10 5.1 5.3 3.2 3.3 52 47 32 32 27 21 11 15 7.8 8.9 52 28 20 19 6.9 6.1 3.7 3.3 1.7 1.7 52 30 24 24 19 19 16 16 13 13 18 7.2 48 32 40 39 62 47 47 54 54 13 42 13 14 8.9 7.2 52 72 73 50 93 95 74 45 31 33 1.9 48 45 45 43 40 38 33 30 25 22 13 10 3.5 2.7 0.76 0.7 0.52 0.51 0.5 0.51 33 29 26 23 17 15 11 9.9 7.6 6.6 41 39 27 25 44 41 43 40 36 33 7.9 6.4 2.7 2.1 0.75 0.7 0.77 0.6 0.29 0.25 39 35 25 21 15 12 14 11 8.8 7.3 44 38 32 25 21 16 15 11 7.8 5.7 38 44 24 38 8.9 25 1.7 11 0.3 2.6 36 29 23 17 11 14 36 5.4 25 2.7 18 0.64 6.1 0.27 1.6 46 44 46 44 46 43 45 43 44 41 41 36 34 29 24 21 16 14 12 10 44 43 46 43 41 40 38 37 38 35 37 34 33 30 45 42 34 31 24 22 35 43 20 35 8 23 1.5 8.9 0.59 4 36 37 27 25 24 22 15 12 13 12 47 45 43 41 43 38 22 22 19 16 38 44 29 40 11 26 6.2 17 3 11 36 32 31 28 26 23 23 21 19 17 34 17 46 35 38 37 61 44 45 52 52 14 48 46 48 46 14 48 70 69 52 89 93 72 48 36 27 2.1 45 44 40 39 34 33 25 24 17 15 45 5.9 2.1 2.1 0.88 0.9 0.58 0.56 0.58 0.56 39 37 36 33 28 26 21 19 16 14 38 38 23 25 42 42 42 41 38 36 45 2.4 0.66 0.9 0.28 0.36 0.26 0.24 0.1 0.1 45 29 19 16 12 10 10 9.2 6.9 6.2 45 42 39 35 32 27 26 21 16 13 45 44 44 44 42 42 39 38 32 30 40 37 32 27 20 45 44 43 43 43 41 39 37 32 30 45 44 44 44 44 44 44 44 43 42 41 40 37 35 31 29 24 22 20 18 44 43 43 43 41 42 40 40 40 39 45 32 28 28 39 39 23 23 14 14 45 44 44 44 43 42 41 39 36 34 37 37 27 26 20 20 9.1 9.2 9.7 9.6 45 44 44 43 44 42 34 30 26 21 45 44 44 44 43 42 42 40 39 37 45 38 36 34 31 30 29 27 25 24 27 12 42 32 34 33 57 40 41 48 48 12 44 44 44 41 11 44 64 65 49 86 91 66 44 34 14 1.4 37 32 29 27 22 21 15 15 9.6 9.2 37 14 8.5 7.5 3.7 3.2 1.2 1 0.49 0.46 19 17 14 13 8.4 7.1 5 4.1 3.2 2.6 31 29 21 20 30 27 26 23 15 15 37 13 8.7 8.1 5.2 4.8 4.4 4 2 1.8 37 15 6.8 6.3 3.5 3.3 3.1 3 2.1 1.9 37 25 18 14 10 8 6.7 4.8 3 2 37 14 4.6 3.8 1.2 0.97 0.43 0.4 0.18 0.16 21 15 7.9 5.8 4.1 37 8 2.5 2 1.2 0.93 0.35 0.35 0.17 0.17 37 29 29 26 27 24 21 17 14 11 26 23 18 16 11 10 7.2 6.5 5.4 5 37 32 30 31 23 25 11 13 16 8 37 21 15 14 27 26 11 11 6.1 6.1 37 13 4.5 3.8 1.5 1.2 0.4 0.41 0.22 0.24 12 14 5.4 4.9 5.4 5.4 2.7 2.7 1.8 1.7 37 33 21 21 17 13 7.7 9.2 5.1 5.3 37 17 12 11 3.2 2.7 1.7 1.3 0.83 0.7 37 20 17 16 13 13 11 11 9.3 9 11 3.2 40 25 27 27 51 33 33 38 38 7.2 32 12 13 7.6 3 37 57 58 35 87 91 61 40 26 13 1.8 32 34 28 32 25 28 21 23 17 18 32 18 11 12 5.9 5.7 2.2 1.7 1.1 0.72 44 42 43 40 42 37 42 33 40 22 33 37 19 22 34 37 30 32 17 19 32 18 12 14 9.8 10 8.3 9 4.1 4.8 32 19 8.1 9.8 4.7 5.9 4.2 5.3 3 3.7 32 43 43 40 37 33 29 24 19 7.8 32 14 8.3 7.4 3.2 2.8 0.92 0.79 0.23 0.18 40 34 18 13 8.3 32 10 5.4 4.7 2.9 2.3 0.74 0.58 0.25 0.21 32 31 27 29 25 26 21 20 16 14 39 39 33 31 21 19 12 11 8 7.2 32 38 37 39 38 37 33 33 34 32 32 23 14 16 29 31 19 20 14 14 32 13 7.9 7.1 3.7 3.3 1.1 0.94 0.5 0.45 12 18 6.5 7.5 7 8.8 3.8 4.8 2.8 3.2 32 32 19 22 17 17 4.6 7 3.1 4.4 32 17 13 12 5.6 5.2 3.4 3.1 1.8 1.6 32 36 29 30 25 26 21 22 17 16 14 3.5 41 25 25 25 48 30 30 36 36 11 19 6.1 6.8 4.8 4.9 32 54 53 39 74 79 55 50 29 7.2 1.4 21 19 15 14 9.9 9.7 6 5.8 3.3 3.3 21 4.6 2.7 2.4 1.3 1.1 0.54 0.51 0.29 0.29 10 8.3 6.8 5.7 3.8 3.3 2.6 2.1 1.8 1.5 18 17 13 12 17 16 15 14 9.7 9.3 21 4.2 2.7 2.4 1.6 1.4 1.2 1.3 0.55 0.64 21 6.4 2.4 2.3 1.3 1.1 1.2 1 0.8 0.76 21 14 9.3 6.6 4.9 3.7 3.1 2.4 1.6 1.3 21 9.4 6 4.9 2.3 1.7 0.7 0.53 0.23 0.2 12 7.5 4.7 3.7 2.6 21 7.1 4.1 3.2 2.2 1.6 0.55 0.43 0.25 0.2 21 19 19 18 18 17 15 14 12 10 14 12 9.5 8.3 5.9 5.3 3.9 3.4 3 2.8 21 19 17 18 14 15 7.8 8.3 5.2 4.6 21 10 7.7 7.2 14 13 4.7 4.8 2.7 2.8 21 9.1 5.6 4.5 2.4 1.9 0.63 0.54 0.32 0.29 5.5 7.2 2.2 1.9 2.2 2.4 1.2 1.1 0.83 0.75 21 20 13 13 9.5 7.5 5.1 5.9 3.4 3.2 21 11 9.4 8.2 4.1 3.2 2.4 1.8 1.2 0.94 21 11 9.3 8.7 7.5 7 6.5 6 5.7 5.1 6.6 1.3 30 20 16 16 34 19 19 23 23 4 20 9.4 10 5.4 1.3 21 38 39 21 75 84 43 34 20 71 80 78 86 80 88 ImageNet Accuracies (top-1, %) Figure 7: An overview of our testbed. Each row is a model, and each column is an evaluation setting. For the corruptions, we display each of the ﬁve severities deﬁned in [38]. We also plot in-memory and on-disk versions of each corruption as jpeg compression was found to be a confounding factor in [31]. A few cells are empty due to resource constraints. Testbed code and data is provided at https://modestyachts.github.io/imagenet-testbed/. 27B Relative and eﬀective robustness B.1 Relative and eﬀective robustness graphical sketch A central question we address in our paper is whether current methodologies provide meaningful robustness to natural distribution shifts. We discuss how both relative robustness and eﬀective robustness are needed to disentangle the confounding eﬀect of original model accuracy. In Figure 8, we graphically illustrate this notion of relative robustness. 60 65 70 75 80 85 ImageNet (top-1, %) 55 60 65 70 75ImageNetV2 (top-1, %) Hypothetical Robustness Intervention Baseline accuracy Standard ResNet50 ResNet50, hypothetical robustness intervention Negative relative robustness Negative effective robustness Figure 8: While a hypothetical intervention (green), applied to a baseline model (blue), leads to eﬀective robustness (it is above the red line), it reduces the model’s accuracy un- der distribution shift. Hence it fails to pro- viderelative robustness. An ideal intervention would place the model in the white quadrant - positive eﬀective and relative robustness. B.2 Relative and eﬀective robustness for ResNet50 models We provide additional plots depicting a subset of the models in our testbed. In order to make an equal comparison, we only plot ResNeet50 variants, models which slightly modify the training data or architecture of a base ResNet50. The plots in this section thus describe what the relative and eﬀective robustness properties of various robustness interventions look like on a standard ResNet50. The models can be directly compared with each other since the base model before intervention is the same. For natural dataset shifts, the plots in Figure 9 demonstrate that the only models that have consistently positive relative and positive eﬀective robustness are models that are trained on more data. However, the eﬀect is small, and not all models trained on more data are more robust. On YTBB-Robust speciﬁcally, a few data augmentation strategies from ImageNet-C provide signiﬁcant both eﬀective and relative robustness: training on greyscale (ρ = 6.9%, τ = 1.8%); training on pixelate (ρ = 5.4%, τ = 2.0%); training on jpeg compression (ρ = 5.4%, τ = 6.3%); training on gaussian noise, contrast, motion blur, and jpeg compression (ρ= 4.8%, τ = 5.0%); and training on gaussian noise (ρ= 3.6%, τ = 4.0%). However, this performance is not consistent across the natural distribution shifts. Exploring why these data augmentation strategies are helpful on YTBB-Robust is an interesting direction for future work. Additionally, while someℓp-adversarially robust models display signiﬁcant eﬀective robustness on YTBB-Robust -ℓ2 robust ResNet50 (ρ= 6.4%), ℓinf robust ResNet50 (ρ= 6.4%), and ResNet50 smoothed with 0.25 gaussian noise and adversarially 1-step PGD trained (ρ= 5.0) - in most cases, they fail to provide positive relative robustness. For natural consistency shifts, the plots in Figure 10 demonstrate that while adversarially robust models provide eﬀective robustness (averageρ= 4.3% on ImageNet-Vid-Robust and averageρ= 3.9% 28on YTBB-Robust), they only sometimes provide relative robustness on YTBB-Robust. For the adversarially ﬁltered shift, the plot in Figure 11 demonstrates that robustness interventions have little impact on ImageNet-A accuracy. Most of the \"knee\"-like response curve can be explained as an artifact of the adversarial ﬁltering, with the knee occuring at the ResNet50 model accuracy. 45 50 55 60 65 70 75 80 ImageNet (top-1, %) 35 40 45 50 55 60 65 70ImageNetV2 (top-1, %) Relative and Effective Robustness - ResNet50 Family 50 55 60 65 70 75 80 85 ImageNet (class-subsampled) (top-1, %) 15 20 25 30 35 40 45 50ObjectNet (top-1, %) Relative and Effective Robustness - ResNet50 Family 85 90 95 ImageNet (class-subsampled) (top-1, %) 45 50 55 60 65 70 75 80ImageNet-Vid-Robust (pm-0, %) Relative and Effective Robustness - ResNet50 Family 90 95 ImageNet (class-subsampled) (top-1, %) 45 50 55 60 65YTBB-Robust (pm-0, %) Relative and Effective Robustness - ResNet50 Family ResNet50 baseline Standard resnet50 Trained with heavy data augmentation Lp adversarially robust Architecture modification Trained with more data Linear fit Negative relative robustness Negative effective robustness Figure 9: Relative and eﬀective robustness for models that are variants of a ResNet50. Model accuracies are displayed on the four natural dataset shifts: ImageNetV2 (top left), ObjectNet (top right), ImageNet-Vid-Robust-anchor (bottom left), and YTBB-Robust-anchor (bottom right). These plots demonstrate that the only models that have consistently positive relative and positive eﬀective robustness are models that are trained on more data. However, the eﬀect is small, and not all models trained on more data are more robust. Conﬁdence intervals, axis scaling, and the linear ﬁt are computed similarly to Figure 2. 2945 50 55 60 65 70 75 80 ImageNet-Vid-Robust (pm-0, %) 35 40 45 50 55 60ImageNet-Vid-Robust (pm-10, %) Relative and Effective Robustness - ResNet50 Family 45 50 55 60 65 YTBB-Robust (pm-0, %) 35 40 45 50YTBB-Robust (pm-10, %) Relative and Effective Robustness - ResNet50 Family ResNet50 baseline Standard resnet50 Trained with heavy data augmentation Lp adversarially robust Architecture modification Trained with more data Linear fit Negative relative robustness Negative effective robustness Figure 10: Relative and eﬀective robustness for models that are variants of a ResNet50. Model accuracies are displayed the two consistency shifts: ImageNet-Vid-Robust (left), and YTBB-Robust (right). These plots demonstrate that while adversarially robust models provide eﬀective robustness, they do not necessarily provide relative robustness. Conﬁdence intervals, axis scaling, and the linear ﬁt are computed similarly to Figure 2. 65 70 75 80 85 90 95 ImageNet (class-subsampled) (top-1, %) 5 10 15 20 25 30ImageNet-A (top-1, %) Relative and Effective Robustness - ResNet50 Family ResNet50 baseline Standard resnet50 Trained with heavy data augmentation Lp adversarially robust Architecture modification Trained with more data Linear fit (piecewise) Negative relative robustness Negative effective robustness Figure 11: Relative and eﬀective robustness for models that are variants of a ResNet50. Model accuracies are displayed on ImageNet-A, a dataset adversarially ﬁltered to contain only images incorrectly classiﬁed by a ResNet50 trained on ImageNet. Due to the \"knee\"-like response curve, an artifact of the adversarial ﬁltering, eﬀective robustness is deﬁned piecewise around the ResNet50 model accuracy point. The plot demonstrates that robustness interventions have little impact on ImageNet-A accuracy. However, the eﬀect is small, and not all models trained on more data are more robust. Conﬁdence intervals, axis scaling, and the linear ﬁt are computed similarly to Figure 2. 30C Eﬀective robustness scatterplots In this section, we further explore to what extent robustness to synthetic distribution shifts predicts robustness on natural distribution shift. We extend the analysis in Figure 5 by computing eﬀective robustness on all natural distribution shifts and comparingn them against eﬀective robustness on synthetic distribution shifts. For natural dataset shifts, the scatter plots in Figure 12 are weakly correlated (the Pearson correlation coeﬃcients are r= 0.24,−0.05,−0.01,−0.26,0.61,0.30,0.52,0.36 in reading order), indicating that improved robustness to corruptions or adversarial attacks in general does not improve eﬀective robustness under natural dataset shifts. Of the group, the two strongest correlations are eﬀective robustness between ImageNet-Vid-Robust and image corruptions (r= 0.61) and between YTBB- Robust and image corruptions (r= 0.52). While not very strong, the correlations are signiﬁcant, and exploring this phenomenon between image corruptions and video anchor frames is an interesting direction for future work. For natural consistency shifts, the plots in Figure 13 are largely uncorrelated, with the exception that accuracy on adversarial attacks is correlated with eﬀective robustness on consistency shifts for lp adversarially models. However, as explored in Appendix B.2, eﬀective robustness on these shifts does not always imply relative robustness. For the adversarially ﬁltered shift, as seen in Figure 14, after computing eﬀective robustness piecewise around the ResNet50 accuracy, there is no observed correlation between the synthetic and natural robustness measures on ImageNet-A. 31-5 0 5 10 15 20 Corruptions Averaged Effective Robustness -1 0 1 2 ImageNetV2 Effective Robustness Effective Robustness Scatterplot -15 -10 -5 0 5 10 15 20 25 30 35 40 45 Lp Attacks Effective Robustness -1 0 1 2 ImageNetV2 Effective Robustness Effective Robustness Scatterplot -5 0 5 10 15 20 Corruptions Averaged Effective Robustness -11 -10 -9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 ObjectNet Effective Robustness Effective Robustness Scatterplot -15 -10 -5 0 5 10 15 20 25 30 35 40 45 Lp Attacks Effective Robustness -10 -9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 ObjectNet Effective Robustness Effective Robustness Scatterplot -5 0 5 10 15 20 Corruptions Averaged Effective Robustness -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 ImageNet-Vid-Robust (pm-0) Effective Robustness Effective Robustness Scatterplot -15 -10 -5 0 5 10 15 20 25 30 35 40 45 Lp Attacks Effective Robustness -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 ImageNet-Vid-Robust (pm-0) Effective Robustness Effective Robustness Scatterplot -5 0 5 10 15 20 Corruptions Averaged Effective Robustness -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 YTBB-Robust (pm-0) Effective Robustness Effective Robustness Scatterplot -15 -10 -5 0 5 10 15 20 25 30 35 40 45 Lp Attacks Effective Robustness -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 YTBB-Robust (pm-0) Effective Robustness Effective Robustness Scatterplot Robustness intervention Trained with more data Figure 12: We compare the eﬀective robustness of models with their accuracy drop due to corruptions (left column) and adversarial attacks (right column). The eﬀective robustness is computed with respect to linear ﬁts on the four natural dataset shifts: ImageNetV2 (ﬁrst row), ObjectNet (second row), ImageNet-Vid-Robust-anchor (third row), and YTBB-Robust-anchor (fourth row). The measures are largely uncorrelated, indicating that improved robustness to corruptions or adversarial attacks does not improve eﬀective robustness under natural dataset shifts. 32-5 0 5 10 15 20 Corruptions Averaged Effective Robustness -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 ImageNet-Vid-Robust (pm-10) Effective Robustness Effective Robustness Scatterplot -15 -10 -5 0 5 10 15 20 25 30 35 40 45 Lp Attacks Effective Robustness -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 ImageNet-Vid-Robust (pm-10) Effective Robustness Effective Robustness Scatterplot -5 0 5 10 15 20 Corruptions Averaged Effective Robustness -4 -3 -2 -1 0 1 2 3 4 5 6 7 YTBB-Robust (pm-10) Effective Robustness Effective Robustness Scatterplot -15 -10 -5 0 5 10 15 20 25 30 35 40 45 Lp Attacks Effective Robustness -4 -3 -2 -1 0 1 2 3 4 5 6 7 YTBB-Robust (pm-10) Effective Robustness Effective Robustness Scatterplot Lp adversarially robust Other robustness intervention Trained with more data Figure 13: We compare the eﬀective robustness of models with their accuracy drop due to corruptions (left column) and adversarial attacks (right column). The eﬀective robustness is computed with respect to linear ﬁts on the two consistency shifts: ImageNet-Vid-Robust (ﬁrst row), and YTBB- Robust (second row). The measures are largely uncorrelated, with the exception that accuracy on adversarial attacks is correlated with eﬀective robustness on consistency shifts for lp adversarially models. -5 0 5 10 15 20 Corruptions Averaged Effective Robustness -10 -9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 ImageNet-A Effective Robustness Effective Robustness Scatterplot -15 -10 -5 0 5 10 15 20 25 30 35 40 45 Lp Attacks Effective Robustness -11 -10 -9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 ImageNet-A Effective Robustness Effective Robustness Scatterplot Robustness intervention Trained with more data Figure 14: We compare the eﬀective robustness of models with their accuracy drop due to corruptions (left column) and adversarial attacks (right column). The eﬀective robustness is computed with respect to a linear ﬁt on ImageNet-A, the adversarially ﬁltered shift. After computing eﬀective robustness piecewise around the ResNet50 accuracy, there is no observed correlation between the synthetic and natural robustness measures. 33D Corruption robustness greyscale brightness_in-memory contrast_in-memory defocus_blur_in-memory fog_in-memory frost_in-memory gaussian_noise_in-memory jpeg_compression_in-memory motion_blur_in-memory pixelate_in-memory saturate_in-memory spatter_in-memory zoom_blur_in-memory brightness_on-disk contrast_on-disk defocus_blur_on-disk fog_on-disk frost_on-disk gaussian_noise_on-disk glass_blur_on-disk jpeg_compression_on-disk motion_blur_on-disk pixelate_on-disk saturate_on-disk spatter_on-disk zoom_blur_on-disk Evaluation resnet50_aws_baseline resnet50_with_greyscale_aws resnet50_with_brightness_aws resnet50_with_contrast_aws resnet50_with_defocus_blur_aws resnet50_with_fog_aws resnet50_with_frost_aws resnet50_with_gaussian_noise_aws resnet50_with_jpeg_compression_aws resnet50_with_motion_blur_aws resnet50_with_pixelate_aws resnet50_with_saturate_aws resnet50_with_spatter_aws resnet50_with_zoom_blur_aws resnet50_with_gaussian_noise_contrast_motion_blur_jpeg_compression_aws FixResNeXt101_32x48d_v2 efficientnet-b8-advprop-autoaug Model 65 69 45 39 53 39 36 58 40 46 64 49 43 64 35 36 41 35 31 26 54 37 48 59 47 36 67 51 30 18 35 27 31 46 23 33 54 35 23 43 20 15 23 21 21 11 41 18 30 49 32 15 63 75 50 39 53 40 39 58 41 48 66 51 42 69 38 36 40 37 36 27 55 36 49 59 48 35 60 65 73 37 52 40 31 55 37 50 58 45 38 61 57 33 42 36 28 26 50 34 50 53 43 33 13 25 10 42 13 10 8.9 24 23 35 21 15 25 27 7.6 35 11 8.8 5 23 24 21 36 21 17 26 58 63 59 36 74 40 24 47 35 37 53 44 36 58 44 30 63 37 22 23 44 31 39 48 42 30 59 68 38 34 53 72 31 53 37 45 61 51 40 61 27 32 37 50 33 34 50 34 46 54 48 35 59 66 33 42 38 41 69 62 37 57 60 52 41 63 28 38 32 39 29 38 57 35 55 56 49 38 62 65 35 39 41 39 32 71 36 55 60 50 39 64 30 36 36 37 26 35 63 35 53 58 48 36 48 58 37 49 42 25 21 46 72 46 52 40 53 60 31 37 37 30 21 29 47 63 47 52 44 46 50 58 38 45 41 32 23 53 38 72 53 41 40 62 34 41 38 34 24 32 50 35 68 55 46 38 67 69 44 36 53 38 38 58 37 49 74 49 38 65 33 33 40 34 31 25 55 33 49 69 46 32 63 68 43 40 50 39 32 56 40 37 63 75 42 63 34 37 38 36 32 31 51 36 46 57 55 37 41 49 34 50 42 24 17 31 58 32 43 30 69 52 26 42 35 23 13 28 30 52 33 43 35 63 61 66 73 49 53 43 68 70 72 50 62 49 56 65 62 41 47 40 36 32 60 66 51 59 47 51 83 84 82 70 83 66 69 77 71 77 83 75 59 79 61 52 68 56 57 35 67 55 68 77 69 51 83 84 72 80 80 71 79 84 82 84 84 81 61 81 59 57 68 63 67 45 77 63 74 80 76 59 ImageNet Accuracies (top-1, %) Figure 15: A detailed view of corruption robustness, with cells sampled from the main grid in Figure 7. Here we present ResNet50s trained on some of the corruptions from the ImageNet-C benchmark, as well as the best model trained on more data, FixResNeXt101_32x48d_v2, and the best model trained on just the standard training set, eﬃcientnet-b8-advprop-autoaug. We have already seen that corruption robustness does not promote eﬀective robustness, or robustness to real distribution shift. Here, we analyze whether robustness to some corruptions transfers to others, and what may contribute to corruption robustness. Figure 15 shows the result of training various ResNet50s3 on a few corruptions from ImageNet-C. In line with prior work, this plot here tells us that training against one type of synthetic corruption or one set of synthetic corruption does not transfer well to other corruptions. There are cases where transfer does happen, but overall the models are only robust to the corruption they are trained on. It is also interesting to note (from Figure 7) that PGD models actually see a drop in robustness to low frequency corruptions such as contrast, a phenomenon also observed in [107]. 3Each ResNet50 was trained with a batch size of 256 for 120 epochs, starting with a learning rate of 0.1 and decaying by a factor of 10 every 30 epochs. For the ResNet50s trained on corruptions, we randomly sample a corruption and severity for each image. Refer to E.2 for details on corruptions and severities. We use our custom fast gpu implementations of these corruptions for training. 34E Evaluation settings in the testbed E.1 Natural distribution shifts For ImageNetV2, we evaluate on the following datasets: imagenetv2-matched-frequency, imagenetv2- matched-frequency-format-val, imagenetv2-threshold-0.7, imagenetv2-threshold-0.7-format-val, imagenetv2- top-images, imagenetv2-top-images-format-val. The format-val versions are variants of the original dataset encoded with jpeg settings similar to the original one. Unless otherwise stated, results in our paper referring to imagenetv2 are for imagenetv2-matched-frequency-format-val. For ObjectNet, we obtained a beta version of the dataset through personal correspondance. Each image in the dataset was then cropped by 2px on each side following the authors’ instructions. Predictions were taken over only the classes that also appeared in the 1000 classes for the ImageNet validation set. For ImageNet-Vid-Robust and YTBB-Robust, we look at the anchor frames in the dataset and evaluate the benign accuracy for pm0. For pm10, we look at up to 20 nearest frames marked “similar” to the anchor frame in the dataset and count it as a misclassiﬁcation if any one of the predictions is wrong. For ImageNet-A, predictions were taken over only the classes that also appeared in the 1000 classes for the ImageNet validation set. E.2 Corruptions We include 38 diﬀerent corruption types: greyscale (in memory), gaussian noise (in memory and on disk), shot noise (in memory and on disk), impulse noise (in memory and on disk), speckle noise (in memory and on disk), gaussian blur (in memory and on disk), defocus blur (in memory and on disk), glass blur (on disk), motion blur (in memory and on disk), zoom blur (in memory and on disk), snow (in memory and on disk), frost (in memory and on disk), fog (in memory and on disk), spatter (in memory and on disk), brightness (in memory and on disk), contrast (in memory and on disk), saturate (in memory and on disk), pixelate (in memory and on disk), jpeg compression (in memory and on disk), elastic transform (in memory and on disk). For each corruption, we average over the ﬁve severities. We make sure to make the distinction between in memory corruptions, for which we provide custom fast gpu implementations, and on disk corruptions, for which we use the publicly available ImageNet- C dataset, since it was reported in [31] that jpeg compression can have a signiﬁcant impact on model accuracies (indeed, as evidenced by Figure 15). E.3 Adversarial attacks We run the following 4 pgd attacks one each model with these settings: pgd.linf.eps0.5 Norm: 0.5/255, Step size: 5.88e-5, Num steps: 100 35pgd.linf.eps2 Norm: 2/255, Step size: 2.35e-4, Num steps: 100 pgd.l2.eps0.1 Norm: 0.1, Step size: 0.01, Num steps: 100 pgd.l2.eps0.5 Norm: 0.5, Step size: 0.05, Num steps: 100 Most of the models were attacked with only 10% of the dataset (in a class-balanced manner) due to computational constraints. These models are displayed with larger error bars in the plots. E.4 Stylized Imagenet We use the stylized imagenet dataset used by [34] as another evaluation dataset. E.5 125 class evaluation For the 125 subsampled class evaluation, we evaluate on the following classes from ILSVRC: n01494475 n01630670 n01644373 n01644900 n01669191 n01677366 n01697457 n01742172 n01796340 n01829413 n01871265 n01924916 n01944390 n01978287 n01980166 n02007558 n02009229 n02017213 n02033041 n02037110 n02056570 n02071294 n02085936 n02086079 n02093428 n02093991 n02095314 n02095570 n02096294 n02096437 n02097474 n02100236 n02100583 n02102318 n02105056 n02107574 n02112706 n02113023 n02114855 n02128925 n02134418 n02138441 n02165105 n02219486 n02226429 n02264363 n02280649 n02441942 n02483708 n02486261 n02488291 n02492035 n02641379 n02730930 n02777292 n02790996 n02795169 n02808440 n02814533 n02814860 n02837789 n02859443 n02892201 n02895154 n02948072 n02951585 n02977058 n03000247 n03110669 n03201208 n03208938 n03216828 n03240683 n03250847 n03272562 n03297495 n03337140 n03376595 n03379051 n03447721 n03492542 n03527444 n03535780 n03642806 n03670208 n03673027 n03692522 n03710193 n03775071 n03832673 n03838899 n03840681 n03868242 n03873416 n03877845 n03884397 n03908714 n03920288 n03933933 n04004767 n04009552 n04037443 n04041544 n04067472 n04074963 n04099969 n04125021 n04141975 n04149813 n04204238 n04208210 n04229816 n04266014 n04310018 n04330267 n04335435 n04336792 n04355338 n04417672 n04479046 n04505470 n07715103 n07875152 n09256479 n12620546 36F Models in the testbed The following list contains all models we evaluated on ImageNet with references and links to the corresponding source code. Also noted is the model type used to color the plots in the paper. 1. BiT-M-R50x1-ILSVRC2012 [49]. Trained with more data model.https://github.com/google-research/big _transfer 2. BiT-M-R50x3-ILSVRC2012 [49]. Trained with more data model.https://github.com/google-research/big _transfer 3. BiT-M-R101x1-ILSVRC2012 [49]. Trained with more data model.https://github.com/google-research/b ig_transfer 4. BiT-M-R101x3-ILSVRC2012 [49]. Trained with more data model.https://github.com/google-research/b ig_transfer 5. BiT-M-R152x4-ILSVRC2012 [49]. Trained with more data model.https://github.com/google-research/b ig_transfer 6. FixPNASNet [92]. Standard training model.https://github.com/facebookresearch/FixRes 7. FixResNeXt101_32x48d[92]. Trainedwithmoredatamodel. https://github.com/facebookresearch/FixRes 8. FixResNeXt101_32x48d_v2 [92]. Trained with more data model.https://github.com/facebookresearch/ FixRes 9. FixResNet50 [92]. Standard training model.https://github.com/facebookresearch/FixRes 10. FixResNet50CutMix [92]. Robustness intervention model.https://github.com/facebookresearch/FixRes 11. FixResNet50CutMix_v2 [92]. Robustness intervention model.https://github.com/facebookresearch/FixR es 12. FixResNet50_no_adaptation [92]. Standard training model.https://github.com/facebookresearch/FixRes 13. FixResNet50_v2 [92]. Standard training model.https://github.com/facebookresearch/FixRes 14. alexnet [50]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 15. alexnet_lpf2 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 16. alexnet_lpf3 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 17. alexnet_lpf5 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 18. bninception [46]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 19. bninception-imagenet21k [46]. Trained with more data model.https://github.com/dmlc/mxnet-model-gall ery/blob/master/imagenet-21k-inception.md 20. caﬀeresnet101 [37]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 21. densenet121 [43]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 22. densenet121_lpf2 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 23. densenet121_lpf3 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 24. densenet121_lpf5 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 25. densenet161 [43]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 26. densenet169 [43]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 3727. densenet201 [43]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 28. dpn107 [11]. Trained with more data model.https://github.com/Cadene/pretrained-models.pytorch 29. dpn131 [11]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 30. dpn68 [11]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 31. dpn68b [11]. Trained with more data model.https://github.com/Cadene/pretrained-models.pytorch 32. dpn92 [11]. Trained with more data model.https://github.com/Cadene/pretrained-models.pytorch 33. dpn98 [11]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 34. eﬃcientnet-b0 [88]. Standard training model.https://github.com/tensorflow/tpu/tree/master/models/o fficial/efficientnet 35. eﬃcientnet-b0-advprop-autoaug [100]. Robustness intervention model.https://github.com/tensorflow/tpu/ tree/master/models/official/efficientnet 36. eﬃcientnet-b0-autoaug [15]. Standard training model.https://github.com/tensorflow/tpu/tree/master/ models/official/efficientnet 37. eﬃcientnet-b1 [88]. Standard training model.https://github.com/tensorflow/tpu/tree/master/models/o fficial/efficientnet 38. eﬃcientnet-b1-advprop-autoaug [100]. Robustness intervention model.https://github.com/tensorflow/tpu/ tree/master/models/official/efficientnet 39. eﬃcientnet-b1-autoaug [15]. Standard training model.https://github.com/tensorflow/tpu/tree/master/ models/official/efficientnet 40. eﬃcientnet-b2 [88]. Standard training model.https://github.com/tensorflow/tpu/tree/master/models/o fficial/efficientnet 41. eﬃcientnet-b2-advprop-autoaug [100]. Robustness intervention model.https://github.com/tensorflow/tpu/ tree/master/models/official/efficientnet 42. eﬃcientnet-b2-autoaug [15]. Standard training model.https://github.com/tensorflow/tpu/tree/master/ models/official/efficientnet 43. eﬃcientnet-b3 [88]. Standard training model.https://github.com/tensorflow/tpu/tree/master/models/o fficial/efficientnet 44. eﬃcientnet-b3-advprop-autoaug [100]. Robustness intervention model.https://github.com/tensorflow/tpu/ tree/master/models/official/efficientnet 45. eﬃcientnet-b3-autoaug [15]. Standard training model.https://github.com/tensorflow/tpu/tree/master/ models/official/efficientnet 46. eﬃcientnet-b4 [88]. Standard training model.https://github.com/tensorflow/tpu/tree/master/models/o fficial/efficientnet 47. eﬃcientnet-b4-advprop-autoaug [100]. Robustness intervention model.https://github.com/tensorflow/tpu/ tree/master/models/official/efficientnet 48. eﬃcientnet-b4-autoaug [15]. Standard training model.https://github.com/tensorflow/tpu/tree/master/ models/official/efficientnet 49. eﬃcientnet-b5 [88]. Standard training model.https://github.com/tensorflow/tpu/tree/master/models/o fficial/efficientnet 50. eﬃcientnet-b5-advprop-autoaug [100]. Robustness intervention model.https://github.com/tensorflow/tpu/ tree/master/models/official/efficientnet 3851. eﬃcientnet-b5-autoaug [15]. Standard training model.https://github.com/tensorflow/tpu/tree/master/ models/official/efficientnet 52. eﬃcientnet-b5-randaug [16]. Standard training model.https://github.com/tensorflow/tpu/tree/master/ models/official/efficientnet 53. eﬃcientnet-b6-advprop-autoaug [100]. Robustness intervention model.https://github.com/tensorflow/tpu/ tree/master/models/official/efficientnet 54. eﬃcientnet-b6-autoaug [15]. Standard training model.https://github.com/tensorflow/tpu/tree/master/ models/official/efficientnet 55. eﬃcientnet-b7-advprop-autoaug [100]. Robustness intervention model.https://github.com/tensorflow/tpu/ tree/master/models/official/efficientnet 56. eﬃcientnet-b7-autoaug [15]. Standard training model.https://github.com/tensorflow/tpu/tree/master/ models/official/efficientnet 57. eﬃcientnet-b7-randaug [16]. Standard training model.https://github.com/tensorflow/tpu/tree/master/ models/official/efficientnet 58. eﬃcientnet-b8-advprop-autoaug [100]. Robustness intervention model.https://github.com/tensorflow/tpu/ tree/master/models/official/efficientnet 59. eﬃcientnet-l2-noisystudent [102]. Trained with more data model.https://github.com/rwightman/pytorch-i mage-models 60. facebook_adv_trained_resnet152_baseline [101]. Robustness intervention model.https://github.com/fac ebookresearch/ImageNet-Adversarial-Training 61. facebook_adv_trained_resnet152_denoise [101]. Robustness intervention model.https://github.com/faceb ookresearch/ImageNet-Adversarial-Training 62. facebook_adv_trained_resnext101_denoiseAll [101]. Robustness intervention model.https://github.com/f acebookresearch/ImageNet-Adversarial-Training 63. fbresnet152 [37]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 64. google_resnet101_jft-300M [82]. Trained with more data model. 65. googlenet/inceptionv1 [85]. Standard training model.https://github.com/pytorch/vision/tree/master/to rchvision/models 66. inceptionresnetv2 [37]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 67. inceptionv3 [86]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 68. inceptionv4 [87]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 69. instagram-resnext101_32x16d [56]. Trained with more data model.https://github.com/facebookresearch/ WSL-Images 70. instagram-resnext101_32x32d [56]. Trained with more data model.https://github.com/facebookresearch/ WSL-Images 71. instagram-resnext101_32x48d [56]. Trained with more data model.https://github.com/facebookresearch/ WSL-Images 72. instagram-resnext101_32x8d [56]. Trained with more data model.https://github.com/facebookresearch/ WSL-Images 73. mnasnet0_5 [89]. Standard training model.https://github.com/pytorch/vision/tree/master/torchvisio n/models 3974. mnasnet1_0 [89]. Standard training model.https://github.com/pytorch/vision/tree/master/torchvisio n/models 75. mobilenet_v2 [73]. Standard training model.https://github.com/pytorch/vision/tree/master/torchvis ion/models 76. mobilenet_v2_lpf2 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 77. mobilenet_v2_lpf3 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 78. mobilenet_v2_lpf5 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 79. nasnetalarge [117]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 80. nasnetamobile [117]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 81. pnasnet5large [53]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 82. polynet [116]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 83. resnet101 [37]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 84. resnet101-tencent-ml-images [97]. Trained with more data model.https://github.com/Tencent/tencent-ml- images 85. resnet101_cutmix [108]. Robustness intervention model.https://github.com/clovaai/CutMix-PyTorch 86. resnet101_lpf2 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 87. resnet101_lpf3 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 88. resnet101_lpf5 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 89. resnet152 [37]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 90. resnet152-imagenet11k [99]. Trained with more data model.https://github.com/tornadomeet/ResNet 91. resnet18 [37]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 92. resnet18-rotation-nocrop_40 [28]. Robustness intervention model.https://github.com/MadryLab/spatial- pytorch 93. resnet18-rotation-random_30 [28]. Robustness intervention model.https://github.com/MadryLab/spatial- pytorch 94. resnet18-rotation-random_40 [28]. Robustness intervention model.https://github.com/MadryLab/spatial- pytorch 95. resnet18-rotation-standard_40 [28]. Robustness intervention model.https://github.com/MadryLab/spatial- pytorch 96. resnet18-rotation-worst10_30 [28]. Robustness intervention model.https://github.com/MadryLab/spatial- pytorch 97. resnet18-rotation-worst10_40 [28]. Robustness intervention model.https://github.com/MadryLab/spatial- pytorch 98. resnet18_lpf2 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 99. resnet18_lpf3 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 100. resnet18_lpf5 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 101. resnet18_ssl [104]. Trained with more data model.https://github.com/facebookresearch/semi-supervise d-ImageNet1K-models 40102. resnet18_swsl [104]. Trained with more data model.https://github.com/facebookresearch/semi-supervi sed-ImageNet1K-models 103. resnet34 [37]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 104. resnet34_lpf2 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 105. resnet34_lpf3 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 106. resnet34_lpf5 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 107. resnet50 [37]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 108. resnet50-randomized_smoothing_noise_0.00 [13]. Standard training model.https://github.com/locuslab/ smoothing 109. resnet50-randomized_smoothing_noise_0.25 [13]. Robustness intervention model.https://github.com/loc uslab/smoothing 110. resnet50-randomized_smoothing_noise_0.50 [13]. Robustness intervention model.https://github.com/loc uslab/smoothing 111. resnet50-randomized_smoothing_noise_1.00 [13]. Robustness intervention model.https://github.com/loc uslab/smoothing 112. resnet50-smoothing_adversarial_DNN_2steps_eps_512_noise_0.25 [72]. Robustness intervention model. https://github.com/Hadisalman/smoothing-adversarial 113. resnet50-smoothing_adversarial_DNN_2steps_eps_512_noise_0.50 [72]. Robustness intervention model. https://github.com/Hadisalman/smoothing-adversarial 114. resnet50-smoothing_adversarial_DNN_2steps_eps_512_noise_1.00 [72]. Robustness intervention model. https://github.com/Hadisalman/smoothing-adversarial 115. resnet50-smoothing_adversarial_PGD_1step_eps_512_noise_0.25 [72]. Robustness intervention model. https://github.com/Hadisalman/smoothing-adversarial 116. resnet50-smoothing_adversarial_PGD_1step_eps_512_noise_0.50 [72]. Robustness intervention model. https://github.com/Hadisalman/smoothing-adversarial 117. resnet50-smoothing_adversarial_PGD_1step_eps_512_noise_1.00 [72]. Robustness intervention model. https://github.com/Hadisalman/smoothing-adversarial 118. resnet50-vtab [112]. Standard training model.https://tfhub.dev/s?publisher=vtab 119. resnet50-vtab-exemplar [112]. Standard training model.https://tfhub.dev/s?publisher=vtab 120. resnet50-vtab-rotation [112]. Standard training model.https://tfhub.dev/s?publisher=vtab 121. resnet50-vtab-semi-exemplar [112]. Standard training model.https://tfhub.dev/s?publisher=vtab 122. resnet50-vtab-semi-rotation [112]. Standard training model.https://tfhub.dev/s?publisher=vtab 123. resnet50_adv-train-free [74]. Robustness intervention model.https://github.com/mahyarnajibi/FreeAdve rsarialTraining 124. resnet50_augmix [41]. Robustness intervention model.https://github.com/google-research/augmix 125. resnet50_aws_baseline. Standard training model. 126. resnet50_cutmix [108]. Robustness intervention model.https://github.com/clovaai/CutMix-PyTorch 127. resnet50_cutout [20]. Robustness intervention model.https://github.com/clovaai/CutMix-PyTorch 128. resnet50_deepaugment [40]. Robustness intervention model.https://github.com/hendrycks/imagenet-r 41129. resnet50_deepaugment_augmix [40]. Robustness intervention model.https://github.com/hendrycks/image net-r 130. resnet50_feature_cutmix [108]. Robustness intervention model.https://github.com/clovaai/CutMix-PyTo rch 131. resnet50_imagenet_100percent_batch64_original_images. Standard training model. 132. resnet50_imagenet_subsample_125_classes_batch64_original_images. Standard training model. 133. resnet50_imagenet_subsample_1_of_16_batch64_original_images. Standard training model. 134. resnet50_imagenet_subsample_1_of_2_batch64_original_images. Standard training model. 135. resnet50_imagenet_subsample_1_of_32_batch64_original_images. Standard training model. 136. resnet50_imagenet_subsample_1_of_4_batch64_original_images. Standard training model. 137. resnet50_imagenet_subsample_1_of_8_batch64_original_images. Standard training model. 138. resnet50_imagenet_subsample_250_classes_batch64_original_images. Standard training model. 139. resnet50_imagenet_subsample_500_classes_batch64_original_images. Standard training model. 140. resnet50_l2_eps3_robust [27]. Robustness intervention model.https://github.com/MadryLab/robustness 141. resnet50_linf_eps4_robust [27]. Robustness intervention model.https://github.com/MadryLab/robustness 142. resnet50_linf_eps8_robust [27]. Robustness intervention model.https://github.com/MadryLab/robustness 143. resnet50_lpf2 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 144. resnet50_lpf3 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 145. resnet50_lpf5 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 146. resnet50_mixup [113]. Robustness intervention model.https://github.com/clovaai/CutMix-PyTorch 147. resnet50_ssl [104]. Trained with more data model.https://github.com/facebookresearch/semi-supervise d-ImageNet1K-models 148. resnet50_swsl [104]. Trained with more data model.https://github.com/facebookresearch/semi-supervi sed-ImageNet1K-models 149. resnet50_trained_on_SIN [34]. Robustness intervention model.https://github.com/rgeirhos/texture-vs -shape 150. resnet50_trained_on_SIN_and_IN [34]. Robustness intervention model.https://github.com/rgeirhos/te xture-vs-shape 151. resnet50_trained_on_SIN_and_IN_then_ﬁnetuned_on_IN [34]. Robustness intervention model.https: //github.com/rgeirhos/texture-vs-shape 152. resnet50_with_brightness_aws. Robustness intervention model. 153. resnet50_with_contrast_aws. Robustness intervention model. 154. resnet50_with_defocus_blur_aws. Robustness intervention model. 155. resnet50_with_fog_aws. Robustness intervention model. 156. resnet50_with_frost_aws. Robustness intervention model. 157. resnet50_with_gaussian_noise_aws. Robustness intervention model. 158. resnet50_with_gaussian_noise_contrast_motion_blur_jpeg_compression_aws. Robustness intervention model. 42159. resnet50_with_greyscale_aws. Robustness intervention model. 160. resnet50_with_jpeg_compression_aws. Robustness intervention model. 161. resnet50_with_motion_blur_aws. Robustness intervention model. 162. resnet50_with_pixelate_aws. Robustness intervention model. 163. resnet50_with_saturate_aws. Robustness intervention model. 164. resnet50_with_spatter_aws. Robustness intervention model. 165. resnet50_with_zoom_blur_aws. Robustness intervention model. 166. resnext101_32x16d_ssl [104]. Trained with more data model.https://github.com/facebookresearch/semi -supervised-ImageNet1K-models 167. resnext101_32x4d [103]. Standard training model.https://github.com/Cadene/pretrained-models.pytorc h 168. resnext101_32x4d_ssl [104]. Trained with more data model.https://github.com/facebookresearch/semi -supervised-ImageNet1K-models 169. resnext101_32x4d_swsl [104]. Trained with more data model.https://github.com/facebookresearch/semi -supervised-ImageNet1K-models 170. resnext101_32x8d [103]. Standard training model.https://github.com/pytorch/vision/tree/master/torc hvision/models 171. resnext101_32x8d_deepaugment_augmix [40]. Robustness intervention model.https://github.com/hendr ycks/imagenet-r 172. resnext101_32x8d_ssl [104]. Trained with more data model.https://github.com/facebookresearch/semi -supervised-ImageNet1K-models 173. resnext101_32x8d_swsl [104]. Trained with more data model.https://github.com/facebookresearch/semi -supervised-ImageNet1K-models 174. resnext101_64x4d [103]. Standard training model.https://github.com/Cadene/pretrained-models.pytorc h 175. resnext50_32x4d [103]. Standard training model.https://github.com/pytorch/vision/tree/master/torc hvision/models 176. resnext50_32x4d_ssl [104]. Trained with more data model.https://github.com/facebookresearch/semi-s upervised-ImageNet1K-models 177. resnext50_32x4d_swsl [104]. Trained with more data model.https://github.com/facebookresearch/semi -supervised-ImageNet1K-models 178. se_resnet101 [42]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 179. se_resnet152 [42]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 180. se_resnet50 [42]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 181. se_resnext101_32x4d [42]. Standard training model.https://github.com/Cadene/pretrained-models.pyto rch 182. se_resnext50_32x4d [42]. Standard training model.https://github.com/Cadene/pretrained-models.pyto rch 183. senet154 [42]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 43184. shuﬄenet_v2_x0_5 [54]. Standard training model.https://github.com/pytorch/vision/tree/master/to rchvision/models 185. shuﬄenet_v2_x1_0 [54]. Standard training model.https://github.com/pytorch/vision/tree/master/to rchvision/models 186. squeezenet1_0 [45]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 187. squeezenet1_1 [45]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 188. vgg11 [78]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 189. vgg11_bn [78]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 190. vgg13 [78]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 191. vgg13_bn [78]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 192. vgg16 [78]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 193. vgg16_bn [78]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 194. vgg16_bn_lpf2 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 195. vgg16_bn_lpf3 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 196. vgg16_bn_lpf5 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 197. vgg16_lpf2 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 198. vgg16_lpf3 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 199. vgg16_lpf5 [115]. Robustness intervention model.https://github.com/adobe/antialiased-cnns 200. vgg19 [78]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 201. vgg19_bn [78]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 202. wide_resnet101_2 [109]. Standard training model.https://github.com/pytorch/vision/tree/master/to rchvision/models 203. wide_resnet50_2 [109]. Standard training model.https://github.com/pytorch/vision/tree/master/torc hvision/models 204. xception [12]. Standard training model.https://github.com/Cadene/pretrained-models.pytorch 44G Model accuracies Table 1: Top-1 model accuracies on ImageNet validation set, eﬀective robustness as calculated with respect to ImageNetV2, an average over all the corruptions, and an average over all the pgd attacks. Note that since we take an average of many attacks, the PGD column can no longer be considered a worst-case attacker for the model (look to E.3 for speciﬁc attacks). Model accuracies Model ImageNet accuracy ImageNetV2 eﬀ. robust. Avg. corr. accuracy Avg. PGD accuracy eﬃcientnet-l2-noisystudent 88.32 1.11 FixResNeXt101_32x48d_v2 86.36 0.97 65.65 FixResNeXt101_32x48d 86.26 0.95 65.56 instagram-resnext101_32x48d 85.44 1.26 65.53 24.1 eﬃcientnet-b8-advprop-autoaug 85.37 0.51 71.85 BiT-M-R152x4-ILSVRC2012 85.18 -0.31 67.26 eﬃcientnet-b7-advprop-autoaug 85.09 0.66 68.92 instagram-resnext101_32x32d 85.09 1.54 64.77 24.4 BiT-M-R101x3-ILSVRC2012 84.78 -1.35 63.44 eﬃcientnet-b6-advprop-autoaug 84.76 0.75 68.65 50.67 eﬃcientnet-b7-randaug 84.73 0.11 69.12 eﬃcientnet-b7-autoaug 84.33 0.32 62.77 eﬃcientnet-b5-advprop-autoaug 84.3 0.51 67.76 50.17 resnext101_32x8d_swsl 84.29 1.19 63.17 23.22 instagram-resnext101_32x16d 84.18 1.51 63.22 29.19 BiT-M-R50x3-ILSVRC2012 84.15 -0.76 60.23 eﬃcientnet-b6-autoaug 84.13 0.14 63.42 34.29 FixPNASNet 83.7 -0.0 61.35 22.8 eﬃcientnet-b5-autoaug 83.63 0.25 62.3 32.43 eﬃcientnet-b5-randaug 83.53 0.08 63.35 34.41 resnext101_32x4d_swsl 83.23 1.41 60.09 21.73 eﬃcientnet-b5 83.11 0.17 60.28 35.18 pnasnet5large 82.74 0.21 61.76 29.46 instagram-resnext101_32x8d 82.69 1.59 60.81 30.13 eﬃcientnet-b4-advprop-autoaug 82.69 0.42 64.88 50.72 eﬃcientnet-b4-autoaug 82.55 0.17 59.59 34.24 BiT-M-R101x1-ILSVRC2012 82.52 -0.42 58.28 nasnetalarge 82.51 0.48 61.74 36.99 eﬃcientnet-b4 82.23 -0.64 57.2 37.06 resnext50_32x4d_swsl 82.18 1.26 56.38 21.09 resnext101_32x16d_ssl 81.84 0.3 58.63 22.34 resnext101_32x8d_ssl 81.63 0.73 57.96 20.82 senet154 81.3 -0.07 54.11 30.65 resnet50_swsl 81.18 1.35 53.95 21.39 eﬃcientnet-b3-advprop-autoaug 81.09 0.29 60.6 51.09 eﬃcientnet-b3-autoaug 81.05 0.17 55.5 31.76 resnext101_32x4d_ssl 80.93 0.48 55.65 20.54 polynet 80.86 0.36 54.02 23.05 BiT-M-R50x1-ILSVRC2012 80.4 -0.63 52.21 12.5 resnext50_32x4d_ssl 80.33 0.44 52.57 19.75 inceptionresnetv2 80.27 0.32 56.85 34.85 se_resnext101_32x4d 80.24 0.47 52.26 28.77 eﬃcientnet-b3 80.21 -0.48 53.31 34.22 inceptionv4 80.08 0.5 55.52 28.02 Table continues onto next page 45Model accuracies(continued from previous page) Model ImageNet accuracy ImageNetV2 eﬀ. robust. Avg. corr. accuracy Avg. PGD accuracy resnext101_32x8d_deepaugment _augmix 79.9 0.25 65.56 resnet101_cutmix 79.83 -0.39 50.15 25.6 eﬃcientnet-b2-autoaug 79.78 0.17 53.5 30.93 FixResNet50CutMix_v2 79.76 -1.21 43.44 18.19 dpn107 79.75 -0.47 52.37 30.64 FixResNet50CutMix 79.74 -1.22 43.39 18.14 eﬃcientnet-b2-advprop-autoaug 79.6 -0.25 55.17 46.33 dpn131 79.43 -0.2 52.06 30.38 dpn92 79.4 -0.65 49.29 25.69 resnext101_32x8d 79.31 -0.34 49.68 25.38 resnet50_ssl 79.23 0.52 50.15 20.57 dpn98 79.22 0.08 51.82 30.14 google_resnet101_jft-300M 79.2 -0.23 53.49 26.84 FixResNet50_v2 79.1 -0.62 43.31 15.38 se_resnext50_32x4d 79.08 0.27 50.65 24.74 FixResNet50 79.0 -0.67 43.25 15.3 resnext101_64x4d 78.96 -0.2 52.06 23.57 eﬃcientnet-b2 78.89 -0.39 50.05 33.88 wide_resnet101_2 78.85 -0.87 48.2 25.24 xception 78.82 0.06 51.7 26.32 eﬃcientnet-b1-autoaug 78.72 -0.07 51.19 30.69 se_resnet152 78.66 0.45 50.94 28.42 resnet50_cutmix 78.6 -1.1 44.7 26.46 eﬃcientnet-b1-advprop-autoaug 78.54 -0.23 53.7 46.54 wide_resnet50_2 78.47 -0.61 46.23 26.13 se_resnet101 78.4 0.43 50.12 28.2 resnet152 78.31 0.27 47.81 22.48 resnet101-tencent-ml-images 78.25 0.04 47.77 resnet50_feature_cutmix 78.21 -0.42 44.33 25.36 resnext101_32x4d 78.19 -0.13 50.96 22.38 resnet101_lpf3 78.12 -0.27 46.52 22.48 eﬃcientnet-b1 77.91 -0.24 47.07 31.33 resnet101_lpf5 77.91 0.1 46.54 23.13 resnet101_lpf2 77.8 0.3 46.06 22.01 se_resnet50 77.64 0.08 48.11 27.55 resnext50_32x4d 77.62 0.1 45.56 22.52 resnet50_augmix 77.54 -0.53 50.78 26.01 resnet50_mixup 77.47 -0.54 48.2 21.95 fbresnet152 77.39 0.02 49.98 23.4 resnet101 77.37 0.01 46.06 21.85 inceptionv3 77.32 0.29 49.83 25.72 densenet161 77.14 0.13 49.36 22.22 eﬃcientnet-b0-advprop-autoaug 77.08 0.21 49.9 44.31 resnet50_cutout 77.07 -0.65 43.81 19.8 FixResNet50_no_adaptation 77.04 -0.02 44.68 20.61 dpn68b 77.03 -0.28 45.67 18.7 resnet50_lpf5 77.03 -0.53 43.54 22.03 densenet201 76.9 -0.12 47.63 23.95 eﬃcientnet-b0-autoaug 76.84 -0.39 45.27 30.66 resnet50_lpf3 76.82 -0.12 43.3 21.83 resnet50_lpf2 76.79 -0.25 42.22 20.91 Table continues onto next page 46Model accuracies(continued from previous page) Model ImageNet accuracy ImageNetV2 eﬀ. robust. Avg. corr. accuracy Avg. PGD accuracy resnet50_trained_on_SIN_and_I N_then_finetuned_on_IN 76.72 -0.04 43.96 22.78 resnet50_deepaugment 76.66 0.73 53.91 29.65 eﬃcientnet-b0 76.53 -0.79 43.84 31.05 resnet50-vtab-rotation 76.5 -0.49 41.93 caﬀeresnet101 76.2 0.08 44.83 25.54 resnet152-imagenet11k 76.18 2.09 47.33 30.64 resnet50_aws_baseline 76.14 -0.36 42.13 21.46 resnet50 76.13 -0.77 41.59 21.24 resnet50_imagenet_100percent_b atch64_original_images 75.98 -0.56 41.61 21.89 dpn68 75.87 -0.56 45.46 17.71 resnet50_deepaugment_augmix 75.82 -0.08 58.29 33.73 resnet50- randomized_smoothing_noise_0.00 75.69 0.31 41.75 21.32 densenet169 75.6 0.19 46.67 21.79 resnet50-vtab 75.54 0.22 43.61 resnet50_with_brightness_aws 75.28 -0.28 43.9 22.78 resnet50_with_spatter_aws 75.21 -0.29 42.81 22.45 densenet121_lpf3 75.14 -0.35 40.48 20.01 densenet121_lpf5 75.03 0.13 41.84 21.13 densenet121_lpf2 75.03 0.41 41.24 20.82 resnet50_with_saturate_aws 74.89 -0.27 42.4 20.46 resnet50_trained_on_SIN_and_IN 74.59 0.55 47.91 22.96 resnet34_lpf2 74.48 0.15 41.54 20.96 densenet121 74.43 0.13 43.54 20.01 resnet34_lpf3 74.34 0.25 42.22 20.97 vgg19_bn 74.22 0.18 37.94 16.51 resnet34_lpf5 74.19 0.46 41.22 21.09 resnet50-vtab-exemplar 74.1 0.3 44.73 nasnetamobile 74.08 -0.29 44.78 22.89 vgg16_bn_lpf5 74.04 -0.4 36.19 18.91 vgg16_bn_lpf2 74.01 0.13 36.06 17.81 vgg16_bn_lpf3 73.92 0.5 36.33 18.33 resnet50_with_frost_aws 73.78 0.29 42.39 20.96 resnet50_with_jpeg_compression _aws 73.63 -0.21 41.76 38.34 bninception 73.52 1.0 40.59 21.27 mnasnet1_0 73.46 -0.47 36.42 18.78 vgg16_bn 73.36 -0.09 35.69 16.19 resnet34 73.31 0.12 40.48 21.23 resnet18_swsl 73.29 1.74 39.95 18.79 resnet50_with_gaussian_noise_aws 72.97 0.21 45.56 43.88 resnet50_with_gaussian_noise_c ontrast_motion_blur_jpeg_comp ression_aws 72.72 0.05 51.8 22.91 mobilenet_v2_lpf2 72.62 -0.56 34.46 17.46 resnet18_ssl 72.6 1.24 39.51 19.19 mobilenet_v2_lpf3 72.57 -0.23 34.78 17.6 mobilenet_v2_lpf5 72.51 -0.1 34.9 17.73 vgg19 72.38 -0.01 32.43 20.65 vgg16_lpf5 72.33 0.15 31.89 19.86 Table continues onto next page 47Model accuracies(continued from previous page) Model ImageNet accuracy ImageNetV2 eﬀ. robust. Avg. corr. accuracy Avg. PGD accuracy vgg16_lpf3 72.19 -0.19 32.18 19.37 vgg16_lpf2 72.16 -0.2 31.98 19.13 resnet50_with_contrast_aws 72.0 -0.42 40.85 17.29 mobilenet_v2 71.88 -0.13 33.96 17.49 resnet50_with_fog_aws 71.76 -0.83 37.9 17.19 resnet18_lpf3 71.68 -0.43 36.84 20.17 vgg16 71.59 -0.33 31.3 20.14 vgg13_bn 71.59 0.01 31.76 15.16 resnet18_lpf2 71.39 -0.09 36.88 19.8 resnet18_lpf5 71.39 -0.51 36.86 20.22 resnet18-rotation-standard_40 71.28 -0.05 36.46 20.26 vgg11_bn 70.37 -0.1 31.7 18.05 resnet50- randomized_smoothing_noise_0.25 70.29 0.28 40.66 63.94 vgg13 69.93 -0.27 28.53 19.32 googlenet/inceptionv1 69.78 1.01 38.84 21.85 resnet18 69.76 0.46 35.01 19.51 shuﬄenet_v2_x1_0 69.36 -0.48 30.87 16.66 resnet18-rotation-worst10_30 69.13 0.72 34.06 22.51 vgg11 69.02 -0.33 28.61 22.38 resnet18-rotation-random_30 68.88 0.19 32.88 18.63 resnet18-rotation-worst10_40 68.6 -0.05 32.24 22.65 resnet50_with_pixelate_aws 68.5 1.17 39.58 18.85 resnet18-rotation-random_40 68.35 0.73 31.87 17.89 facebook_adv_trained_resnext101 _denoiseAll 68.33 -0.11 40.86 41.42 resnet50-smoothing_adversarial _DNN_2steps_eps_512_noise_0. 25 67.87 -0.31 40.57 62.89 mnasnet0_5 67.6 -0.37 27.9 17.39 resnet50_with_motion_blur_aws 67.46 1.49 38.71 15.34 resnet18-rotation-nocrop_40 65.37 1.23 30.1 20.5 facebook_adv_trained_resnet152 _denoise 65.32 0.38 37.97 39.48 bninception-imagenet21k 65.24 1.78 32.8 30.3 resnet50- randomized_smoothing_noise_0.50 64.24 0.04 39.8 61.41 resnet50_with_greyscale_aws 63.33 0.49 28.33 18.16 resnet50_linf_eps4_robust 62.42 0.53 32.37 60.3 facebook_adv_trained_resnet152 _baseline 62.34 0.58 35.77 37.63 resnet50-smoothing_adversarial _DNN_2steps_eps_512_noise_0. 50 62.19 -0.04 39.14 59.26 resnet50-vtab-semi-exemplar 61.62 0.98 33.85 resnet50_with_zoom_blur_aws 61.25 1.22 33.27 13.01 resnet50-vtab-semi-rotation 60.92 0.94 26.38 shuﬄenet_v2_x0_5 60.55 -0.27 23.58 16.08 resnet50_adv-train-free 60.49 -0.03 29.41 57.42 resnet50-smoothing_adversarial _PGD_1step_eps_512_noise_0.2 5 60.47 -0.45 37.21 58.49 Table continues onto next page 48Model accuracies(continued from previous page) Model ImageNet accuracy ImageNetV2 eﬀ. robust. Avg. corr. accuracy Avg. PGD accuracy resnet50_trained_on_SIN 60.18 1.4 39.42 19.25 squeezenet1_1 58.18 0.12 20.18 16.08 squeezenet1_0 58.09 -0.26 20.17 18.06 resnet50_l2_eps3_robust 57.9 0.33 31.83 56.25 alexnet_lpf2 57.23 -0.38 22.54 29.09 alexnet_lpf3 56.89 -0.41 22.77 30.67 alexnet_lpf5 56.58 -0.41 22.77 31.71 alexnet 56.52 -0.28 21.55 24.08 resnet50-smoothing_adversarial _PGD_1step_eps_512_noise_0.5 0 54.66 -0.31 35.7 53.09 resnet50- randomized_smoothing_noise_1.00 53.12 0.12 34.93 52.11 resnet50-smoothing_adversarial _DNN_2steps_eps_512_noise_1. 00 51.87 0.23 34.43 50.95 resnet50_linf_eps8_robust 47.91 1.35 23.93 46.97 resnet50-smoothing_adversarial _PGD_1step_eps_512_noise_1.0 0 44.28 0.2 29.84 43.57 resnet50_with_defocus_blur_aws 31.9 1.3 18.18 9.29 End of table 49H Synthetic robustness correlation with natural robustness In this section, we investigate which individual synthetic robustness measures are most predictive of natural distribution shift. For each of the synthetic shifts in our testbed, we compute the eﬀective robustness for each model and measure the Pearson correlation coeﬃcients against the eﬀective robustness under each of the natural distribution shifts in our testbed. Table 2 provides a full list of the correlation numbers, and Figures 16 to 22 show scatter plots of the two highest correlated synthetic shifts for each natural distribution shift. We ﬁnd that some of the synthetic shifts are more predictive than others, but none have high correlation with all of the natural shifts. For instance,ℓp-robustness has the highest correlation with consistency shifts, but only low correlation with dataset shifts. On the other hand, some image corruptions such as brightness, gaussian blur, defocus blur, and saturate have higher correlation with the dataset shifts. It is worth nothing our testbed indicates that these synthetic measures are not causal, i.e., models trained on brightness, gaussian blur, defocus blur, or saturate do not have signiﬁcant positive eﬀective robustness on dataset shifts. Further analyzing these ﬁne-grained connections between synthetic and natural forms of distribution shift is an important direction for future work. Table 2: Pearson correlation coeﬃcients between all synthetic and natural distribution shifts in our testbed. For each distribution shift, eﬀective robustness was calculated using a linear ﬁt on the standard models. The correlation between synthetic and natural eﬀective robustness was then only computed after ﬁltering out the standard models. Pearson correlation coeﬃcients Synthetic shift ImageNetV2 ObjectNet ImageNetVid (pm-0) YTBB (pm-0) ImageNetVid (pm-10) YTBB (pm-10) ImageNet- A avg_corruptions 0.25 0.06 0.6 0.5 0.65 0.52 0.02 avg_pgd -0.04 -0.19 0.3 0.35 0.84 0.7 -0.12 brightness_in- memory 0.34 0.11 0.32 0.3 0.29 0.23 0.13 brightness_on-disk 0.56 0.48 0.56 0.39 0.22 0.15 0.16 contrast_in- memory 0.15 0.07 0.14 0.04 -0.61 -0.5 0.14 contrast_on-disk 0.26 0.28 0.17 0.05 -0.61 -0.54 0.15 defocus_blur_in- memory 0.27 -0.04 0.66 0.56 0.43 0.27 -0.05 defocus_blur_on- disk 0.39 0.39 0.65 0.49 0.28 0.17 0.12 elastic_transform_in- memory 0.14 -0.12 0.49 0.42 0.75 0.63 -0.15 elastic_transform_on- disk 0.3 0.21 0.57 0.41 0.65 0.58 0.01 fog_in-memory 0.14 0.07 -0.04 -0.07 -0.59 -0.56 0.02 fog_on-disk 0.28 0.31 0.04 -0.03 -0.64 -0.6 0.04 frost_in-memory 0.15 -0.12 0.42 0.44 0.54 0.42 -0.02 frost_on-disk 0.32 0.15 0.53 0.45 0.44 0.36 0.08 gaussian_blur_in- memory 0.27 -0.07 0.67 0.57 0.47 0.33 -0.05 gaussian_blur_on- disk 0.41 0.4 0.65 0.48 0.26 0.16 0.13 Table continues onto next page 50Pearson correlation coeﬃcients(continued from previous page) Synthetic shift ImageNetV2 ObjectNet ImageNetVid (pm-0) YTBB (pm-0) ImageNetVid (pm-10) YTBB (pm-10) ImageNet- A gaussian_noise_in- memory -0.01 -0.13 0.41 0.38 0.68 0.51 -0.04 gaussian_noise_on- disk 0.08 0.0 0.4 0.34 0.71 0.62 0.07 glass_blur_on-disk 0.24 0.17 0.56 0.45 0.61 0.53 -0.0 greyscale 0.3 0.17 0.11 0.29 0.09 -0.06 0.04 impulse_noise_in- memory -0.06 -0.1 0.35 0.34 0.65 0.45 -0.05 impulse_noise_on- disk 0.04 0.0 0.34 0.31 0.72 0.6 0.03 jpeg_compression_in- memory 0.04 -0.11 0.43 0.41 0.8 0.62 -0.01 jpeg_compression_on- disk 0.09 0.01 0.44 0.4 0.8 0.65 0.03 motion_blur_in- memory 0.2 -0.02 0.51 0.43 0.56 0.41 -0.08 motion_blur_on- disk 0.32 0.25 0.58 0.43 0.39 0.31 0.07 pgd.l2.eps0.1 -0.03 -0.01 0.18 0.25 0.64 0.44 -0.33 pgd.l2.eps0.5 -0.05 -0.22 0.31 0.34 0.71 0.63 -0.11 pgd.linf.eps0.5 -0.05 -0.23 0.28 0.33 0.84 0.7 -0.13 pgd.linf.eps2 0.01 -0.18 0.3 0.31 0.76 0.69 0.05 pixelate_in- memory 0.27 0.03 0.61 0.48 0.66 0.53 0.05 pixelate_on-disk 0.31 0.16 0.62 0.46 0.63 0.54 0.12 saturate_in- memory 0.35 0.08 0.4 0.43 0.38 0.27 0.12 saturate_on-disk 0.55 0.43 0.46 0.41 0.26 0.16 0.13 shot_noise_in- memory -0.01 -0.14 0.41 0.39 0.69 0.51 -0.05 shot_noise_on- disk 0.07 -0.01 0.4 0.35 0.71 0.62 0.06 snow_in-memory 0.26 0.02 0.39 0.35 0.61 0.55 0.04 snow_on-disk 0.33 0.14 0.5 0.43 0.6 0.51 0.04 spatter_in-memory 0.09 -0.06 0.36 0.36 0.8 0.66 -0.08 spatter_on-disk 0.26 0.08 0.5 0.43 0.75 0.63 -0.04 speckle_noise_in- memory 0.0 -0.13 0.43 0.39 0.71 0.55 -0.04 speckle_noise_on- disk 0.08 -0.02 0.42 0.36 0.74 0.66 0.02 stylized_imagenet 0.32 0.24 0.31 0.3 0.44 0.31 -0.02 zoom_blur_in- memory 0.21 0.23 0.45 0.35 0.45 0.36 -0.01 zoom_blur_on- disk 0.26 0.21 0.55 0.41 0.49 0.39 0.0 End of table 5160 65 70 75 80 85 ImageNet (top-1, %) 40 45 50 55 60 65 70 75 80Brightness (on-disk) (top-1, %) Distribution Shift to Brightness (on-disk) -5 0 5 Brightness (on-disk) Effective Robustness -1 0 1 2 ImagetNetV2 Effective Robustness Effective Robustness Scatterplot 60 65 70 75 80 85 ImageNet (top-1, %) 35 40 45 50 55 60 65 70 75 80Saturate (on-disk) (top-1, %) Distribution Shift to Saturate (on-disk) -5 0 5 10 Saturate (on-disk) Effective Robustness -1 0 1 2 ImagetNetV2 Effective Robustness Effective Robustness Scatterplot y = x Standard training Lp adversarially robust Other robustness intervention Trained with more data Linear fit Figure 16: Plots of the two synthetic distribution shifts with the highest correlation with ImageNetV2, compared similarly to Figure 5. 5260 65 70 75 80 85 ImageNet (top-1, %) 5 10 15 20 25 30 35 40 45 50 55 60 65Contrast (on-disk) (top-1, %) Distribution Shift to Contrast (on-disk) -15 -10 -5 0 5 10 15 20 25 Contrast (on-disk) Effective Robustness -11 -10 -9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 ObjectNet Effective Robustness Effective Robustness Scatterplot 60 65 70 75 80 85 ImageNet (top-1, %) 5 10 15 20 25 30 35 40 45 50 55 60 65Fog (on-disk) (top-1, %) Distribution Shift to Fog (on-disk) -25 -20 -15 -10 -5 0 5 10 15 20 25 Fog (on-disk) Effective Robustness -11 -10 -9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 ObjectNet Effective Robustness Effective Robustness Scatterplot y = x Standard training Lp adversarially robust Other robustness intervention Trained with more data Linear fit Figure 17: Plots of the two synthetic distribution shifts with the highest correlation with ObjectNet, compared similarly to Figure 5. 5360 65 70 75 80 85 ImageNet (top-1, %) 20 25 30 35 40 45 50 55 60Gaussian Blur (on-disk) (top-1, %) Distribution Shift to Gaussian Blur (on-disk) -10 -5 0 5 10 15 20 Gaussian Blur (on-disk) Effective Robustness -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 ImageNet-Vid-Robust (pm-0) Effective Robustness Effective Robustness Scatterplot 60 65 70 75 80 85 ImageNet (top-1, %) 15 20 25 30 35 40 45 50 55 60Defocus Blur (on-disk) (top-1, %) Distribution Shift to Defocus Blur (on-disk) -10 -5 0 5 10 15 20 25 30 Defocus Blur (on-disk) Effective Robustness -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 ImageNet-Vid-Robust (pm-0) Effective Robustness Effective Robustness Scatterplot y = x Standard training Lp adversarially robust Other robustness intervention Trained with more data Linear fit Figure 18: Plots of the two synthetic distribution shifts with the highest correlation with ImageNet- Vid-Robust pm-0, compared similarly to Figure 5. 5460 65 70 75 80 85 ImageNet (top-1, %) 15 20 25 30 35 40 45 50 55 60Defocus Blur (on-disk) (top-1, %) Distribution Shift to Defocus Blur (on-disk) -10 -5 0 5 10 15 20 25 30 Defocus Blur (on-disk) Effective Robustness -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 YTBB-Robust (pm-0) Effective Robustness Effective Robustness Scatterplot 60 65 70 75 80 85 ImageNet (top-1, %) 20 25 30 35 40 45 50 55 60 65 70 75 80Defocus Blur (in-memory) (top-1, %) Distribution Shift to Defocus Blur (in-memory) -10 -5 0 5 10 15 20 25 30 35 40 Defocus Blur (in-memory) Effective Robustness -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 YTBB-Robust (pm-0) Effective Robustness Effective Robustness Scatterplot y = x Standard training Lp adversarially robust Other robustness intervention Trained with more data Linear fit Figure 19: Plots of the two synthetic distribution shifts with the highest correlation with YTBB- Robust pm-0, compared similarly to Figure 5. 5560 65 70 75 80 85 ImageNet (top-1, %) 10 15 20 25 30 35 40 45 50 55 60 65 70PGD (Linf Eps0.5) (top-1, %) Distribution Shift to PGD (Linf Eps0.5) -15 -10 -5 0 5 10 15 20 25 30 35 40 45 50 55 PGD (Linf Eps0.5) Effective Robustness -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 ImageNet-Vid-Robust (pm-10) Effective Robustness Effective Robustness Scatterplot 60 65 70 75 80 85 ImageNet (top-1, %) 30 35 40 45 50 55 60 65 70 75 80Spatter (in-memory) (top-1, %) Distribution Shift to Spatter (in-memory) -10 -5 0 5 10 15 20 25 Spatter (in-memory) Effective Robustness -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 ImageNet-Vid-Robust (pm-10) Effective Robustness Effective Robustness Scatterplot y = x Standard training Lp adversarially robust Other robustness intervention Trained with more data Linear fit Figure 20: Plots of the two synthetic distribution shifts with the highest correlation with ImageNet- Vid-Robust pm-10, compared similarly to Figure 5. 5660 65 70 75 80 85 ImageNet (top-1, %) 5 10 15 20 25 30 35 40 45 50 55 60 65 70PGD (L2 Eps0.5) (top-1, %) Distribution Shift to PGD (L2 Eps0.5) -5 0 5 10 15 20 25 30 35 40 45 50 55 60 PGD (L2 Eps0.5) Effective Robustness -4 -3 -2 -1 0 1 2 3 4 5 6 7 YTBB-Robust (pm-10) Effective Robustness Effective Robustness Scatterplot 60 65 70 75 80 85 ImageNet (top-1, %) 15 20 25 30 35 40 45 50 55 60 65 70Speckle Noise (on-disk)) (top-1, %) Distribution Shift to Speckle Noise (on-disk)) -10 -5 0 5 10 15 20 25 30 35 Speckle Noise (on-disk)) Effective Robustness -4 -3 -2 -1 0 1 2 3 4 5 6 7 YTBB-Robust (pm-10) Effective Robustness Effective Robustness Scatterplot y = x Standard training Lp adversarially robust Other robustness intervention Trained with more data Linear fit Figure 21: Plots of the two synthetic distribution shifts with the highest correlation with YTBB- Robust pm-10, compared similarly to Figure 5. 5760 65 70 75 80 85 ImageNet (top-1, %) 5 10 15 20 25 30 35 40 45 50 55 60 65Contrast (on-disk) (top-1, %) Distribution Shift to Contrast (on-disk) -15 -10 -5 0 5 10 15 20 25 Contrast (on-disk) Effective Robustness -10 -9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 ImageNet-A Effective Robustness Effective Robustness Scatterplot 60 65 70 75 80 85 ImageNet (top-1, %) 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80Contrast (in-memory) (top-1, %) Distribution Shift to Contrast (in-memory) -15 -10 -5 0 5 10 15 20 25 30 Contrast (in-memory) Effective Robustness -10 -9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 ImageNet-A Effective Robustness Effective Robustness Scatterplot y = x Standard training Lp adversarially robust Other robustness intervention Trained with more data Linear fit Figure 22: Plots of the two synthetic distribution shifts with the highest correlation with ImageNet-A, compared similarly to Figure 5. 58I Information on our main ﬁgures I.1 Constructing beta β For each distribution shift, we construct the baseline accuracy functionβ by analyzing the linear relationship between model performance on the original and shifted distributions. In particular, when constructingβ we only include \"standard models,\" models that had not been designed with any robustness properties in mind or have not been trained on any data other than the standard 1,000-class ImageNet training set. Before constructing the predictor, model accuracies are then transformed according to the logit distribution; this transform assigns greater mass at the tails and experimentally provided the best linear ﬁts.β is then simply the linear predictor of the shifted distribution based on the independent variable (the original distribution), computed in this scaled space. I.2 Ablations on our main ﬁgures Here we provide various versions of the main ﬁgures in the main text. In each plot, we use logit scaling to demonstrate that gains in performance at higher accuracies represent greater progress. The 95% conﬁdence intervals were empirically computed from the bootstrapped samples. The bootstrapping was performed by computing 1,000 linear ﬁts by sampling the models with replacement. 5960 65 70 75 80 85 ImageNet (top-1, %) 45 50 55 60 65 70 75ImageNetV2 (top-1, %) Distribution Shift to ImageNetV2 55 60 65 70 75 80 85 ImageNet (class-subsampled) (top-1, %) 15 20 25 30 35 40 45 50ObjectNet (top-1, %) Distribution Shift to ObjectNet 93 94 95 96 97 98 99 ImageNet (class-subsampled) (top-1, %) 50 55 60 65 70 75 80ImageNet-Vid-Robust (pm-0, %) Distribution Shift to ImageNet-Vid-Anchors 95 96 97 98 99 ImageNet (class-subsampled) (top-1, %) 45 50 55 60 65YTBB-Robust (pm-0, %) Distribution Shift to YTBB-Anchors 50 55 60 65 70 75 80 ImageNet-Vid-Robust (pm-0, %) 30 35 40 45 50 55 60 65 70ImageNet-Vid-Robust (pm-10, %) Distribution Shift to ImageNet-Vid-Robust 45 50 55 60 65 YTBB-Robust (pm-0, %) 30 35 40 45 50 55YTBB-Robust (pm-10, %) Distribution Shift to YTBB-Robust 80 90 95 96 97 ImageNet (class-subsampled) (top-1, %) 5 10 20 30 40ImageNet-A (top-1, %) Distribution Shift to Imagenet-A y = x Standard training Linear fit Figure 23: Only standard models are shown in these plots. Otherwise, they are identical to the main plots in the main text. This is done to better illustrate the quality of the linear ﬁt. 6060 65 70 75 80 85 ImageNet (top-1, %) 45 50 55 60 65 70 75 80ImageNetV2 (top-1, %) Distribution Shift to ImageNetV2 60 65 70 75 80 85 ImageNet (top-1, %) 15 20 25 30 35 40 45 50 55 60 65 70ObjectNet (top-1, %) Distribution Shift to ObjectNet 60 65 70 75 80 85 ImageNet (top-1, %) 50 55 60 65 70 75 80 85 90ImageNet-Vid-Robust (pm-0, %) Distribution Shift to ImageNet-Vid-Anchors 60 65 70 75 80 85 ImageNet (top-1, %) 45 50 55 60 65 70YTBB-Robust (pm-0, %) Distribution Shift to YTBB-Anchors 50 55 60 65 70 75 80 85 90 ImageNet-Vid-Robust (pm-0, %) 30 35 40 45 50 55 60 65 70 75 80ImageNet-Vid-Robust (pm-10, %) Distribution Shift to ImageNet-Vid-Robust 45 50 55 60 65 70 YTBB-Robust (pm-0, %) 30 35 40 45 50 55 60 65YTBB-Robust (pm-10, %) Distribution Shift to YTBB-Robust 60 70 80 ImageNet (top-1, %) 5 10 20 30 40 50 60 70 80ImageNet-A (top-1, %) Distribution Shift to Imagenet-A y = x Standard training Robustness intervention Trained with more data Linear fit Figure 24: The x-axes are not subsampled in these plots (they are performance on the full ImageNet validation set). Otherwise, they are identical to the main plots in the main text. This is done to clarify that subsampling the axes does not skew the discussed results. 6160 65 70 75 80 85 ImageNet (top-1, %) 45 50 55 60 65 70 75 80 85ImageNetV2 (top-1, %) Distribution Shift to ImageNetV2 55 60 65 70 75 80 85 90 ImageNet (class-subsampled) (top-1, %) 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90ObjectNet (top-1, %) Distribution Shift to ObjectNet 93 94 95 96 97 98 99 ImageNet (class-subsampled) (top-1, %) 505560 65 70 75 80 85 90 95ImageNet-Vid-Robust (pm-0, %) Distribution Shift to ImageNet-Vid-Anchors 95 96 97 98 99 ImageNet (class-subsampled) (top-1, %) 45505560 65 70 75 80 85 90 95YTBB-Robust (pm-0, %) Distribution Shift to YTBB-Anchors 50 55 60 65 70 75 80 85 90 ImageNet-Vid-Robust (pm-0, %) 30 35 40 45 50 55 60 65 70 75 80 85ImageNet-Vid-Robust (pm-10, %) Distribution Shift to ImageNet-Vid-Robust 45 50 55 60 65 70 YTBB-Robust (pm-0, %) 30 35 40 45 50 55 60 65 70YTBB-Robust (pm-10, %) Distribution Shift to YTBB-Robust 80 90 95 96 97 98 99 ImageNet (class-subsampled) (top-1, %) 5 10 20 30 40 50 60 70 80 90ImageNet-A (top-1, %) Distribution Shift to Imagenet-A y = x Standard training Robustness intervention Trained with more data Linear fit Figure 25: The full y=x line is shown here in these plots. Otherwise, they are identical to the main plots in the main text. This is done to illustrate the performance gap due to distribution shift for each of the natural shifts. 62J Example images of distribution shifts in our testbed J.1 Natural distribution shift images Figure 26: Dataset shifts. Examples from ImageNetV2 (ﬁrst row), ObjectNet (second row), ImageNet- Vid-Robust (third row), and YTBB-Robust (fourth row). Figure 27: Consistency shifts. Sequences of video frames from ImageNet-Vid-Robust (top) and YTBB-Robust (bottom). 63Figure 28: Adversarial shifts. Examples from ImageNet-A. J.2 Synthetic distribution shift images 64(a) original  (b) brightness  (c) contrast  (d) defocus blur  (e) elastic transform (f) fog  (g) frost  (h) gaussian blur  (i) gaussian noise  (j) greyscale (k) impulse noise  (l) jpeg compression  (m) motion blur  (n) pixelate  (o) saturate (p) shot noise  (q) snow  (r) spatter  (s) speckle noise  (t) stylized imagenet (u) zoom blur  (v) ℓp-attack Figure 29: Sample demonstration of the synthetic distribution shifts in our testbed. Note: This list is not complete. See Appendix E for a complete list. 65K Additional discussion of related work K.1 ImageNet-R & ImageNet-Sketch Recently, Hendrycks et al.[40] studied robustness of classiﬁers to a new dataset that measure distribution shift, ImageNet-R, along with a new data augmentation method, DeepAugment. The authors make a number of comparisons in relation to an earlier version of this manuscript [90]. In order to provide more clarity, we integrate the ImageNet-R dataset and the DeepAugment models into our testbed in this paper. 80 85 90 95 ImageNet (class-subsampled) (top-1, %) 25 30 35 40 45 50 55 60 65 70 75 80ImageNet-R (top-1, %) Distribution Shift to ImageNet-R 60 65 70 75 80 85 ImageNet (top-1, %) 10 15 20 25 30 35 40 45 50 55 60ImageNet-Sketch (top-1, %) Distribution Shift to ImageNet-Sketch y = x Standard training Lp adversarially robust Other robustness intervention Trained with more data Linear fit Figure 30: Model accuracies on two datasets: ImageNet-R (left), and ImageNet-Sketch (right). Both datasets create a distribution shift by selectively sampling images of renditions or sketches, respectively. Evaluations on these distribution shifts are similar to each other and follow the high-level trends of the other natural dataset distribution shifts in our testbed, with models trained on extra data providing the most robustness (though the eﬀect is not uniform). On the left plot, DeepAugment models are highlighted in dark brown squares, and ImageNet classes were subsampled to match the class distribution of ImageNet-R; the ImageNet-Sketch class distribution already matches ImageNet. Conﬁdence intervals, axis scaling, and the linear ﬁt are computed similarly to Figure 2. ImageNet-R. In Figure 30, we plot model accuracies on ImageNet-R(endition) [40] and a similar dataset of sketches, ImageNet-Sketch [95]. We ﬁnd that a few of the models trained on more data substantially outperform the rest. The top-right green cluster on both plots consists of several ResNet and ResNeXt models trained on 1 billion Instagram images [56, 92, 104] and EﬃcientNet-L2 (NoisyStudent) trained on the JFT-300M dataset of 300 million images [102]. However, as with the other dataset shifts, not all models trained on more data follow this trend. Several ResNet models trained on either the YFCC 100 Million images dataset [104] or the full ImageNet 21k-class dataset [49] have close to zero or negative eﬀective robustness. When interpreting the results of models trained on more data, a caveat is that the extra training data may contain renditions that do not occur in ImageNet. To clarify this point, we have reached out to the authors of [56] to obtain more information about the Instagram dataset. We will update 66-5 0 5 10 15 20 Corruptions Averaged Effective Robustness -8-7-6-5-4-3-2-101234567891011121314151617181920212223242526272829 ImageNet-R Effective Robustness Effective Robustness Scatterplot -15 -10 -5 0 5 10 15 20 25 30 35 40 45 Lp Attacks Effective Robustness -8-7-6-5-4-3-2-101234567891011121314151617181920212223242526272829 ImageNet-R Effective Robustness Effective Robustness Scatterplot Lp adversarially robust Other robustness intervention Trained with more data Figure 31: We compare the eﬀective robustness of models with their accuracy drop due to corruptions (left) and adversarial attacks (right). The eﬀective robustness is computed with respect to the linear ﬁt on ImageNet-R. The measures are weakly correlated, indicating that improved robustness to corruptions or adversarial attacks does not in general improve eﬀective robustness under ImageNet-R. our paper when suﬃcient data becomes available to estimate the relative frequency of renditions in the Instagram dataset. In the meantime, we note that the performance of the Instagram-trained models gives an answer to a question between the following two extremes: (i) How much performance on ImageNet-R do current models gain from a large, uncurated set of social media images that contains renditions? (ii) How much robustness to ImageNet-R do current models gain from a large, uncurated set of social media images that contains little to no renditions? Interestingly, we also ﬁnd that a number ofℓp-adversarially robust models provide substantial eﬀective and relative robustness on both datasets. The top-left cluster of three yellow points on both plots are feature denoising models trained by Xie et al.[101]. These results suggest that adversarial robustness and denoising blocks can be viable approaches for distribution shift comprised of renditions or sketches. A natural follow-up question is whether synthetic robustness is correlated with ImageNet-R robustness. Similar to Appendix C, in Figure 31 we compare eﬀective robustness on synthetic distribution shifts against eﬀective robustness on ImageNet-R. The scatter plots are weakly correlated (the Pearson correlation coeﬃcients are r = 0.35,0.30), indicating that improved robustness to corruptions or adversarial attacks in general does not improve eﬀective robustness on ImageNet-R. However, there does appear to be a strong trend for the brown points in the left plot. Indeed, the correlation coeﬃcient computed for only the “other robustness intervention” models isr = 0.76, suggesting that for this category of models, image corruptions robustness is well correlated with ImageNet-R robustness. DeepAugment. Hendrycks et al.[40] also introduce a new data augmentation method, Deep- Augment, which generates data augmentations by distorting the weights and activations of an image-to-image translation network. As seen in Figure 30, the DeepAugment+Augmix models, the top two dark brown squares on the left plot, have higher eﬀective robustness on ImageNet-R than most other models (ρ= 11.2% for ResNeXt101 andρ= 10.2% for ResNet50). 67As mentioned above, some of the models trained on the large Instagram and JFT-300M datasets outperform all other approaches on ImageNet-R including DeepAugment, but it is unclear how many images of renditions these datasets contain. Among the other models trained only on ImageNet, the comparison betweenℓp-adversarial robustness and DeepAugment is nuanced. Theℓp-robust model of [101] has higher eﬀective robustness but reduces standard ImageNet accuracy. The highest accuracy on ImageNet-R is also achieved by a model with anℓp-based robustness intervention (an AdvProp model [100]), but the model is derived from EﬃcientNet [88] which achieves higher standard accuracy than the wide ResNeXt model [103] used in DeepAugment. An interesting question for future work is how and whyℓp-robustness helps on ImageNet-R, e.g., by training a ResNeXt model with AdvProp. On the anchor frames of ImageNet-Vid-Robust and YTBB-Robust, DeepAgument provides eﬀective robustness comparable to models trained on multiple synthetic perturbations (e.g., a combination of Gaussian noise, contrast, motion blur, and JPEG compression). On ImageNetV2 and ObjectNet, DeepAugment does not provide eﬀective robustness. For ImageNet-C corruptions [38], the combination of DeepAugment and AugMix oﬀers substantial robustness. Excluding ℓp-adversarially robust models in the low accuracy regime, the two models with highest eﬀective robustness to ImageNet-C corruptions are DeepAugment- and Augmix- trained ResNet50 (ρ= 14.2%) and ResNeXt101 (ρ= 13.2%). To put this in context, a ResNet50 trained directly on four of the ImageNet-C corruptions (Gaussian noise, contrast, motion blur, and JPEG compression) achieves an eﬀective robustness ofρ= 13.3%. K.2 Video robustness In the context of video robustness, Gu et al.[35] have previously measured the performance of image classiﬁers on video sequences from the YouTube-BoundingBoxes(YT-BB) dataset [67]. They ﬁnd that video robustness is strongly correlated with accuracy on color corruptions such as brightness, hue, and saturation, with correlation coeﬃcientsr near 0.95. There are two potential reasons our testbed ﬁnds these measures to be only weakly correlated with robustness on YTBB-Robust and ImageNet-Vid-Robust (r ranging from0.1 to 0.5 - full table in Appendix H): Standard accuracy as a confounder.The analysis in [35] does not account for standard accuracy as a confounder. The authors consider video robustness as accuracy within k frames of an anchor frame given that the anchor frame was correctly classiﬁed. While this deﬁnition does somewhat account for models with higher standard accuracies, it is natural to expect that models with higher standard accuracy are still more likely to predict the neighboring frames correctly given that the anchor frame was predicted correctly. Thus, standard accuracy will be correlated with video robustness. Moreover, our testbed reveals that standard accuracy is also correlated with corruption accuracy, and hence corruption accuracy will be correlated with video robustness as well. Additionally, it is worth noting that correlation does not mean that robustness to color corruptions cause robustness on videos. For instance, our testbed contains a model trained on saturation as data augmentation. While this model is highly robust to saturation (exhibiting only a 1% drop from standard accuracy to accuracy under saturations, compared to a baseline model exhibiting a 12% drop), it is no more video robust than a baseline without the saturation training (the saturation-trained model still experiences an 18% video robustness drop, compared to a baseline 68model exhibiting a 19% drop). This example further shows the need for our measure of eﬀective robustness as it explicitly corrects for the confounding eﬀect of standard accuracy. Diﬀerences in data preparation. Gu et al. [35] split the full YT-BB dataset into training, validation, and testing splits, and evaluate ImageNet models on sequences from the test split. In contrast, Shankar et al.[76] derive datasets from ImageNet-Vid and Youtube-BB through a rigorous cleaning process: inspecting and annotating each sequence with human experts to check that subjects appear in frame throughout the sequence, match the correct class, and are not very blurry. This cleaning process indicates the derived datasets (ImageNet-Vid-Robust and YTBB-Robust) are better calibrated to measuring classiﬁcation performance. 69",
      "meta_data": {
        "arxiv_id": "2007.00644v2",
        "authors": [
          "Rohan Taori",
          "Achal Dave",
          "Vaishaal Shankar",
          "Nicholas Carlini",
          "Benjamin Recht",
          "Ludwig Schmidt"
        ],
        "published_date": "2020-07-01T17:53:26Z",
        "pdf_url": "https://arxiv.org/pdf/2007.00644v2.pdf",
        "github_url": "https://github.com/MadryLab/robustness"
      },
      "llm_extracted_info": {
        "main_contributions": "1. Provide the first large-scale, systematic audit of ImageNet model robustness to naturally-occurring distribution shifts.\n2. Build and release a testbed: 204 pretrained ImageNet classifiers × 213 evaluation conditions (≈109K accuracy measurements), 100× larger than prior work.\n3. Introduce two accuracy-controlled metrics—Effective Robustness (ρ) and Relative Robustness (τ)—that disentangle robustness gains from mere accuracy gains.\n4. Empirically show that (a) robustness to synthetic corruptions or adversarial perturbations rarely transfers to natural shifts; (b) most popular robustness interventions (adv. training, data-augmentation, architectural tweaks) fail on natural shifts; (c) the only broadly helpful lever is training on much larger/more diverse data, though gains are small and inconsistent.\n5. Publicly release code, predictions and analysis tools to catalyze future research.",
        "methodology": "• Define a robustness baseline β(x): log-linear fit mapping standard-test accuracy (x) to expected accuracy under shift using 78 ‘standard’ models.\n• Effective Robustness ρ(f)=acc_shift(f)−β(acc_std(f)) quantifies accuracy improvement beyond the baseline; Relative Robustness τ compares paired models before/after an intervention.\n• Curate model pool:  \n  – Standard ERM models (AlexNet→EfficientNet).  \n  – ‘Robust’ models (adv. training, MixUp/CutMix, RandAug, shift-invariance, etc.).  \n  – Large-data models (Instagram-1B, JFT-300M, ImageNet-11K, etc.).\n• Natural shifts evaluated:  \n  – Dataset shifts: ImageNetV2, ObjectNet (bias-controlled), ImageNet-Vid-Anchor, YTBB-Anchor.  \n  – Consistency shifts: frame-to-frame worst-case (pm-k) in ImageNet-Vid & YTBB.  \n  – Adversarially filtered: ImageNet-A.\n• Synthetic shifts: 38 ImageNet-C corruptions (5 severities), Stylized-ImageNet, ℓ∞ & ℓ2 PGD attacks at multiple ε.\n• Statistical analysis: scatter plots with Clopper–Pearson CIs, r² correlations, bootstrap confidence bands; data-ablation experiments (subsample images/classes).",
        "experimental_setup": "Hardware/Training: all models are off-the-shelf checkpoints (no retraining).  \nEvaluation pipeline: single-crop, center-resize default preprocessing; PGD uses 40 steps, step size per prior work.\nNatural test-set sizes: ImageNetV2 (10k), ObjectNet (50k), ImageNet-Vid-Anchor (1.1k), YTBB-Anchor (2.5k), ImageNet-A (7.5k).  \nSynthetic test-set size: ≈500k corruption images + 500k adversarial examples.  \nData-ablation: train new ResNet-50s on ImageNet subsets (1/2…1/32 images; 125/250/500 class subsets) using identical training hyper-params; evaluate on matched ImageNetV2 subsets.",
        "limitations": "1. Domain restricted to ImageNet-style image classification; conclusions may not transfer to other modalities/tasks.\n2. ‘Natural’ shifts still limited (mostly web-scraped images/videos); ignores demographic/geographic bias and real deployment environments.\n3. Relies on existing pretrained models—cannot isolate individual design choices cleanly; some models trained with proprietary data (JFT) lack public training details.\n4. Only top-1 accuracy considered; calibration, detection, and downstream tasks not evaluated.\n5. No assessment of domain-adaptation or distributionally-robust optimization methods due to lack of publicly available ImageNet DRO models.",
        "future_research_directions": "• Develop algorithms whose robustness on synthetic benchmarks causally translates to natural shifts (e.g., causal data augmentation, invariance induction, self-training).\n• Theorize and model the relationship between data diversity/scale and robustness—when does more data help?\n• Expand benchmarks to other datasets (OpenImages, Inclusive Images), tasks (detection, segmentation) and modalities (NLP, speech).\n• Integrate and evaluate DRO, domain-generalization and test-time adaptation techniques on the released testbed.\n• Investigate fairness-oriented distribution shifts (demographic/geographic) and their interaction with robustness.\n• Design synthetic perturbations more predictive of real-world failures; study frequency-domain or semantic perturbations as potential proxies.",
        "experimental_code": "\"\"\"\nImplementation of the three central quantitative tools introduced in the\npaper:\n    •  β(x):   log–linear baseline mapping from standard accuracy to\n               expected accuracy under a given shift.\n    •  ρ(f):   Effective-Robustness of a single model.\n    •  τ(f₁→f₂): Relative-Robustness of an intervention going from model f₁\n               to model f₂.\n\nThe code assumes that you have already gathered the per-model accuracies on\nImageNet-val (std) and on every shifted test-set you care about.  A minimal\nCSV expected by the helper below looks like\n ---------------------------------------------------------------------------\n | model_id | family | n_params | acc_std | acc_InetV2 | acc_ObjectNet | … |\n ---------------------------------------------------------------------------\nwhere every ‘acc_*’ column is top-1 accuracy in [0,100].\n\"\"\"\nimport pandas as pd\nimport numpy as np\nfrom typing import List, Dict\n\n###############################################################################\n# 1.  Fit the log–linear robustness baseline β(x) per shift ####################\n###############################################################################\n\ndef fit_baseline(df: pd.DataFrame,\n                 shift_columns: List[str],\n                 standard_column: str = 'acc_std',\n                 pool: List[str] = None,\n                 r2: bool = False) -> Dict[str, Dict[str, float]]:\n    \"\"\"Return per-shift {a,b} for  β(x)=ax+b  (x in [%])\n    Args\n    ----\n    df              dataframe with accuracies\n    shift_columns    list of column names with shifted accuracies\n    standard_column  name of the column with standard accuracy\n    pool             if not None, only fit on these model_id’s (baseline pool)\n    r2               if True, also return r² of the fit\n    \"\"\"\n    if pool is not None:\n        df = df[df.model_id.isin(pool)]\n    res = {}\n    x = np.log(df[standard_column].values / 100 + 1e-8)\n    for col in shift_columns:\n        y = np.log(df[col].values / 100 + 1e-8)\n        a, b = np.polyfit(x, y, deg=1)\n        entry = {'a': float(a), 'b': float(b)}\n        if r2:\n            y_hat = a * x + b\n            ssr = ((y_hat - y.mean())**2).sum()\n            sst = ((y     - y.mean())**2).sum()\n            entry['r2'] = float(ssr / sst)\n        res[col] = entry\n    return res\n\n###############################################################################\n# 2.  Effective-Robustness ρ(f) ###############################################\n###############################################################################\n\ndef effective_robustness(df: pd.DataFrame,\n                         baseline: Dict[str, Dict[str, float]],\n                         shift_columns: List[str],\n                         standard_column: str = 'acc_std') -> pd.DataFrame:\n    \"\"\"Append columns  ρ_<shift>  to df and return it.\"\"\"\n    df = df.copy()\n    x_log = np.log(df[standard_column].values / 100 + 1e-8)\n    for col in shift_columns:\n        a, b = baseline[col]['a'], baseline[col]['b']\n        beta = np.exp(a * x_log + b) * 100   # back to %-acc\n        df[f'rho_{col}'] = df[col] - beta\n    return df\n\n###############################################################################\n# 3.  Relative-Robustness τ(f₁→f₂) ###########################################\n###############################################################################\n\ndef relative_robustness(before: pd.Series,\n                        after:  pd.Series,\n                        baseline: Dict[str, Dict[str, float]],\n                        shift_columns: List[str],\n                        standard_column: str = 'acc_std') -> Dict[str, float]:\n    \"\"\"Return τ per shift for an intervention.\n\n    before / after  are rows (model instances) from the original dataframe.\n    \"\"\"\n    tau = {}\n    x1, x2 = before[standard_column], after[standard_column]\n    for col in shift_columns:\n        # slope of iso-robustness line is  β'(x) = a * (acc_shift/x)\n        a = baseline[col]['a']\n        # finite-difference formulation from paper (Eq.(4))\n        delta_std  = x2 - x1\n        delta_adv  = after[col] - before[col]\n        tau[col] = delta_adv - a * delta_std\n    return tau\n\n###############################################################################\n# 4.  Example usage (assuming df loaded elsewhere) ############################\n###############################################################################\nif __name__ == '__main__':\n    NAT_COL = 'acc_std'\n    SHIFT_COLS = [\n        'acc_InetV2', 'acc_ObjectNet', 'acc_ImageNetVIdA', 'acc_YTBB_Anchor',\n        'acc_ImageNetA',\n        # synthetic\n        'acc_ImageNetC_mean', 'acc_SIN', 'acc_PGD_Linf_4'  # … etc.\n    ]\n\n    # df_all = pd.read_csv('model_accuracies.csv')\n    # baseline_pool = df_all[df_all.family == 'ERM'].model_id.tolist()\n    # beta = fit_baseline(df_all, SHIFT_COLS, NAT_COL, pool=baseline_pool, r2=True)\n    # df_all = effective_robustness(df_all, beta, SHIFT_COLS, NAT_COL)\n\n    # ----- plotting effective robustness scatter for one shift ------------\n    # import matplotlib.pyplot as plt, seaborn as sns\n    # sns.scatterplot(data=df_all, x=NAT_COL, y='acc_ObjectNet', hue='family')\n    # x = np.linspace(30, 90, 200)\n    # a, b = beta['acc_ObjectNet'][\"a\"], beta['acc_ObjectNet'][\"b\"]\n    # plt.plot(x, np.exp(a*np.log(x/100)+b)*100, '--k', label='β baseline')\n    # plt.legend(); plt.show()\n",
        "experimental_info": "Experimental settings encoded in constants above:\n\n1. Model pools (follow paper Sect.3):\n   STANDARD_MODELS  = ERM-trained ImageNet models (AlexNet, … EfficientNet-B7)\n   ROBUST_MODELS    = adversarial-trained, MixUp/CutMix, RandAug, etc.\n   LARGE_DATA_MODELS= Instagram-1B, JFT-300M, ImageNet-11k pre-tr.\n\n2. Natural shifts evaluated (columns expected in dataframe):\n   acc_InetV2, acc_ObjectNet, acc_ImageNetVIdA (ImageNet-Vid Anchor),\n   acc_YTBB_Anchor, acc_ImageNetA, plus frame consistency (pm-k) metrics.\n\n3. Synthetic shifts (columns):\n   acc_ImageNetC_mean  (mean over 38 corruptions × 5 severities),\n   acc_SIN             (Stylized-ImageNet),\n   acc_PGD_Linf_4, acc_PGD_L2_3 etc.  (multiple ε).\n\n4. Statistics:  baseline fitting uses log-linear regression (NumPy polyfit),\n   r² optionally returned.  Effective-Robustness stored as ρ_<shift> in df.\n\n5. Reproducibility:  script needs a CSV of per-model accuracies; regression\n   and robustness metrics are deterministic.  For bootstrap CIs, wrap fits\n   in resampling loop (not included here for brevity)."
      }
    },
    {
      "title": "Vector Quantization With Self-Attention for Quality-Independent Representation Learning"
    },
    {
      "title": "On Interaction Between Augmentations and Corruptions in Natural Corruption Robustness",
      "abstract": "Invariance to a broad array of image corruptions, such as warping, noise, or\ncolor shifts, is an important aspect of building robust models in computer\nvision. Recently, several new data augmentations have been proposed that\nsignificantly improve performance on ImageNet-C, a benchmark of such\ncorruptions. However, there is still a lack of basic understanding on the\nrelationship between data augmentations and test-time corruptions. To this end,\nwe develop a feature space for image transforms, and then use a new measure in\nthis space between augmentations and corruptions called the Minimal Sample\nDistance to demonstrate a strong correlation between similarity and\nperformance. We then investigate recent data augmentations and observe a\nsignificant degradation in corruption robustness when the test-time corruptions\nare sampled to be perceptually dissimilar from ImageNet-C in this feature\nspace. Our results suggest that test error can be improved by training on\nperceptually similar augmentations, and data augmentations may not generalize\nwell beyond the existing benchmark. We hope our results and tools will allow\nfor more robust progress towards improving robustness to image corruptions. We\nprovide code at https://github.com/facebookresearch/augmentation-corruption.",
      "full_text": "On Interaction Between Augmentations and Corruptions in Natural Corruption Robustness Eric Mintun∗ Facebook AI Research mintun@fb.com Alexander Kirillov Facebook AI Research akirillov@fb.com Saining Xie Facebook AI Research s9xie@fb.com Abstract Invariance to a broad array of image corruptions, such as warping, noise, or color shifts, is an important aspect of building robust models in computer vision. Recently, several new data augmentations have been proposed that signiﬁcantly improve performance on ImageNet-C, a benchmark of such corruptions. However, there is still a lack of basic understanding on the relationship between data augmen- tations and test-time corruptions. To this end, we develop a feature space for image transforms, and then use a new measure in this space between augmentations and corruptions called the Minimal Sample Distance to demonstrate a strong correlation between similarity and performance. We then investigate recent data augmentations and observe a signiﬁcant degradation in corruption robustness when the test-time corruptions are sampled to be perceptually dissimilar from ImageNet-C in this fea- ture space. Our results suggest that test error can be improved by training on percep- tually similar augmentations, and data augmentations may not generalize well be- yond the existing benchmark. We hope our results and tools will allow for more ro- bust progress towards improving robustness to image corruptions. We provide code at https://github.com/facebookresearch/augmentation-corruption. 1 Introduction Robustness to distribution shift, i.e. when the train and test distributions differ, is an important feature of practical machine learning models. Among many forms of distribution shift, one particularly relevant category for computer vision are image corruptions. For example, test data may come from sources that differ from the training set in terms of lighting, camera quality, or other features. Post- processing transforms, such as photo touch-up, image ﬁlters, or compression effects are commonplace in real-world data. Models developed using clean, undistorted inputs typically perform dramatically worse when confronted with these sorts of image corruptions [ 8, 13]. The subject of corruption robustness has a long history in computer vision [1, 6, 30] and recently has been studied actively with the release of benchmark datasets such as ImageNet-C [13]. One particular property of image corruptions is that they are low-level distortions in nature. Corrup- tions are transformations of an image that affect structural information such as colors, textures, or geometry [5] and are typically free of high-level semantics. Therefore, it is natural to expect that data augmentation techniques, which expand the training set with random low-level transformations, can help learn robust models. Indeed, data augmentation has become a central technique in several recent methods [14, 20, 27] that achieve large improvements on ImageNet-C and related benchmarks. One caveat for data augmentation based approaches is the test corruptions are expected to beunknown at training time. If the corruptions are known, they may simply be applied to the training set as data augmentations to trivially adapt to the test distribution. Instead, an ideal robust model needs to be ∗This work completed as part of the Facebook AI residency program. 35th Conference on Neural Information Processing Systems (NeurIPS 2021). arXiv:2102.11273v2  [cs.CV]  19 Nov 2021train time  augmentation: test set corrupted by motion blur top-1 error clean motion blur translate shear rotate posterize equalize solarize 30 20 10 0 Figure 1: A toy experiment.We train multiple models on CIFAR-10 [17] using different augmenta- tion schemes. Each scheme is based on a single basic image transformation type and enhanced by overlaying random instantiations of the transformation for each input image following Hendrycks et al. [14]. We compare these models on the CIFAR-10 test set corrupted by the motion blur, a corruption used in the ImageNet-C corruption benchmark [13]. None of the augmentation schemes contains motion blur; however, the models trained with geometric-based augmentations signiﬁcantly outperform the baseline model trained on the clean images while color-based augmentations show no gains. We note the geometric augmentations can produce a result visually similar to a blur by overlaying copies of shifted images2. robust to any valid corruption, including ones unseen in any previous benchmark. Of course, in practice the robustness of a model can only be evaluated approximately by measuring its corruption error on a representative corruption benchmark. To avoid trivial adaptation to the benchmark, recent works manually exclude test corruptions from the training augmentations. However, with a toy experiment presented in Figure 1, we argue that this strategy alone might not be enough and that visually similar augmentation outputs and test corruptions can lead to signiﬁcant benchmark improvements even if the exact corruption transformations are excluded. This observation raises two important questions. One, how exactly does the similarity between train time augmentations and corruptions of the test set affect the error?And two, if the gains are due to the similarity, they may not translate into better robustness to other possible corruptions, so how well will data augmentations generalize beyond a given benchmark?In this work, we take a step towards answering these questions, with the goal of better understanding the relationship between data augmentation and test-time corruptions. Using a feature space on image transforms and a new measure called Minimal Sample Distance (MSD) on this space, we are able to quantify the distance between augmentation schemes and classes of corruption transformation. With our approach, we empirically show an intuitive yet surprisingly overlooked ﬁnding: Augmentation-corruption perceptual similarity is a strong predictor of corruption error. Based on this ﬁnding, we perform additional experiments to show that data augmentation aids corruption robustness by increasing perceptual similarity between a (possibly small) fraction of the training data and the test set. To further support our claims, we introduce a set of new corruptions, called CIFAR/ImageNet-C, to test the degree to which common data augmentation methods generalize from the original CIFAR/ImageNet-C. To choose these corruptions, we expand the set of natural corruptions and sample new corruptions that are far away from CIFAR/ImageNet-C in our feature space for measuring perceptual similarity. We then demonstrate that augmentation schemes designed speciﬁcally to improve robustness show signiﬁcantly degraded performance on CIFAR/ImageNet-C. Some augmentation schemes still show some improvement over baseline, which suggests meaningful progress towards general corruption robustness is being made, but different augmentation schemes exhibit different degrees of generalization capability. As an implication, caution is needed for fair robustness evaluations when additional data augmentation is introduced. These results suggest a major challenge that is often overlooked in the study of corruption robustness: generalization is often poor. Since perceptual similarity can predict performance, for any ﬁxed ﬁnite set of test corruptions, improvements on that set may generalize poorly to dissimilar corruptions. We 2Example transforms are for illustrative purpose only and are exaggerated. Base image © Sehee Park. 2hope that these results, tools, and benchmarks will help researchers better understand why a given augmentation scheme has good corruption error and whether it should be expected to generalize to dissimilar corruptions. On the positive side, our experiments show that generalization does emerge among perceptually similar transforms, and that only a small fractionof sampled augmentations need to be similar to a given corruption. Section 6 discusses these points in more depth. 2 Related Work Corruption robustness benchmarks and analysis.ImageNet-C [13] is a corruption dataset often used as a benchmark in robustness studies. Other corruption datasets [ 15, 29] collect corrupted images from real world sources and thus have a mixture of semantic distribution shifts and perceptual transforms. Corruption robustness differs from adversarial robustness [33], which seeks invariance to small, worst case distortions. One notable difference is that improving corruption robustness often slightly improves regular test error, instead of harming it. Yin et al.[41] analyzes corruption robustness in the context of transforms’ frequency spectra; this can also inﬂuence corruption error independently from perceptual similarity. Here we study the relationship between augmentations and corruptions more generically, and explore the relationship between perceptual similarity and generalization to new corruptions. Dao et al. [3] and Wu et al. [38] study the theory of data augmentation for regular test error. Hendrycks et al. [15] and Taori et al. [35] study how the performance on synthetic corruption transforms generalizes to performance on corruption datasets collected from the real world. Here we do not address this issue directly but touch upon it in the discussion. Improving corruption robustness. Data augmentations designed to improve robustness include AugMix [14], which composites common image transforms, Patch Gaussian [ 20], which applies Gaussian noise in square patches, and ANT [27], which augments with an adversarially learned noise distribution. AutoAugment [2] learns augmentation policies that optimize clean error but has since been shown to improve corruption error [41]. Mixup [43] can improve robustness [18], but its label augmentation complicates the dependence on image augmentation. Stylized-ImageNet [9], which applies style transfer to input images, can also improve robustness. DeepAugment [15], which applies augmentations to a deep representation of an image, can also give large improvements in robustness. Noisy Student [39] and Assemble-ResNet [18] combine data augmentation with new models and training procedures and greatly enhance corruption robustness. In addition to training-time methods, there are approaches that adapt to unseen corruptions at test time, e.g. using self-supervised tasks [32], entropy minimization [37], or with a focus on privacy and data transmission efﬁciency [ 19]. While we do not directly address these approaches here, our methods potentially provide tools that could be used to measure shifting distributions in an online regime. 3 Perceptual similarity for augmentations and corruptions First, we study the importance of similarity between augmentations and corruptions for improving performance on those corruptions. To do so, we need a means to compare augmentations and corruptions. Both types of transforms are perceptual in nature, meaning they affect low-level image structure while leaving high-level semantic information intact, so we expect a good distance to be a measure of perceptual similarity. Then, we need to ﬁnd the appropriate measure of distance between the augmentation and corruption distributions. We will argue below that distributional equivalence is not appropriate in the context of corruption robustness, and instead introduce the minimal sample distance, a simple measure that does capture a relevant sense of distribution distance. Measuring similarity between perceptual transforms.We deﬁne a perceptual transform as a transform that acts on low-level image structure but not high-level semantic information. As such, we expect two transforms should be similar if their actions on this low-level structure are similar, independent of algorithmic or per-pixel differences between them. A closely related, well-studied problem is the perceptual similarity between images. A common approach is to train a neural network on a classiﬁcation task and use intermediate layers as a feature space for measuring distances [45]. We adapt this idea to obtain a feature space for measuring distances between perceptual transforms. We start with a feature extractor for images, which we call ˆf(x). To train the model from which we will extract features, we assume access to a dataset D of image label pairs (x,y) associated with a 3Distance to Impulse Noise MSD MMD 0.0 0.5 1.0 1.5 2.0Impulse Noise Error Impulse Noise Fraction 1.0 0.8 0.6 0.4 0.2 0.0 10 20 30 40 50 60 MMDMSD Corruption 1 Corruption 2 Augmentation Augmentation sample Closest sample (a) (b) Figure 2: (a) Schematic comparison of MMD to MSD. MMD measures the distance between distribution centers and is only small if the augmentation overlaps with a corruption. MSD measures to the nearest sampled point in the set of samples (marked by a star) and is small even for broad distributions that overlap with multiple corruptions. (b) We test on images corrupted with impulse noise, and train on images augmented with a mixture ofimpulse noiseand motion blur. As the mixing fraction of impulse noisedecreases, MMD between the augmentation and corruption grows linearly while MSD and error stay low until nearly 0% mixing fraction. classiﬁcation task. The model should be trained using only default data augmentation for the task in question so that the feature extractor is independent of the transforms we will use it to study. In order to obtain a very simple measure, we use just the last hidden layer of the network as a feature space. A perceptual transform t(x) may be encoded by applying it to all images in D, encoding the transformed images, and averaging the features over these images. For efﬁciency, we ﬁnd it sufﬁcient to average over only a randomly sampled subset of images DS in D. In Section 4.1 we discuss the size of DS. The random choice of images is a property of the feature extractor, and so remains ﬁxed when encoding multiple transforms. This reduces variance when computing distances between two transforms. The transform feature extractor is given by f(t) = Ex∈DS [ ˆf(t(x)) −ˆf(x)]. The perceptual similaritybetween an augmentation and a corruption can be taken as the L2 distance on this feature space f. Minimal sample distance. We now seek to compare the distribution of an augmentation schemepa to a distribution of a corruption benchmarkpc. If the goal was to optimize error on aknown corruption distribution, exact equivalence of distributions is the correct measure to minimize. But since the goal is robustness to general, unknown corruption distributions, a good augmentation scheme should be equivalent to no single corruption distribution. To illustrate this behavior, consider a toy problem where we have access to the corruption transforms at training time. A very rough, necessary-but-insufﬁcient measure of distributional similarity is dMMD(pa,pc) = ||Ea∼pa[f(a)] −Ec∼pc[f(c)]||. This is the maximal mean discrepancy on a ﬁxed, ﬁnite feature space, so for brevity we will refer to it as MMD. We still employ the featurization f(t), since we are comparing transforms and not images, unlike in typical domain adaptation. Consider two corruption distributions, here impulse noiseand motion blur, and an augmentation scheme that is a mixture of the two corruption distributions. Figure 2b shows MMD between the augmentation and impulse noisecorruption scales linearly with mixing fraction, but error on impulse noiseremains low until the mixing fraction is almost 0% impulse noise. This implies distributional similarity is a poor predictor of corruption error. Indeed, low dMMD with any one corruption distribution suggests the augmentation overlaps it signiﬁcantly, so the augmentation is unlikely to aid dissimilar corruptions. Our expectation for the behavior of the error in Figure 2b is that networks can often successfully memorize rare examples seen during training, so that only a very small fraction of sampled images need impulse noiseaugmentations to perform well on impulse noisecorruptions. An appropriate distance should then measure how close augmentation samples can come to the corruption distribution, even if the density of those samples is low. We thus propose a very simple measure calledminimal sample distance (MSD), which is just the perceptual similarity between an average corruption and the closest augmentation from a ﬁnite set of samples A ∼pa: dMSD(pa,pc) = min a∈A∼pa ||f(a) −Ec∼pc[f(c)]||. (1) 4Minimal Sample Distance Corruption Error 0.2 0.4 0.6 0.8 0.4 0.8 1.2 1.6 Elastic Transform, Frost, 12 14 16 18 20 12 16 20 24 1.0 1.5 2.0 2.5 3.0 20 30 40 50 Zoom Blur, 0.4 0.8 1.2 1.6 10 15 20 25 Gaussian Noise, 6.0 6.5 7.0 7.5 0.10 0.14 0.18 0.22 Brightness, 10 15 20 25 0.6 0.8 1.0 1.2 Contrast, Minimal Sample Distance Corruption Error 0.2 0.4 0.6 0.8 0.4 0.8 1.2 1.6 Elastic Transform, Frost, 12 14 16 18 20 12 16 20 24 1.0 1.5 2.0 2.5 3.0 20 30 40 50 Zoom Blur, 0.4 0.8 1.2 1.6 10 15 20 25 Gaussian Noise, 6.0 6.5 7.0 7.5 0.10 0.14 0.18 0.22 Brightness, 10 15 20 25 0.6 0.8 1.0 1.2 Contrast, Minimal Sample Distance Corruption Error 0.2 0.4 0.6 0.8 0.4 0.8 1.2 1.6 Elastic Transform, Frost, 12 14 16 18 20 12 16 20 24 1.0 1.5 2.0 2.5 3.0 20 30 40 50 Zoom Blur, 0.4 0.8 1.2 1.6 10 15 20 25 Gaussian Noise, 6.0 6.5 7.0 7.5 0.10 0.14 0.18 0.22 Brightness, 10 15 20 25 0.6 0.8 1.0 1.2 Contrast, Minimal Sample Distance Corruption Error 0.2 0.4 0.6 0.8 0.4 0.8 1.2 1.6 Elastic Transform, Frost, 12 14 16 18 20 12 16 20 24 1.0 1.5 2.0 2.5 3.0 20 30 40 50 Zoom Blur, 0.4 0.8 1.2 1.6 10 15 20 25 Gaussian Noise, 6.0 6.5 7.0 7.5 0.10 0.14 0.18 0.22 Brightness, 10 15 20 25 0.6 0.8 1.0 1.2 Contrast, Figure 3: Example relationships between MSD and corruption error. ρ is the Spearman rank correlation. MSD correlates well with error across all four categories of corruption in CIFAR-10-C. For completeness, we also show brightness, a negative example where correlation is poor. A schematic comparison of MMD and MSD is shown in Figure 2a. While both MMD and MSD are small for an augmentation scheme that is distributionally similar to a corruption distribution, only MSD remains small for a broad distribution that occasionally produces samples near multiple corruption distributions. Figure 2b shows MSD, like test error, is small for most mixing fractions in the toy problem described above. Note the measure’s need to accommodate robustness to general, unknown corruption distributions has led it to be asymmetric, so it differs from more formal distance metrics that may be used to predict generalization error, such as the Wasserstein distance [46]. 4 Perceptual similarity is predictive of corruption error We are now equipped to measure how important this augmentation-corruption similarity is for corruption error. For a large number of augmentation schemes, we will measure both the MSD to a corruption distribution and the corruption error of a model trained with that scheme. We will ﬁnd a correlation between MSD and corruption error, which provides evidence that networks generalize across perceptually similar transforms. Then, we will calculate MSD for augmentation schemes in the literature that have been shown to improve error on corruption benchmarks. We will ﬁnd a correlation between MSD and error here as well, suggesting their success is in part explained by their perceptual similarity to the benchmark. This implies there may be a risk of poor generalization to different benchmarks, since we would not expect this improvement to transfer to a dissimilar corruption. 4.1 Experimental setup Corruptions. We use CIFAR-10-C [13], which is a common benchmark used for studying cor- ruption robustness. It consists of 15 corruptions, each further split into ﬁve different severities of transformation, applied to the CIFAR-10 test set. The 15 corruptions fall into four categories: per-pixel noise, blurring, synthetic weather effects, and digital transforms. We treat each corruption at each severity as a separate distribution for the sake of calculating MSD and error; however, for simplicity we average errors and distances over severity to present a single result per corruption. Space of augmentation schemes.To build each sampled augmentation transform, we will com- posite a set of base augmentations. For base augmentations, we consider the nine common image transforms used in Hendrycks et al. [14]. There are ﬁve geometric transforms and four color trans- forms. By taking all subsets of these base augmentations, we obtain 29 = 512 unique augmentation schemes, collectively called the augmentation powerset. Also following Hendrycks et al. [14], we composite transforms in two ways: by applying one after another, or by applying them to copies of the image and then linearly superimposing the results. Examples of both augmentations and corruptions are provided in Appendix F. Computing similarity and corruption error.A WideResNet-40-2 [42] model is pre-trained on CIFAR-10 using default augmentation and training parameters from Hendrycks et al. [14]. WideRes- Net is a common baseline model used when studying data augmentation on CIFAR-10 [2, 14, 43]. Its last hidden layer is used as the feature space. For MSD, we average over 100 images, 100 corruptions, and minimize over 100k augmentations. With this number of corruptions and images, we ﬁnd that the average standard deviation in distance between an augmentation and the averaged corruptions is roughly ﬁve percent of the mean, which is smaller than the typical feature in our results found below, given in Figure 3. We also ﬁnd that using VGG [31] instead of WideResNet for the feature extractor gives similar results. Details for these calculations are in Appendix C. Images for calculating MSD 5Corruption Error Impulse Noise w/o x-translation w/ x-translation w/o solarize w/ solarize 1.0 1.5 2.0  1.0 1.5 2.0 15 25 35 45 Motion Blur Minimum Sample Distance 0.2 0.6 1.0 1.4 0.2 0.6 1.0 1.4 10 15 20 25 w/o solarize w/ solarize w/o x-translation w/ x-translation Corruption Error Impulse Noise w/o x-translation w/ x-translation w/o solarize w/ solarize 1.0 1.5 2.0 1.0 1.5 2.0 15 25 35 45 Motion Blur Minimum Sample Distance 0.2 0.6 1.0 1.4  0.2 0.6 1.0 1.4 10 15 20 25 w/o solarize w/ solarize w/o x-translation w/ x-translation Corruption Error Impulse Noise w/o x-translation w/ x-translation w/o solarize w/ solarize 1.0 1.5 2.0 1.0 1.5 2.0 15 25 35 45 Motion Blur Minimum Sample Distance 0.2 0.6 1.0 1.4 0.2 0.6 1.0 1.4 10 15 20 25 w/o solarize w/ solarize w/o x-translation w/ x-translation Corruption Error Impulse Noise w/o x-translation w/ x-translation w/o solarize w/ solarize 1.0 1.5 2.0 1.0 1.5 2.0 15 25 35 45 Motion Blur Minimum Sample Distance 0.2 0.6 1.0 1.4 0.2 0.6 1.0 1.4 10 15 20 25 w/o solarize w/ solarize w/o x-translation w/ x-translation Figure 4: Example relationships between base augmentations and corruptions. Including solarize reduces MSD on the perceptually similar impulse noisecorruption. Including x translationreduces MSD on the perceptually similar motion blur corruption. MSD is not decreased for dissimilar augmentation-corruption pairs. are from the training set and do not have default training augmentation. A WideResNet-40-2 with the same training parameters is used for corruption error evaluation. 4.2 Analysis MSD correlates with corruption error.First, we establish the correlation between MSD and corruption error on the augmentation powerset. MSD shows strong correlation with corruption error across corruptions types in all four categories of CIFAR-10-C, and for a large majority of CIFAR-10-C corruptions in general: 12 of 15 have Spearman rank correlation greater than 0.6. Figure 3 shows the relationship between distance and corruption error on six example corruptions, including one negative example for which correlation is low. A complete set of plots is below in Figure 5. This corruption, brightness, may give poor results because it is a single low-level image statistic that can vary signiﬁcantly from image to image, and thus may not be well represented by our feature extractor. Appendix B has a few supplemental experiments. First, we we conﬁrm MMD correlates poorly with corruption error, as expected. In particular, we expect broad augmentation schemes produce samples similar to a larger set of corruptions, leading to both lower MSD and lower corruption error but higher MMD. Second, we repeat our experiment but do not train on the augmentations, instead only adapting the batch norm statistics of a pre-trained model to them. We still ﬁnd a strong correlation, suggesting our methods are compatible with the results of Schneider et al. [28], which shows such an adaptation of the batch norm statistics to a corruption can improve corruption error. An example of perceptual similarity.Here we illustrate the perceptual nature of the similarity measure, using an example with two base augmentations and two corruptions. The augmentation solarize and the corruption impulse noiseboth insert bright pixels into the image, though in different ways. Linear superpositions of the augmentation x translationare visually similar to a blur, such as the corruption motion blur. Figure 4 shows MSD vs error where augmentation schemes that include solarize and x translationare colored. It is clear that including an augmentation greatly decreases MSD to its perceptually similar corruption, while having little effect on MSD to its perceptually dissimilar corruption. MSD and corruption error in real augmentation methods.The augmentation powerset may be used as a baseline for comparing real data augmentation schemes. Figure 5 shows MSD-error correlations for Patch Gaussian [20], AutoAugment [2], and Augmix [14], along with the cloud of augmentation powerset points for all 15 CIFAR-10-C corruptions. The real augmentation schemes follow the same general trend that lower error predicts lower MSD. A few intuitive correlations are also captured in Figure 5. Patch Gaussian has low MSD to noise corruptions. AutoAugment, which contains contrast and Gaussian blurring augmentations in its sub-policies, has low MSD withcontrast and defocus blur. A negative example is fog, on which MSD to AutoAugment is not predictive of corruption error. This correlation suggests generalization may be poor beyond an existing benchmark, since an aug- mentation scheme may be perceptually similar to one benchmark but not another. For augmentations and corruptions that are explicitly the same, such as contrast in AutoAugment and ImageNet-C, this is typically accounted for by removing such transforms from the augmentation scheme when testing 660 50 40 30 20 10 25 20 15 10 30 40 50 60 12 16 20 24 14 18 22 26 30 16 18 20 22 14 12 16 18 20 5.0 5.5 6.0 6.5 7.0 7.5 10 15 20 10 20 30 40 10 20 30 40 10 20 30 12 10 8 25 20 15 10 20 18 16 14 12 1.0 2.0 3.0 0.5 1.0 1.5 2.0 2.5 0.5 1.0 1.5 2.0 0.2 0.6 1.0 1.4 0.2 0.4 0.6 0.8 1.0 0.4 0.8 1.2 1.6 1.0 1.5 2.0 0.10 0.14 0.18 0.22 0.2 0.4 0.6 0.4 0.8 1.2 1.6 0.3 0.5 0.7 0.9 0.4 0.6 0.8 1.0 1.2 0.8 1.2 1.6 0.2 0.4 0.6 0.8 0.2 0.4 0.6 0.8 Gaussian noise, Impulse noise, Shot noise,  Motion blur, Zoom blur, Defocus blur, Brightness,  Fog, Glass blur,  Frost, Contrast, Snow,  JPEG compression, Pixelate, Elastic transform, Patch Gaussian Augmix*AutoAugmentBaseline Augmentation powerset Minimal Sample Distance Corruption Error Figure 5: Correlations for augmentation schemes from the literature. Patch Gaussian is similar to noise, while AutoAugment is similar to contrast and blur, as expected from their formulation. Glass blur acts more like a noise corruption than a blur for these augmentation schemes, likely because it randomly permutes pixels. As a negative example, MSD does not correlate well with error for AutoAugment on fog. *AugMix here refers to just the augmentation distribution in Hendrycks et al. [14], not the proposed Jensen-Shannon divergence loss. corruption robustness3. But in addition to these explicit similarities, Figure 5 shows quantitatively that perceptual similarity between non-identical augmentations and corruptions is also strongly predictive of corruption error. This includes possibly unexpected similarities, such as between Patch Gaussian and glass blur, which introduces random pixel-level permutations as noise. This suggests that perceptually similar augmentations and corruptions should be treated with the same care as identical transforms. In particular, tools such as MSD help us determinewhy an augmentation scheme improves corruption error, so we can better understand if new methods will generalize beyond their tested benchmarks. Next we test this generalization by ﬁnding corruptions dissimilar to ImageNet-C. 5 ImageNet- C: benchmarking with dissimilar corruptions We now introduce a set of corruptions, called ImageNet- C, that are perceptually dissimilar to ImageNet-C in our transform feature space, and we will show that several augmentation schemes have degraded performance on the new dataset. We emphasize that the dataset selection method uses only default data augmentation and was ﬁxed before we looked at the results for different augmentations, so we are not adversarially selecting against the tested augmentation schemes. Dataset construction. Here we present an overview of the dataset construction method. We build 30 new corruptions in 10 severities, from which the 10 most dissimilar corruptions will be chosen. We adapt common ﬁlters and noise distributions available online [10, 16] to produce human interpretable images. The transforms include warps, blurs, color distortions, noise additions, and obscuring effects. Examples of the new corruptions and exact details of the construction method are provided in Appendices D and F. 3For this analysis, we wish to treat explicit transform similarity and perceptual transform similarity on the same footing, so we choose not to remove these overlapping augmentations. 7Transverse Chromatic  AbberationBrown Noise Circular Motion Blur Lines Sparkles Blue Noise Sample Checkerboard Inverse Sparkle Pinch and Twirl Ripple CIFAR-10-C Corruptions AR-10-C Corruptions Brown Noise Checkerboard Cocentric Sine Waves Perlin Noise Single Frequency Noise Blue Noise Sample Caustic Refraction Inverse Sparkle Plasma Noise Sparkles ImageNet-C Corruptions ImageNet-C Corruptions Transverse Chromatic  AbberationBrown Noise Circular Motion Blur Lines Sparkles Blue Noise Sample Checkerboard Inverse Sparkle Pinch and Twirl Ripple CIFAR-10-C Corruptions AR-10-C Corruptions Brown Noise Checkerboard Cocentric Sine Waves Perlin Noise Single Frequency Noise Blue Noise Sample Caustic Refraction Inverse Sparkle Plasma Noise Sparkles ImageNet-C Corruptions ImageNet-C Corruptions Figure 6: Example CIFAR-10-C and ImageNet-C corruptions. While still human interpretable, new corruptions are sampled to be dissimilar from CIFAR-10/ImageNet-C. Base images © Sehee Park and Chenxu Han. To assure that the new dataset is no harder than ImageNet-C, we restrict the average corruption error of the new dataset to be similar to that of ImageNet-C for default augmentation. We then generate many potential datasets and measure the average shift in distance to ImageNet-C that each corruption contributes. Note that while MSD is a measure between augmentations and corruptions, here we are comparing corruptions to other corruptions and thus use MMD in our transform feature space. ImageNet-C then consists of the 10 corruptions types with the largest average shift in distance. Like ImageNet-C, each has ﬁve different severities, with severities chosen so that the average error matches ImageNet-C for default augmentation. Example transforms from ImageNet-C and CIFAR-10-C are shown in Figure 6. This procedure in our feature space produces corruptions intuitively dissimilar from ImageNet-C and CIFAR-10-C. Results. We test AutoAugment [2], Patch Gaussian [ 20], AugMix [14], ANT3x3 [27], Stylized- ImageNet [9], and DeepAugment [15] on our new datasets and show results in Table 1. CIFAR-10 models are WideResNet-40-2 with training parameters from Hendrycks et al. [14]. ImageNet [ 4] models are ResNet-50 [12] with training parameters from Goyal et al. [11]. Stylized-ImageNet is trained jointly with ImageNet for half the epochs and starts from a model pre-trained on ImageNet, following Geirhos et al. [9]. Models use default data augmentation as well as the augmentation being tested, except ImageNet color jittering is not used. All corruptions are applied in-memory instead of loaded from a compressed ﬁle; this can affect results especially on high frequency corruptions. Since Section 4 suggests several augmentation schemes are perceptually similar to ImageNet-C corruptions, we might expect these methods to have worse error on the new corruptions. Indeed, every augmentation scheme performs worse. Different augmentation schemes also degrade by signiﬁcantly different amounts, from +0.7% for AutoAugment to +7.3% for PatchGaussian, which changes their ranking by corruption error and leads to inconsistency of generalization. In Table 2, we compare performance on several robust models[7, 21, 22, 34, 36, 39, 44] that are not primarily augmentation- based and see no similar pattern of degradation, further suggesting that augmentation-corruption dissimilarity is the cause of the higher error. Errors of individual corruptions in ImageNet-C are also revealing. For all augmentation schemes, there is signiﬁcant improvement on blue sample noise4 but little improvement on sparkles or inverse sparkles. Only AutoAugment does well on checkerboard, perhaps because only AutoAugment’s geometric transforms produce empty space, similar to checkerboard’s occluded regions. These examples suggest a slightly different benchmark could yield signiﬁcantly different results. Indeed, for a hypothetical benchmark that excluded blue sample noiseand checkerboard, AutoAugment and Patch Gaussian have 57.3% and 57.2% error respectively, little better than baseline of 57.4%. AugMix fairs only a little better with 54.3% error. Even DeepAugment+AugMix, which is in general a strong augmentation scheme, shows a big discrepancy in performance across different corruptions, improving single frequency noiseby 31%, but inverse sparklesby only 2.3%. Generalization to dissimilar corruptions is thus both inconsistent and typically quite poor. Single benchmarks and aggregate corruption scores are likely not enough for careful evaluation of robustness to unknown corruptions, and it is important to study why proposed augmentations succeed to better understand how well they might generalize. 4This corruption is conceptually similar with impulse noisebut also gives a large distance; this may be a failure mode of our measure, maybe since impulse noisehas bright pixels and blue noise samplehas dark pixels. 8Table 1: Test error for several data augmentation methods on CIFAR-10-C and ImageNet-10-C, for which every method performs worse than on ImageNet-C or CIFAR-10-C. The increase in error differs signiﬁcantly between different augmentation methods. Descriptions of the abbreviations and standard deviations for individual corruptions are in Appendix D. ‘Baseline’ refers to default augmentation only. Averages are over ﬁve runs for ImageNet and ten for CIFAR-10.*ANT, DeepAugment(DA) and DeepAugment+AugMix (DA+AM) use the pre-trained model provided with the associated papers and have different training parameters. IN-C IN- C ImageNet- C Corruptions Aug Err Err ∆IN-C BSmpl Plsm Ckbd CSin SFrq Brwn Prln Sprk ISprk Rfrac Baseline 58.1 ±0.4 57.7±0.2 -0.4 68.6 71.7 49.4 84.7 79.0 37.5 34.3 32.4 76.7 42.8 AA 55.0 ±0.2 55.7±0.3 +0.7 54.8 68.3 43.8 86.5 78.8 34.5 33.8 36.1 77.1 43.8 SIN 52.4 ±0.1 55.8±0.3 +3.4 54.7 69.8 52.8 79.6 69.2 37.8 35.3 37.0 77.3 44.1 AugMix 49.2 ±0.7 52.4±0.2 +3.2 43.2 72.2 46.1 76.3 67.4 38.8 32.4 32.3 76.4 39.2 PG 49.3 ±0.2 56.6±0.4 +7.3 60.3 74.1 48.5 82.1 76.7 38.9 34.6 32.1 76.5 42.1 ANT* 48.8 53.9 +5.1 35.8 75.5 56.9 76.4 63.7 41.0 35.2 35.0 76.1 43.3 DA* 46.6 51.0 +4.4 41.7 73.3 53.9 74.6 50.9 37.2 30.3 32.9 74.7 40.9 DA+AM* 41.0 48.3 +7.3 34.9 67.9 49.8 69.7 48.0 35.2 30.6 32.9 74.3 39.8 C10-C C10- C CIFAR-10- C Corruptions Aug Err Err ∆C10-C BSmpl Brwn Ckbd CBlur ISprk Line P&T Rppl Sprk TCA Baseline 27.0 ±0.6 27.1±0.5 +0.1 42.9 27.2 23.3 11.8 43.3 26.2 11.3 21.6 21.0 42.9 AA 19.4 ±0.2 21.0±0.4 +1.6 17.7 17.5 17.6 9.5 40.4 23.6 10.7 23.5 17.5 31.8 AugMix 11.1 ±0.2 16.0±0.3 +5.9 9.8 27.8 13.4 5.9 30.3 18.0 8.3 12.1 15.5 19.2 PG 17.0 ±0.3 23.8±0.5 +6.8 9.0 30.1 21.6 12.8 35.4 20.6 8.8 21.5 19.3 59.5 Table 2: Comparison of errors on ImageNet-C and ImageNet- C for several robust models: WSL (weakly supervised ResNeXt-101-32x8d [21, 22]), EN (EfﬁcientNet-B0 [34]), NS (Noisy Student EN-B0 [39]), ViT-S (Transformer [7, 36]), ResNeSt (ResNeSt-50d, [44]), using pre-trained models provided with the respective papers. These models do not rely primarily on data augmentation to be robust, and there is no consistent degradation on ImageNet-C. This is additional evidence that the worse performance in Table 1 does not occur because ImageNet-C is harder generally. WSL EN NS ViT-S ResNeSt IN-C Err 38.1 55.7 52.1 44.5 44.4 IN-C Err 39.2 53.4 52.2 41.1 41.6 It may be surprising that Stylized-ImageNet also degrades, given that it is intuitively very different from every corruption. While our measure works for augmentations, it does not cover all possible methods that improve robustness, such as more complicated algorithms like Stylized-ImageNet. Stylized-ImageNet degradation may be due to other reasons. For instance, it primarily augments texture information and may help mostly with higher frequency corruptions, as can be seen by its improvement on single frequency noiseand cocentric sine waves; ImageNet-C has fewer such corruptions than ImageNet-C. ImageNet-C is thus a useful tool for understanding the interaction between training procedure and corruption distribution, even beyond perceptual similarity. Nevertheless, note that it is the intuitively broader augmentation schemes, such as AutoAugment, AugMix, Stylized-ImageNet, and DeepAugment that generalize better to ImageNet-C. The impor- tance of breadth has also been explored elsewhere[ 15, 41], but in the previous sections we have provided new quantitative evidence for why this may be true: broad augmentation schemes may be perceptually similar to more types of corruptions, and thus more likely to be perceptually similar to a new corruption. Moreover, AugMix and DeepAugment still improve over baseline on ImageNet-C, so there is reason to be optimistic that robustness to unknown corruptions is an achievable goal, as long as evaluation is treated carefully. 6 Discussion Societal Impact. Our method for ﬁnding dissimilar corruptions could in principle be used to adversarially attack computer vision systems, such as those in content moderation or self-driving cars. Moreover, our ultimate goal is to help improve robustness in computer vision, and such robust 9systems may be used in detrimentals ways, for example in autonomous weapons or surveillance. However, we expect better evaluation of robust models to have deﬁnite beneﬁts as well. In the long run, such an understanding should help defend against adversarial attacks. Our tools could also be used to challenge purportedly robust systems that are actually dangerously unreliable, such as an autonomous driving system that is robust to common corruption benchmarks yet fails to be robust to a dissimilar but important corruption, e.g., maybe glare. For instance, is the model employing data augmentation that is perceptually similar to the corruptions being used to report good robustness? Is the set of validation corruptions sufﬁciently broad that we would expect reasonable generalization to an unseen corruption? If we generate a dissimilar set of corruptions using the procedure we develop here, does the model still perform well on the new corruptions? Quantitative ways to answer these questions may provide a means to verify the robust performance of a model before it encounters and potentially fails on a critical, previously unseen corruption. Corruption robustness as a secondary learning task.We have provided evidence that data aug- mentation may not generalize well beyond a given corruption benchmark. To explore this further, consider an analogy to a regular learning problem. We may think of corruption robustness in the presence of data augmentation as a sort of secondary task layered on the primary classiﬁcation task: the set of data augmentations is the training set, the set of corruptions is the test set, and the goal is to achieve invariance of the underlying primary task. In this language, the ‘datasets’ involved are quite small: ImageNet-C has only 15 corruption types, and several augmentation schemes composite only around 10 basic transforms. In this case, standard machine learning practice would dictate a training/validation/test set split; it is only the size and breadth of modern vision datasets that has allowed this to be neglected in certain cases recently. But the effective dataset size of a corruption robustness problem is tiny, so having a held-out test set seems necessary. To emphasize, this is not a test set of the underlying classiﬁcation task, for which generalization has been studied by Recht et al. [25, 26]. Instead, it is a test set of corruption transforms themselves. This means there would be validation/test split of dissimilar transformations, both applied to the ImageNet validation set5. Real-world corruption robustness. Recently, Hendrycks et al. [15] and Taori et al. [35] study how performance on corruption transforms generalizes to real-world corruptions and come to conﬂicting conclusions. Though we do not study real-world corruptions, we have proposed a mechanism that may explain the conﬂict: performance will generalize between transforms and real-world corruptions if they are perceptually similar, but will likely not if they are dissimilar. Since Hendrycks et al. [15] and Taori et al. [35] draw on different real-world and synthetic corruptions, it may be that the perceptual similarity between datasets differs in the two analyses. This also suggests a way to ﬁnd additional corruption transforms that correlate with real-world corruptions: transforms should be sought that have maximal perceptual similarity with real-world corruptions. Generalization does occur. We have encountered two features of data augmentation that may explain why it can be such a powerful tool for corruption robustness, despite the issues discussed above. First, within a class of perceptually similar transforms, generalization does occur. This means each simple data augmentation may confer robustness to many complicated corruptions, as long as they share perceptual similarity. Second, dissimilar augmentations in an augmentation scheme often causes little to no loss in performance, as long as a similar augmentation is also present. We brieﬂy study this in Appendix A by demonstrating that adding many dissimilar augmentations increases error much less than adding a few similar augmentations decreases it. These two features suggest broad augmentation schemes with many dissimilar augmentations may confer robustness to a large class of unknown corruptions. More generally, we think data augmentation is a promising direction of study for corruption robustness, as long as signiﬁcant care is taken in evaluation. Acknowledgements and Funding Disclosure Eric Mintun would like to thank Matthew Leavitt, Sho Yaida, and Achal Dave for discussions during the development of this work. Additionally, he would like to acknowledge the Facebook AI residency program for providing excellent training and support in AI research. The authors received no external funding and have no competing interests. 5The validation set provided in Hendrycks & Dietterich [13] consists of perceptually similar transforms to ImageNet-C and would not be expected to work well for the validation discussed here. 10References [1] Bruna, J. and Mallat, S. Invariant scattering convolution networks.IEEE transactions on pattern analysis and machine intelligence, 35(8):1872–1886, 2013. [2] Cubuk, E. D., Zoph, B., Mané, D., Vasudevan, V ., and Le, Q. V . AutoAugment: Learning augmentation strategies from data. In CVPR, 2019. [3] Dao, T., Gu, A., Ratner, A. J., Smith, V ., De Sa, C., and Ré, C. A kernel theory of modern data augmentation. Proceedings of machine learning research, 97:1528, 2019. [4] Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L. ImageNet: A large-scale hierarchical image database. In CVPR, 2009. [5] Ding, K., Ma, K., Wang, S., and Simoncelli, E. P. Image quality assessment: Unifying structure and texture similarity. IEEE transactions on pattern analysis and machine intelligence, 2020. [6] Dodge, S. and Karam, L. A study and comparison of human and deep learning recognition performance under visual distortions. In ICCCN, 2017. [7] Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., Uszkoreit, J., and Houlsby, N. An image is worth 16x16 words: Transformers for image recognition at scale. In ICLR, 2021. [8] Geirhos, R., Temme, C. R., Rauber, J., Schütt, H. H., Bethge, M., and Wichmann, F. A. Generalisation in humans and deep neural networks. In NeurIPS, 2018. [9] Geirhos, R., Rubisch, P., Michaelis, C., Bethge, M., Wichmann, F. A., and Brendel, W. ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness. In ICLR, 2019. [10] Gladman, S. J. Filterpedia, 2016. URL https://github.com/FlexMonkey/Filterpedia. [11] Goyal, P., Dollár, P., Girshick, R., Noordhuis, P., Wesolowski, L., Kyrola, A., Tulloch, A., Jia, Y ., and He, K. Accurate, large minibatch SGD: Training ImageNet in 1 hour.arXiv preprint arXiv:1706.02677, 2017. [12] He, K., Zhang, X., Ren, S., and Sun, J. Deep residual learning for image recognition. In CVPR, 2016. [13] Hendrycks, D. and Dietterich, T. Benchmarking neural network robustness to common corrup- tions and perturbations. In ICLR, 2018. [14] Hendrycks, D., Mu, N., Cubuk, E. D., Zoph, B., Gilmer, J., and Lakshminarayanan, B. AugMix: A simple data processing method to improve robustness and uncertainty. In ICLR, 2019. [15] Hendrycks, D., Basart, S., Mu, N., Kadavath, S., Wang, F., Dorundo, E., Desai, R., Zhu, T., Parajuli, S., Guo, M., Song, D., Steinhardt, J., and Gilmer, J. The many faces of robustness: A critical analysis of out-of-distribution generalization. arXiv preprint arXiv:2006.16241, 2020. [16] Huxtable, J. JH Labs Java Image Processing, 2006. URL http://www.jhlabs.com/ip/ filters/. [17] Krizhevsky, A., Hinton, G., et al. Learning multiple layers of features from tiny images. 2009. [18] Lee, J., Won, T., and Hong, K. Compounding the performance improvements of assembled techniques in a convolutional neural network. arXiv preprint arXiv:2001.06268, 2020. [19] Liang, J., Hu, D., and Feng, J. Do we really need to access the source data? source hypothesis transfer for unsupervised domain adaptation. In International Conference on Machine Learning, pp. 6028–6039. PMLR, 2020. [20] Lopes, R. G., Yin, D., Poole, B., Gilmer, J., and Cubuk, E. D. Improving robustness without sacriﬁcing accuracy with Patch Gaussian augmentation. arXiv preprint arXiv:1906.02611, 2019. 11[21] Mahajan, D., Girshick, R., Ramanathan, V ., He, K., Paluri, M., Li, Y ., Bharambe, A., and van der Maaten, L. Exploring the limits of weakly supervised pretraining. In Proceedings of the European Conference on Computer Vision (ECCV), pp. 181–196, 2018. [22] Orhan, A. E. Robustness properties of Facebook’s ResNeXt WSL models. arXiv preprint arXiv:1907.07640, 2019. [23] Radosavovic, I., Johnson, J., Xie, S., Lo, W.-Y ., and Dollár, P. On network design spaces for visual recognition. In ICCV, 2019. [24] Radosavovic, I., Kosaraju, R. P., Girshick, R., He, K., and Dollár, P. Designing network design spaces. In CVPR, 2020. [25] Recht, B., Roelofs, R., Schmidt, L., and Shankar, V . Do CIFAR-10 classiﬁers generalize to CIFAR-10? arXiv preprint arXiv:1806.00451, 2018. [26] Recht, B., Roelofs, R., Schmidt, L., and Shankar, V . Do ImageNet classiﬁers generalize to ImageNet? In ICML, 2019. [27] Rusak, E., Schott, L., Zimmermann, R., Bitterwolf, J., Bringmann, O., Bethge, M., and Brendel, W. A simple way to make neural networks robust against diverse image corruptions. arXiv preprint arXiv:2001.06057, 2020. [28] Schneider, S., Rusak, E., Eck, L., Bringmann, O., Brendel, W., and Bethge, M. Improving robustness against common corruptions by covariate shift adaptation. In NeurIPS, 2020. [29] Shankar, V ., Dave, A., Roelofs, R., Ramanan, D., Recht, B., and Schmidt, L. Do image classiﬁers generalize across time? arXiv preprint arXiv:1906.02168, 2019. [30] Simard, P. Y ., LeCun, Y . A., Denker, J. S., and Victorri, B. Transformation invariance in pattern recognition—tangent distance and tangent propagation. In Neural networks: tricks of the trade, pp. 239–274. Springer, 1998. [31] Simonyan, K. and Zisserman, A. Very deep convolutional networks for large-scale image recognition. In ICLR, 2015. [32] Sun, Y ., Wang, X., Liu, Z., Miller, J., Efros, A., and Hardt, M. Test-time training with self- supervision for generalization under distribution shifts. In International Conference on Machine Learning, pp. 9229–9248. PMLR, 2020. [33] Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., and Fergus, R. Intriguing properties of neural networks. In ICLR, 2014. [34] Tan, M. and Le, Q. EfﬁcientNet: Rethinking model scaling for convolutional neural networks. In ICML, 2019. [35] Taori, R., Dave, A., Shankar, V ., Carlini, N., Recht, B., and Schmidt, L. Measuring robustness to natural distribution shifts in image classiﬁcation. In NeurIPS, 2020. [36] Touvron, H., Cord, M., Douze, M., Massa, F., Sablayrolles, A., and Jégou, H. Training data- efﬁcient image transformers & distillation through attention. arXiv preprint arXiv:2012.12877, 2020. [37] Wang, D., Shelhamer, E., Liu, S., Olshausen, B., and Darrell, T. Tent: Fully test-time adaptation by entropy minimization. ICLR, 2021. [38] Wu, S., Zhang, H. R., Valiant, G., and Ré, C. On the generalization effects of linear transforma- tions in data augmentation. In ICML, 2020. [39] Xie, Q., Luong, M.-T., Hovy, E., and Le, Q. V . Self-training with Noisy Student improves imagenet classiﬁcation. In CVPR, 2020. [40] Yadan, O. Hydra - a framework for elegantly conﬁguring complex applications. Github, 2019. URL https://github.com/facebookresearch/hydra. 12[41] Yin, D., Lopes, R. G., Shlens, J., Cubuk, E. D., and Gilmer, J. A Fourier perspective on model robustness in computer vision. In NeurIPS, 2019. [42] Zagoruyko, S. and Komodakis, N. Wide residual networks. In BMVC, 2016. [43] Zhang, H., Cisse, M., Dauphin, Y . N., and Lopez-Paz, D. mixup: Beyond empirical risk minimization. In ICLR, 2018. [44] Zhang, H., Wu, C., Zhang, Z., Zhu, Y ., Zhang, Z., Lin, H., Sun, Y ., He, T., Muller, J., Manmatha, R., Li, M., and Smola, A. ResNeSt: Split-Attention Networks. arXiv preprint arXiv:2004.08955, 2020. [45] Zhang, R., Isola, P., Efros, A. A., Shechtman, E., and Wang, O. The unreasonable effectiveness of deep features as a perceptual metric. In CVPR, 2018. [46] Zilly, J., Zilly, H., Richter, O., Wattenhofer, R., Censi, A., and Frazzoli, E. The Frechet Distance of training and test distribution predicts the generalization gap. OpenReview preprint, 2019. URL https://openreview.net/forum?id=SJgSflHKDr. 13Corruption Error Random Closest to Corruptions Farthest from Corruptions Number of Transforms 101 103102 105104 101 103102 105104 101 103102 105104 16 12 14 18 20 22 24 Figure 7: Average corruption error on ImageNet-C as a function the size of a ﬁxed subset of AugMix augmentations. During training, augmentations are only sampled from the subset. The subset is chosen one of three ways: randomly, the most similar augmentations to ImageNet-C, or the least similar augmentations to ImageNet-C. Choosing similar corruptions improves error beyond AugMix, but not by as much that choosing dissimilar augmentations harms it. A Sampling similar augmentations more frequently gives minor performance improvements Here we describe an alternative experiment that shows how the introduction of dissimilar augmenta- tions affects corruption error. For a broad data augmentation scheme that provides robustness to many dissimilar corruptions, each corruption may only have a similar augmentation sampled some small fraction of the time. This small fraction of samples must be sufﬁcient to yield good performance on each corruption to obtain robustness overall. We expect that this should be the case, since neural networks are often good at memorizing rare examples. Additionally, the toy problem in Figure 2 suggests that a large fraction of sampled augmentations may be dissimilar without signiﬁcant loss in corruption error. Here we show the effect using a real augmentation scheme. We consider performance on CIFAR-10-C when training with AugMix augmentations (we do not use their Jensen-Shannon divergence loss, which gives additional improvements). However, instead of sampling directly from the AugMix distribution during training, we ﬁrst sample 100k transforms and sort these transforms by their distance to the CIFAR-10-C corruptions. This sorting is done to evenly distribute the augmentations among the 75 (15 corruptions in 5 severities) individual corruptions; e.g. the ﬁrst 75 augmentations in the list are the closest augmentation to each corruption. Then we take a ﬁxed-size subset A of these transforms and train on augmentations sampled only from this subset using the training parameters from Hendrycks et al. [14]. We select A three different ways: randomly, taking the |A|closest augmentations, and taking the |A|farthest augmentations. We then measure the average corruption error on CIFAR-10-C and plot this error against |A|in Figure 7. First, we note that for randomly sampled augmentations, A does not need to be very large to match AugMix in performance. Even though training on AugMix with our training parameters would normally would produce 5 million uniquely sampled augmentations, only around 1000 are needed to achieve equivalent performance. Training on the closest augmentations exceeds regular AugMix performance with only around 100 unique transforms, which acts as additional evidence that augmentation-corruption similarity correlates with corruption error. This gain in accuracy comes not from having access to better transformations, but from having more frequent access to them at training time. However, the gain is fairly mild at only around 1%, even though the best transformations are sampled all of the time instead of rarely. The gain from frequency is much less than the gain from having more similar augmentations, since choosing the most dissimilar augmentations gives around a 5% drop in accuracy. This suggests that it is a net positive to decrease the frequency of sampling similar augmentations in order to include augmentations similar to another set of corruptions: the gain in accuracy on the new corruption set will likely out weight the small loss in accuracy on the original set. 14Distance Corruption Error MMDMSD 0.2 0.4 0.6 0.8 0.4 0.8 1.2 1.6 Gaussian Noise Zoom Blur Elastic Transform Frost 1.0 1.5 2.0 2.5 3.0  0.4 0.8 1.2 1.6 2.6 2.8 3.0 3.2  3.4  0.9 1.1 1.3 1.5  0.5 0.7 0.9  1.0 1.2 1.4 1.6 20 30 40 50 20 30 40 50 10 15 20 25 10 15 20 25 12 14 16 18 20 12 14 16 18 20 12 16 20 24 12 16 20 24 Figure 8: Example relationships between augmentation-corruption distance and corruption error for two distance scores, MMD and MSD. ρ is the Spearman rank correlation. MMD between an augmentation and corruption distribution is not typically predictive of corruption error. MSD correlates well across all four categories of corruption in CIFAR-10-C. B Additional MSD and MMD experiments B.1 Comparison of MSD and MMD To support the use of MSD for comparing augmentations and corruptions, we conﬁrm here that the more naive measure of MMD correlates poorly with corruption error. We calculate MMD and MSD as deﬁned in Section 3 between each augmentation in the augmentation powerset and the corruptions in CIFAR-10-C. Figure 8 shows a comparison of how MMD and MSD correlate with corruption error on sample corruptions. MMD typically shows poor correlation, while MSD has strong correlation in all four categories of corruption. B.2 Analyzing generalization with MMD In Section 3, we argue distributional equivalence is usually not appropriate for studying augmentation- correlation similarity because augmentation distributions are typically broader than any one corruption distribution. However, were an augmentation perceptually similar to a class of corruptions in the distributional sense, it might suggest at poor generalization to dissimilar corruptions. Using the simple, necessary but insufﬁcient measure we call MMD in Section 3, we can study a weak sense of distributional equivalence. Figure 9 shows example MMD-error correlations. For Patch Guassian, MMD is low for the noise corruptions and high for everything else, while AutoAugment and AugMix, which are constructed out of many visually distinct transforms, show no strong correlation. This suggests the intuitive result that Patch Gaussian does not just have perceptual overlap with the noise corruptions, but is perceptually similar to them in a more distributional sense. We might then expect poorer generalization from Patch Gaussian to corruptions dissimilar from the noise corruptions, which includes ImageNet-C. B.3 MSD vs Batch-Norm Adaptation It is suggested in Schneider et al. [28] that signiﬁcant improvement on a set of corruptions may be obtained by adapting only the batch norm parameters of a model trained on clean data to the statistics of the corrupted dataset. One might then expect that there will be a correlation between augmentation-corruption MSD and the error of a model whose batch norm has been adapted to the 15Impulse Noise Defocus Blur BrightnessContrast MMD Corruption Test Error 2.0 2.2 2.4 2.6 1.0 1.5 2.0 1.0 1.5 2.0 2.5 0.5 1.0 1.5 2.0 5 15 25 35 45 10 15 20 25 20 15 10 5.0 5.5 6.0 6.5 7.0 Patch Gaussian AugmixAutoAugmentBaseline Transform Subsets 20 18 16 14 12 20 18 16 14 12 0.5 1.0 1.5 2.0 0.5 1.0 1.5 2.0 Snow Elastic Transform MMD Corruption Test Error (a) (b) Figure 9: (a) Patch Gaussian shows a low MMD distance on the noise corruptions and a high MMD distance on every other corruption, suggesting that it may be perceptually similar to the noise corruptions in a distributional sense. (b) While AutoAugment contains contrast and brightness augmentations, it is broad enough that it doesn’t have a low MMD to these corruptions. Note that since brightness shows poor correlation for MSD, it is possible that in this case the MMD does not change for other reasons. augmentation distribution. Such a correlation would suggest that a signiﬁcant beneﬁt of performing augmentations comes from making the batch norm statistics of the training set more similar to the corruption set. Here we test this, performing batch norm adaptation as described in Schneider et al. [28], starting from a model trained with default CIFAR-10 augmentation. We choose the one hyperparameter in their algorithm such that the batch norm parameters are adapted completely to the augmented data distribution. Results are shown in Figure 10. We ﬁnd that this still correlates well with MSD (though, as is to be expected, less well than training on the augmentations). This lends support to the claim that batch norm statistics are an important aspect of the choice of augmentation. C MSD Ablation C.1 Architecture choice Here we provide evidence that changing the architecture of the feature extractor used in the deﬁnition of MSD does not have any qualitative effect on the correlation with corruption error. We use a version of VGG-19 with batch normalization that has been modiﬁed for CIFAR-10. Otherwise, all other parameters are chosen the same. We then repeat the experiment of Section 4. In Table 3 and Figure 11, we show that the qualitative results of this experiment are unchanged when using VGG-19-BN as the feature extractor. C.2 Parameter dependencies In calculating the feature space for transforms and MSD, it is necessary to both pick a number of images to average over and a number of corruptions to average over. In our experiments, we use 100 16MSD Corruption Error 45 50 55 60 65 35 40 45 50 40 45 50 55 15 20 25 30 28 24 20 16 12 15 20 25 30 35 42 44 46 48 50 7.0 7.5 8.0 11 12 13 14 26 24 22 20 18 20 22 16 20 24 28 23 25 27 29 21 22 23 24 14 16 18 20 22 1.5 2.0 2.5 3.0 1.0 1.5 2.0 1.0 1.4 1.8 0.2 0.6 1.0 0.2 0.6 1.0 0.2 0.6 1.0 1.4 0.8 1.2 1.6 2.0 0.1 0.2 0.3 0.2 0.4 0.6 0.4 0.8 1.2 0.3 0.5 0.7 0.5 0.7 0.9 1.1 0.8 1.2 1.6 0.2 0.4 0.6 0.8 0.2 0.4 0.6 0.8 Gaussian Noise,  Shot Noise,  Impulse Noise,  Motion Blur,  Defocus Blur, Zoom Blur,  Glass Blur,  Brightness,  Fog,  Frost, Contrast,  Elastic Transform, JPEG Compression, Pixelate, Snow, Figure 10: MSD vs. test error on the speciﬁed corruption. The test error is obtained by adapting a model’s batch norm statistics to the augmented data distribution. The Spearman rank coefﬁcient is given in parenthesis for each corruption. Correlation is still strong but weaker than training the models from scratch on the augmentations. 0.2 0.4 0.6 0.8 0.4 0.8 1.2 1.6 0.6 1.0 1.4 0.2 0.4 0.6 0.8 0.1 0.3 0.5 0.7 0.2 0.6 1.0 1.0 1.5 2.0 0.05 0.10 0.15 0.20 0.1 0.3 0.5 0.4 0.8 1.2 1.0 2.0 3.0 4.0 1.0 2.0 3.0 0.5 1.5 2.5 0.2 0.6 1.0 0.2 0.6 1.0 13 15 17 19 10 20 30 10 30 50 10 15 20 25 25 35 45 55 10 20 30 40 15 20 25 30 5.0 6.0 7.0 5 15 25 35 45 14 18 22 8 10 12 10 15 20 25 12 16 20 12 16 20 24 10 15 20 Gaussian Noise Shot Noise Impulse Noise Motion Blur Defocus Blur Zoom Blur Glass Blur Brightness Fog Frost Snow Contrast Pixelate JPEG Compression Elastic Transform Patch Gaussian AugmixAutoAugmentBaseline Transform Subsets MSD Corruption Test Error Figure 11: MSD vs corruption test error for which MSD is calculated using VGG-19-BN as the architecture for feature extraction. The corruption error is still calculated using WideResNet-40-2. Compare to Figure 13 to see that the qualitative structure of the correlation is the regardless of which architecture is used for the feature extractor. 17Table 3: Spearman’s rank coefﬁcient for the correlation between MSD and corruption error for two architectures in the feature extractor: WideResNet-40-2 and VGG-19-BN. While WideResNet has slightly better correlations overall, the relative behavior across corruptions remains the same for the two architectures. Corruption WRN VGG Gaussian Noise 0.76 0.70 Shot Noise 0.83 0.78 Impulse Noise 0.90 0.92 Motion Blur 0.86 0.81 Defocus Blur 0.83 0.78 Zoom Noise 0.77 0.68 Glass Blur 0.69 0.66 Brightness 0.27 0.08 Corruption WRN VGG Fog 0.68 0.60 Frost 0.66 0.66 Snow 0.65 0.53 Contrast 0.66 0.65 Pixelate 0.35 0.29 JPEG Compression 0.33 0.26 Elastic Transform 0.77 0.74 100 101 102 103 100 101 102 0.1 0.2 0.3 0.4 0.06 0.07 0.08 0.09 0.1 Number of images Number of corruptions (std. dist.) / (mean dist.) Distance variation at 100 corruptions Distance variation at 100 images Figure 12: The standard deviation of the distance between an augmentation and a corruption center, taken over 100 resamplings of images and corruptions. The standard deviation is calculated as a percentage of the mean distance, then averaged over 100 augmentation-corruption pairs. At our choice of parameters, 100 images and 100 corruptions, the standard deviation is only around 5% of the distance. This is smaller than the feature size in the scatter plots of Figure 8 images and 100 corruptions. Here we provide evidence that these are reasonable choices for these parameters. To do so, we use the augmentation scheme from AugMix and corruptions distributions from CIFAR- 10-C to randomly sample 100 augmentation-corruption pairs. Then, for different samplings of a ﬁxed number of images and sampled corruptions, we measure the augmentation-corruption distance in the transform feature space 100 times for each augmentation-corruption pair. We calculate the standard deviation of the distance as a percentage of the mean distance for each augmentation-corruption pair, and average this over pairs. The results are shown in Figure 12. For our choice of image and corruption number, the standard deviation in distance is only around 5% of the mean distance, which is smaller than the size of the features in the scatter plots in Figure 8. D ImageNet- C details D.1 Dataset construction details First, 30 new corruptions, examples of which are shown in Figure 15, are adapted from common image ﬁlters and noise distributions available online [10, 16]. These corruptions are generated in 10 severities such that the image remains human interpretable at all severities and the distribution of errors on a baseline model roughly matches that of ImageNet-C. For each corruption, groups of 5 severities are generated that roughly match the average spread in error across severities in ImageNet-C on a baseline model. Seven of these groups are formed for each corruption, each with one of severity 3 through 8 as the center severity of the group of 5. A candidate dataset is a set of 10 groups of severities, each from a different corruption whose average corruption error on a baseline model is within 1% of ImageNet-C. This is necessary so that a relative decrease in error of data augmented models is normalized against a ﬁxed baseline. Also, more 18Single Frequency Cocentric Sine Waves Blue Noise Blue Noise Sample Voronoi Noise Perlin Noise Plasma Noise Brown Noise Caustic Noise Caustic Refraction Sparkles Inverse Sparkle Checkerboard Lines Scatter Fish Eye Lenses Circular Motion Blur Ripple Pinch and Twirl Water Drop Quadrilateral Transform Perspective Transform Color Dither Chromatic Aberration Transverse Chromatic Aberration Pseudocolor Technicolor Hue Shift Color Balance Bleach Bypass Brown Noise Plasma Noise Single Frequency Inverse Sparkle Checkerboard Perlin Noise Caustic Refraction Blue Noise Sample Cocentric Sine Waves Sparkles Caustic Noise Lines Circular Motion Blur Color Dither Voronoi Noise Chromatic Aberration Technicolor Hue Shift Color Balance Bleach Bypass Transverse Chromatic Aberration Pseudocolor Quadrilateral Transform Water Drop Pinch and Twirl Ripple Scatter Perspective Transform Blue Noise Fish Eye Lenses -0.6 -0.4 -0.2 0.0 0.2 0.4 -0.6 -0.4 -0.2 0.0 0.2 0.4 ImageNetCifar10 Distance shift per standard deviation Figure 13: A corruption’s average contribution to the distance to ImageNet-C, as a fraction of the population’s standard deviation. The blue corruptions are those used to construct ImageNet-C. distorted, harder transforms are likely farther away, so if this wasn’t ﬁxed maximizing distance would likely just pick the hardest transforms in the highest severities. It was computationally infeasible to enumerate all candidate datasets, so they were sampled as follows. For each choice of 5 corruptions, one choice of severities was selected at random so that the average corruption error was within 1% of ImageNet-C, if it existed. Then random disjoint pairs of two sets of 5 were sampled to generate candidate datasets. 100k candidate datasets are sampled. Call the set of all corruption-severity pairs in a dataset C. The distance of a candidate dataset to ImageNet-C is deﬁned as d(Cnew,CIN−C) = Ec∼Cnew [ min c′∼CIN−C dMMD(c,c′) ] , (2) where dMMD is deﬁned in Section 3. The minimum helps assure that new corruptions are far from all ImageNet-C corruptions. This distance is calculated for all 100k sampled candidate datasets. For CIFAR-10, the same parameters described in Section 4 are used to calculate the distance. For ImageNet, the feature extractor is a ResNet-50 trained according to Goyal et al. [11], except color jittering is not used as a data augmentation. Since there is much greater image diversity in ImageNet, we jointly sample 10k images and corruptions instead of independently sampling 100 images and 100 corruptions. Code for measuring distances and training models is based on pyCls [23, 24], and Hydra [40] is used for conﬁguration. The corruptions are then ranked according the their average contribution to the dataset distance. This entire procedure is repeated 10 times for CIFAR and 5 times for ImageNet, and corruption contributions are averaged. The top 10 are chosen to form the new dataset. These rankings are shown in Figure 13. There may still be multiple candidate datasets made up of these 10 corruptions, differing by the choice of severities. Among these across all runs, we pick the one with error closest to ImageNet-C, though there may still be variation in error run-to-run. D.2 Complete results Here we show results comparing ImageNet/CIFAR-10-C to ImageNet/CIFAR-10-C. The 10 trans- forms chosen for ImageNet-C are blue noise sample (BSmpl), plasma noise (Plsm), checkerboard (Ckbd), cocentric sine waves (CSin), single frequency (SFrq), brown noise (Brwn), perlin noise (Prln), inverse sparkle (ISprk), sparkles (Sprk), and caustic refraction (Rfrac). For CIFAR-10- C, there is blue noise sample (BSmpl), brown noise (Brwn), checkerboard (Ckbd), circular motion blur (CBlur), inverse sparkle (ISprk), lines (Line), pinch and twirl (P&T), ripple (Rppl), sparkles (Sprk), and transverse chromatic abberation (TCA). Table 4 compares average results, representing the results from Table 1 in the main text for completeness. A breakdown of ImageNet/CIFAR-10-C results by corruption is in Table 5, including standard deviations for each corruption individually. 19Patch Gaussian Augmix*AutoAugmentBaseline Augmentation powerset Minimal Sample Distance Corruption Error 0.4 0.8 1.2 0.2 0.4 0.6 0.8 0.6 0.8 1.0 1.2 0.4 0.8 1.2 1.0 1.5 2.0 2.5 40 30 20 10 40 30 20 16 20 24 14 10 6 44 40 36 32 28 24 20 12 11 10 9 22 20 18 16 24 20 16 12 50 40 30 20 1.2 1.4 1.6 1.8 0.6 0.8 1.0 1.0 1.5 2.0 0.3 0.4 0.5 0.6 0.4 0.8 1.2 Blue Noise Sample, Checkerboard,  Inverse Sparkles,  Pinch and Twirl,  Ripple, Brown Noise,  Circular Motion Blur,  Lines,  Sparkles,  Transverse Cromatic Abberation, Figure 14: The correlation between MSD and corruption error on the dataset CIFAR-10-C. ρis the Spearman rank correlation. Table 4: Comparison between performance on ImageNet/CIFAR10-C and ImageNet/CIFAR10-C. Standard deviations are over 10 runs for CIFAR-10 and 5 runs for ImageNet. *ANT, DeepAugment (DA), and DeepAugment+AugMix (DA+AM) results use the pre-trained models provided with the respective papers and thus have different training parameters and only one run. IN-C IN- C Aug Err Err ∆IN-C Baseline 58.1±0.4 57.7±0.2 -0.5 AA 55.0±0.2 55.7±0.3 +0.7 SIN 52.4±0.1 55.8±0.3 +3.4 AugMix 49.2±0.7 52.4±0.2 +3.2 PG 49.3±0.2 56.6±0.4 +7.3 ANT* 48.8 53.9 +5.1 DA* 46.6 51.0 +4.4 DA+AM* 41.0 48.3 +7.3 C10-C C10- C Aug Err Err ∆C10-C Baseline 27.0±0.6 27.1±0.5 +0.1 AA 19.4±0.2 21.0±0.4 +1.6 AugMix 11.1±0.2 16.0±0.3 +4.9 PG 17.0±0.4 23.8±0.5 +6.8 Stylized-ImageNet is trained jointly with ImageNet for half the epochs, as is done in Geirhos et al. [9]. ImageNet results are averaged over ﬁve runs, and CIFAR-10 over ten. For each of the ﬁve Stylized-ImageNet runs, we generate a new Stylized-ImageNet dataset using a different random seed and the code provided by Geirhos et al. [9]. D.3 MSD for CIFAR-10-C We repeat the experiment of Section 4 of the main text that measures the correlation between MSD and corruption error using the new corruptions in CIFAR-10-C. Results are shown in Figure 14. We ﬁnd that the correlation is still quite strong for many corruptions, though, like in CIFAR-10-C, there are some corruptions such as inverse sparkleswhere the correlation is weak. E Resource usage WideResNet-40-2 on CIFAR-10 is trained for about 45 minutes to an hour on 1 V100 GPU, while ResNet-50 on ImageNet is trained for approximately 20 hours on 8 V100 GPUS. Collecting augmen- tation features for MSD requires 45 to an hour on 1 V100 GPU. In-memory corruption evaluation and feature extraction for CIFAR-10/ImageNet-C and the newly introduced corruptions is often CPU limited and runtimes vary signiﬁcantly from corruption type to corruption type. This ranges up to approximately 6 hours on 80 Intel Xenon 2.2Ghz CPUs for per corruption and severity for ImageNet, 20Table 5: Breakdown of performance on individual corruptions in ImageNet/CIFAR10-C. Standard deviations are over 10 runs for CIFAR-10 and 5 runs for ImageNet. Examples and full names of each corruption are given in Appendix F. *ANT, DeepAugment (DA), and DeepAugment+AugMix (DA+AM) results use the pre-trained models provided with the respective papers and thus have different training parameters and only one run. ImageNet-C Corruptions Aug BSmpl Plsm Ckbd CSin SFrq Brwn Prln ISprk Sprk Rfrac Baseline 68.6 ±0.5 71.7±0.7 49.4±0.6 84.7±0.5 79.0±0.8 37.5±0.5 34.3±0.1 32.4±0.5 76.7±0.2 42.8±0.2 AA 54.8 ±0.7 68.3±0.7 43.8±1.0 86.5±0.6 78.8±0.9 34.5±0.8 33.8±0.2 36.1±1.0 77.1±1.2 43.8±0.2 SIN 54.7 ±1.5 69.8±1.1 52.8±1.0 79.6±0.4 69.2±0.6 37.8±0.4 35.3±0.1 37.0±0.5 77.3±0.8 44.1±0.2 AugMix 43.2 ±0.8 72.2±0.4 46.1±0.2 76.3±0.3 67.4±0.7 38.8±0.5 32.4±0.1 32.3±0.2 76.4±0.4 39.2±0.2 PG 60.3 ±2.9 74.1±0.7 48.5±1.0 82.1±0.4 76.7±0.8 38.9±0.4 34.6±0.1 32.1±0.7 76.5±0.6 42.1±0.4 ANT* 35.8 75.5 56.9 76.4 63.7 41.0 35.2 35.0 76.1 43.3 DA* 41.7 73.3 53.9 74.6 50.9 37.2 30.3 32.9 74.7 40.9 DA+AM* 34.9 67.9 49.8 69.7 48.0 35.2 30.6 32.9 74.3 39.8 CIFAR-10-C Corruptions Aug BSmpl Brwn Ckbd CBlur ISprk Line P&T Rppl Sprk TCA Baseline 42.9 ±5.1 27.2±0.5 23.3±0.6 11.8±0.4 43.3±0.8 26.2±0.9 11.3±0.3 21.6±1.2 21.0±1.1 42.9±2.7 AA 17.7 ±1.7 17.5±0.5 17.6±0.5 9.5±0.3 40.4±1.5 23.6±0.7 10.7±0.3 23.5±0.5 17.5±0.7 31.8±1.8 AugMix 9.8 ±0.7 27.8±1.3 13.4±0.4 5.9±0.2 30.3±0.7 18.0±0.6 8.3±0.2 12.1±0.4 15.5±0.5 19.2±1.0 PG 9.0 ±1.1 30.1±1.1 21.6±0.8 12.8±0.5 35.4±1.6 20.6±0.5 8.8±0.2 21.5±0.9 19.3±0.5 59.5±3.5 or up to approximately 8 minutes per corruption and severity on 40 CPUs for CIFAR-10. When calculating distances for choosing CIFAR-10/ImageNet-C, CIFAR-10 uses the same amount of time per corruption as evaluation of the corruption, while ImageNet uses 1/5th the time, simply as a result of the number of images processed in each case. F Glossary of transforms This appendix contains examples of the augmentations and corruptions discussed in the text. Figure 15 shows the 30 new corruptions introduced in Section 5. These transforms are adapted from common online ﬁlters and noise sources [10, 16]. They are designed to be human interpretable and cover a wide range transforms, including noise additions, obscuring, warping, and color shifts. Figure 16 shows the 9 base transforms used to build augmentation schemes in the analysis. These are transforms from the Pillow Image Library that are often used as data augmentation. They have no exact overlap with either the corruptions of ImageNet-C or the new corruptions we introduce here. There are ﬁve geometric transforms (shear x/y, translate x/y, and rotate) and four color transforms (solarize, equalize, autocontrast, and posterize). We choose this particular set of augmentations following Hendrycks et al. [14]. Figure 17 shows example corruptions from the ImageNet-C benchmark [13]. They a grouped into four categories: noise (gaussian noise, shot noise, and impulse noise), blurs (motion blur, defocus blur, zoom blur, and glass blur), synthetic weather effects (brightness, fog, frost, and snow), and digital transforms (contrast, pixelate, JPEG compression, and elastic transform). 21Transverse Chromatic  Aberration Chromatic  AberrationColor Dither Quadrilateral Transform Perspective Transform Pseudocolor Technicolor Hue Shift Color Balance Bleach Bypass Water DropPinch and TwirlRippleCircular  Motion BlurFish Eye Lenses ScatterLinesCheckerboardSparkles Caustic RefractionCaustic NoiseBrown NoisePlasma NoisePerlin Noise Voronoi NoiseBlue Noise SampleBlue NoiseSingle Frequency Cocentric  Sine Waves Inverse Sparkle Figure 15: Examples of each corruption considered when building the dataset dissimilar to ImageNet- C. Base image © Sehee Park. 22PosterizeEqualizeSolarize Translate YTranslate X RotateShear X Shear Y AutoContrast Figure 16: The nine base transforms used as augmentations in analysis. Base image © Sehee Park. Elastic TransformJPEG CompressionPixelateSnow FrostFogBrightnessGlass BlurZoom Blur Defocus BlurMotion BlurImpulse NoiseGaussian Noise Shot Noise Contrast Figure 17: Examples of the 15 corruptions in the ImageNet-C corruption benchmark [ 13]. Base image © Sehee Park. 23",
      "meta_data": {
        "arxiv_id": "2102.11273v2",
        "authors": [
          "Eric Mintun",
          "Alexander Kirillov",
          "Saining Xie"
        ],
        "published_date": "2021-02-22T18:58:39Z",
        "pdf_url": "https://arxiv.org/pdf/2102.11273v2.pdf",
        "github_url": "https://github.com/facebookresearch/augmentation-corruption"
      },
      "llm_extracted_info": {
        "main_contributions": "Introduces a transform feature space and a new metric, Minimal Sample Distance (MSD), to quantify perceptual similarity between training-time data augmentations and test-time corruptions; empirically shows MSD strongly predicts corruption error, revealing that many recent augmentation-based robustness gains stem from overlap with benchmark corruptions; constructs new corruption suites (CIFAR-10-C and ImageNet-C) that are far from the original ImageNet-C and demonstrates significant performance drops for state-of-the-art augmentation methods, highlighting limited generalization; publishes code and tools to aid future robustness research.",
        "methodology": "1) Encode any image transform by applying it to a fixed subset of images and averaging the last-layer features of a pretrained classifier, producing vector f(t). 2) Compare augmentation and corruption distributions using MSD: the L2 distance between the corruption-mean vector and the nearest sampled augmentation vector; contrasts with MMD which measures distribution centers. 3) Generate 512 augmentation schemes (powerset of nine Pillow transforms) and compute MSD/error correlations. 4) Train WideResNet-40-2 on CIFAR-10 and ResNet-50 on ImageNet with various modern augmentations (AugMix, AutoAugment, PatchGaussian, ANT, DeepAugment, Stylized-ImageNet) and measure top-1 error on corruption benchmarks. 5) Create new corruption sets by sampling 30 candidate transforms and selecting the 10 that maximize average MMD distance to ImageNet-C while keeping baseline difficulty constant.",
        "experimental_setup": "Datasets: CIFAR-10 and ImageNet for training; benchmarks: original CIFAR-10-C and ImageNet-C (15 corruptions×5 severities) plus newly proposed CIFAR-10-C and ImageNet-C (10 dissimilar corruptions×5 severities). Models: WideResNet-40-2 (CIFAR-10) and ResNet-50 (ImageNet) trained with default augmentation plus tested schemes; additional robust models (WSL ResNeXt, EfficientNet, Noisy Student, ViT, ResNeSt) evaluated for comparison. Validation: compute MSD across 100 images and 100 corruption samples; report Spearman rank correlations; average corruption errors over 5 runs (ImageNet) or 10 runs (CIFAR-10); evaluate per-corruption errors and aggregate scores; adaptation-only batch-norm experiment included.",
        "limitations": "Feature space depends on a pretrained network and might not capture all perceptual aspects; MSD is asymmetric and can mis-rank certain corruptions (e.g., brightness); analysis restricted to synthetic low-level distortions—real-world shifts not evaluated; new corruption selection involves heuristic parameters and limited candidate pool; computational cost for large-scale distance computation and in-memory corruptions; study centers on augmentation-based robustness, leaving other robustness strategies largely unexplored.",
        "future_research_directions": "1) Design augmentation policies that maintain robustness to both similar and dissimilar corruptions, possibly by maximizing minimum MSD coverage. 2) Explore alternative or learned feature spaces that better capture perceptual similarity, including frequency-domain and high-level semantics. 3) Extend evaluation to real-world corruptions and develop methods to predict real-world robustness from synthetic similarity metrics. 4) Combine MSD-driven augmentation selection with automated search or adversarial augmentation generation. 5) Integrate similarity measurements with test-time adaptation or online detection of distribution shifts to trigger model adjustment.",
        "experimental_code": "# -------------------------------------------------------------\n# 1)  Feature extraction utility used to encode a transform t  \n#     into its feature vector f(t).\n# -------------------------------------------------------------\n# File  : overlap/extract_features.py (abridged to essentials)\n# -------------------------------------------------------------\nimport torch\nimport numpy as np\n\ndef distributed_gather_features(curr_features, batch_size, num_gpus):\n    \"\"\"Utility that gathers features from all GPUs and trims padding.\"\"\"\n    gather_list = [torch.zeros((batch_size, curr_features.size(-1)),\n                               device=curr_features.device)\n                   for _ in range(num_gpus)]\n    count = curr_features.size(0)\n    if count < batch_size:                        # pad to full batch for all_gather\n        pad = torch.zeros(batch_size-count, curr_features.size(-1),\n                          device=curr_features.device)\n        curr_features = torch.cat((curr_features, pad), dim=0)\n    torch.distributed.all_gather(gather_list, curr_features)\n    count = torch.tensor([count], device=curr_features.device)\n    torch.distributed.all_reduce(count)\n    count = int(count.item())\n    curr_features = torch.stack(gather_list, dim=1).view(-1, curr_features.size(-1))\n    return curr_features[:count]\n\n\ndef extract_features(feature_extractor, dataset, batch_size, loader_params,\n                     average=True, average_num=None, num_gpus=1):\n    \"\"\"Return features (or mean feature) for `dataset` using `feature_extractor`.\"\"\"\n    sampler = (torch.utils.data.distributed.DistributedSampler(dataset, shuffle=False)\n               if num_gpus > 1 else None)\n    loader = torch.utils.data.DataLoader(dataset,\n                                         batch_size=batch_size,\n                                         shuffle=False,\n                                         sampler=sampler,\n                                         num_workers=loader_params.num_workers,\n                                         pin_memory=loader_params.pin_memory,\n                                         drop_last=False)\n    feats, count = None, 0\n    for inp, _ in loader:\n        inp = inp.cuda(non_blocking=True)\n        curr = feature_extractor.extract(inp)          # last-layer penultimate features\n        if num_gpus > 1:\n            curr = distributed_gather_features(curr, batch_size, num_gpus)\n        if average and average_num is None:            # global mean feature\n            curr = curr.sum(dim=0)\n            torch.distributed.all_reduce(curr) if num_gpus > 1 else None\n            feats = curr if feats is None else feats + curr\n        elif average:                                  # class-conditional means\n            if feats is None:\n                feats = torch.zeros(len(dataset)//average_num, curr.size(-1))\n            feats[count:count+curr.size(0)] += curr.cpu()\n            count = (count + curr.size(0)) % feats.size(0)\n        else:                                          # store all vectors\n            if feats is None:\n                feats = torch.zeros(len(dataset), curr.size(-1))\n            feats[count:count+curr.size(0)] = curr.cpu()\n            count += curr.size(0)\n    if average and average_num is None:\n        feats /= len(dataset)\n    elif average:\n        feats /= average_num\n    return feats.numpy()\n\n# -------------------------------------------------------------\n# 2)  Script that computes MSD and MMD between augmentation and\n#     corruption distributions (experiments/feature_corrupt_error.py)\n# -------------------------------------------------------------\nimport hydra\nimport logging\nfrom hydra.utils import instantiate\nimport numpy as np\nimport torch\nimport omegaconf\nfrom overlap.extract_features import extract_features\n\nlog = logging.getLogger(__name__)\n\n@hydra.main(config_path=\"conf/feature_corrupt_error.yaml\")\ndef main(cfg):\n    torch.manual_seed(cfg.rng_seed)\n    np.random.seed(cfg.rng_seed)\n\n    # (a)  build pretrained feature extractor (frozen network)\n    feature_extractor = instantiate(cfg.ft)\n    feature_extractor.train()\n\n    # (b)  collect/compute f(t) vectors for *augmentation* transforms\n    if cfg.aug_feature_file and os.path.exists(cfg.aug_feature_file):\n        aug_feats = np.load(cfg.aug_feature_file)['features']\n        idx = np.load(cfg.aug_feature_file)['indices']\n    else:\n        aug_ds = instantiate(cfg.ft_augmentation)\n        idx = np.random.choice(len(aug_ds), size=cfg.num_images, replace=False)\n        aug_ds = aug_ds.serialize(idx)                # fixed subset\n        aug_feats = extract_features(feature_extractor, aug_ds,\n                                     cfg.ft_augmentation.batch_size,\n                                     cfg.data_loader,\n                                     average=True,\n                                     average_num=len(idx))\n        if cfg.aug_feature_file:\n            np.savez(cfg.aug_feature_file, features=aug_feats, indices=idx)\n\n    # (c)  compute MSD/MMD between augmentation set and each corruption\n    aug_strings = cfg.ft_corrupt.aug_string.split(\"--\")\n    for aug in aug_strings:\n        with omegaconf.open_dict(cfg):\n            corr_ds = instantiate(cfg.ft_corrupt, aug_string=aug)\n        corr_ds = corr_ds.serialize(idx)              # same image subset\n        corr_feats = extract_features(feature_extractor, corr_ds,\n                                      cfg.ft_corrupt.batch_size,\n                                      cfg.data_loader,\n                                      average=True,\n                                      average_num=len(idx))\n        mean_aug = aug_feats.reshape(-1, aug_feats.shape[-1]).mean(axis=0)\n        mean_corr = corr_feats.reshape(-1, corr_feats.shape[-1]).mean(axis=0)\n        mmd = np.linalg.norm(mean_aug - mean_corr)    # Maximum-Mean Distance\n        msd = np.min(np.linalg.norm(aug_feats.reshape(-1, aug_feats.shape[-1])\n                                    - mean_corr, axis=1))   # Minimum-Sample Distance\n        log.info({\"_type\": aug, \"mmd\": mmd, \"msd\": msd})\n\nif __name__ == \"__main__\":\n    main()\n",
        "experimental_info": "Experimental settings that reproduce the paper’s results\n-------------------------------------------------------\n1.  Base feature encoder\n    • Network:  WideResNet-40-2 for CIFAR-10 or ResNet-50 for ImageNet.\n    • Pre-trained on the clean training set – weights frozen when used as\n      feature extractor (penultimate layer output).\n    • Images are resized to 32×32 (CIFAR-10) or 224×224 (ImageNet) and\n      normalised with the usual dataset means/stds.\n    • Feature vector dimensionality: 1280 (WRN-40-2) or 2048 (ResNet-50).\n\n2.  Image subset S\n    • |S| = 5 000 for CIFAR-10, 50 000 for ImageNet (default in YAML).\n    • The same random subset indices are reused for every transform so that\n      feature differences are only due to the transform, not image content.\n\n3.  Augmentation pool A (512 candidates)\n    • Powerset of 9 Pillow geometric/colour transforms (AutoContrast, Equalize,\n      Posterize, Solarize, ShearX/Y, TranslateX/Y, Rotate).\n    • Severity = 3 for all transforms (unless explicitly swept).\n    • For each candidate t ∈ A, apply t to every x ∈ S and store\n      f(t)=1/|S|∑_x ϕ(x∘t).\n\n4.  Corruption pool C\n    • All 75 corruptions from ImageNet-C and CIFAR-10-C (5 severities\n      1…5 each) plus the newly proposed ‘Bar’ corruptions.\n    • For each corruption c and severity s, compute f(c,s) the same way.\n\n5.  Distance metrics\n    • Maximum-Mean Distance (MMD): ‖mean_A − mean_C‖₂.\n    • Minimum-Sample Distance (MSD): min_{t∈A} ‖f(t) − mean_C‖₂.\n\n6.  Correlation experiment (feature_corrupt_error.py)\n    • For every corruption severity pair compute MSD & MMD w.r.t. the 512\n      augmentation vectors and record the corresponding top-1 error of the\n      classifier trained with a given augmentation method.\n    • Pearson/Spearman correlation between distance metric and error is then\n      reported (done in the accompanying analysis notebook).\n\n7.  Training runs used in paper\n    • CIFAR-10: WideResNet-40-2, batch = 128, SGD 0.1, Cosine LR, 100 epochs.\n    • ImageNet:  ResNet-50, batch = 256, SGD 0.1, Cosine LR, 90 epochs.\n    • Augmentation recipes compared:  Baseline, AugMix, AutoAugment,\n      PatchGaussian, DeepAugment, ANT, Stylised-ImageNet.\n\n8.  Selection of ‘representative’ corruption sets (calc_distance_shifts.py)\n    • Sample 100 000 random 10-corruption sets; keep those whose averaged clean\n      error matches ImageNet-C but maximise average MMD distance.\n    • Used to define the ImageNet-C-Bar benchmark.\n\nAll hyper-parameters above are configurable via the Hydra YAML files shipped\nin experiments/conf/. The defaults correspond to the settings described in the\npaper.\n"
      }
    },
    {
      "title": "Improving robustness against common corruptions by covariate shift adaptation",
      "abstract": "Today's state-of-the-art machine vision models are vulnerable to image\ncorruptions like blurring or compression artefacts, limiting their performance\nin many real-world applications. We here argue that popular benchmarks to\nmeasure model robustness against common corruptions (like ImageNet-C)\nunderestimate model robustness in many (but not all) application scenarios. The\nkey insight is that in many scenarios, multiple unlabeled examples of the\ncorruptions are available and can be used for unsupervised online adaptation.\nReplacing the activation statistics estimated by batch normalization on the\ntraining set with the statistics of the corrupted images consistently improves\nthe robustness across 25 different popular computer vision models. Using the\ncorrected statistics, ResNet-50 reaches 62.2% mCE on ImageNet-C compared to\n76.7% without adaptation. With the more robust DeepAugment+AugMix model, we\nimprove the state of the art achieved by a ResNet50 model up to date from 53.6%\nmCE to 45.4% mCE. Even adapting to a single sample improves robustness for the\nResNet-50 and AugMix models, and 32 samples are sufficient to improve the\ncurrent state of the art for a ResNet-50 architecture. We argue that results\nwith adapted statistics should be included whenever reporting scores in\ncorruption benchmarks and other out-of-distribution generalization settings.",
      "full_text": "Improving robustness against common corruptions by covariate shift adaptation Steffen Schneider∗ University of Tübingen & IMPRS-IS Evgenia Rusak∗ University of Tübingen & IMPRS-IS Luisa Eck LMU Munich Oliver Bringmann† University of Tübingen Wieland Brendel† University of Tübingen Matthias Bethge† University of Tübingen Abstract Today’s state-of-the-art machine vision models are vulnerable to image corruptions like blurring or compression artefacts, limiting their performance in many real- world applications. We here argue that popular benchmarks to measure model robustness against common corruptions (like ImageNet-C) underestimate model robustness in many (but not all) application scenarios. The key insight is that in many scenarios, multiple unlabeled examples of the corruptions are available and can be used for unsupervised online adaptation. Replacing the activation statistics estimated by batch normalization on the training set with the statistics of the corrupted images consistently improves the robustness across 25 different popular computer vision models. Using the corrected statistics, ResNet-50 reaches 62.2% mCE on ImageNet-C compared to 76.7% without adaptation. With the more robust DeepAugment+AugMix model, we improve the state of the art achieved by a ResNet50 model up to date from 53.6% mCE to 45.4% mCE. Even adapting to a single sample improves robustness for the ResNet-50 and AugMix models, and 32 samples are sufﬁcient to improve the current state of the art for a ResNet- 50 architecture. We argue that results with adapted statistics should be included whenever reporting scores in corruption benchmarks and other out-of-distribution generalization settings. 1 Introduction Deep neural networks (DNNs) are known to perform well in the independent and identically dis- tributed (i.i.d.) setting when the test and training data are sampled from the same distribution. However, for many applications this assumption does not hold. In medical imaging, X-ray images or histology slides will differ from the training data if different acquisition systems are being used. In quality assessment, the images might differ from the training data if lighting conditions change or if dirt particles accumulate on the camera. Autonomous cars may face rare weather conditions like sandstorms or big hailstones. While human vision is quite robust to those deviations [1], modern machine vision models are often sensitive to such image corruptions. We argue that current evaluations of model robustness underestimate performance in many (but not all) real-world scenarios. So far, popular image corruption benchmarks like ImageNet-C [IN-C; 2] focus only on ad hoc scenarios in which the tested model has zero prior knowledge about the corruptions it encounters during test time, even if it encounters the same corruption multiple times. In the example of medical images or quality assurance, the image corruptions do not change from sample to sample ∗Equal contribution. †Equal contribution.; Online version and code: domainadaptation.org/batchnorm 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada. arXiv:2006.16971v2  [cs.LG]  23 Oct 2020but are continuously present over a potentially large number of samples. Similarly, autonomous cars will face the same weather condition over a continuous stream of inputs during the same sand- or hailstorm. These (unlabeled) observations can allow recognition models to adapt to the change in the input distribution. Such unsupervised adaptation mechanisms are studied in the ﬁeld of domain adaptation (DA), which is concerned with adapting models trained on one domain (the source, here clean images) to another for which only unlabeled samples exist (the target, here the corrupted images). Tools and methods from domain adaptation are thus directly applicable to increase model robustness against common corruptions, but so far no results on popular benchmarks have been reported. The overall goal of this work is to encourage stronger interactions between the currently disjoint ﬁelds of domain adaptation and robustness towards common corruptions. We here focus on one popular technique in DA, namely adapting batch normalization [BN; 3] statistics [4–6]. In computer vision, BN is a popular technique for speeding up training and is present in almost all current state-of-the-art image recognition models. BN estimates the statistics of activations for the training dataset and uses them to normalize intermediate activations in the network. By design, activation statistics obtained during training time do not reﬂect the statistics of the test distribution when testing in out-of-distribution settings like corrupted images. We investigate and corroborate the hypothesis that high-level distributional shifts from clean to corrupted images largely manifest themselves in a difference of ﬁrst and second order moments in the internal representations of a deep network, which can be mitigated by adapting BN statistics, i.e. by estimating the BN statistics on the corrupted images. We demonstrate that this simple adaptation alone can greatly increase recognition performance on corrupted images. Our contributions can be summarized as follows: • We suggest to augment current benchmarks for common corruptions with two additional performance metrics that measure robustness after partial and full unsupervised adaptation to the corrupted images. • We draw connections to domain adaptation and show that even adapting to a single corrupted sample improves the baseline performance of a ResNet-50 model trained on IN from 76.7% mCE to 71.4%. Robustness increases with more samples for adaptation and converges to a mCE of 62.2%. • We show that the robustness of a variety of vanilla models trained on ImageNet [IN;7, 8] substantially increases after adaptation, sometimes approaching the current state-of-the-art performance on IN-C without adaptation. • Similarly, we show that the robustness of state-of-the-art ResNet-50 models on IN-C consis- tently increases when adapted statistics are used. We surpass the best non-adapted model (52.3% mCE) by almost 7% points. • We show results on several popular image datasets and discuss both the generality and limitations of our approach. • We demonstrate that the performance degradation of a non-adapted model can be well predicted from the Wasserstein distance between the source and target statistics. We propose a simple theoretical model for bounding the Wasserstein distance based on the adaptation parameters. 2 Measuring robustness against common corruptions The ImageNet-C benchmark [2] consists of 15 test corruptions and four hold-out corruptions which are applied with ﬁve different severity levels to the 50 000 test images of the ILSVRC 2012 subset of ImageNet [8]. During evaluation, model responses are assumed to be conditioned only on single samples, and are not allowed to adapt to e.g. a batch of samples from the same corruption. We call this the ad hoc or non-adaptive scenario. The main performance metric on IN-C is the mean corruption error (mCE), which is obtained by normalizing the model’s top-1 errors with the top-1 errors of AlexNet [9] across the C = 15 test corruptions and S = 5 severities (cf. 2): mCE(model) = 1 C C∑ c=1 ∑S s=1 errmodel c,s ∑S s=1 errAlexNetc,s . (1) 2Note that mCE reﬂects only one possible averaging scheme over the IN-C corruption types. We additionally report the overall top-1 accuracies and report results for all individual corruptions in the supplementary material and the project repository. In many application scenarios, this ad hoc evaluation is too restrictive. Instead, often many unlabeled samples with similar corruptions are available, which can allow models to adapt to the shifted data distribution. To reﬂect such scenarios, we propose to also benchmark the robustness of adapted models. To this end, we split the 50 000 validation samples with the same corruption and severity into batches with nsamples each and allow the model to condition its responses on the complete batch of images. We then compute mCE and top-1 accuracy in the usual way. We consider three scenarios: In the ad hoc scenario, we set n= 1 which is the typically considered setting. In the full adaptation scenario, we set n= 50 000, meaning the model may adapt to the full set of unlabeled samples with the same corruption type before evaluation. In the partial adaptation scenario, we set n = 8 to test how efﬁciently models can adapt to a relatively small number of unlabeled samples. 3 Correcting Batch Normalization statistics as a strong baseline for reducing covariate shift induced by common corruptions We propose to use a well-known tool from domain adaptation—adapting batch normalization statis- tics [5, 6]—as a simple baseline to increase robustness against image corruptions in the adaptive evaluation scenarios. IN trained models typically make use of batch normalization [BN; 3] for faster convergence and improved stability during training. Within a BN layer, ﬁrst and second order statis- tics µc,σ2 c of the activation tensors zc are estimated across the spatial dimensions and samples for each feature map c. The activations are then normalized by subtracting the mean µc and dividing by σ2 c. During training, µc and σ2 c are estimated per batch. During evaluation, µc and σ2 c are estimated over the whole training dataset, typically using exponential averaging [10]. Using the BN statistics obtained during training for testing makes the model decisions deterministic but is also problematic if the input distribution changes. If the activation statistics µc,σ2 c change for samples from the test domain, then the activations of feature map care no longer normalized to zero mean and unit variance, breaking a crucial assumption that all downstream layers depend on. Mathematically, this covariate shift2 can be formalized as follows: Deﬁnition 1 (Covariate Shift, cf. 12, 13). There exists covariate shift between a source distribution with density ps : X×Y→ R+ and a target distribution with density pt : X×Y→ R+, written as ps(x,y) = ps(x)ps(y|x) and pt(x,y) = pt(x)pt(y|x), if ps(y|x) = pt(y|x) and ps(x) ̸= pt(x) where y∈Y denotes the class label. Removal of covariate shift. If covariate shift (Def. 1) only causes differences in the ﬁrst and second order moments of the feature activations z = f(x), it can be removed by applying normalization: p ( f(x) −Es[f(x)]√ Vs[f(x)] ⏐⏐⏐x ) ps(x) ≈p ( f(x) −Et[f(x)]√ Vt[f(x)] ⏐⏐⏐x ) pt(x). (2) Reducing the covariate shift in models with batch normalization is particularly straightforward: it sufﬁces to estimate the BN statistics µt,σ2 t on (unlabeled) samples from the test data available for adaptation. If the number of available samples nis too small, the estimated statistics would be too unreliable. We therefore leverage the statistics µs,σ2 s already computed on the training dataset as a prior and infer the test statistics for each test batch as follows, ¯µ= N N + nµs + n N + nµt, ¯σ2 = N N + nσ2 s + n N + nσ2 t. (3) 2Note that our notion of internal covariate shift differs from previous work [ 3, 11]: In i.i.d. training settings, Ioffe and Szegedy [3] hypothesized that covariate shift introduced by changing lower layers in the network is reduced by BN, explaining the empirical success of the method. We do not provide evidence for this line of research in this work: Instead, we focus on the covariate shift introduced (by design) in datasets such as IN-C, and provide evidence for the hypothesis that high-level domain shifts in the input partly manifests in shifts and scaling of internal activations. 31 8 64 512 50 000 40 60 80 100 120 140 Batch size mCE RN50 AM N = ∞(base) N = 0(ours) Nbest (ours) DAug+AM (RN-50 SoTA) N = ∞(base) Nbest (ours) 20 25 30 35 50.0 60.0 70.0 80.0 90.0 100.0 IN top1 error IN-C mCE ResNet DenseNet ResNeXt WRN MNASnet MobileNet ShufﬂeNet GoogLeNet Inception VGG Figure 1: Sample size vs. performance tradeoff in terms of the mean corruption error (mCE) on IN-C for ResNet-50 and AugMix (AM). Black line corresponds to (non-adapted) ResNet50 state- of-the-art performance of DeepAug+AugMix. Figure 2: Across 25 model architectures in the torchvision library, the baseline mCE ( ◦) improves with adaptation ( •), often on the order of 10 points. Best viewed in color. The hyperparameter N controls the trade-off between source and estimated target statistics and has the intuitive interpretation of a pseudo sample size (p. 117, 14) for samples from the training set. The case N →∞ ignores the test set statistics and is equivalent to the standard ad hoc scenario while N = 0 ignores the training statistics. Supported by empirical and theoretical results (see results section and appendix), we suggest using N ∈[8,128] for practical applications with small n< 32. 4 Experimental Setup Models. We consider a large range of models (cf. Table 2, §B,E) and evaluate pre-trained variants of DenseNet [15], GoogLeNet [16], Inception and GoogLeNet [17], MNASnet [18], MobileNet [19], ResNet [20], ResNeXt [21], ShufﬂeNet [22], VGG [23] and Wide Residual Network [WRN,24] from the torchvision library [25]. All models are trained on the ILSVRC 2012 subset of IN comprised of 1.2 million images in the training and a total of 1000 classes [7, 8]. We also consider a ResNeXt-101 variant pre-trained on a 3.5 billion image dataset and then ﬁne-tuned on the IN training set [26]. We evaluate 3 models from the SimCLRv2 framework [27]. We additionally evaluate the four leading methods from the ImageNet-C leaderboard, namely Stylized ImageNet training [SIN; 28], adversarial noise training [ANT;29] as well as a combination of ANT and SIN [29], optimized data augmentation using AutoAugment [AugMix; 30, 31] and Assemble Net [32]. For partial adaptation, we choose N ∈{20,··· ,210}and select the optimal value on the holdout corruption mCE. Datasets. ImageNet-C [IN-C; 2] is comprised of corrupted versions of the 50 000 images in the IN validation set. The dataset offers ﬁve severities per corruption type, for a total of 15 “test” and 4 “holdout” corruptions. ImageNet-A [IN-A; 33] consists of unmodiﬁed real-world images which yield chance level classiﬁcation performance in IN trained ResNet-50 models. ImageNet-V2 [IN- V2; 34] aims to mimic the test distribution of IN, with slight differences in image selection strategies. ObjectNet [ON; 35] is a test set containing 50 000 images like IN organized in 313 object classes with 109 unambiguously overlapping IN classes. ImageNet-R [IN-R; 36] contains 30 000 images with various artistic renditions of 200 classes of the original IN dataset. Additional information on the used models and datasets can be found in §B. For IN, we resize all images to 256 ×256px and take the center 224 ×224px crop. For IN-C, images are already cropped. We also center and re-scale the color values with µRGB = [0.485,0.456,0.406] and σ= [0.229,0.224,0.225]. 5 Results Adaptation boosts robustness of a vanilla trained ResNet-50 model. We consider the pre-trained ResNet-50 architecture from the torchvision library and adapt the running mean and variance on all corruptions and severities of IN-C for different batch sizes. The results are displayed in Fig. 1 where different line styles of the green lines show the number of pseudo-samples N indicating the 4Table 1: Adaptation improves mCE (lower is better) and Top1 accuracy (higher is better) on IN-C for different models and surpasses the previous state of the art without adaptation. We consider n= 8 for partial adaptation. IN-C mCE (↘) Top1 accuracy ( ↗) w/o partial full w/o partial full Model adapt adapt adapt ∆ adapt adapt adapt ∆ Vanilla ResNet-50 76.7 65 .0 62.2 (−14.5) 39.2 48 .6 50.7 (+11.5) SIN [28] 69.3 61 .5 59.5 (−9.8) 45.2 51 .6 53.1 (+7.9) ANT [29] 63.4 56 .1 53.6 (−9.8) 50.4 56 .1 58.0 (+7.6) ANT+SIN [29] 60.7 55 .3 53.6 (−7.0) 52.6 56 .8 58.0 (+5.4) AugMix [AM; 30] 65.3 55 .4 51.0 (−14.3) 48.3 56 .3 59.8 (+11.4) Assemble Net [32] 52.3 – 50.1 (−1.2) 59.2 – 60.8 (+1.5) DeepAug [36] 60.4 52 .3 49.4 (−10.9) 52.6 59 .0 61.2 (+8.6) DeepAug+AM [36] 53.6 48 .4 45.4 (−8.2) 58.1 62 .2 64.5 (+6.4) DeepAug+AM+RNXt101 [36] 44.5 40.7 38.0 (−6.6) 65.2 68.2 70.3 (+5.1) inﬂuence of the prior given by the training statistics. With N = 16, we see that even adapting to a single sample can sufﬁce to increase robustness, suggesting that even the ad hoc evaluation scenario can beneﬁt from adaptation. If the training statistics are not used as a prior ( N = 0), then it takes around 8 samples to surpass the performance of the non-adapted baseline model (76.7% mCE). After around 16 to 32 samples, the performance quickly converges to 62.2% mCE, considerably improving the baseline result. These results highlight the practical applicability of batch norm adaptation in basically all application scenarios, independent of the number of available test samples. Adaptation consistently improves corruption robustness across IN trained models. To evalu- ate the interaction between architecture and BN adaptation, we evaluate all 25 pre-trained models in the torchvision package and visualize the results in Fig. 2. All models are evaluated with N = 0 and n = 2000. We group models into different families based on their architecture and observe consistent improvements in mCE for all of these families, typically on the order of 10% points. We observe that in both evaluation modes, DenseNets [15] exhibit higher corruption robustness despite having a comparable or even smaller number of trainable parameters than ResNets which are usually considered as the relevant baseline architecture. A take-away from this study is thus that model architecture alone plays a signiﬁcant role for corruption robustness and the ResNet architecture might not be the optimal choice for practical applications. Adaptation yields new state of the art on IN-C for robust models. We now investigate if BN adaptation also improves the most robust models on IN-C. The results are displayed in Table 1. All models are adapted using n = 50 000 (vanilla) or n = 4096 (all other models) and N = 0. The performance of all models is considerably higher whenever the BN statistics are adapted. The DeepAugment+AugMix reaches a new state of the art on IN-C for a ResNet-50 architecture of 45.4% mCE. Evaluating the performance of AugMix over the number of samples for adaptation (Fig. 1, we ﬁnd that as little as eight samples are sufﬁcient to improve over AssembleNet [32], the current state-of-the-art ResNet-50 model on IN-C without adaptation. We have included additional results in §C. 6 Analysis and Ablation Studies Severity of covariate shift correlates with performance degradation. The relationship between the performance degradation on IN-C and the covariate shift suggests an unsupervised way of estimating the classiﬁcation performance of a model on a new corruption. Taking the normalized Wasserstein distance (cf. §A) between the statistics of the source and target domains 3 computed on all samples with the same corruption and severity and averaged across all network layers, we ﬁnd a correlation with the top-1 error (Fig. 3 i–iii) of both non-adapted (i) and fully adapted model (ii) on IN-C corruptions. Within single corruption categories (noise, blur, weather, and digital), the relationship between top-1 error and Wasserstein distance is particularly striking: using linear 3For computing the Wasserstein metric we make the simplifying assumption that the empirical mean and covariances fully parametrize the respective distributions. 50 1 2 3 4 20 40 60 80 100 avg W (across layers) Top-1 error (i) µIN,ΣIN on IN-C pred err blur 11.04 digital 6.97 noise 5.84 weather 11.21 pred err blur 5.65 digital 4.14 noise 4.14 weather 7.80 pred err blur 13.43 digital 12.97 noise 13.08 weather 8.98 category test corruptions holdout blur defocus glass motion zoom Gaussian digital contrast elastic pixelate jpeg saturate noise Gaussian shot impulse – speckle weather snow frost fog brightness spatter clean clean 0 1 2 3 4 20 40 60 80 100 avg W (across layers) (ii) µINC,ΣINC on IN-C 0 1 2 3 4 20 40 60 80 100 avg W (across layers) (iii) µINC,ΣINC on IN 1 5 0 2 4 (iv) avgerate W 1 2 3 4 5 (v) Figure 3: The Wasserstein metric between optimal source (IN) and target (IN-C) statistics correlates well with top-1 errors ( i) of non-adapted models on IN-C, ( ii) of adapted models on IN-C, indicating that even after reducing covariate shift, the metric is predictive of the remaining source–target mismatch (iii) IN-C adapted models on IN, the reverse case of (i). Holdout corruptions can be used to get a linear estimate on the prediction error of test corruptions (tables). We depict input and downsample (iv) as well as bottlneck layers (v) and notice the largest shift in early and late downsampling layers. The metric is either averaged across layers ( i–iii) or across corruptions (iv–v). Table 2: Improvements from adapting the BN parameters vanish for models trained with weakly supervised pre-training. IN-C mCE (↘) ResNeXt101 BN BN+adapt 32x8d, IN 66.6 56 .7 (−9.9) 32x8d, IG-3.5B 51.7 51 .6 (−0.1) 32x48d, IG-3.5B 45.7 47.3 (+1.6) Table 3: Fixup and GN trained models perform better than non-adapted BN models but worse than adapted BN models. IN-C mCE (↘) Model Fixup GN BN BN+adapt ResNet-50 72.0 72 .4 76 .7 62.2 ResNet-101 68.2 67 .6 69 .0 59.1 ResNet-152 67.6 65 .4 69 .3 58.0 regression, the top-1 accuracy of hold-out corruptions can be estimated with around 1–2% absolute mean deviation (cf. §C.5) within a corruption, and with around 5–15% absolute mean deviation when the estimate is computed on the holdout corruption of each category (see Fig. 3, typically, a systematic offset remains). In Fig. 3 (iv–v), we display the Wasserstein distance across individual layers and observe that the covariate shift is particularly present in early and late downsampling layers of the ResNet-50. Large scale pre-training alleviates the need for adaptation. Computer vision models based on the ResNeXt architecture [21] pretrained on a much larger dataset comprised of 3.5 ×109 Instagram images (IG-3.5B) achieve a 45.7% mCE on IN-C [26, 37]. We re-evaluate these models with our proposed paradigm and summarize the results in Table 2. While we see improvements for the small model pre-trained on IN, these improvements vanish once the model is trained on the full IG-3.5B dataset. This observation also holds for the largest model, suggesting that training on very large datasets might alleviate the need for covariate shift adaptation. Group Normalization and Fixup Initialization performs better than non-adapted batch norm models, but worse than batch norm with covariate shift adaptation. So far, we considered image classiﬁcation models with BN layers and concluded that using training dataset statistics in BN generally degrades model performance in out-of-distribution evaluation settings. We now consider models trained without BN and study the impact on corruption robustness, similar to Galloway et al. [38]. 61 8 64 512 4096 20 40 60 80 100 Batch size Top1 Error ImageNet V1 vs. V2 ImageNet Threshold Top Matched 1 8 64 512 4096 Batch size ImageNet vs. ObjectNet ImageNet (1k classes) ObjectNet (109 classes) 1 8 64 512 4096 Batch size ImageNet-R Baseline AM Deepaug+AM Figure 4: Batch size vs. performance trade-off for different natural image datasets with no covariate shift (IN, IN-V2), complex and shufﬂed covariate shift (ObjectNet), complex and systematic covariate shift (ImageNet-R). Straight black lines show baseline performance (no adaptation). ImageNet plotted for reference. Table 4: GN and Fixup achieve the best results on ObjectNet (ON). After shufﬂing IN-C corruptions, BN adaptation does no longer decrease the error. Adaptation improves the performance of a vanilla ResNet50 on IN-R. ON Mixed IN-C IN-R ResNet50 top-1 top-5 top-1 top-5 top-1 BN w/o adapt 78.2 60 .9 61 .1 40 .8 63 .8 BN w/ adapt 76.0 58 .9 60 .9 40 .3 59.9 GroupNorm 70.8 49.8 57.3 36 .0 61.2 Fixup 71.5 51 .4 56.8 35.4 65.0 Table 5: Adaptation improves the performance (top-1 error) of robust models on IN-R (n=2048). Model base adapt ∆ ResNet50 63.8 59.9 -3.9 SIN 58.6 54.2 -4.4 ANT 61.0 58.0 -3.0 ANT+SIN 53.8 52.0 -1.8 AugMix (AM) 59.0 55.8 -3.2 DeepAug (DAug) 57.8 52.5 -5.3 DAug+AM 53.2 48.9 -4.3 DAug+AM+RNXt101 47.9 44.0 -3.9 First, using Fixup initialization [39] alleviates the need for BN layers. We train a ResNet-50 model on IN for 100 epochs to obtain a top-1 error of 24.2% and top-5 error of 7.6% (compared to 27.6% reported by Zhang et al. [39] with shorter training, and the 23.9% obtained by our ResNet-50 baseline trained with BN). The model obtains an IN-C mCE of 72.0% compared to 76.7% mCE of the vanilla ResNet-50 model and 62.2% mCE of our adapted ResNet-50 model (cf. Table 3). Additionally, we train a ResNet-101 and a ResNet-152 with Fixup initialization with similar results. Second, GroupNorm [GN; 40] has been proposed as a batch-size independent normalization technique. We train a ResNet-50, a ResNet-101 and a ResNet-152 architecture for 100 epochs and evaluate them on IN-C and ﬁnd results very similar to Fixup. Results on other datasets: IN-A, IN-V2, ObjectNet, IN-R We use N = 0 and vary n in all ablation studies in this subsection. The technique does not work for the case of “natural adversarial examples” of IN-A [ 33] and the error rate stays above 99%, suggesting that the covariate shift introduced in IN-A by design is more severe compared to the covariate shift of IN-C and can not be corrected by merely calculating the correct BN statistics. We are not able to increase performance neither on IN nor on IN-V2, since in these datasets, no domain shift is present by design (see Fig. 4). For ON, the performance increases slightly when computing statistics on more than 64 samples. In Table 4 (ﬁrst and second column), we observe that the GroupNorm and Fixup models perform better than our BN adaptation scheme: while there is a dataset shift in ON compared to IN, BN adaptation is only helpful for systematic shifts across multiple inputs and this assumption is violated on ON. As a control experiment, we sample a dataset “Mixed IN-C” where we shufﬂe the corruptions and severities. In Table 4 (third and fourth column), we now observe that BN adaptation expectedly no longer improves performance. On IN-R, we achieve better results for the adapted model compared to the non-adapted model as well as the GroupNorm and Fixup models, see Table 4 (last column). Additionally, on IN-R, we decrease the top-1 error for a wide range of models through adaptation (see 7Table 5). For IN-R, we observe performance improvements for the vanilla trained ResNet50 when using a sample size of larger than 32 samples for calculating the statistics (Fig. 4, right-most plot). 0.0 5.0σ2 t /σ2 s 0.0 1.0µt − µs minN L (n = 8) 0.0 5.0σ2 t /σ2 s minN U (n = 8) 102 Batchsize n 0.0 0.6√ L 102 Batchsize n 61.22 98.11mCE 100 102 Figure 5: The bound suggests small optimal N for most param- eters (i) and qualitatively explains our empirical observation (ii). A model for correcting covariate shift effects. We evaluate how the batch size for estimating the statistics at test time affects the performance on IN, IN-V2, ON and IN-R in Fig. 4. As expected, for IN the adaptation to test time statistics converges to the performance of the train time statistics in the limit of large batch sizes, see Fig. 4 middle. For IN-V2, we ﬁnd similar results, see Fig. 4 left. This observation shows that ( i) there is no systematic covariate shift between the IN train set and the IN-V2 validation set that could be corrected by using the correct statistics and (ii) is further evidence for the i.i.d. setting pursued by the authors of IN-V2. In case of ON (Fig. 4 right), we see slight improvements when using a batch size bigger than 128. Choosing the number of pseudo-samples N offers an intuitive trade- off between estimating accurate target statistics (low N) and relying on the source statistics (large N). We propose a simple model to investigate optimal choices for N, disregarding all special structure of DNNs, and focusing on the statistical error introduced by estimating ˆµt and ˆσ2 t from a limited number of samples n. To this end, we estimate upper ( U) and lower (L) bounds of the expected squared Wasserstein distance W2 2 as a function of N and the covariate shift which provides good empirical ﬁts between the estimated W and empirical performance for ResNet-50 for different N (Fig. 5; bottom row). Choosing N such that Lor U are minimized (Fig. 5; example in top row) qualitatively matches the values we ﬁnd, see §D for all details. Proposition 1 (Bounds on the expected value of the Wasserstein distance between target and com- bined estimated target and source statistics). We denote the source statistics as µs,σ2 s, the true target statistics as µt,σ2 t and the biased estimates of the target statistics as ˆµt,ˆσ2 t. For normalization, we take a convex combination of the source statistics and estimated target statistics as discussed in Eq. 3. At a conﬁdence level 1 −α, the expectation value of the Wasserstein distanceW2 2 (¯µ,¯σ,µt,σt) between ideal and estimated target statistics w.r.t. to the distribution of sample mean ˆµt and sample variance ˆσ2 t is bounded from above and below with L≤E[W2 2 ] ≤U, where L= ( σt − √ N N + nσ2s + n−1 N + nσ2 t )2 + N2 (N + n)2 (µt −µs)2 + n (N + n)2 σ2 t U = L+ σ5 t (n−1) 2(N + n)2 ( N N + nσ2 s + 1 N + nχ2 1−α/2,n−1σ2 t )−3/2 The quantity χ2 1−α/2,n−1 denotes the left tail value of a chi square distribution with n−1 degrees of freedom, deﬁned as P ( X ≤χ2 1−α/2,n−1 ) = α/2 for X ∼χ2 n−1. Proof: See Appendix §D. 7 Related Work The IN-C benchmark [2] has been extended to MNIST [41], several object detection datasets [42] and image segmentation [43] reﬂecting the interest of the robustness community. Most proposals for improving robustness involve special training protocols, requiring time and additional resources. This includes data augmentation like Gaussian noise [44], optimized mixtures of data augmentations in conjunction with a consistency loss [30], training on stylized images [28, 42, 45] or against adversarial noise distributions [29]. Other approaches tweak the architecture, e.g. by adding shift-equivariance with an anti-aliasing module, [46] or assemble different training techniques [32]. Unsupervised domain adaptation (DA) is a form of transductive inference where additional informa- tion about the test dataset is used to adapt a model to the test distribution. Adapting feature statistics was proposed by Sun et al. [47] and follow up work evaluated the performance of adapting BN parameters in unsupervised [ 5, 6] and supervised DA settings [ 4]. As an application example in medical imaging, Bug et al. [48] show that adaptive normalization is useful for removing domain 8shifts on histopathological data. More involved methods for DA include self-supervised domain adaptation on single examples [49] and pseudo-labeling French et al. [50]. Xie et al. [51] achieve the state of the art on IN-C with pseudo-labeling. In work concurrent to ours, Wang et al. [52] also show BN adaptation results on IN-C. They also perform experiments on CIFAR10-C and CIFAR100-C and explore other domain adaptation techniques. Robustness scores obtained by adversarial training can be improved when separate BN or GroupNorm layers are used for clean and adversarial images [53]. The expressive power of adapting only afﬁne BN parameters BN parameters was shown in multi-task [54] and DA contexts [4] and holds even for ﬁne-tuning randomly initialized ResNets [55]. Concurrent work shows additional evidence that BN adaptation yields increased performance on ImageNet-C [56]. 8 Discussion and Conclusion We showed that reducing covariate shift induced by common image corruptions improves the robustness of computer vision models trained with BN layers, typically by 10–15% points (mCE) on IN-C. Current state-of-the-art models on IN-C can beneﬁt from adaptation, sometimes drastically like AugMix (−14% points mCE). This observation underlines that current benchmark results on IN-C underestimate the corruption robustness that can be reached in many application scenarios where additional (unlabeled) samples are available for adaptation. Robustness against common corruptions improves even if models are adapted only to a single sample, suggesting that BN adaptation should always be used whenever we expect machine vision algorithms to encounter out-of-domain samples. Most further improvements can be reaped by adapting to 32 to 64 samples, after which additional improvements are minor. Our empirical results suggest that the performance degradation on corrupted images can mostly be explained by the difference in feature-wise ﬁrst and second order moments. While this might sound trivial, the performance could also degrade because models mostly extract features susceptible to common corruptions [57], which could not be ﬁxed without substantially adapting the model weights. The fact that model robustness increases after correcting the BN statistics suggests that the features upon which the models rely on are still present in the corrupted images. The opposite is true in other out-of-domain datasets like IN-A or ObjectNet where our simple adaptation scheme does not substantially improve performance, suggesting that here the main problem is in the features that models have learned to use for prediction. Batch Norm itself is not the reason why models are susceptible to common corruptions. While alternatives like Group Normalization and Fixup initialization slightly increase robustness, the adapted BN models are still substantially more robust. This suggests that non-BN models still experience an internal covariate shift on corrupted images, but one that is now absorbed by the model parameters instead of being exposed in the BN layers, making it harder to ﬁx. Large-scale pre-training on orders of magnitude more data (like IG-3.5B) can remove the ﬁrst- and second-order covariate shift between clean and corrupted image samples, at least partially explaining why models trained with weakly supervised training [26] generalize so well to IN-C. Current corruption benchmarks emphasize ad hoc scenarios and thus focus and bias future research efforts on these constraints. Unfortunately, the ad hoc scenario does not accurately reﬂect the information available in many machine vision applications like classiﬁers in medical computer vision or visual quality inspection algorithms, which typically encounter a similar corruption continuously and could beneﬁt from adaptation. This work is meant to spark more research in this direction by suggesting two suitable evaluation metrics—which we strongly suggest to include in all future evaluations on IN-C—as well as by highlighting the potential that even a fairly simple adaptation mechanism can have for increasing model robustness. We envision future work to also adopt and evaluate more powerful domain adaptation methods on IN-C and to develop new adaptation methods speciﬁcally designed to increase robustness against common corruptions. Broader Impact The primary goal of this paper is to increase the robustness of machine vision models against common corruptions and to spur further progress in this area. Increasing the robustness of machine vision 9systems can enhance their reliability and safety, which can potentially contribute to a large range of use cases including autonomous driving, manufacturing automation, surveillance systems, health care and others. Each of these uses may have a broad range of societal implications: autonomous driving can increase mobility of the elderly and enhance safety, but could also enable more autonomous weapon systems. Manufacturing automation can increase resource efﬁciency and reduce costs for goods, but may also increase societal tension through job losses or increase consumption and thus waste. Of particular concern (besides surveillance) is the use of generative vision models for spreading misinformation or for creating an information environment of uncertainty and mistrust. We encourage further work to understand the limitations of machine vision models in out-of- distribution generalization settings. More robust models carry the potential risk of automation bias, i.e., an undue trust in vision models. However, even if models are robust to common corruptions, they might still quickly fail on slightly different perturbations like surface reﬂections. Understanding under what conditions model decisions can be deemed reliable or not is still an open research question that deserves further attention. Acknowledgments and Disclosure of Funding We thank Julian Bitterwolf, Roland S. Zimmermann, Lukas Schott, Mackenzie W. Mathis, Alexander Mathis, Asim Iqbal, David Klindt, Robert Geirhos, other members of the Bethge and Mathis labs and four anonymous reviewers for helpful suggestions for improving our manuscript and providing ideas for additional ablation studies. We thank the International Max Planck Research School for Intelligent Systems (IMPRS-IS) for supporting E.R. and St.S.; St.S. acknowledges his membership in the European Laboratory for Learning and Intelligent Systems (ELLIS) PhD program. This work was supported by the German Federal Ministry of Education and Research (BMBF) through the Tübingen AI Center (FKZ: 01IS18039A), by the Deutsche Forschungsgemeinschaft (DFG) in the priority program 1835 under grant BR2321/5-2 and by SFB 1233, Robust Vision: Inference Principles and Neural Mechanisms (TP3), project number: 276693517. The authors declare no conﬂicts of interests. References [1] Robert Geirhos, Carlos R. M. Temme, Jonas Rauber, Heiko H. Schütt, Matthias Bethge, and Felix A. Wichmann. Generalisation in humans and deep neural networks. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems 31, pages 7538–7550. Curran Associates, Inc., 2018. URL http://papers.nips.cc/paper/ 7982-generalisation-in-humans-and-deep-neural-networks.pdf . [2] Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. In International Conference on Learning Representations (ICLR), 2019. [3] Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In International Conference on Machine Learning (ICLR), 2015. [4] Steffen Schneider, Alexander S Ecker, Jakob H Macke, and Matthias Bethge. Multi-task generalization and adaptation between noisy digit datasets: An empirical study. In Neural Information Processing Systems (NeurIPS), Workshop on Continual Learning, 2018. [5] Fabio Maria Cariucci, Lorenzo Porzi, Barbara Caputo, Elisa Ricci, and Samuel Rota Bulo. Autodial: Automatic domain alignment layers. In 2017 IEEE International Conference on Computer Vision (ICCV), 2017. [6] Yanghao Li, Naiyan Wang, Jianping Shi, Jiaying Liu, and Xiaodi Hou. Revisiting batch normalization for practical domain adaptation. In International Conference on Machine Learning (ICLR), 2017. [7] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. Imagenet large scale visual recognition challenge. International journal of computer vision (IJCV), 2015. [8] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In Conference on computer vision and pattern recognition (CVPR), 2009. [9] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classiﬁcation with deep convolutional neural networks. In Advances in neural information processing systems, pages 1097–1105, 2012. 10[10] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in PyTorch. In NIPS Autodiff Workshop, 2017. [11] Shibani Santurkar, Dimitris Tsipras, Andrew Ilyas, and Aleksander Madry. How does batch normalization help optimization? In Advances in Neural Information Processing Systems (NIPS), 2018. [12] Masashi Sugiyama and Motoaki Kawanabe. Machine learning in non-stationary environments: Introduc- tion to covariate shift adaptation. MIT press, 2012. [13] Bernhard Schölkopf, Dominik Janzing, Jonas Peters, Eleni Sgouritsa, Kun Zhang, and Joris Mooij. On causal and anticausal learning. In Proceedings of the 29th International Coference on International Conference on Machine Learning, ICML’12, page 459–466, Madison, WI, USA, 2012. Omnipress. ISBN 9781450312851. [14] Christopher M. Bishop. Pattern Recognition and Machine Learning (Information Science and Statistics). Springer-Verlag, Berlin, Heidelberg, 2006. ISBN 0387310738. [15] Gao Huang, Zhuang Liu, and Kilian Q. Weinberger. Densely connected convolutional networks. In Conference on Computer Vision and Pattern Recognition (CVPR), 2017. [16] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott E. Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In Conference on Computer Vision and Pattern Recognition (CVPR), 2015. [17] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna. Rethinking the inception architecture for computer vision. In Conference on computer vision and pattern recognition (CVPR), 2016. [18] Mingxing Tan, Bo Chen, Ruoming Pang, Vijay Vasudevan, Mark Sandler, Andrew Howard, and Quoc V Le. Mnasnet: Platform-aware neural architecture search for mobile. In Conference on Computer Vision and Pattern Recognition (CVPR), 2019. [19] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen. Mobilenetv2: Inverted residuals and linear bottlenecks. In Conference on computer vision and pattern recognition (CVPR), 2018. [20] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Conference on computer vision and pattern recognition (CVPR), 2016. [21] Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, and Kaiming He. Aggregated residual transfor- mations for deep neural networks. In Conference on computer vision and pattern recognition (CVPR), 2017. [22] Ningning Ma, Xiangyu Zhang, Hai-Tao Zheng, and Jian Sun. Shufﬂenet v2: Practical guidelines for efﬁcient cnn architecture design. In Proceedings of the European Conference on Computer Vision (ECCV), 2018. [23] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recogni- tion. In International Conference on Learning Representations (ICLR), 2015. [24] Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. CoRR, abs/1605.07146, 2016. [25] Sébastien Marcel and Yann Rodriguez. Torchvision the machine-vision package of torch. In ACM International Conference on Multimedia, 2010. [26] Dhruv Mahajan, Ross Girshick, Vignesh Ramanathan, Kaiming He, Manohar Paluri, Yixuan Li, Ashwin Bharambe, and Laurens van der Maaten. Exploring the limits of weakly supervised pretraining. In Proceedings of the European Conference on Computer Vision (ECCV), 2018. [27] Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geoffrey Hinton. Big self- supervised models are strong semi-supervised learners. CoRR, abs/2006.10029, 2020. [28] Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix A. Wichmann, and Wieland Brendel. Imagenet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness. In International Conference on Learning Representations (ICLR), 2019. [29] Evgenia Rusak, Lukas Schott, Roland Zimmermann, Julian Bitterwolf, Oliver Bringmann, Matthias Bethge, and Wieland Brendel. Increasing the robustness of dnns against image corruptions by playing the game of noise. CoRR, abs/2001.06057, 2020. 11[30] Dan Hendrycks, Norman Mu, Ekin D Cubuk, Barret Zoph, Justin Gilmer, and Balaji Lakshminarayanan. Augmix: A simple data processing method to improve robustness and uncertainty. In International Conference on Learning Representations (ICLR), 2020. [31] Ekin Dogus Cubuk, Barret Zoph, Dandelion Mané, Vijay Vasudevan, and Quoc V . Le. Autoaugment: Learning augmentation policies from data. In Conference on Computer Vision and Pattern Recognition (CVPR), 2019. [32] Jungkyu Lee, Taeryun Won, and Kiho Hong. Compounding the performance improvements of assembled techniques in a convolutional neural network. CoRR, abs/2001.06268, 2020. [33] Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, and Dawn Song. Natural adversarial examples. CoRR, abs/1907.07174, 2019. [34] Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar. Do imagenet classiﬁers generalize to imagenet? In Conference on Computer Vision and Pattern Recognition (CVPR), 2020. [35] Andrei Barbu, David Mayo, Julian Alverio, William Luo, Christopher Wang, Dan Gutfreund, Josh Tenenbaum, and Boris Katz. Objectnet: A large-scale bias-controlled dataset for pushing the limits of object recognition models. In Advances in Neural Information Processing Systems 32, 2019. [36] Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, et al. The many faces of robustness: A critical analysis of out-of-distribution generalization. CoRR, abs/2006.16241, 2020. [37] A Emin Orhan. Robustness properties of facebook’s resnext wsl models. CoRR, abs/1907.07640, 2019. [38] Angus Galloway, Anna Golubeva, Thomas Tanay, Medhat Moussa, and Graham W Taylor. Batch normalization is a cause of adversarial vulnerability. CoRR, abs/1905.02161, 2019. [39] Hongyi Zhang, Yann N Dauphin, and Tengyu Ma. Fixup initialization: Residual learning without normalization. CoRR, abs/1901.09321, 2019. [40] Yuxin Wu and Kaiming He. Group normalization. InProceedings of the European Conference on Computer Vision (ECCV), 2018. [41] Norman Mu and Justin Gilmer. MNIST-C: A robustness benchmark for computer vision. CoRR, abs/1906.02337, 2019. [42] Claudio Michaelis, Benjamin Mitzkus, Robert Geirhos, Evgenia Rusak, Oliver Bringmann, Alexander S Ecker, Matthias Bethge, and Wieland Brendel. Benchmarking robustness in object detection: Autonomous driving when winter is coming. CoRR, abs/1907.07484, 2019. [43] Christoph Kamann and Carsten Rother. Benchmarking the robustness of semantic segmentation models. CoRR, abs/1908.05005, 2019. [44] Nic Ford, Justin Gilmer, Nicolas Carlini, and Dogus Cubuk. Adversarial examples are a natural consequence of test error in noise. In International Conference on Machine Learning (ICML), 2019. [45] Agnieszka Mikołajczyk and Michał Grochowski. Data augmentation for improving deep learning in image classiﬁcation problem. In International Interdisciplinary PhD Workshop (IIPhDW), 2018. [46] Richard Zhang. Making convolutional networks shift-invariant again.International Conference on Machine Learning (ICML), 2019. [47] Baochen Sun, Jiashi Feng, and Kate Saenko. Correlation alignment for unsupervised domain adaptation. In Domain Adaptation in Computer Vision Applications, pages 153–171. Springer, 2017. [48] Daniel Bug, Steffen Schneider, Anne Grote, Eva Oswald, Friedrich Feuerhake, Julia Schüler, and Dorit Merhof. Context-based normalization of histological stains using deep convolutional features. In Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support. Springer, 2017. [49] Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei A Efros, and Moritz Hardt. Test-time training for out-of-distribution generalization. CoRR, abs/1909.13231, 2019. [50] Geoffrey French, Michal Mackiewicz, and Mark H. Fisher. Self-ensembling for domain adaptation. CoRR, abs/1706.05208, 2017. 12[51] Qizhe Xie, Minh-Thang Luong, Eduard Hovy, and Quoc V Le. Self-training with noisy student improves imagenet classiﬁcation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 10687–10698, 2020. [52] Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, and Trevor Darrell. Fully test-time adaptation by entropy minimization. CoRR, abs/2006.10726, 2020. [53] Cihang Xie and Alan L. Yuille. Intriguing properties of adversarial training. In International Conference on Learning Representations (ICLR), 2020. [54] Sylvestre-Alvise Rebufﬁ, Hakan Bilen, and Andrea Vedaldi. Learning multiple visual domains with residual adapters. In Advances in Neural Information Processing Systems (NIPS), 2017. [55] Jonathan Frankle, David J Schwab, and Ari S Morcos. Training batchnorm and only batchnorm: On the expressive power of random features in cnns. CoRR, abs/2003.00152, 2020. [56] Zachary Nado, Shreyas Padhy, D Sculley, Alexander D’Amour, Balaji Lakshminarayanan, and Jasper Snoek. Evaluating prediction-time batch normalization for robustness under covariate shift. CoRR, abs/2006.10963, 2020. [57] Robert Geirhos, Jörn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, and Felix A Wichmann. Shortcut learning in deep neural networks. CoRR, abs/2004.07780, 2020. [58] Cédric Villani. Optimal transport: old and new, volume 338. Springer Science & Business Media, 2008. [59] Logan Engstrom, Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Jacob Steinhardt, and Aleksander Madry. Identifying statistical bias in dataset replication. CoRR, abs/2005.09619, 2020. [60] Dirk Merkel. Docker: Lightweight linux containers for consistent development and deployment. Linux J., 2014(239), March 2014. ISSN 1075-3583. [61] Pauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan Bright, Stéfan J. van der Walt, Matthew Brett, Joshua Wilson, K. Jarrod Millman, Nikolay Mayorov, Andrew R. J. Nelson, Eric Jones, Robert Kern, Eric Larson, CJ Carey, ˙Ilhan Polat, Yu Feng, Eric W. Moore, Jake Vand erPlas, Denis Laxalde, Josef Perktold, Robert Cimrman, Ian Henriksen, E. A. Quintero, Charles R Harris, Anne M. Archibald, Antônio H. Ribeiro, Fabian Pedregosa, Paul van Mulbregt, and SciPy 1. 0 Contributors. SciPy 1.0: Fundamental Algorithms for Scientiﬁc Computing in Python. Nature Methods, 17:261–272, 2020. doi: https://doi.org/10.1038/s41592-019-0686-2. [62] O. Tange. Gnu parallel - the command-line power tool. ;login: The USENIX Magazine, 36(1):42–47, Feb 2011. URL http://www.gnu.org/s/parallel. [63] Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al. Tensorﬂow: A system for large-scale machine learning. In 12th {USENIX}Symposium on Operating Systems Design and Implementation ({OSDI}16), pages 265–283, 2016. [64] Ji Lin. A PyTorch Converter for SimCLR Checkpoints , 2020 (accessed October 21, 2020). URL https://github.com/tonylins/simclr-converter. Commit ID: 139d3cb0bd0c64b5ad32aab810e0bd0a0dddaae0. [65] Eric Weisstein. Standard deviation distribution, 2020. URL https://mathworld.wolfram.com/ StandardDeviationDistribution.html. [66] Robert A. Becker. The variance drain and jensen’s inequality. 2012-004, 2012. [67] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classiﬁcation with deep convolutional neural networks. In Advances in Neural Information Processing Systems (NIPS). 2012. 13Supplementary Material A Distances and divergences for quantifying domain shift 15 A.1 The Wasserstein distance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 A.2 The source-normalized Wasserstein distance . . . . . . . . . . . . . . . . . . . 15 A.3 The Jeffrey divergence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 A.4 Summary statistics and quantiﬁcation of covariate shift between different IN-C conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 B Notes on the experimental setup 19 B.1 Practical considerations for implementing the method . . . . . . . . . . . . . . 19 B.2 Notes on models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 B.3 Hyperparameter tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 B.4 Notes on datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 B.5 Overview of models in torchvision . . . . . . . . . . . . . . . . . . . . . . . . 20 B.6 Baseline corruption errors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 B.7 Software stack . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 C Additional results 22 C.1 Performance of SimCLRv2 models . . . . . . . . . . . . . . . . . . . . . . . . 22 C.2 Relationship between parameter count and IN-C improvements . . . . . . . . . 22 C.3 Per-corruption results on IN-C . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 C.4 Qualitative analysis of similarities between common corruptions . . . . . . . . . 23 C.5 Error prediction based on the Wasserstein distance . . . . . . . . . . . . . . . . 24 C.6 Training details on the models trained with Fixup initialization and GroupNorm . 24 C.7 Effect of Pseudo Batchsize . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 D Analytical error model 27 D.1 Proof sketch . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 D.2 Prerequisites . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 D.3 Proof of Proposition 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 D.4 Extension to multivariate distributions. . . . . . . . . . . . . . . . . . . . . . . 32 D.5 Limits of Proposition 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 D.6 Bounds on the normalized Wasserstein distance . . . . . . . . . . . . . . . . . . 33 E Full list of models evaluated on IN 34 E.1 Torchvision models trained on IN . . . . . . . . . . . . . . . . . . . . . . . . . 34 E.2 Robust ResNet50 models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34 E.3 SimCLRv2 models [27] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 E.4 Robust ResNext models [21] . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 E.5 ResNet50 with Group Normalization [40] . . . . . . . . . . . . . . . . . . . . . 35 E.6 ResNet50 with Fixup initialization [39] . . . . . . . . . . . . . . . . . . . . . . 35 14A Distances and divergences for quantifying domain shift Besides analyzing the performance drop when evaluating a model using source statistics on a target dataset, we consider the mismatch in model statistics directly. We ﬁrst take an ImageNet trained model and adapt it to each of the 95 conditions in IN-C. To obtain a more exact estimate of the true statistics, we split the model into multiple stages with only few BN layers per stage and apply the following simple algorithm4: • Start with image inputs z0 n ←xn from the validation set to adapt to, for each n∈[50000]. • Split the model into multiple stages, h(x) = (fm ◦···◦ f1)(x), where each module fi can potentially contain one or multiple BN layers. We denote the number of BN layers in the i-th module as bi. • For each stage i ∈[m], repeat bi times: zi n ←fi(zi−1 n ) for each n, and update the BN statistics in module fi(zi−1 n ). • Return hwith adapted statistics. Using this scheme, we get source statistics µs and Σs for each layer and µt and Σt for each layer and corruption. In total, we get 96 different collections of statistics across network layers (for IN and the 95 conditions in IN-C). For simplicity, we will not further index the statistics. Note that all covariance matrices considered here are diagonal, which is a further simpliﬁcation. We expect that our domain shift estimates could be improved by considering the full covariance matrices. In the following, we will introduce three possible distances and divergences which can be applied between source and target statistics to quantify the effect of common corruptions induced covariate shift. We consider the Wasserstein distance, a normalized version of the Wasserstein distance, and the Jeffrey divergence. A.1 The Wasserstein distance Given a baseline ResNet-50 model with source statistics µs,Σs on IN, the Wasserstein distance (cf. 58) between the train and test distribution with statistics µt,Σt is given as W2(ps,pt)2 = ∥µs −µt∥2 2 + tr ( Σs + Σt −2 ( Σ1/2 t ΣsΣ1/2 t )1/2) . (4) A.2 The source-normalized Wasserstein distance When estimated for multiple layers across the network, the Wasserstein distance between source and target depends on the overall magnitude of the statistics. Practically, this means the metric is dominated by features with large magnitude (e.g. in the ﬁrst layer of a neural network, which receives larger inputs). To mitigate this issue, we normalize both statistics with the source statistics and deﬁne the normalized Wasserstein distance as ˜W2 2 = W2 2 ( Σ−1/2 s µs,I,Σ−1/2 s µt,Σ−1 s Σt ) (5) = Tr ( I + ΣtΣ−1 s −2Σ1/2 t Σ−1/2 s ) + (µt −µs)TΣ−1 s (µt −µs). (6) In the uni-variate case, the normalized Wasserstein distance ˜W2 2 is equal to the Wasserstein distance W2 2 between source and target statistics divided by σ2 s: ˜W2 2 = W2 2 (µs σs ,1,µt σs ,σ2 t σ2s ) = 1 + σ2 t σ2s −2 σt σs + (µt −µs)2 σ2s = 1 σ2s W2 2 (µs,σ2 s,µt,σ2 t). (7) 4Note that for simplicity, we do not reset the statistics of the remaining (bi −i) BN layers. This could potentially be adapted in future work. 15A.3 The Jeffrey divergence The Jeffrey divergence J(ps,pt) between source distribution ps and target distribution pt is the symmetrized version of the Kullback-Leibler divergence DKL: J(ps,pt) = 1 2 (DKL(ps∥pt) + DKL(pt∥ps)) (8) The Kullback-Leibler divergence between the D-dimensional multivariate normal source and target distributions is deﬁned as DKL(Nt∥Ns) = 1 2 ( Tr ( Σ−1 s Σt ) + (µs −µt)⊤Σ−1 s (µs −µt) −D+ ln (det Σs det Σt )) . (9) The Jeffrey divergence between theD-dimensional multivariate normal source and target distributions then follows as J(Nt,Ns) = 1 4 ( Tr ( Σ−1 s Σt ) + Tr ( Σ−1 t Σs ) + (µs −µt)⊤( Σ−1 s + Σ−1 t ) (µs −µt) −2D ) . (10) A.4 Summary statistics and quantiﬁcation of covariate shift between different IN-C conditions Given the 95 distances/divergences between the baseline (IN) statistics and 95 IN-C conditions, we ﬁrst perform a layer-wise analysis of the statistics and depict the results in Figure 6. The unnormalized Wasserstein distance is sensitive to the magnitude of the source statistics and hence differs qualitatively from the results on the normalized Wasserstein distance and Jeffrey Divergence. We appreciate that the most notable difference between source and target domains is visible in the ResNet-50 downsampling layers. All three metrics suggest that the shift is mainly present in the ﬁrst and ﬁnal layers of the network, supporting the hypothesis that within the common corruption dataset, we have both superﬁcial covariate shift which can be corrected by simple means (such as brightness or contrast variations) in the ﬁrst layers, and also more “high-level” domain shifts which can only be corrected in the later layers of the network. In Figure 7, we more closely analyze this relationship for different common corruptions. We can generally appreciate the increased measures as the corruption severity increases. 161.0.bn1 1.0.bn2 1.0.bn3 1.0 1.1.bn1 1.1.bn2 1.1.bn3 1.2.bn1 1.2.bn2 1.2.bn3 2.0.bn1 2.0.bn2 2.0.bn3 2.0 2.1.bn1 2.1.bn2 2.1.bn3 2.2.bn1 2.2.bn2 2.2.bn3 2.3.bn1 2.3.bn2 2.3.bn3 3.0.bn1 3.0.bn2 3.0.bn3 3.0 3.1.bn1 3.1.bn2 3.1.bn3 3.2.bn1 3.2.bn2 3.2.bn3 3.3.bn1 3.3.bn2 3.3.bn3 3.4.bn1 3.4.bn2 3.4.bn3 3.5.bn1 3.5.bn2 3.5.bn3 4.0.bn1 4.0.bn2 4.0.bn3 4.0 4.1.bn1 4.1.bn2 4.1.bn3 4.2.bn1 4.2.bn2 4.2.bn3 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 Wasserstein Distance downsample bottleneck 0 bottleneck 1 bottleneck 2 1.0.bn1 1.0.bn2 1.0.bn3 1.0 1.1.bn1 1.1.bn2 1.1.bn3 1.2.bn1 1.2.bn2 1.2.bn3 2.0.bn1 2.0.bn2 2.0.bn3 2.0 2.1.bn1 2.1.bn2 2.1.bn3 2.2.bn1 2.2.bn2 2.2.bn3 2.3.bn1 2.3.bn2 2.3.bn3 3.0.bn1 3.0.bn2 3.0.bn3 3.0 3.1.bn1 3.1.bn2 3.1.bn3 3.2.bn1 3.2.bn2 3.2.bn3 3.3.bn1 3.3.bn2 3.3.bn3 3.4.bn1 3.4.bn2 3.4.bn3 3.5.bn1 3.5.bn2 3.5.bn3 4.0.bn1 4.0.bn2 4.0.bn3 4.0 4.1.bn1 4.1.bn2 4.1.bn3 4.2.bn1 4.2.bn2 4.2.bn3 0 1 2 3 4 5 Wasserstein Distance (normalized) downsample bottleneck 0 bottleneck 1 bottleneck 2 1.0.bn1 1.0.bn2 1.0.bn3 1.0 1.1.bn1 1.1.bn2 1.1.bn3 1.2.bn1 1.2.bn2 1.2.bn3 2.0.bn1 2.0.bn2 2.0.bn3 2.0 2.1.bn1 2.1.bn2 2.1.bn3 2.2.bn1 2.2.bn2 2.2.bn3 2.3.bn1 2.3.bn2 2.3.bn3 3.0.bn1 3.0.bn2 3.0.bn3 3.0 3.1.bn1 3.1.bn2 3.1.bn3 3.2.bn1 3.2.bn2 3.2.bn3 3.3.bn1 3.3.bn2 3.3.bn3 3.4.bn1 3.4.bn2 3.4.bn3 3.5.bn1 3.5.bn2 3.5.bn3 4.0.bn1 4.0.bn2 4.0.bn3 4.0 4.1.bn1 4.1.bn2 4.1.bn3 4.2.bn1 4.2.bn2 4.2.bn3 0 10 20 30 40 50 60 Jeffrey Divergence downsample bottleneck 0 bottleneck 1 bottleneck 2 Figure 6: Wasserstein distance, normalized Wasserstein distance and Jeffrey divergence estimated among source and target statistics between different network layers. We report the respective metric w.r.t. to the difference between baseline (IN) and target (IN-C) statistics and show the value averaged across all corruptions. We note that for a ResNet-50 model, downsampling layers contribute most to the overall error. 17brightness contrastdefocusblur elastic transform fog frost gaussianblurgaussiannoise glassblur impulsenoisejpeg compression motionblur pixelatesaturate shotnoise snow spatterspecklenoise zoomblur 1.0.bn1 1.0.bn2 1.0.bn3 1.0 1.1.bn1 1.1.bn2 1.1.bn3 1.2.bn1 1.2.bn2 1.2.bn3 2.0.bn1 2.0.bn2 2.0.bn3 2.0 2.1.bn1 2.1.bn2 2.1.bn3 2.2.bn1 2.2.bn2 2.2.bn3 2.3.bn1 2.3.bn2 2.3.bn3 3.0.bn1 3.0.bn2 3.0.bn3 3.0 3.1.bn1 3.1.bn2 3.1.bn3 3.2.bn1 3.2.bn2 3.2.bn3 3.3.bn1 3.3.bn2 3.3.bn3 3.4.bn1 3.4.bn2 3.4.bn3 3.5.bn1 3.5.bn2 3.5.bn3 4.0.bn1 4.0.bn2 4.0.bn3 4.0 4.1.bn1 4.1.bn2 4.1.bn3 4.2.bn1 4.2.bn2 4.2.bn3 Wasserstein Distance (normalized), across layers and corruptions 0 2 4 6 8 10 12 brightness contrastdefocusblur elastic transform fog frost gaussianblurgaussiannoise glassblur impulsenoisejpeg compression motionblur pixelatesaturate shotnoise snow spatterspecklenoise zoomblur 1.0.bn1 1.0.bn2 1.0.bn3 1.0 1.1.bn1 1.1.bn2 1.1.bn3 1.2.bn1 1.2.bn2 1.2.bn3 2.0.bn1 2.0.bn2 2.0.bn3 2.0 2.1.bn1 2.1.bn2 2.1.bn3 2.2.bn1 2.2.bn2 2.2.bn3 2.3.bn1 2.3.bn2 2.3.bn3 3.0.bn1 3.0.bn2 3.0.bn3 3.0 3.1.bn1 3.1.bn2 3.1.bn3 3.2.bn1 3.2.bn2 3.2.bn3 3.3.bn1 3.3.bn2 3.3.bn3 3.4.bn1 3.4.bn2 3.4.bn3 3.5.bn1 3.5.bn2 3.5.bn3 4.0.bn1 4.0.bn2 4.0.bn3 4.0 4.1.bn1 4.1.bn2 4.1.bn3 4.2.bn1 4.2.bn2 4.2.bn3 Jeffrey Divergence, across layers and corruptions 0 100 200 300 Figure 7: Normalized Wasserstein distance and Jeffrey divergence across corruptions and layers in a ResNet-50. 18B Notes on the experimental setup B.1 Practical considerations for implementing the method Our method is conceptually very easy to implement. We generally recommend to ﬁrst explore the easier variant of the algorithm where N = 0, i.e., no source statistics are used. As shown in our experiments, this setting works well if 100 or more target samples are available. In this case, implementing the method boils down to enabling the training mode for all BN layers across the network. We will discuss this option along with two variants important for application to practical problems: Using exponential moving averaging (EMA) to collect target statistics across multiple batches, and using the source statistics as a prior. Example implementation in PyTorch and caveats We encourage authors of robust models to always evaluate their models, and in particular baseline algorithms on both the train and test set statistics. Implementation in both PyTorch, Tensorﬂow and other machine learning libraries is straightforward and adds only minimal overhead. For PyTorch, adaptation is possible by simply adding def use_test_statistics(module): if isisinstance(module, nn._BatchNorm): module.train() model.eval() model.apply(use_test_statistics) before starting a model evaluation. For the adaptation to a full dataset, we provide a reference implementation with the source code release of this paper. Also, in contrast to the convention of not shufﬂing examples during test time, make sure to enable dataset shufﬂing also during test time in order to compute the correct statistics marginalized over class assignment. Exponential moving averaging In practice, it might be beneﬁcial to keep track of samples already encountered and use a running mean and variance on the test set to normalize new samples. We can conﬁrm that this technique closely matches the full-dataset adaptation case even when evaluating with batch size 1 and is well suited for settings with less powerful hardware, or in general settings where access to the full batch of samples is not possible. Variants of this technique include the adaptation of the decay factor to discard statistics of samples encountered in the past (e.g. when the data domain slowly drifts over time). B.2 Notes on models Note that we only re-evaluate existing model checkpoints, and hence do not perform any hyperpa- rameter tuning or adaptations to model training except for selecting the pseudo batchsize N for the source domain. Depending on the batch size and the architecture, model evaluations are done on one to eight Nvidia RTX 2080 GPUs (i.e., using 12 to 96 GB of memory) or up to four Nvidia V100 GPUs (128 GB of memory). Since we merely re-evaluate trained models, it is also possible to work on less powerful hardware with less memory. In these cases, the aggregation of batch normalization statistics has to be done across several batches using a variant of EMA. B.3 Hyperparameter tuning Our method is generally parameter-free if only target statistics should be considered for normalization. This approach is generally preferred for larger batch sizes nand should also be adapted in practice when a sufﬁcient amount of samples is available. For tuning N, we consider the pre-deﬁned holdout corruptions in IN-C, including speckle noise, saturation, Gaussian blur and spatter using a grid search across different values for N. B.4 Notes on datasets In the main paper, we have used several datasets and provide more relevant information here: 19ImageNet-C (IN-C) For the evaluation on IN-C, we use the JPEG compressed images from github.com/hendrycks/robustness as is advised by the authors to ensure reproducibility. We note that Ford et al. [44] report a decrease in performance when the compressed JPEG ﬁles are used as opposed to applying the corruptions directly in memory without compression artefacts. ObjectNet (ON) We ﬁnd that there are 9 classes with multiple possible mappings from ON to IN (see the list in Table 6); we discard these classes in our evaluation. Models trained on IN experience a large performance drop on the order of 40–45% when tested on ON. ON is an interesting test case for unsupervised domain adaptation since IN and ON are likely sampled from different distributions. ON intentionally shows objects from new viewpoints on new backgrounds. ImageNet-V2 (IN-V2) There are three test sets in IN-V2 that differ in selection frequencies of the MTurk workers. The selection frequency is given by the fraction of MTurk workers who selected an image for its target class. For the “MatchedFrequency” dataset, images were sampled according to the estimated selection frequency of sampling of the original IN validation dataset. For the “Threshold0.7” variant of IN-V2, images were sampled with a selection frequency of at least 0.7. The “TopImages” was sampled from images with the highest selection frequency. Although all three test sets were sampled from the same Flickr candidate pool and were labeled correctly and selected by more than 70% of MTurk workers, the model accuracies on these datasets vary by 14%. The authors observe a systematic accuracy drop when comparing model performance on the original IN validation set and IN-V2 and attribute it to the distribution gap between their datasets and the original IN dataset. They quantify the distribution gap by how much the change from the original distribution to the new distribution affects the considered model. Engstrom et al. analyze the creation process of IN-V2 and identify statistical bias resulting from noisy readings of the selection frequency statistic as a main source of dropping performance [59]. After correcting the bias, [59] ﬁnd that the accuracy drop between IN and IN-V2 measures only 3.6% ± 1.5% of the original 11.7% ± 1.0%. ON class IN classes wheel wheel; paddlewheel, paddle wheel helmet football helmet; crash helmet chair barber chair; folding chair; rocking chair, rocker still_camera Polaroid camera, Polaroid Land camera; reﬂex camera alarm_clock analog clock; digital clock tie bow tie, bow-tie, bowtie; Windsor tie pen ballpoint, ballpoint pen, ballpen, Biro; quill, quill pen; fountain pen bicycle mountain bike, all-terrain bike, off-roader; bicycle-built-for-two, tandem bicycle, tandem skirt hoopskirt, crinoline; miniskirt, mini; overskirt Table 6: Mapping between 9 ambiguous ON classes and the possible correspondences in IN. Different IN classes are separated with a semicolon. B.5 Overview of models in torchvision In Table 7, we provide a list of the models we evaluate in the main paper, along with numbers of trainable parameters and BN parameters. Note that the fraction of BN parameters is at most at 1% compared to all trainable parameters in all considered models. B.6 Baseline corruption errors In Table 8, we report the scores used for converting top-1 error into the mean corruption error (mCE) metric proposed by Hendrycks and Dietterich [2]. B.7 Software stack We use various open source software packages for our experiments, most notably Docker [60], scipy and numpy [61], GNU parallel [62], Tensorﬂow [63], PyTorch [10] and torchvision [25]. 20Model Parameter Count BN Parameters Fraction (%) densenet121 7.98 ×106 8.36 ×104 0.010 densenet161 2.87 ×107 2.20 ×105 0.008 densenet169 1.41 ×107 1.58 ×105 0.011 densenet201 2.00 ×107 2.29 ×105 0.011 googlenet 1.30 ×107 1.51 ×104 0.001 inception-v3 2.72 ×107 3.62 ×104 0.001 mnasnet0-5 2.22 ×106 2.06 ×104 0.009 mnasnet0-75 3.17 ×106 2.98 ×104 0.009 mnasnet1-0 4.38 ×106 3.79 ×104 0.009 mnasnet1-3 6.28 ×106 4.88 ×104 0.008 mobilenet-v2 3.50 ×106 3.41 ×104 0.010 resnet101 4.45 ×107 1.05 ×105 0.002 resnet152 6.02 ×107 1.51 ×105 0.003 resnet18 1.17 ×107 9.60 ×103 0.001 resnet34 2.18 ×107 1.70 ×104 0.001 resnet50 2.56 ×107 5.31 ×104 0.002 resnext101-32x8d 8.88 ×107 2.03 ×105 0.002 shufﬂenet-v2-x0-5 1.37 ×106 7.95 ×103 0.006 shufﬂenet-v2-x1-0 2.28 ×106 1.62 ×104 0.007 shufﬂenet-v2-x1-5 3.50 ×106 2.34 ×104 0.007 shufﬂenet-v2-x2-0 7.39 ×106 3.37 ×104 0.005 vgg11-bn 1.33 ×108 5.50 ×103 4.142 ×10−5 vgg13-bn 1.33 ×108 5.89 ×103 4.425 ×10−5 vgg16-bn 1.38 ×108 8.45 ×103 6.106 ×10−5 vgg19-bn 1.44 ×108 1.10 ×104 7.662 ×10−5 wide-resnet101-2 1.27 ×108 1.38 ×105 0.001 wide-resnet50-2 6.89 ×107 6.82 ×104 0.001 Table 7: Overview of different models with parameter counts. We show the total number of BN parameters, which is a sum of afﬁne parameters. Category Corruption top1 error Noise Gaussian Noise 0.886428 Shot Noise 0.894468 Impulse Noise 0.922640 Blur Defocus Blur 0.819880 Glass Blur 0.826268 Motion Blur 0.785948 Zoom Blur 0.798360 Weather Snow 0.866816 Frost 0.826572 Fog 0.819324 Brightness 0.564592 Contrast 0.853204 Digital Elastic Transform 0.646056 Pixelate 0.717840 JPEG Compression 0.606500 Hold-out Noise Speckle Noise 0.845388 Hold-out Digital Saturate 0.658248 Hold-out Blur Gaussian Blur 0.787108 Hold-out Weather Spatter 0.717512 Table 8: AlexNet top1 errors on ImageNet-C 21Table 9: After converting the checkpoints from TensorFlow to Pytorch, we notice a slight degradation in performance on the IN val set. IN val top-1 accuracy in %. Model TF PyTorch SimCLRv2 ResNet50 76.3 75.6 SimCLRv2 ResNet101 78.2 77.5 SimCLRv2 ResNet152 79.3 78.6 Table 10: Adaptation improves the perfor- mance of the ResNet50 and the ResNet101 model but hurts the performance of the ResNet152 model. ImageNet-C (n=4096), mCE. Model, adaptation: base adapt ∆ SimCLRv2 ResNet50 72.4 68.0 -4.2 SimCLRv2 ResNet101 66.6 65.1 -0.9 SimCLRv2 ResNet152 63.7 64.2 +0.5 107 108 50.0 60.0 70.0 80.0 90.0 100.0 Parameter Count IN-C mCE DenseNet GoogLeNet Inception MNASnet Mobilenet ResNet ResNext ShufﬂeNet VGG WRN Figure 8: Adaptation ( •) improves baseline (◦) mCE across all 25 model architectures in the torchvision library, often on the order of 10% points. Best viewed in color. C Additional results C.1 Performance of SimCLRv2 models We evaluate the performance of 3 models from the SimCLRv2 framework with and without batchnorm adaptation. We test a ResNet50, a ResNet101 and a ResNet152, ﬁnetuned on 100% of IN training data. Since our code-base is in PyTorch, we use the Pytorch-SimCLR-Converter [64] to convert the provided checkpoints from Tensorﬂow to PyTorch. We notice a slight decline in performance when comparing the top-1 accuracy on the IN validation set, see Table 9. For preprocessing, we disable the usual PyTorch normalization and use the PIL.Image.BICUBIC interpolation for resizing because this interpolation is used in the TensorFlow code (instead of the default PIL.Image.BILINEAR in PyTorch). The BN adaptation results for the converted models are shown in Table 10. Adaptation improves the performance of the ResNet50 and the ResNet101 model, but hurts the performance of the ResNet152 model. C.2 Relationship between parameter count and IN-C improvements In addition to Fig. 3 in the main paper, we show the relationship between parameter count and IN-C mCE. In general, we see that the parameter counts correlates with corruption robustness since larger models have smaller mCE values. C.3 Per-corruption results on IN-C We provide more detailed results on the individual corruptions of IN-C for the most important models considered in our study in Fig. 9. The results are shown for models where the BN parameters are 22adapted on the full test sets. The adaptation consistently improves the error rates on all corruptions for both vanilla and AugMix. brightnesscontrast defocus-blur elastic-transform fog frost gaussian-blurgaussian-noise glass-blur impulse-noise jpeg-compression motion-blur pixelatesaturateshot-noise snow spatter speckle-noise zoom-blur 0 20 40 60 80 32 61 61 55 54 62 58 71 73 76 47 61 55 38 73 67 51 65 64 29 46 61 41 39 54 57 57 62 59 41 51 38 31 59 54 42 51 49 top-1 error Vanilla Resnet-50 Baseline Adapted brightnesscontrast defocus-blur elastic-transform fog frost gaussian-blurgaussian-noise glass-blur impulse-noise jpeg-compression motion-blur pixelatesaturateshot-noise snow spatter speckle-noise zoom-blur 0 20 40 60 80 31 49 52 48 53 56 50 59 65 62 40 46 43 36 59 60 44 48 51 26 39 48 35 36 45 46 46 48 48 35 37 32 28 47 44 36 41 37 top-1 error Augmix Baseline Adapted Figure 9: Results on the individual corruptions of IN-C for the vanilla trained ResNet-50 and the AugMix model with and without adaptation. Adaptation reduces the error on all corruptions. C.4 Qualitative analysis of similarities between common corruptions In this analysis, we compute a t-SNE embedding of the Wasserstein distances between the adapted models and the non-adapted model from Section 5, Fig. 4(i) of the main paper. The results are displayed in Fig. 10. We observe that the different corruption categories indicated by the different colors are grouped together except for the ’digital’ category (pink). This visualization shows that corruption categories mostly induce similar shifts in the BN parameters. This might be an explanation why training a model on Gaussian noise generalizes so well to other noise types as has been observed by Rusak et al. [29]: By training on Gaussian noise, the BN statistics are adapted to the Gaussian noise corruption and from Fig. 10, we observe that these statistics are similar to the BN statistics of other noises. −8 −7 −6 −6 −4 −2 0 t-SNE embedding gaussian-noise shot-noise impulse-noise speckle-noise defocus-blur glass-blur motion-blur zoom-blur snow frost fog brightness contrast elastic-transform pixelate Figure 10: t-SNE embeddings of the Wasserstein distances between BN statistics adapted on the different corruptions. This plot shows evidence on the similarities between different corruption types. 23C.5 Error prediction based on the Wasserstein distance In Section 5, Fig. 4(i), we observe that the relationship between the Wasserstein distance and the top-1 error on IN-C is strikingly linear in the considered range of the Wasserstein distance. Similar corruptions and corruption types (indicated by color) exhibit similar slope, allowing to approximate the expected top-1 error rate without any information about the test domain itself. Using the split of the 19 corruptions into 15 test and 4 holdout corruptions [2], we compute a linear regression model on the ﬁve data points we get for each of the holdout corruptions (corresponding to the ﬁve severity levels), and use this model to predict the expected top-1 error rates for the remaining corruptions within the corruption family. This scheme works particularly for the “well deﬁned” corruption types such as noise and digital (4.1% points absolute mean deviation from the real error. The full results are depicted in Table 11. test error holdout (train) error model true pred |∆| true pred |∆| coef intercept Fig. 3 (i) blur 64.89 54.53 11.04 58.13 58.13 3.24 37.59 -0.70 digital 54.37 51.96 6.97 38.08 38.08 0.60 37.20 6.39 noise 73.29 69.68 5.84 64.51 64.51 0.65 24.66 1.68 weather 53.87 42.92 11.21 50.84 50.84 5.48 25.80 6.33 Fig. 3 (ii) blur 55.68 53.28 5.65 57.38 57.38 4.01 42.74 -9.51 digital 41.53 39.80 4.14 31.05 31.05 0.34 23.44 11.09 noise 58.43 55.04 4.14 51.24 51.24 1.01 18.13 5.06 weather 43.84 36.16 7.80 41.63 41.63 4.32 17.80 10.91 Fig. 3 (iii) blur 57.10 69.84 13.43 74.01 74.01 3.96 43.50 5.93 digital 46.16 38.06 12.97 36.22 36.22 10.52 4.94 32.01 noise 93.60 85.84 13.08 81.10 81.10 3.52 22.56 23.65 weather 43.74 36.90 8.98 44.05 44.05 6.20 23.29 3.87 Table 11: Estimating top-1 error of unseen corruptions within the different corruption classes. We note that especially for well deﬁned corruptions (like noise or digital corruptions), the estimation scheme works well. We follow the categorization originally proposed by Hendrycks and Dietterich [2]. C.6 Training details on the models trained with Fixup initialization and GroupNorm In Section 5 of the main paper, we consider IN models trained with GroupNorm and Fixup ini- tialization. For these models, we consider the original reference implementations provided by the authors. We train ResNet-50, ResNet-101 and ResNet-152 models with stochastic gradient descent with momentum (learning rate 0.1, momentum 0.9), with batch size 256 and weight decay 1 ×10−4 for 100 epochs. C.7 Effect of Pseudo Batchsize We show the full results for considering different choices of N for ResNet-50, Augmix, ANT, ANT+SIN and SIN models and display the result in Fig. 12. We observe a characteristic shape which we believe can be attributed to the way statistics are estimated. We provide evidence for this view by proposing an analytical model which we discuss in §D. 241 8 64 512 50 60 70 Batch size mCE Performance for optimal N ResNet AugMix ANT ANT+SIN SIN 1 8 64 512 8 64 512 Batch size Pseudo Batch Size Best Pseudo Batchsize N Figure 11: Left: Performance for all the considered ResNet-50 variants based on the sample batch size. The optimal N is chosen according to the mCE on the holdout corruptions. Right: Best choice for N depending on the input batchsize n. Note that in general for high values n, the model is generally more robust to the choice of N. 1 8 64 512 50 60 70 80 90 100 Batch size mCE resnet N 1 2 4 8 16 32 64 128 256 1 8 64 512 50 60 70 80 90 100 Batch size mCE augmix 1 8 64 512 50 60 70 80 90 100 Batch size mCE sin 1 8 64 512 50 60 70 80 90 100 Batch size mCE ant 1 8 64 512 50 60 70 80 90 100 Batch size mCE antsin Figure 12: Effects of batch size nand pseudo batch size N for the various considered models. We report mCE averaged across 15 test corruptions. 25ResNet-50 1 2 4 8 16 32 64 128 256 1 117.76 98.78 81.06 72.80 71.39 72.72 74.28 75.36 75.99 2 98.11 89.92 80.13 72.36 69.63 70.39 72.39 74.16 75.32 4 81.10 78.45 74.70 70.27 67.48 67.69 69.77 72.19 74.10 8 71.56 70.74 69.44 67.56 65.60 65.02 66.70 69.41 72.07 16 66.82 66.52 66.06 65.32 64.29 63.32 63.81 66.19 69.24 32 64.51 64.39 64.19 63.87 63.38 62.72 62.21 63.22 65.94 64 63.33 63.28 63.19 63.05 62.81 62.43 61.95 61.68 62.90 128 62.78 62.75 62.69 62.62 62.50 62.29 62.00 61.56 61.42 256 62.51 62.49 62.44 62.41 62.32 62.22 62.01 61.73 61.35 512 62.36 62.36 62.33 62.29 62.26 62.17 62.06 61.90 61.62 AugMix 1 2 4 8 16 32 64 128 256 1 122.56 99.72 76.23 65.46 62.08 61.78 62.70 63.75 64.47 2 100.39 88.69 75.16 64.86 60.93 60.51 61.28 62.52 63.67 4 78.55 74.41 68.69 62.52 58.58 58.30 59.53 60.94 62.39 8 65.02 63.81 61.86 59.21 56.39 55.40 56.87 59.00 60.77 16 58.02 57.55 56.96 56.02 54.69 53.44 53.78 56.15 58.71 32 54.37 54.20 53.99 53.68 53.21 52.50 51.99 53.01 55.78 64 52.55 52.50 52.38 52.24 52.07 51.83 51.39 51.25 52.59 128 51.64 51.60 51.54 51.47 51.38 51.26 51.10 50.88 50.89 256 51.18 51.17 51.12 51.08 51.02 50.95 50.86 50.76 50.60 512 50.96 50.95 50.93 50.90 50.86 50.80 50.72 50.65 50.61 ANT 1 2 4 8 16 32 64 128 256 1 116.10 93.58 72.31 62.28 60.07 60.73 61.75 62.48 62.90 2 93.88 83.74 72.01 62.69 58.97 59.10 60.44 61.67 62.44 4 74.51 71.06 66.34 61.15 57.55 57.03 58.51 60.29 61.64 8 63.65 62.50 60.74 58.43 56.04 55.02 56.10 58.22 60.20 16 58.37 57.87 57.14 56.11 54.77 53.67 53.76 55.61 58.06 32 55.78 55.54 55.20 54.66 53.91 53.06 52.50 53.18 55.35 64 54.51 54.41 54.21 53.88 53.42 52.84 52.23 51.94 52.87 128 53.92 53.85 53.71 53.53 53.28 52.85 52.29 51.80 51.65 256 53.66 53.61 53.50 53.37 53.20 52.96 52.54 52.04 51.60 512 53.53 53.49 53.41 53.33 53.21 53.02 52.78 52.38 51.90 ANT+SIN 1 2 4 8 16 32 64 128 256 1 108.24 84.75 67.42 59.91 58.15 58.49 59.24 59.85 60.23 2 87.60 78.40 68.32 60.63 57.54 57.47 58.33 59.23 59.87 4 71.12 68.32 64.31 59.78 56.63 56.06 57.01 58.24 59.23 8 62.23 61.38 59.98 57.93 55.69 54.59 55.30 56.79 58.21 16 57.83 57.51 57.00 56.17 54.96 53.76 53.61 54.92 56.68 32 55.62 55.51 55.33 54.96 54.38 53.55 52.80 53.13 54.73 64 54.57 54.49 54.40 54.25 53.98 53.51 52.84 52.36 52.89 128 54.02 53.98 53.95 53.85 53.72 53.49 53.07 52.53 52.12 256 53.76 53.74 53.71 53.67 53.59 53.47 53.23 52.85 52.33 512 53.64 53.63 53.60 53.57 53.51 53.45 53.35 53.12 52.75 SIN 1 2 4 8 16 32 64 128 256 1 119.11 94.43 74.93 67.03 65.43 66.08 67.16 68.04 68.62 2 98.85 88.62 76.99 67.88 64.23 64.42 65.72 67.02 67.99 4 81.35 78.10 73.38 67.84 63.49 62.47 63.76 65.48 66.94 8 70.92 69.94 68.38 66.02 63.14 61.09 61.45 63.35 65.35 16 65.29 64.97 64.48 63.68 62.39 60.78 59.90 60.92 63.16 32 62.34 62.25 62.08 61.80 61.36 60.55 59.55 59.26 60.65 64 60.84 60.80 60.74 60.61 60.47 60.15 59.67 58.96 58.93 128 60.07 60.04 60.02 59.96 59.87 59.77 59.57 59.18 58.64 256 59.68 59.66 59.64 59.62 59.59 59.53 59.43 59.27 58.97 512 59.48 59.47 59.46 59.44 59.42 59.40 59.33 59.26 59.11 DeepAugment 1 2 4 8 16 32 64 128 256 8 65.37 63.87 61.37 58.11 54.48 52.17 52.33 54.18 56.36 DeepAugment+AugMix 1 2 4 8 16 32 64 128 256 8 52.59 51.98 51.05 49.83 48.5 47.81 48.36 49.72 51.12 ResNext+DeepAugment+Augmix 1 2 4 8 16 32 64 128 256 8 42.09 41.74 41.29 40.67 39.96 39.69 40.35 41.55 42.69 Table 12: Test mCE for various batch sizes (rows) vs. pseudo batch sizes (columns) 26D Analytical error model We consider a univariate model in §D.1–D.3 and discuss a simple extension to the multivariate diagonal case in §D.4. As highlighted in the main text, the model qualitatively explains the overall characteristics of our experimental data. Note that we assume a linear relationship between the Wasserstein distance and the error under domain shift, as suggested by our empirical ﬁndings. Univariate model. We denote the source statistics as µs,σ2 s, the true target statistics as µt,σ2 t and the estimated target statistics as ˆµt,ˆσ2 t. For normalization, we take a convex combination of the source statistics and estimated target statistics: ¯µ= N N + nµs + n N + nˆµt, ¯σ2 = N N + nσ2 s + n N + nˆσ2 t. (11) We now analyze the trade-off between using an estimate closer to the source or closer to the estimated target statistics. In the former case, the model will suffer under the covariate shift present between target and source distribution. In the latter case, small batch sizes nwill yield unreliable estimates for the true target statistics, which might hurt the performance even more than the source-target mismatch. Hence, we aim to gain understanding in the trade-off between both options, and potential optimal choices of N for a given sample size n. As a metric of domain shift with good properties for our following derivation, we leverage the Wasserstein distance. In §5 and §C.5, we already established an empirical link between domain shift measured in terms of the top-1 performance vs. the Wasserstein distance between model statistics and observed a linear relationship for case of common corruptions. Proposition 1 (Bounds on the expected value of the Wasserstein distance between target and com- bined estimated target and source statistics). We denote the source statistics as µs,σ2 s, the true target statistics as µt,σ2 t and the biased estimates of the target statistics as ˆµt,ˆσ2 t. For normalization, we take a convex combination of the source statistics and estimated target statistics as discussed in Eq. 11. At a conﬁdence level 1 −α, the expectation value of the squared Wasserstein distance W2 2 (¯µ,¯σ,µt,σt) between ideal and estimated target statistics w.r.t. to the distribution of sample mean ˆµt and sample variance ˆσ2 t is bounded from above and below with L≤E[W2 2 ] ≤U, where L= ( σt − √ N N + nσ2s + n−1 N + nσ2 t )2 + N2 (N + n)2 (µt −µs)2 + n (N + n)2 σ2 t U = L+ σ5 t (n−1) 2(N + n)2 ( N N + nσ2 s + 1 N + nχ2 1−α/2,n−1σ2 t )−3/2 (12) The quantity χ2 1−α/2,n−1 denotes the left tail value of a chi square distribution with n−1 degrees of freedom, deﬁned as P ( X ≤χ2 1−α/2,n−1 ) = α/2 for X ∼χ2 n−1. D.1 Proof sketch We are interested in the expected value of the Wasserstein distance deﬁned in(A.1) between the target statistics µt,σ2 t and the mixed statistics ¯µ,¯σ2 introduced above in equation (11), taken with respect to the distribution of the sample moments ˆµt, ˆσ2 t. The expectation value itself cannot be evaluated in closed form because the Wasserstein distance contains a term proportional to ¯σbeing the square root of the convex combination of target and source variance. In Lemma 3, the square root term is bounded from above and below using Jensen’s inequality and Holder’s defect formula which is reviewed in Lemma 2. After having bounded the problematic square root term, the proof of Proposition 1 reduces to inserting the expectation values of sample mean and sample variance reviewed in Lemma 1. 27D.2 Prerequisites Lemma 1 (Mean and variance of sample moments, following [65]). The sample moments ˆµt,ˆσ2 t are random variables depending on the sample size n. ˆµt = 1 n n∑ j=1 xj, ˆσ2 t = 1 n n∑ j=1 (xj −ˆµt)2 with xj ∼N ( µt,σ2 t ) . (13) For brevity, we use the shorthandE[·] for all expectation values with respect to the distribution of p(ˆµt,ˆσ2 t|n). In particular, our computation uses mean and variance of ˆµt and ˆσ2 t which are well known for a normal target distribution: ˆµt ∼N ( µt, 1 nσ2 t ) , E[ˆµt] = µt, V[ˆµt] = 1 nσ2 t (14) ˆσ2 t σ2 t/n ∼χ2 n−1, E[ˆσ2 t] = n−1 n σ2 t, V[ˆσ2 t] = σ4 t n2 V [ ˆσ2 t σ2 t/n ] = σ4 t n2 2(n−1). (15) The derivation of the variance V[ˆσ2 t] in the last line uses the fact that the variance of a chi square distributed variable with (n−1) degrees of freedom is equal to 2(n−1). Lemma 2 (Holder’s defect formula for concave functions in probabilistic notation, following Becker [66] ). If the concave function f : [a,b] →R is twice continuously differentiable and there are ﬁnite bounds mand M such that −M ≤f′′(x) ≤−m≤0 ∀x∈[a,b], (16) then the defect between Jensen’s inequality estimatef(E[X]) for a random variable Xtaking values x∈[a,b] and the true expectation value E[f(X)] is bounded from above by a term proportional to the variance of X: f(E[X]) −E[f(X)] ≤1 2MV[X]. (17) Lemma 3 (Upper and lower bounds on the expectation value of ¯σ). The expectation value of the square root of the random variable ¯σ2 deﬁned as ¯σ2 = N N + nσ2 s + n N + nˆσ2 t, (18) is bounded from above and below at a conﬁdence level 1 −αby √ E[¯σ2] −1 2MV[¯σ2] ≤E [√ ¯σ2 ] ≤ √ E[¯σ2] (19) √ E[¯σ2] = √ N N + nσ2s + n−1 N + nσ2 t, (20) 1 2MV[¯σ2] = (n−1) 4(N + n)2 σ4 t ( N N + nσ2 s + 1 N + nχ2 1−α/2,n−1σ2 t ) . (21) The quantity χ2 1−α/2,n−1 denotes the left tail value of a chi square distribution with n−1 degrees of freedom, deﬁned as P ( X ≤χ2 1−α/2,n−1 ) = α/2 for X ∼χ2 n−1. Proof. The square root function is concave, therefore Jensen’s inequality implies the upper bound E [√ ¯σ2 ] ≤ √ E[¯σ2]. (22) The square root of the expectation value of ¯σ2 is computed using the expectation value of the sample variance as given in Lemma 1. √ E[¯σ2] = √ N N + nσ2s + n N + n n−1 n σ2 t = √ N N + nσ2s + n−1 N + nσ2 t. (23) To state a lower bound, we use Holder’s defect formula in probabilistic notation stated in Lemma 2. Holder’s formula for concave functions requires that the random variable ¯σ2 can take values in 28the compact interval [a,b] and that the second derivative of the square root functionf(¯σ2) = √ ¯σ2, exists and is strictly smaller than zero in [a,b]. Regarding the interval of ¯σ2, we provide probabilistic upper and lower bounds. The ratio of sample variance and true variance divided by nfollows a chi square distribution with n−1 degrees of freedom. At conﬁdence level 1 −α, this ratio lies between χ2 1−α/2,n−1 and χ2 α/2,n−1 which are deﬁned as follows: χ2 1−α/2,n−1 ≤ ˆσ2 t σ2 t/n ≤χ2 α/2,n−1, (24) Pr(X ≤χ2 1−α/2,n−1) = α 2 , Pr(X ≥χ2 α/2,n−1) = α 2 . (25) Then at the same conﬁdence level, the sample variance itself lies between the two quantiles multiplied by σ2 t/n, χ2 1−α/2,n−1 σ2 t n ≤ˆσ2 t ≤χ2 α/2,n−1 σ2 t n , (26) and the random variable ¯σ2 lies in the interval ¯σ2 ∈[a,b] with a= N N + nσ2 s + 1 N + nχ2 1−α/2,n−1σ2 t, (27) and b= N N + nσ2 s + 1 N + nχ2 α/2,n−1σ2 t. (28) The variances and chi square values are all positive and therefore bothaand bare positive as well, implying that the second derivative of the square root is strictly negative in the interval[a,b]. f(¯σ2) = √ ¯σ2, f′(¯σ2) = 1 2(¯σ2)−1/2, f′′(¯σ2) = −1 4(¯σ2)−3/2 <0 ∈[a,b]. (29) Consequently the second derivative is in the interval [M,m] at the given conﬁdence level: −M ≤f′′(¯σ2) ≤−m≤0 for ¯σ2 ∈[a,b] with M = 1 4a−3/2, m= 1 4b−3/2. (30) The defect formula 2 states that the defect is bounded by √ E[¯σ2] −E[ √ ¯σ2] ≤1 2MV[¯σ2]. (31) The constant M was computed above in (30), and the variance of ¯σ2 is calculated in the next lines, using the ﬁrst and second moment of the sample variance as stated in 1. V[¯σ2] = E[(¯σ2 −E[¯σ2])2] = E [( n N + nˆσ2 t − n N + n n−1 n σ2 t )2] = n2 (N + n)2 E [( ˆσ2 t −E[ˆσ2 t )2] = n2 (N + n)2 V [ ˆσ2 t ] = n2 (N + n)2 2(n−1) n2 σ4 t = 2(n−1) (N + n)2 σ4 t. (32) Inserting V[¯σ2] computed in (32) and M deﬁned in (30) with aas deﬁned in (27) into the defect formula (31) yields the lower bound: √ E[¯σ2] −1 2MV[¯σ2] ≤E[ √ ¯σ2] √ E[¯σ2] −1 2MV[¯σ2] = √ E[¯σ2] −1 2 ·1 4a−3/2 2(n−1) (N + n)2 σ4 t = √ E[¯σ2] − (n−1) 4(N + n)2 σ4 t ( N N + nσ2 s + 1 N + nχ2 1−α/2,n−1σ2 t )−3/2 . (33) Assuming that source and target variance are of the same order of magnitude σ, the defect will be of order of magnitude σ: The factor V[X] scales with σ4 and M with σ−3. 29D.3 Proof of Proposition 1 Proof. For two univariate normal distributions with moments µt,σ2 t and ¯µ,¯σ2, the Wasserstein distance as deﬁned in (A.1) reduces to W2 2 = σ2 t + ¯σ2 −2¯σσt + (¯µ−µ)2. (34) The expected value of the Wasserstein distance across many batches is given as E[W2 2 ] = σ2 t + E[¯σ2] −2E[¯σ]σt + E[(µt −¯µ)2] = σ2 t + N N + nσ2 s + n N + n n−1 n σ2 t −2σtE [√ N N + nσ2s + n N + nˆσ2 t ] + E [( µt − N N + nµs − n N + nˆµt )2] (35) which can already serve as the basis for our numerical simulations. To arrive at a closed form analytical solution, we invoke Lemma 3 to bound the expectation value E[¯σ] in equation (35). −2σt √ E[¯σ2] ≤−2σtE [√ ¯σ2 ] ≤−2σt √ E[¯σ2] −2σt ( −1 2MV[¯σ2] ) (36) Apart from the square root term bounded in equation (36) above, the expectation value of the Wasserstein distance can be computed exactly. Hence the bounds on E[¯σ] multiplied by a factor of (−2σ2 t) coming from equation (35) determine lower and upper bounds Land U on the expected value of W2 2 : L≤E [ W2 2 ] ≤U = L+ σtMV[¯σ2] (37) In the next lines, the lower bound is calculated: L= σ2 t + N N + nσ2 s + n−1 N + nσ2 t −2σt √ E [ N N + nσ2s + n−1 N + nσ2 t ] + ( µt − N N + nµs )2 −2 ( µt − N N + nµs ) n N + nE[ˆµt] + n2 (N + n)2 ( V[ˆµt] + (E[ˆµt])2 ) = σ2 t + N N + nσ2 s + n−1 N + nσ2 t −2σt √ N N + nσ2s + n−1 N + nσ2 t + ( µt − N N + nµs )2 −2 ( µt − N N + nµs ) n N + nµt + n2 (N + n)2 (1 nσ2 t + µ2 t ) = ( σt − √ N N + nσ2s + n−1 N + nσ2 t )2 + ( µt − N N + nµs − n N + nµt )2 + n (N + n)2 σ2 t = ( σt − √ N N + nσ2s + n−1 N + nσ2 t )2 + N2 (N + n)2 (µt −µs)2 + n (N + n)2 σ2 t (38) After having derived the lower bound, the upper bound is the sum of the lower bound and the defect term as computed in Lemma 3. E[W2] ≥U = L+ σtMV[¯σ2] = L+ σt 1 4 ( N N + nσ2 s + n N + nχ2 1−α/2,n−1 σ2 t n )−3/2 2(n−1) (N + n)2 σ4 t = L+ ( N N + nσ2 s + 1 N + nχ2 1−α/2,n−1σ2 t )−3/2 (n−1) 2(N + n)2 σ5 t. (39) Based on choices of the model parameters, the model qualitatively matches our experimental results. We plot different choices in Fig. 13. 30(0.00, 0.03) (0.00, 0.05) (0.00, 0.08) (0.00, 0.10) (0.00, 0.13) (0.00, 0.15) (0.00, 0.18) (0.00, 0.20) (0.00, 0.23) (0.00, 0.25) (0.01, 0.03) (0.01, 0.05) (0.01, 0.08) (0.01, 0.10) (0.01, 0.13) (0.01, 0.15) (0.01, 0.18) (0.01, 0.20) (0.01, 0.23) (0.01, 0.25) (0.01, 0.03) (0.01, 0.05) (0.01, 0.08) (0.01, 0.10) (0.01, 0.13) (0.01, 0.15) (0.01, 0.18) (0.01, 0.20) (0.01, 0.23) (0.01, 0.25) (0.02, 0.03) (0.02, 0.05) (0.02, 0.08) (0.02, 0.10) (0.02, 0.13) (0.02, 0.15) (0.02, 0.18) (0.02, 0.20) (0.02, 0.23) (0.02, 0.25) (0.02, 0.03) (0.02, 0.05) (0.02, 0.08) (0.02, 0.10) (0.02, 0.13) (0.02, 0.15) (0.02, 0.18) (0.02, 0.20) (0.02, 0.23) (0.02, 0.25) (0.03, 0.03) (0.03, 0.05) (0.03, 0.08) (0.03, 0.10) (0.03, 0.13) (0.03, 0.15) (0.03, 0.18) (0.03, 0.20) (0.03, 0.23) (0.03, 0.25) (0.03, 0.03) (0.03, 0.05) (0.03, 0.08) (0.03, 0.10) (0.03, 0.13) (0.03, 0.15) (0.03, 0.18) (0.03, 0.20) (0.03, 0.23) (0.03, 0.25) (0.04, 0.03) (0.04, 0.05) (0.04, 0.08) (0.04, 0.10) (0.04, 0.13) (0.04, 0.15) (0.04, 0.18) (0.04, 0.20) (0.04, 0.23) (0.04, 0.25) (0.04, 0.03) (0.04, 0.05) (0.04, 0.08) (0.04, 0.10) (0.04, 0.13) (0.04, 0.15) (0.04, 0.18) (0.04, 0.20) (0.04, 0.23) (0.04, 0.25) (0.05, 0.03) (0.05, 0.05) (0.05, 0.08) (0.05, 0.10) (0.05, 0.13) (0.05, 0.15) (0.05, 0.18) (0.05, 0.20) (0.05, 0.23) (0.05, 0.25) Figure 13: Overview of different parametrizations of the model. We denote each plot with (µt −µs,σt/σs) and report the lower bound √ L on the Wasserstein distance. Parametrizations in columns four to seven produce qualitatively similar results we observed in our experiments, assuming a linear relationship between the Wasserstein distance and the error rate. 31D.4 Extension to multivariate distributions. We now derive a multivariate variant that can be ﬁt to data from a DNN. Due to the estimation of running statistics in the network, we have access to a diagonal approximation of the true covariance matrix. We denote the diagonal covariance matrices with matrix elements σ2 i as (Σt)ii = (σ2 t)i, (ˆΣt)ii = (ˆσ2 t)i, (Σs)ii = (σ2 s)i (40) and extend our deﬁnition of the statistics used for normalization to ¯µ and ¯Σ: ¯µ = N N + nµs + n N + nˆµt, ¯Σ = N N + nΣs + n N + n ˆΣt. (41) The Wasserstein distance between ¯µ, ¯Σ and µt,Σt is then deﬁned as W2 2 = Tr Σt + ¯Σ −2Σ1/2 t ¯Σ1/2 + (µt −¯µ)T(µt −¯µ) = D∑ i=1 (σ2 t)i + (¯σ2)i −2(¯σ)i(σt)i + ((µt)i −(¯µt)i)2 = D∑ i=1 (W2 2 )i (42) Every component (W2 2 )i in the sum above is bounded by the univariate bound discussed above. The multivariate Wasserstein distance which sums over the diagonal covariance matrix entries is then bounded by the sums over the individual bounds Li and Ui given in (12). Li ≤(W2 2 )i ≤Ui ⇒ D∑ i=1 Li ≤W2 2 ≤ D∑ i=1 Ui. (43) D.5 Limits of Proposition 1 Limit n→∞ In the limit of inﬁnite batch size n→∞, upper and lower bounds on the expected Wasserstein distance between ¯µ,¯σ2 and µt,σ2 t both go to zero. lim n→∞ L= lim n→∞ ( σt − √ N N + nσ2s + n−1 N + nσ2 t )2 + N2 (N + n)2 (µt −µs)2 + n (N + n)2 σ2 t =(σt −σt)2 = 0 lim n→∞ U = lim n→∞ L+ lim n→∞ σ5 t (n−1) 2(N + n)2 ( N N + nσ2 s + 1 N + nχ2 1−α/2,n−1σ2 t )−3/2 = 0. (44) The intuition behind this limit is that if a large number of samples from the target domain is given, ˆµ and ˆσ2 approximate the true target statistics very well. As ˆµand ˆσ2 dominate ¯µand ¯σ2 for large n, the expected Wasserstein distance has to vanish. Limit N →∞ In the opposite limit N →∞, the expected value of the Wasserstein distance reduces to the Wasserstein distance between source and target statistics. lim N→∞ ¯µ= µs, lim N→∞ ¯σ2 = σ2 s, (45) ⇒ lim N→∞ E[W2 2 ] = σ2 t + σ2 s −2σtσs + (µt −µs)2 = W2 2 ( µs,σ2 s,µt,σ2 t ) . (46) Limiting case µt = µs and σ2 t = σ2 s When source and target domain coincide, and the statistics σ2 s = σ2 t and µs = µt are known, then the source target mismatch is not an error source. However, one might assume that source and target domain are different even though they actually coincide. In this case, proceeding with our proposed strategy and using the statistics ¯µ and ¯σ2, the bounds on the expected Wasserstein distance follow from setting σ2 t to σ2 s and µt to µs in 32Proposition 1. ¯µ= N N + nµt + n N + nˆµt, ¯σ2 = N N + nσ2 t + n N + nˆσ2 t, L≤E[W2 2 ] ≤U L= σ2 t ( 2N2 + 4Nn −N + 2n2 (N + n)2 −2 √ 1 − 1 N + n ) , U = L+ σ2 t n−1 2(N + n)2 ( N + χ2 1−α/2,n−1 N + n )−3/2 . (47) It could also be the case that the equality of source and target statistics is known but the concrete values of the statistics are unknown. In our model, this amounts to setting the number of pseudo samples N to zero and assuming that source and target statistics are equal. Setting N = 0 in equation (47) and keeping nﬁnite yields L= 2σ2 t ( 1 − √ 1 −1 n ) , U= L+ σ2 t n−1 2n2 ( χ2 1−α/2,n−1 n )−3/2 . (48) D.6 Bounds on the normalized Wasserstein distance The Wasserstein distance (cf. §A.1) between the interpolating statistics ¯µ, ¯σ2 and the target statistics can also be normalized by a factor of σ−2 s . Because σ−2 s is constant, the bounds on the expectation value of the unnormalized Wasserstein distance discussed in the previous subsections just have to be multiplied by σ−2 s to obtain bounds on the normalized Wasserstein distance (cf. §A.2): L σ2s ≤˜W2 2 = W2 2 ( ¯µ σs ,, ¯σ2 σ2s ,µt σs ,σ2 t σ2s ) = 1 σ2s W2 2 (¯µ,¯σ2,µt,σ2 t) ≤ U σ2s . (49) 33E Full list of models evaluated on IN The following lists contains all models we evaluated on various datasets with references and links to the corresponding source code. E.1 Torchvision models trained on IN Weights were taken from https://github.com/pytorch/vision/tree/master/ torchvision/models 1. alexnet [67] 2. densenet121 [15] 3. densenet161 [15] 4. densenet169 [15] 5. densenet201 [15] 6. densenet201 [15] 7. googlenet [16] 8. inception_v3 [17] 9. mnasnet0_5 [18] 10. mnasnet1_0 [18] 11. mobilenet_v2 [19] 12. resnet18 [20] 13. resnet34 [20] 14. resnet50 [20] 15. resnet101 [20] 16. resnet152 [20] 17. resnext50_32x4d [21] 18. resnext101_32x8d [21] 19. shufflenet_v2_x0_5 [22] 20. shufflenet_v2_x1_0 [22] 21. vgg11_bn [23] 22. vgg13_bn [23] 23. vgg16_bn [23] 24. vgg19_bn [23] 25. wide_resnet101_2 [24] 26. wide_resnet50_2 [24] E.2 Robust ResNet50 models 1. resnet50 AugMix [30] https://github.com/google-research/augmix 2. resnet50 SIN+IN [28] https://github.com/rgeirhos/texture-vs-shape 3. resnet50 ANT [29] https://github.com/bethgelab/game-of-noise 4. resnet50 ANT+SIN [29] https://github.com/bethgelab/game-of-noise 5. resnet50 DeepAugment [36] https://github.com/hendrycks/imagenet-r 6. resnet50 DeepAugment+AugMix [36] https://github.com/hendrycks/imagenet-r 34E.3 SimCLRv2 models [27] We used the checkpoints from https://github.com/google-research/simclr and converted them from TensorFlow to PyTorch withhttps://github.com/tonylins/simclr-converter, commit ID: 139d3cb0bd0c64b5ad32aab810e0bd0a0dddaae0. 1. resnet50 FT100 SK=0 width=1 2. resnet101 FT100 SK=0 width=1 3. resnet152 FT100 SK=0 width=1 E.4 Robust ResNext models [21] Note that the baseline resnext50_32x4d model trained on ImageNet is available as part of the torchvision library. 1. resnext50_32x4d WSL [26] https://github.com/facebookresearch/WSL-Images/blob/ master/hubconf.py 2. resnext101_32x4d WSL [26] https://github.com/facebookresearch/WSL-Images/blob/ master/hubconf.py 3. resnext101_32x8d Deepaugment+AugMix [36] https://github.com/hendrycks/ imagenet-r E.5 ResNet50 with Group Normalization [40] Model weights and training code was taken from https://github.com/ppwwyyxx/ GroupNorm-reproduce 1. resnet50 GroupNorm 2. resnet101 GroupNorm 3. resnet152 GroupNorm E.6 ResNet50 with Fixup initialization [39] Model weights and training code was taken from https://github.com/hongyi-zhang/Fixup/ tree/master/imagenet. For training, we keep all hyperparameters at their default values and note that in particular the batchsize of 256 is a sensitive parameter. 1. resnet50 FixUp 2. resnet101 FixUp 3. resnet152 FixUp 35",
      "meta_data": {
        "arxiv_id": "2006.16971v2",
        "authors": [
          "Steffen Schneider",
          "Evgenia Rusak",
          "Luisa Eck",
          "Oliver Bringmann",
          "Wieland Brendel",
          "Matthias Bethge"
        ],
        "published_date": "2020-06-30T17:01:37Z",
        "pdf_url": "https://arxiv.org/pdf/2006.16971v2.pdf",
        "github_url": "https://github.com/hongyi-zhang/Fixup"
      },
      "llm_extracted_info": {
        "main_contributions": "The paper shows that common-corruption benchmarks (e.g., ImageNet-C) undervalue model robustness because they forbid using unlabeled corrupted data available at test time. It proposes a simple unsupervised adaptation—re-estimating Batch-Normalization (BN) activation statistics on the corrupted inputs—and adds partial and full adaptation metrics. Across 25 ImageNet models this cuts ResNet-50 mCE from 76.7% to 62.2% and sets new state-of-the-art (45.4% mCE) with DeepAugment+AugMix. A theoretical analysis bounds expected performance using the Wasserstein distance between source and target statistics and predicts error drops.",
        "methodology": "1) Replace training BN means/variances with those computed on test images; optionally mix them with training stats via a pseudo-count N (Eq.3). 2) Evaluate three scenarios: ad-hoc (n=1), partial (n=8), full (n=50k) adaptation. 3) Correlate performance with covariate shift measured by (normalized) Wasserstein distance of feature moments; derive upper/lower bounds on expected distance. 4) Compare vanilla, robustly trained, GroupNorm/Fixup, and large-scale pre-trained models; analyze effect of batch size and N.",
        "experimental_setup": "Models: 25 torchvision architectures (ResNet, DenseNet, MobileNet, etc.), robust ResNet-50 variants (AugMix, ANT, SIN, DeepAug), ResNeXt WSL, SimCLRv2, GroupNorm and Fixup versions. Datasets: ImageNet training/validation; ImageNet-C (15 test +4 hold-out corruptions, 5 severities, 50k images); ImageNet-A, ImageNet-V2, ObjectNet, ImageNet-R for generalization checks. Metrics: mean Corruption Error (mCE) and top-1 accuracy, reported under ad-hoc, partial (n=8) and full adaptation. Validation: grid-search N on hold-out corruptions; run experiments with batch sizes 1–50k; additional EMA variant for streaming.",
        "limitations": "• Requires multiple unlabeled samples from the same corruption; gains vanish when corruptions vary per image or are too severe (ImageNet-A).\n• Ineffective for shuffled corruptions or datasets without systematic shift (ImageNet/IN-V2).\n• Relies on BN layers; non-BN models need alternative mechanisms (GroupNorm/Fixup give smaller gains).\n• Only corrects first/second-order moment shifts (diagonal covariance); more complex distribution changes remain.\n• Assumes label distribution unchanged (pure covariate shift).",
        "future_research_directions": "1) Develop adaptation methods that work with non-BN or normalization-free architectures.\n2) Explore richer statistics (full covariance, higher moments) or feature-level transformations.\n3) Combine BN adaptation with other unsupervised DA techniques (self-training, contrastive, pseudo-labels).\n4) Extend to other tasks (detection, segmentation) and real-time/continual adaptation settings.\n5) Investigate robustness on harder OOD datasets (ImageNet-A, ObjectNet) and non-covariate shifts.\n6) Study interaction with large-scale pretraining and design benchmarks including adaptation metrics.",
        "experimental_code": "\"\"\"\nBatchNorm Test-Time Adaptation + Covariate-Shift Measurement\n-----------------------------------------------------------\nThis is a **stand-alone** Python3 module extracted/assembled from the\nrepository that implements the method described in the paper:\n1) Replace (or mix) BatchNorm running statistics with statistics\n   computed on (a subset of) the test images.\n2) Evaluate three adaptation scenarios: ad-hoc (n=1), partial (n=8),\n   full (n=50 000).\n3) Optionally mix the new statistics with the training statistics using\n   a pseudo-count N (Eq.3 in the paper).\n4) Measure covariate shift with the normalised Wasserstein–2 distance\n   between feature distributions of train and test sets.\n\nThe code assumes that you already have a *trained* CIFAR-10 model that\ncontains BatchNorm layers (e.g. the `resnet56` defined in\n`cifar/models/resnet_cifar.py`).  The script loads the checkpoint,\nperforms BN adaptation according to the chosen scenario and evaluates\naccuracy + covariate shift.\n\nExperimental settings that reproduce the paper’s protocol are provided\nat the bottom of the file (see `if __name__ == \"__main__\"`).\n\"\"\"\n\nimport argparse\nimport copy\nimport math\nimport os\nfrom typing import Iterable, Tuple\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\n\n# ---------------------------------------------------------------------------\n# 1.  Utilities\n# ---------------------------------------------------------------------------\n\ndef _iter_subset(dataloader: Iterable, n: int):\n    \"\"\"Yield exactly *n* samples (may span several mini-batches).\"\"\"\n    yielded = 0\n    for x, y in dataloader:\n        if yielded >= n:\n            break\n        take = min(x.size(0), n - yielded)\n        yield x[:take].cuda(non_blocking=True)\n        yielded += take\n\n\ndef _update_running_stats(module: nn.modules.batchnorm._BatchNorm,\n                          batch_mean: torch.Tensor,\n                          batch_var: torch.Tensor,\n                          m: int,\n                          N: float):\n    \"\"\"Mix training stats with new stats using pseudo-count *N* (Eq.3).\"\"\"\n    # training stats (already stored in the module)\n    old_mean = module.running_mean.detach()\n    old_var = module.running_var.detach()\n\n    new_mean = (old_mean * N + batch_mean * m) / (N + m)\n    new_var  = (old_var  * N + batch_var  * m) / (N + m)\n\n    module.running_mean.data.copy_(new_mean)\n    module.running_var.data.copy_(new_var)\n\n\ndef adapt_batchnorm(model: nn.Module,\n                    data_loader: torch.utils.data.DataLoader,\n                    n_adapt: int,\n                    N: float = 0.\n                    ) -> None:\n    \"\"\"Collect BN statistics on *n_adapt* images from *data_loader*.\n\n    If *N* > 0 we mix the freshly computed statistics with the training\n    statistics using the pseudo-count formula (Eq.3).  If *N* == 0 we\n    completely overwrite the running statistics (the default setting in\n    the paper).\n    \"\"\"\n    model.train()  # ensure BN layers update their running stats\n    with torch.no_grad():\n        for param in model.parameters():\n            param.requires_grad = False\n\n        # Zero statistics before accumulating.\n        for m in model.modules():\n            if isinstance(m, nn.modules.batchnorm._BatchNorm):\n                m.running_mean.zero_()\n                m.running_var.zero_()\n                m.num_batches_tracked.zero_()\n\n        # Accumulate per-batch stats.\n        seen = 0\n        for x in _iter_subset(data_loader, n_adapt):\n            _ = model(x)  # forward pass updates running stats internally\n            seen += x.size(0)\n\n        # Blend with training stats if required (pseudo-count N).\n        if N > 0:\n            for m in model.modules():\n                if isinstance(m, nn.modules.batchnorm._BatchNorm):\n                    batch_mean = m.running_mean.clone()\n                    batch_var  = m.running_var.clone()\n                    _update_running_stats(m, batch_mean, batch_var, m=seen, N=N)\n\n    model.eval()  # put model back into eval mode for inference\n\n# ---------------------------------------------------------------------------\n# 2.  Covariate-shift metric: normalised Wasserstein-2 distance\n# ---------------------------------------------------------------------------\n\ndef gaussian_w2(mu1: torch.Tensor,  cov1: torch.Tensor,\n                mu2: torch.Tensor,  cov2: torch.Tensor) -> float:\n    \"\"\"Closed-form squared W2 between two Gaussians (PyTorch, CPU).\"\"\"\n    # ||μ1 − μ2||² term\n    diff = (mu1 - mu2).pow(2).sum().item()\n    # trace term  Tr(C1 + C2 − 2(C1^{1/2} C2 C1^{1/2})^{1/2})\n    c1_sqrt = cov1.sqrt()\n    # For diagonal covariances (as used in paper) the term simplifies.\n    trace = (cov1 + cov2 - 2 * (c1_sqrt * cov2 * c1_sqrt).sqrt()).sum().item()\n    return diff + trace\n\n\ndef feature_moments(model: nn.Module,\n                    data_loader: torch.utils.data.DataLoader,\n                    n_samples: int = 10000) -> Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"Return mean (D,) and *diagonal* covariance (D,) of penultimate features.\"\"\"\n    feats = []\n    with torch.no_grad():\n        for i, (x, _) in enumerate(data_loader):\n            if len(feats) * x.size(0) >= n_samples:\n                break\n            feats.append(model.module.avgpool(model.module.layer3(model.module.layer2(model.module.layer1(model.module.relu(model.module.bn1(model.module.conv1(x.cuda()))))))).view(x.size(0), -1).cpu())\n        feats = torch.cat(feats, dim=0)[:n_samples]\n    mu  = feats.mean(dim=0)\n    var = feats.var(dim=0, unbiased=False)\n    return mu, var\n\n# ---------------------------------------------------------------------------\n# 3.  Evaluation helper\n# ---------------------------------------------------------------------------\n\ndef accuracy(model: nn.Module, data_loader: torch.utils.data.DataLoader) -> float:\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for x, y in data_loader:\n            logits = model(x.cuda(non_blocking=True))\n            pred = logits.argmax(1)\n            correct += (pred.cpu() == y).sum().item()\n            total += y.size(0)\n    return 100. * correct / total\n\n# ---------------------------------------------------------------------------\n# 4.  Main: run the three adaptation scenarios on CIFAR-10\n# ---------------------------------------------------------------------------\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--arch\", default=\"resnet56\", choices=[\n        \"resnet20\", \"resnet32\", \"resnet44\", \"resnet56\", \"resnet110\"],\n        help=\"model architecture (Batch-Norm version)\")\n    parser.add_argument(\"--ckpt\", required=True, help=\"path to the trained checkpoint (*.ckpt)\")\n    parser.add_argument(\"--data\", default=\"./data\", help=\"CIFAR root dir (will be downloaded if absent)\")\n    parser.add_argument(\"--N\", type=float, default=0.0, help=\"pseudo-count to mix training and test stats (Eq.3)\")\n    args = parser.parse_args()\n\n    # ---------------------- data ----------------------\n    tf = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n    test_set = torchvision.datasets.CIFAR10(root=args.data, train=False, download=True, transform=tf)\n    test_loader = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2)\n\n    # ---------------------- model ---------------------\n    import cifar.models as models\n    net = models.__dict__[args.arch]()\n    ckpt = torch.load(args.ckpt)\n    net.load_state_dict(ckpt['net'] if 'net' in ckpt else ckpt['state_dict'])\n    net.cuda()\n    net.eval()\n    net = torch.nn.DataParallel(net)\n\n    # ---------------- adaptation scenarios ------------\n    scenarios = {\n        \"ad-hoc (n=1)\"   : 1,\n        \"partial (n=8)\"  : 8,\n        \"full (n=50k)\"   : len(test_set),\n    }\n\n    print(\"Before adaptation: {:.2f}% accuracy\".format(accuracy(net, test_loader)))\n\n    # Train-set moments for covariate shift baseline\n    # (subsample 10k train images for speed)\n    train_set = torchvision.datasets.CIFAR10(root=args.data, train=True, download=True, transform=tf)\n    train_loader = torch.utils.data.DataLoader(train_set, batch_size=256, shuffle=True, num_workers=2)\n    mu_train, var_train = feature_moments(net, train_loader, n_samples=10000)\n\n    for name, n in scenarios.items():\n        # create a fresh copy of the model to avoid cross-scenario contamination\n        m_adapt = copy.deepcopy(net)\n        adapt_batchnorm(m_adapt, test_loader, n_adapt=n, N=args.N)\n        acc = accuracy(m_adapt, test_loader)\n\n        mu_test, var_test = feature_moments(m_adapt, test_loader, n_samples=10000)\n        w2 = gaussian_w2(mu_train, var_train, mu_test, var_test) / len(mu_train)  # normalised\n\n        print(f\"{name:15s} | Acc = {acc:6.2f}% |  W2 = {w2:.4f}\")\n\n\nif __name__ == \"__main__\":\n    # ------------------ Experimental settings ------------------\n    # Example command lines that reproduce the three evaluations\n    # reported in the paper, assuming a ResNet-56 checkpoint is\n    # available in ./checkpoint/resnet56_mixup_default_0.ckpt.\n    #\n    # 1)  Ad-hoc adaptation with *full* overwrite of BN stats (N=0):\n    #     python bn_adapt.py --arch resnet56 \\\n    #                        --ckpt ./checkpoint/resnet56_mixup_default_0.ckpt \\\n    #                        --N 0\n    #\n    # 2)  Same but mix with training stats using pseudo-count N=2000:\n    #     python bn_adapt.py --arch resnet56 --ckpt ... --N 2000\n    #\n    # 3)  Evaluate a GroupNorm/Fixup model (no BN) – the script will\n    #     detect that no BN layers exist and therefore accuracy numbers\n    #     will be identical across scenarios (not shown here).\n\n    main()\n",
        "experimental_info": "Experimental settings embedded in the code (see bottom of module):\n• Dataset: CIFAR-10 test set, normalised with mean/std used during training.\n• Three adaptation regimes: n = 1 (ad-hoc), 8 (partial), 50 000 (full).\n• Pseudo-count N (Eq.3) configurable via --N (default 0 → complete overwrite).\n• Architecture: any Batch-Norm CIFAR model in cifar/models/resnet_cifar.py\n  (default shown: resnet56).\n• Checkpoint: pass with --ckpt (expects keys 'net' or 'state_dict').\n• Evaluation metric: top-1 accuracy; covariate shift measured with normalised\n  Wasserstein-2 distance between diagonal Gaussians fitted to penultimate\n  layer features (10 k samples from train and test each).\n\nExample command line used in the manuscript:\n  python bn_adapt.py --arch resnet56 \\\n                     --ckpt ./checkpoint/resnet56_mixup_default_0.ckpt \\\n                     --N 0\n"
      }
    },
    {
      "title": "Vector Quantization With Self-Attention for Quality-Independent Representation Learning"
    }
  ]
}